{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "939f33d2-23b5-4da7-a6c0-3baa7725822d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T11:38:43.536390Z",
     "iopub.status.busy": "2023-11-05T11:38:43.536390Z",
     "iopub.status.idle": "2023-11-05T11:39:15.223917Z",
     "shell.execute_reply": "2023-11-05T11:39:15.223917Z",
     "shell.execute_reply.started": "2023-11-05T11:38:43.536390Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib.jianji.code_csf import csf\n",
    "from lib.model.resnet50 import ResNet50\n",
    "from lib.jianji.tool import *\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from d2l import torch as d2l\n",
    "traindSet = csf(csv_path='original_train_set.pkl', mode='train')\n",
    "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=256, drop_last=True, shuffle=True)\n",
    "testset = csf(csv_path='test_valid_edited(30000).pkl', mode='valid')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c8e3ad-aeed-4a89-b6e3-a86bdf02ece4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T11:43:01.661305Z",
     "iopub.status.busy": "2023-11-05T11:43:01.661305Z",
     "iopub.status.idle": "2023-11-05T11:43:01.666242Z",
     "shell.execute_reply": "2023-11-05T11:43:01.666242Z",
     "shell.execute_reply.started": "2023-11-05T11:43:01.661305Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold_value_list = [0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 , 0.65, 0.7 , \n",
    "                        0.75, 0.8 , 0.85, 0.9 , 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b829671b-0b33-496b-b6f6-169ed95de6cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T09:48:17.599764Z",
     "iopub.status.busy": "2023-11-05T09:48:17.599764Z",
     "iopub.status.idle": "2023-11-05T10:11:03.557615Z",
     "shell.execute_reply": "2023-11-05T10:11:03.557615Z",
     "shell.execute_reply.started": "2023-11-05T09:48:17.599764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5316, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5695, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5546, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5405, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5640, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5784, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5594, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5583, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5390, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5136, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5342, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5312, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5329, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5511, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5267, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5036, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5025, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5185, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5193, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5261, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5513, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4453, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4583, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4167, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4026, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4477, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4577, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3945, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4140, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3407, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3827, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4054, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4103, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2988, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3281, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3743, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2788, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2986, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2365, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2068, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2716, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2334, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2107, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2639, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2504, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2306, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1708, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1339, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1195, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1560, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2471, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1000, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2137, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.5986244658119658\n",
      "0.1 0.6073717948717948\n",
      "0.15 0.6132144764957265\n",
      "0.2 0.6182892628205128\n",
      "0.25 0.6207932692307693\n",
      "0.3 0.6223624465811965\n",
      "0.35 0.6237646901709402\n",
      "0.4 0.6254006410256411\n",
      "0.45 0.6264690170940171\n",
      "0.5 0.62890625\n",
      "0.55 0.6302083333333334\n",
      "0.6 0.6309428418803419\n",
      "0.65 0.6316439636752137\n",
      "0.7 0.6330462072649573\n",
      "0.75 0.6328125\n",
      "0.8 0.6332465277777778\n",
      "0.85 0.633346688034188\n",
      "0.9 0.6335803952991453\n",
      "0.95 0.6305755876068376\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "net = ResNet34()\n",
    "device = d2l.try_gpu()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "loss = nn.BCELoss()\n",
    "train_from_scratch(net, optimizer, loss, 3, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80376890-d34a-47ef-ad2b-83d57a0f8673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T10:11:32.719067Z",
     "iopub.status.busy": "2023-11-05T10:11:32.718068Z",
     "iopub.status.idle": "2023-11-05T10:19:29.104200Z",
     "shell.execute_reply": "2023-11-05T10:19:29.104200Z",
     "shell.execute_reply.started": "2023-11-05T10:11:32.719067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0495, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0301, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0373, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0249, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.7173811431623932\n",
      "0.1 0.7196180555555556\n",
      "0.15 0.7202190170940171\n",
      "0.2 0.7200854700854701\n",
      "0.25 0.7206196581196581\n",
      "0.3 0.7206530448717948\n",
      "0.35 0.7204861111111112\n",
      "0.4 0.7203525641025641\n",
      "0.45 0.7206530448717948\n",
      "0.5 0.7202524038461539\n",
      "0.55 0.7200854700854701\n",
      "0.6 0.7201856303418803\n",
      "0.65 0.7203525641025641\n",
      "0.7 0.7198851495726496\n",
      "0.75 0.7192508012820513\n",
      "0.8 0.7192174145299145\n",
      "0.85 0.7193843482905983\n",
      "0.9 0.7186498397435898\n",
      "0.95 0.7170472756410257\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0fca1a2-6b8f-488b-99b3-d653905afd7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T10:27:39.514582Z",
     "iopub.status.busy": "2023-11-05T10:27:39.514582Z",
     "iopub.status.idle": "2023-11-05T10:27:39.721690Z",
     "shell.execute_reply": "2023-11-05T10:27:39.721690Z",
     "shell.execute_reply.started": "2023-11-05T10:27:39.514582Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'resnet34_acc_0.72.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5733f7-44b7-4f4e-9f35-d437eb4b4d1e",
   "metadata": {},
   "source": [
    "# 开始训练resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3b80a1-2a18-40aa-a38a-dbab55e840e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T11:43:15.784920Z",
     "iopub.status.busy": "2023-11-05T11:43:15.784920Z",
     "iopub.status.idle": "2023-11-05T12:11:35.917193Z",
     "shell.execute_reply": "2023-11-05T12:11:35.917193Z",
     "shell.execute_reply.started": "2023-11-05T11:43:15.784920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6977, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6960, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7057, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6934, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6850, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6323, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6381, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6232, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5788, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5676, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5663, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6226, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6135, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5725, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5722, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5712, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5606, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5705, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5535, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5688, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5853, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5515, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5737, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5583, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5976, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5562, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5528, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5429, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6087, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6022, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5723, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5629, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5953, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5633, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5444, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5564, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5615, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5469, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5119, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5518, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5474, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5771, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5846, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6075, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5756, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5751, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5595, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5258, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5767, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5190, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5357, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5634, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5335, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6127, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.6716412927350427\n",
      "0.1 0.6723424145299145\n",
      "0.15 0.6715745192307693\n",
      "0.2 0.6696714743589743\n",
      "0.25 0.6608907585470085\n",
      "0.3 0.5923477564102564\n",
      "0.35 0.5131209935897436\n",
      "0.4 0.5002337072649573\n",
      "0.45 0.49979967948717946\n",
      "0.5 0.5001001602564102\n",
      "0.55 0.5001669337606838\n",
      "0.6 0.49979967948717946\n",
      "0.65 0.5000333867521367\n",
      "0.7 0.5000667735042735\n",
      "0.75 0.4998330662393162\n",
      "0.8 0.49989983974358976\n",
      "0.85 0.4998330662393162\n",
      "0.9 0.499866452991453\n",
      "0.95 0.5001001602564102\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "net = ResNet50()\n",
    "device = d2l.try_gpu()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "loss = nn.BCELoss()\n",
    "train_from_scratch(net, optimizer, loss, 3, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a3fadf-9e55-474f-ae6b-1102dc8fedc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:19:57.194202Z",
     "iopub.status.busy": "2023-11-05T12:19:57.193204Z",
     "iopub.status.idle": "2023-11-05T12:29:47.487255Z",
     "shell.execute_reply": "2023-11-05T12:29:47.487255Z",
     "shell.execute_reply.started": "2023-11-05T12:19:57.194202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5436, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5094, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5281, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5205, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5440, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5128, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4803, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5437, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4788, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5187, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4629, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5096, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4680, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4058, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4153, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4138, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.6094751602564102\n",
      "0.1 0.6242654914529915\n",
      "0.15 0.6295739850427351\n",
      "0.2 0.6287727029914529\n",
      "0.25 0.6238648504273504\n",
      "0.3 0.6170873397435898\n",
      "0.35 0.613548344017094\n",
      "0.4 0.6041332799145299\n",
      "0.45 0.5939837072649573\n",
      "0.5 0.5844684829059829\n",
      "0.55 0.5745860042735043\n",
      "0.6 0.5644030448717948\n",
      "0.65 0.5556557158119658\n",
      "0.7 0.5449719551282052\n",
      "0.75 0.5355568910256411\n",
      "0.8 0.5265090811965812\n",
      "0.85 0.5178619123931624\n",
      "0.9 0.5108840811965812\n",
      "0.95 0.50390625\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c584ba-1e15-470e-984b-4eb29e1e7393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:31:26.981441Z",
     "iopub.status.busy": "2023-11-05T12:31:26.981441Z",
     "iopub.status.idle": "2023-11-05T12:41:17.684956Z",
     "shell.execute_reply": "2023-11-05T12:41:17.684956Z",
     "shell.execute_reply.started": "2023-11-05T12:31:26.981441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4452, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3744, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3521, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3679, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3450, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3165, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3775, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3337, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3394, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3358, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3251, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2969, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3263, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3008, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3021, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2848, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3085, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2105, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.4340277777777778\n",
      "0.1 0.4332932692307692\n",
      "0.15 0.4328258547008547\n",
      "0.2 0.4323918269230769\n",
      "0.25 0.43249198717948717\n",
      "0.3 0.4324252136752137\n",
      "0.35 0.43195779914529914\n",
      "0.4 0.43192441239316237\n",
      "0.45 0.43125667735042733\n",
      "0.5 0.4309895833333333\n",
      "0.55 0.4309895833333333\n",
      "0.6 0.43105635683760685\n",
      "0.65 0.43078926282051283\n",
      "0.7 0.4308226495726496\n",
      "0.75 0.43042200854700857\n",
      "0.8 0.4311231303418803\n",
      "0.85 0.43165731837606836\n",
      "0.9 0.43222489316239315\n",
      "0.95 0.43496260683760685\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4556dbed-6684-4a18-84f4-4da3fc63e986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:42:28.039412Z",
     "iopub.status.busy": "2023-11-05T12:42:28.034690Z",
     "iopub.status.idle": "2023-11-05T12:49:06.441709Z",
     "shell.execute_reply": "2023-11-05T12:49:06.440703Z",
     "shell.execute_reply.started": "2023-11-05T12:42:28.039412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2137, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1639, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1451, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1250, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1353, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1333, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1537, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1472, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0702, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0845, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcontinue_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m threshold_value_list:\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\tool.py:31\u001b[0m, in \u001b[0;36mcontinue_train\u001b[1;34m(net, optimizer, loss, num_epochs, train_iter, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m net(X)\n\u001b[0;32m     30\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[1;32m---> 31\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3768797d-8a89-423c-828b-bb645b79009e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:49:14.562424Z",
     "iopub.status.busy": "2023-11-05T12:49:14.562424Z",
     "iopub.status.idle": "2023-11-05T12:49:53.230785Z",
     "shell.execute_reply": "2023-11-05T12:49:53.229847Z",
     "shell.execute_reply.started": "2023-11-05T12:49:14.562424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.7011551816239316\n",
      "0.1 0.7105034722222222\n",
      "0.15 0.7135082799145299\n",
      "0.2 0.7149439102564102\n",
      "0.25 0.7159455128205128\n",
      "0.3 0.7166800213675214\n",
      "0.35 0.7171140491452992\n",
      "0.4 0.7174145299145299\n",
      "0.45 0.7169471153846154\n",
      "0.5 0.7168135683760684\n",
      "0.55 0.7166466346153846\n",
      "0.6 0.7159121260683761\n",
      "0.65 0.7161124465811965\n",
      "0.7 0.7161124465811965\n",
      "0.75 0.7158453525641025\n",
      "0.8 0.7165464743589743\n",
      "0.85 0.7159121260683761\n",
      "0.9 0.7146768162393162\n",
      "0.95 0.7135082799145299\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe9dbf15-83b0-4ca3-865e-6cdf932e460b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:50:45.691726Z",
     "iopub.status.busy": "2023-11-05T12:50:45.684055Z",
     "iopub.status.idle": "2023-11-05T12:50:45.925595Z",
     "shell.execute_reply": "2023-11-05T12:50:45.924773Z",
     "shell.execute_reply.started": "2023-11-05T12:50:45.691726Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'resnet50_acc_0.717.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f3d20f0-71c0-4ecc-a9d1-8acaa4e6d5b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:51:34.204821Z",
     "iopub.status.busy": "2023-11-05T12:51:34.204821Z",
     "iopub.status.idle": "2023-11-05T12:53:36.135629Z",
     "shell.execute_reply": "2023-11-05T12:53:36.134683Z",
     "shell.execute_reply.started": "2023-11-05T12:51:34.204821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0729, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0865, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0904, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcontinue_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m threshold_value_list:\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\tool.py:29\u001b[0m, in \u001b[0;36mcontinue_train\u001b[1;34m(net, optimizer, loss, num_epochs, train_iter, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[0;32m     31\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\model\\resnet50.py:23\u001b[0m, in \u001b[0;36mResidual.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m     22\u001b[0m     Y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(X)))\n\u001b[1;32m---> 23\u001b[0m     Y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     24\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(Y))\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4:\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b58970f-7c40-4852-b98f-1ba72dd8c3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:53:43.857248Z",
     "iopub.status.busy": "2023-11-05T12:53:43.857248Z",
     "iopub.status.idle": "2023-11-05T12:54:22.187360Z",
     "shell.execute_reply": "2023-11-05T12:54:22.187360Z",
     "shell.execute_reply.started": "2023-11-05T12:53:43.857248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.6949452457264957\n",
      "0.1 0.7084001068376068\n",
      "0.15 0.7136752136752137\n",
      "0.2 0.7162126068376068\n",
      "0.25 0.7167467948717948\n",
      "0.3 0.7175146901709402\n",
      "0.35 0.7177150106837606\n",
      "0.4 0.7180488782051282\n",
      "0.45 0.7176148504273504\n",
      "0.5 0.7176482371794872\n",
      "0.55 0.7180822649572649\n",
      "0.6 0.7180488782051282\n",
      "0.65 0.7186164529914529\n",
      "0.7 0.7182491987179487\n",
      "0.75 0.7177150106837606\n",
      "0.8 0.7172809829059829\n",
      "0.85 0.7173811431623932\n",
      "0.9 0.7164463141025641\n",
      "0.95 0.7155448717948718\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc5ee37-ab17-4f07-b917-52b8311a30da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:54:37.697919Z",
     "iopub.status.busy": "2023-11-05T12:54:37.697919Z",
     "iopub.status.idle": "2023-11-05T12:56:08.277378Z",
     "shell.execute_reply": "2023-11-05T12:56:08.276376Z",
     "shell.execute_reply.started": "2023-11-05T12:54:37.697919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0697, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0683, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0556, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcontinue_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m threshold_value_list:\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\tool.py:29\u001b[0m, in \u001b[0;36mcontinue_train\u001b[1;34m(net, optimizer, loss, num_epochs, train_iter, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[0;32m     31\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\model\\resnet50.py:24\u001b[0m, in \u001b[0;36mResidual.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     22\u001b[0m Y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(X)))\n\u001b[0;32m     23\u001b[0m Y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(Y)))\n\u001b[1;32m---> 24\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4:\n\u001b[0;32m     26\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(X)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.0001)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc692ed-7126-45a6-b7bb-d47c07054500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:56:16.473414Z",
     "iopub.status.busy": "2023-11-05T12:56:16.473414Z",
     "iopub.status.idle": "2023-11-05T12:56:54.798727Z",
     "shell.execute_reply": "2023-11-05T12:56:54.798400Z",
     "shell.execute_reply.started": "2023-11-05T12:56:16.473414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.7013888888888888\n",
      "0.1 0.7122061965811965\n",
      "0.15 0.7151442307692307\n",
      "0.2 0.7171140491452992\n",
      "0.25 0.7174145299145299\n",
      "0.3 0.7175814636752137\n",
      "0.35 0.7176148504273504\n",
      "0.4 0.7170806623931624\n",
      "0.45 0.7173811431623932\n",
      "0.5 0.7178485576923077\n",
      "0.55 0.7178485576923077\n",
      "0.6 0.7183493589743589\n",
      "0.65 0.718215811965812\n",
      "0.7 0.7176482371794872\n",
      "0.75 0.7170806623931624\n",
      "0.8 0.7170138888888888\n",
      "0.85 0.7166132478632479\n",
      "0.9 0.7158453525641025\n",
      "0.95 0.7139089209401709\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a2ba16-c42f-4373-9673-ba56ee72e4b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T12:58:06.261273Z",
     "iopub.status.busy": "2023-11-05T12:58:06.261273Z",
     "iopub.status.idle": "2023-11-05T12:58:06.476525Z",
     "shell.execute_reply": "2023-11-05T12:58:06.476525Z",
     "shell.execute_reply.started": "2023-11-05T12:58:06.261273Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'resnet50_acc_0.718_thd_0.6.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce3c5edf-4971-4d94-97b6-a78f26658fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:06:42.199937Z",
     "iopub.status.busy": "2023-11-05T13:06:42.185830Z",
     "iopub.status.idle": "2023-11-05T13:06:42.325652Z",
     "shell.execute_reply": "2023-11-05T13:06:42.324979Z",
     "shell.execute_reply.started": "2023-11-05T13:06:42.199937Z"
    }
   },
   "outputs": [],
   "source": [
    "testset = csf(csv_path='test_valid_edited(neg15000positive10000).pkl', mode='valid')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cabdf2-c57d-47e9-a1ef-30c6c9615c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:06:44.097794Z",
     "iopub.status.busy": "2023-11-05T13:06:44.097794Z",
     "iopub.status.idle": "2023-11-05T13:07:15.770120Z",
     "shell.execute_reply": "2023-11-05T13:07:15.770120Z",
     "shell.execute_reply.started": "2023-11-05T13:06:44.097794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.3545022551546392\n",
      "0.1 0.34024645618556704\n",
      "0.15 0.3360583118556701\n",
      "0.2 0.3326755798969072\n",
      "0.25 0.33211179123711343\n",
      "0.3 0.33021907216494845\n",
      "0.35 0.33009826030927836\n",
      "0.4 0.33009826030927836\n",
      "0.45 0.3287290592783505\n",
      "0.5 0.3282860824742268\n",
      "0.55 0.3279236469072165\n",
      "0.6 0.32554768041237114\n",
      "0.65 0.3257893041237113\n",
      "0.7 0.32603092783505155\n",
      "0.75 0.3248630798969072\n",
      "0.8 0.3247422680412371\n",
      "0.85 0.3236146907216495\n",
      "0.9 0.32301063144329895\n",
      "0.95 0.32236630154639173\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7337a5f-d6e1-4b89-bb3e-8193adfef4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:36:45.158367Z",
     "iopub.status.busy": "2023-11-05T13:36:45.154039Z",
     "iopub.status.idle": "2023-11-05T13:36:45.342928Z",
     "shell.execute_reply": "2023-11-05T13:36:45.342819Z",
     "shell.execute_reply.started": "2023-11-05T13:36:45.158367Z"
    }
   },
   "outputs": [],
   "source": [
    "testset = csf(csv_path='test_valid_edited(30000).pkl', mode='valid')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8347db34-71b4-4ad7-99f1-c7be75d462b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:11:09.642399Z",
     "iopub.status.busy": "2023-11-05T13:11:09.641222Z",
     "iopub.status.idle": "2023-11-05T13:11:28.585571Z",
     "shell.execute_reply": "2023-11-05T13:11:28.584539Z",
     "shell.execute_reply.started": "2023-11-05T13:11:09.642399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.41864224137931033\n",
      "0.1 0.44793911637931033\n",
      "0.15 0.45871497844827586\n",
      "0.2 0.4658539870689655\n",
      "0.25 0.47023168103448276\n",
      "0.3 0.47393588362068967\n",
      "0.35 0.47649515086206895\n",
      "0.4 0.4783135775862069\n",
      "0.45 0.4808054956896552\n",
      "0.5 0.48370150862068967\n",
      "0.55 0.4875404094827586\n",
      "0.6 0.4905711206896552\n",
      "0.65 0.49427532327586204\n",
      "0.7 0.49676724137931033\n",
      "0.75 0.5008081896551724\n",
      "0.8 0.5051185344827587\n",
      "0.85 0.509698275862069\n",
      "0.9 0.5160964439655172\n",
      "0.95 0.5278825431034483\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9a33de1-0f7b-4aef-a8f6-d07508704cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:44:55.180301Z",
     "iopub.status.busy": "2023-11-05T13:44:55.180301Z",
     "iopub.status.idle": "2023-11-05T13:45:00.235569Z",
     "shell.execute_reply": "2023-11-05T13:45:00.234569Z",
     "shell.execute_reply.started": "2023-11-05T13:44:55.180301Z"
    }
   },
   "outputs": [],
   "source": [
    "traindSet_new = csf(csv_path='original_all_neg_train.pkl', mode='train')\n",
    "trainloader_new =  torch.utils.data.DataLoader(traindSet_new, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e055f-aa99-47d5-b0b1-b6a31143a60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "244fca5c-0cf6-4244-bbc5-f0c132d59bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:30:33.500340Z",
     "iopub.status.busy": "2023-11-05T13:30:33.500340Z",
     "iopub.status.idle": "2023-11-05T13:35:19.350956Z",
     "shell.execute_reply": "2023-11-05T13:35:19.349837Z",
     "shell.execute_reply.started": "2023-11-05T13:30:33.500340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2131, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2428, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1221, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9485, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0867, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2499, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0466, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0090, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3703, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6253, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5658, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcontinue_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m threshold_value_list:\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\tool.py:29\u001b[0m, in \u001b[0;36mcontinue_train\u001b[1;34m(net, optimizer, loss, num_epochs, train_iter, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[0;32m     31\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\model\\resnet50.py:24\u001b[0m, in \u001b[0;36mResidual.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     22\u001b[0m Y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(X)))\n\u001b[0;32m     23\u001b[0m Y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(Y)))\n\u001b[1;32m---> 24\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4:\n\u001b[0;32m     26\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(X)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:151\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[0;32m    153\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "continue_train(net, optimizer, loss, 1, trainloader_new, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07406ac4-b30a-4c39-87de-6da60f2c413e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:44:13.552918Z",
     "iopub.status.busy": "2023-11-05T13:44:13.552918Z",
     "iopub.status.idle": "2023-11-05T13:44:51.626269Z",
     "shell.execute_reply": "2023-11-05T13:44:51.626269Z",
     "shell.execute_reply.started": "2023-11-05T13:44:13.552918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.6388555021367521\n",
      "0.1 0.6736778846153846\n",
      "0.15 0.6895365918803419\n",
      "0.2 0.698951655982906\n",
      "0.25 0.7031917735042735\n",
      "0.3 0.7071647970085471\n",
      "0.35 0.7084334935897436\n",
      "0.4 0.7095352564102564\n",
      "0.45 0.7099025106837606\n",
      "0.5 0.7093015491452992\n",
      "0.55 0.7090678418803419\n",
      "0.6 0.7075320512820513\n",
      "0.65 0.7064636752136753\n",
      "0.7 0.7052951388888888\n",
      "0.75 0.7024238782051282\n",
      "0.8 0.7013888888888888\n",
      "0.85 0.6980168269230769\n",
      "0.9 0.6928752670940171\n",
      "0.95 0.6776175213675214\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcfe86ea-13c1-47cd-bd18-16c8d188cf06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:37:55.969297Z",
     "iopub.status.busy": "2023-11-05T13:37:55.969297Z",
     "iopub.status.idle": "2023-11-05T13:43:25.697216Z",
     "shell.execute_reply": "2023-11-05T13:43:25.696066Z",
     "shell.execute_reply.started": "2023-11-05T13:37:55.969297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0696, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2063, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1785, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0934, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0768, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0776, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1325, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0958, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1336, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1048, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1400, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1450, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcontinue_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m threshold_value_list:\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\tool.py:31\u001b[0m, in \u001b[0;36mcontinue_train\u001b[1;34m(net, optimizer, loss, num_epochs, train_iter, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m net(X)\n\u001b[0;32m     30\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[1;32m---> 31\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "continue_train(net, optimizer, loss, 1, trainloader_new, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98f3d843-30ce-469f-9477-bd23bab57cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:45:35.465486Z",
     "iopub.status.busy": "2023-11-05T13:45:35.465486Z",
     "iopub.status.idle": "2023-11-05T13:47:44.937528Z",
     "shell.execute_reply": "2023-11-05T13:47:44.937528Z",
     "shell.execute_reply.started": "2023-11-05T13:45:35.465486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1863, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1361, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.6830929487179487\n",
      "0.1 0.6824586004273504\n",
      "0.15 0.6653979700854701\n",
      "0.2 0.6504073183760684\n",
      "0.25 0.6329794337606838\n",
      "0.3 0.6176215277777778\n",
      "0.35 0.6033653846153846\n",
      "0.4 0.5898771367521367\n",
      "0.45 0.5719484508547008\n",
      "0.5 0.5559561965811965\n",
      "0.55 0.5407652243589743\n",
      "0.6 0.5259081196581197\n",
      "0.65 0.5145232371794872\n",
      "0.7 0.5062099358974359\n",
      "0.75 0.5019698183760684\n",
      "0.8 0.5003004807692307\n",
      "0.85 0.49993322649572647\n",
      "0.9 0.5001669337606838\n",
      "0.95 0.49996661324786323\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "continue_train(net, optimizer, loss, 1, trainloader_new, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b27444ba-0eb0-49d6-bea4-f7ccccce9ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T13:48:01.750535Z",
     "iopub.status.busy": "2023-11-05T13:48:01.750535Z",
     "iopub.status.idle": "2023-11-05T13:50:12.231719Z",
     "shell.execute_reply": "2023-11-05T13:50:12.231719Z",
     "shell.execute_reply.started": "2023-11-05T13:48:01.750535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0015, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.5001001602564102\n",
      "0.1 0.5\n",
      "0.15 0.5000333867521367\n",
      "0.2 0.49989983974358976\n",
      "0.25 0.5\n",
      "0.3 0.5000667735042735\n",
      "0.35 0.5001335470085471\n",
      "0.4 0.5000333867521367\n",
      "0.45 0.4998330662393162\n",
      "0.5 0.5002003205128205\n",
      "0.55 0.5001669337606838\n",
      "0.6 0.5001001602564102\n",
      "0.65 0.49996661324786323\n",
      "0.7 0.4998330662393162\n",
      "0.75 0.49989983974358976\n",
      "0.8 0.5002003205128205\n",
      "0.85 0.5002337072649573\n",
      "0.9 0.5002003205128205\n",
      "0.95 0.5002003205128205\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
    "continue_train(net, optimizer, loss, 1, trainloader_new, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6820fc-32a7-454a-8b66-5bdf7c8c9311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:31:00.790496Z",
     "iopub.status.busy": "2023-11-05T14:31:00.790496Z",
     "iopub.status.idle": "2023-11-05T14:31:02.200340Z",
     "shell.execute_reply": "2023-11-05T14:31:02.200340Z",
     "shell.execute_reply.started": "2023-11-05T14:31:00.790496Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib.jianji.code_csf import csf\n",
    "from lib.model.resnet50 import ResNet50\n",
    "from lib.jianji.tool import *\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459ca9d3-b03a-4574-acf7-0169d6e9c1d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:31:07.560404Z",
     "iopub.status.busy": "2023-11-05T14:31:07.560404Z",
     "iopub.status.idle": "2023-11-05T14:31:09.437665Z",
     "shell.execute_reply": "2023-11-05T14:31:09.437665Z",
     "shell.execute_reply.started": "2023-11-05T14:31:07.560404Z"
    }
   },
   "outputs": [],
   "source": [
    "traindSet_new = csf(csv_path='positive125000neg125000.pkl', mode='train')\n",
    "trainloader_new =  torch.utils.data.DataLoader(traindSet_new, batch_size=32, shuffle=True)\n",
    "testset = csf(csv_path='temp.pkl', mode='valid')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb968fa-741c-47c4-86d8-2c3ebcea4a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:31:10.572977Z",
     "iopub.status.busy": "2023-11-05T14:31:10.571978Z",
     "iopub.status.idle": "2023-11-05T14:31:10.582131Z",
     "shell.execute_reply": "2023-11-05T14:31:10.581561Z",
     "shell.execute_reply.started": "2023-11-05T14:31:10.572977Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold_value_list = [0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 , 0.65, 0.7 , \n",
    "                        0.75, 0.8 , 0.85, 0.9 , 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e111731e-099f-4b8f-b11e-6cc14980468e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:16:14.773557Z",
     "iopub.status.busy": "2023-11-05T14:16:14.773557Z",
     "iopub.status.idle": "2023-11-05T14:20:45.141256Z",
     "shell.execute_reply": "2023-11-05T14:20:45.140614Z",
     "shell.execute_reply.started": "2023-11-05T14:16:14.773557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3671, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5194, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2963, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3173, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3887, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4291, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.5768896901709402\n",
      "0.1 0.5856370192307693\n",
      "0.15 0.5962206196581197\n",
      "0.2 0.6076388888888888\n",
      "0.25 0.6191907051282052\n",
      "0.3 0.6321113782051282\n",
      "0.35 0.6420606303418803\n",
      "0.4 0.6516760149572649\n",
      "0.45 0.6594217414529915\n",
      "0.5 0.6661658653846154\n",
      "0.55 0.6706063034188035\n",
      "0.6 0.6728432158119658\n",
      "0.65 0.6718082264957265\n",
      "0.7 0.6702056623931624\n",
      "0.75 0.6663995726495726\n",
      "0.8 0.6607238247863247\n",
      "0.85 0.6538461538461539\n",
      "0.9 0.6370192307692307\n",
      "0.95 0.6033653846153846\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "net = ResNet50()\n",
    "net.load_state_dict(torch.load('resnet50_acc_0.717.pth'))\n",
    "net.cuda()\n",
    "device = d2l.try_gpu()\n",
    "loss = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
    "continue_train(net, optimizer, loss, 1, trainloader_new, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be2fd4d1-81f0-44ca-b709-0d6929cb4899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:20:52.023879Z",
     "iopub.status.busy": "2023-11-05T14:20:52.023879Z",
     "iopub.status.idle": "2023-11-05T14:25:22.434769Z",
     "shell.execute_reply": "2023-11-05T14:25:22.434769Z",
     "shell.execute_reply.started": "2023-11-05T14:20:52.023879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5281, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6176, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5775, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5361, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5860, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.5678752670940171\n",
      "0.1 0.5657051282051282\n",
      "0.15 0.5645699786324786\n",
      "0.2 0.5631677350427351\n",
      "0.25 0.561698717948718\n",
      "0.3 0.5600627670940171\n",
      "0.35 0.5594284188034188\n",
      "0.4 0.5584268162393162\n",
      "0.45 0.5579260149572649\n",
      "0.5 0.5565237713675214\n",
      "0.55 0.5558226495726496\n",
      "0.6 0.5555889423076923\n",
      "0.65 0.555488782051282\n",
      "0.7 0.5598290598290598\n",
      "0.75 0.565604967948718\n",
      "0.8 0.5740518162393162\n",
      "0.85 0.5893429487179487\n",
      "0.9 0.5958867521367521\n",
      "0.95 0.5385950854700855\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "continue_train(net, optimizer, loss, 1, trainloader_new, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d7cc8c-4eef-4365-9dee-43e9713ee6de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:25:42.154927Z",
     "iopub.status.busy": "2023-11-05T14:25:42.154927Z",
     "iopub.status.idle": "2023-11-05T14:30:12.031731Z",
     "shell.execute_reply": "2023-11-05T14:30:12.031517Z",
     "shell.execute_reply.started": "2023-11-05T14:25:42.154927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4216, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4373, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4769, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5567, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3547, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5893, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.5006677350427351\n",
      "0.1 0.5001335470085471\n",
      "0.15 0.5003004807692307\n",
      "0.2 0.5001669337606838\n",
      "0.25 0.5000667735042735\n",
      "0.3 0.5001001602564102\n",
      "0.35 0.5\n",
      "0.4 0.5000333867521367\n",
      "0.45 0.5000333867521367\n",
      "0.5 0.49993322649572647\n",
      "0.55 0.5001001602564102\n",
      "0.6 0.5\n",
      "0.65 0.49989983974358976\n",
      "0.7 0.5001001602564102\n",
      "0.75 0.5\n",
      "0.8 0.5001001602564102\n",
      "0.85 0.5000667735042735\n",
      "0.9 0.5001669337606838\n",
      "0.95 0.5001335470085471\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.09)\n",
    "continue_train(net, optimizer, loss, 1, trainloader_new, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9abf5b4-b20d-47bb-87ae-2bd40d57b395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:33:32.149138Z",
     "iopub.status.busy": "2023-11-05T14:33:32.149138Z",
     "iopub.status.idle": "2023-11-05T14:33:40.870963Z",
     "shell.execute_reply": "2023-11-05T14:33:40.870963Z",
     "shell.execute_reply.started": "2023-11-05T14:33:32.149138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.8609759221311475\n"
     ]
    }
   ],
   "source": [
    "net = ResNet50()\n",
    "net.load_state_dict(torch.load('resnet50_acc_0.717.pth'))\n",
    "net.cuda()\n",
    "device = d2l.try_gpu()\n",
    "loss = nn.BCELoss()    \n",
    "print(j,evalute_results(net, testloader, 0.99, d2l.try_gpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413bfdcc-88d8-4ef6-910d-026a706f6fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:36:33.144113Z",
     "iopub.status.busy": "2023-11-05T14:36:33.144113Z",
     "iopub.status.idle": "2023-11-05T14:36:33.168782Z",
     "shell.execute_reply": "2023-11-05T14:36:33.168782Z",
     "shell.execute_reply.started": "2023-11-05T14:36:33.144113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.weight\n",
      "0.0.bias\n",
      "0.1.weight\n",
      "0.1.bias\n",
      "1.0.conv1.weight\n",
      "1.0.conv1.bias\n",
      "1.0.conv2.weight\n",
      "1.0.conv2.bias\n",
      "1.0.conv3.weight\n",
      "1.0.conv3.bias\n",
      "1.0.conv4.weight\n",
      "1.0.conv4.bias\n",
      "1.0.bn1.weight\n",
      "1.0.bn1.bias\n",
      "1.0.bn2.weight\n",
      "1.0.bn2.bias\n",
      "1.0.bn3.weight\n",
      "1.0.bn3.bias\n",
      "1.1.conv1.weight\n",
      "1.1.conv1.bias\n",
      "1.1.conv2.weight\n",
      "1.1.conv2.bias\n",
      "1.1.conv3.weight\n",
      "1.1.conv3.bias\n",
      "1.1.bn1.weight\n",
      "1.1.bn1.bias\n",
      "1.1.bn2.weight\n",
      "1.1.bn2.bias\n",
      "1.1.bn3.weight\n",
      "1.1.bn3.bias\n",
      "1.2.conv1.weight\n",
      "1.2.conv1.bias\n",
      "1.2.conv2.weight\n",
      "1.2.conv2.bias\n",
      "1.2.conv3.weight\n",
      "1.2.conv3.bias\n",
      "1.2.bn1.weight\n",
      "1.2.bn1.bias\n",
      "1.2.bn2.weight\n",
      "1.2.bn2.bias\n",
      "1.2.bn3.weight\n",
      "1.2.bn3.bias\n",
      "3.0.conv1.weight\n",
      "3.0.conv1.bias\n",
      "3.0.conv2.weight\n",
      "3.0.conv2.bias\n",
      "3.0.conv3.weight\n",
      "3.0.conv3.bias\n",
      "3.0.conv4.weight\n",
      "3.0.conv4.bias\n",
      "3.0.bn1.weight\n",
      "3.0.bn1.bias\n",
      "3.0.bn2.weight\n",
      "3.0.bn2.bias\n",
      "3.0.bn3.weight\n",
      "3.0.bn3.bias\n",
      "3.1.conv1.weight\n",
      "3.1.conv1.bias\n",
      "3.1.conv2.weight\n",
      "3.1.conv2.bias\n",
      "3.1.conv3.weight\n",
      "3.1.conv3.bias\n",
      "3.1.bn1.weight\n",
      "3.1.bn1.bias\n",
      "3.1.bn2.weight\n",
      "3.1.bn2.bias\n",
      "3.1.bn3.weight\n",
      "3.1.bn3.bias\n",
      "3.2.conv1.weight\n",
      "3.2.conv1.bias\n",
      "3.2.conv2.weight\n",
      "3.2.conv2.bias\n",
      "3.2.conv3.weight\n",
      "3.2.conv3.bias\n",
      "3.2.bn1.weight\n",
      "3.2.bn1.bias\n",
      "3.2.bn2.weight\n",
      "3.2.bn2.bias\n",
      "3.2.bn3.weight\n",
      "3.2.bn3.bias\n",
      "3.3.conv1.weight\n",
      "3.3.conv1.bias\n",
      "3.3.conv2.weight\n",
      "3.3.conv2.bias\n",
      "3.3.conv3.weight\n",
      "3.3.conv3.bias\n",
      "3.3.bn1.weight\n",
      "3.3.bn1.bias\n",
      "3.3.bn2.weight\n",
      "3.3.bn2.bias\n",
      "3.3.bn3.weight\n",
      "3.3.bn3.bias\n",
      "5.0.conv1.weight\n",
      "5.0.conv1.bias\n",
      "5.0.conv2.weight\n",
      "5.0.conv2.bias\n",
      "5.0.conv3.weight\n",
      "5.0.conv3.bias\n",
      "5.0.conv4.weight\n",
      "5.0.conv4.bias\n",
      "5.0.bn1.weight\n",
      "5.0.bn1.bias\n",
      "5.0.bn2.weight\n",
      "5.0.bn2.bias\n",
      "5.0.bn3.weight\n",
      "5.0.bn3.bias\n",
      "5.1.conv1.weight\n",
      "5.1.conv1.bias\n",
      "5.1.conv2.weight\n",
      "5.1.conv2.bias\n",
      "5.1.conv3.weight\n",
      "5.1.conv3.bias\n",
      "5.1.bn1.weight\n",
      "5.1.bn1.bias\n",
      "5.1.bn2.weight\n",
      "5.1.bn2.bias\n",
      "5.1.bn3.weight\n",
      "5.1.bn3.bias\n",
      "5.2.conv1.weight\n",
      "5.2.conv1.bias\n",
      "5.2.conv2.weight\n",
      "5.2.conv2.bias\n",
      "5.2.conv3.weight\n",
      "5.2.conv3.bias\n",
      "5.2.bn1.weight\n",
      "5.2.bn1.bias\n",
      "5.2.bn2.weight\n",
      "5.2.bn2.bias\n",
      "5.2.bn3.weight\n",
      "5.2.bn3.bias\n",
      "5.3.conv1.weight\n",
      "5.3.conv1.bias\n",
      "5.3.conv2.weight\n",
      "5.3.conv2.bias\n",
      "5.3.conv3.weight\n",
      "5.3.conv3.bias\n",
      "5.3.bn1.weight\n",
      "5.3.bn1.bias\n",
      "5.3.bn2.weight\n",
      "5.3.bn2.bias\n",
      "5.3.bn3.weight\n",
      "5.3.bn3.bias\n",
      "5.4.conv1.weight\n",
      "5.4.conv1.bias\n",
      "5.4.conv2.weight\n",
      "5.4.conv2.bias\n",
      "5.4.conv3.weight\n",
      "5.4.conv3.bias\n",
      "5.4.bn1.weight\n",
      "5.4.bn1.bias\n",
      "5.4.bn2.weight\n",
      "5.4.bn2.bias\n",
      "5.4.bn3.weight\n",
      "5.4.bn3.bias\n",
      "5.5.conv1.weight\n",
      "5.5.conv1.bias\n",
      "5.5.conv2.weight\n",
      "5.5.conv2.bias\n",
      "5.5.conv3.weight\n",
      "5.5.conv3.bias\n",
      "5.5.bn1.weight\n",
      "5.5.bn1.bias\n",
      "5.5.bn2.weight\n",
      "5.5.bn2.bias\n",
      "5.5.bn3.weight\n",
      "5.5.bn3.bias\n",
      "7.0.conv1.weight\n",
      "7.0.conv1.bias\n",
      "7.0.conv2.weight\n",
      "7.0.conv2.bias\n",
      "7.0.conv3.weight\n",
      "7.0.conv3.bias\n",
      "7.0.conv4.weight\n",
      "7.0.conv4.bias\n",
      "7.0.bn1.weight\n",
      "7.0.bn1.bias\n",
      "7.0.bn2.weight\n",
      "7.0.bn2.bias\n",
      "7.0.bn3.weight\n",
      "7.0.bn3.bias\n",
      "7.1.conv1.weight\n",
      "7.1.conv1.bias\n",
      "7.1.conv2.weight\n",
      "7.1.conv2.bias\n",
      "7.1.conv3.weight\n",
      "7.1.conv3.bias\n",
      "7.1.bn1.weight\n",
      "7.1.bn1.bias\n",
      "7.1.bn2.weight\n",
      "7.1.bn2.bias\n",
      "7.1.bn3.weight\n",
      "7.1.bn3.bias\n",
      "7.2.conv1.weight\n",
      "7.2.conv1.bias\n",
      "7.2.conv2.weight\n",
      "7.2.conv2.bias\n",
      "7.2.conv3.weight\n",
      "7.2.conv3.bias\n",
      "7.2.bn1.weight\n",
      "7.2.bn1.bias\n",
      "7.2.bn2.weight\n",
      "7.2.bn2.bias\n",
      "7.2.bn3.weight\n",
      "7.2.bn3.bias\n",
      "10.0.weight\n",
      "10.0.bias\n",
      "10.2.weight\n",
      "10.2.bias\n",
      "10.3.weight\n",
      "10.3.bias\n",
      "10.5.weight\n",
      "10.5.bias\n",
      "10.6.weight\n",
      "10.6.bias\n",
      "10.8.weight\n",
      "10.8.bias\n",
      "10.9.weight\n",
      "10.9.bias\n",
      "10.11.weight\n",
      "10.11.bias\n",
      "10.12.weight\n",
      "10.12.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    # if \"fc1\" in name:\n",
    "    #     param.requires_grad = False\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "719807b5-7b2f-48f2-b491-ee2cb8209497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:36:50.870899Z",
     "iopub.status.busy": "2023-11-05T14:36:50.870899Z",
     "iopub.status.idle": "2023-11-05T14:36:50.887234Z",
     "shell.execute_reply": "2023-11-05T14:36:50.886515Z",
     "shell.execute_reply.started": "2023-11-05T14:36:50.870899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (2): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (3): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Residual(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (4): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (5): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (7): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool1d(output_size=2)\n",
       "  (9): Flatten(start_dim=1, end_dim=-1)\n",
       "  (10): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a110b9b-096f-458a-89d1-155a97aff7e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:37:10.239503Z",
     "iopub.status.busy": "2023-11-05T14:37:10.239503Z",
     "iopub.status.idle": "2023-11-05T14:37:10.252668Z",
     "shell.execute_reply": "2023-11-05T14:37:10.252460Z",
     "shell.execute_reply.started": "2023-11-05T14:37:10.239503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,))\n",
       "  (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7483bf7-bf2e-4d41-8cd2-95cc013baa4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:37:16.258739Z",
     "iopub.status.busy": "2023-11-05T14:37:16.258739Z",
     "iopub.status.idle": "2023-11-05T14:37:16.274710Z",
     "shell.execute_reply": "2023-11-05T14:37:16.274710Z",
     "shell.execute_reply.started": "2023-11-05T14:37:16.258739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Residual(\n",
       "    (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "    (conv4): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): Residual(\n",
       "    (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): Residual(\n",
       "    (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ef3419-446c-4343-954c-7ec5f8d903ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:37:22.714344Z",
     "iopub.status.busy": "2023-11-05T14:37:22.714344Z",
     "iopub.status.idle": "2023-11-05T14:37:22.737902Z",
     "shell.execute_reply": "2023-11-05T14:37:22.737494Z",
     "shell.execute_reply.started": "2023-11-05T14:37:22.714344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c290c1e2-a0f3-421f-9837-1a9008b52f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:37:27.573899Z",
     "iopub.status.busy": "2023-11-05T14:37:27.573899Z",
     "iopub.status.idle": "2023-11-05T14:37:27.593021Z",
     "shell.execute_reply": "2023-11-05T14:37:27.592763Z",
     "shell.execute_reply.started": "2023-11-05T14:37:27.573899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Residual(\n",
       "    (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): Residual(\n",
       "    (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): Residual(\n",
       "    (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (3): Residual(\n",
       "    (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c18f3fef-892f-46a4-954f-68c573025c39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:37:34.418736Z",
     "iopub.status.busy": "2023-11-05T14:37:34.418736Z",
     "iopub.status.idle": "2023-11-05T14:37:34.431656Z",
     "shell.execute_reply": "2023-11-05T14:37:34.431359Z",
     "shell.execute_reply.started": "2023-11-05T14:37:34.418736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8326d978-0ac7-4aec-b659-36e55f461abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:37:38.864246Z",
     "iopub.status.busy": "2023-11-05T14:37:38.864246Z",
     "iopub.status.idle": "2023-11-05T14:37:38.872796Z",
     "shell.execute_reply": "2023-11-05T14:37:38.872388Z",
     "shell.execute_reply.started": "2023-11-05T14:37:38.864246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Residual(\n",
       "    (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (conv4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): Residual(\n",
       "    (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): Residual(\n",
       "    (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (3): Residual(\n",
       "    (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (4): Residual(\n",
       "    (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (5): Residual(\n",
       "    (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f101b62c-a47c-4144-be3c-439233e9a19c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:37:47.267640Z",
     "iopub.status.busy": "2023-11-05T14:37:47.267640Z",
     "iopub.status.idle": "2023-11-05T14:37:47.289049Z",
     "shell.execute_reply": "2023-11-05T14:37:47.288618Z",
     "shell.execute_reply.started": "2023-11-05T14:37:47.267640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6185daf-abd5-4391-95d9-0a3b46ff8e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:37:51.973056Z",
     "iopub.status.busy": "2023-11-05T14:37:51.973056Z",
     "iopub.status.idle": "2023-11-05T14:37:51.996823Z",
     "shell.execute_reply": "2023-11-05T14:37:51.996087Z",
     "shell.execute_reply.started": "2023-11-05T14:37:51.973056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Residual(\n",
       "    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "    (conv4): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): Residual(\n",
       "    (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): Residual(\n",
       "    (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52542ec8-df2c-4783-a8b1-e731b477ef20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:37:58.086866Z",
     "iopub.status.busy": "2023-11-05T14:37:58.086866Z",
     "iopub.status.idle": "2023-11-05T14:37:58.098497Z",
     "shell.execute_reply": "2023-11-05T14:37:58.098497Z",
     "shell.execute_reply.started": "2023-11-05T14:37:58.086866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool1d(output_size=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65059d81-a246-490e-a807-f8885028f71b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:38:45.810036Z",
     "iopub.status.busy": "2023-11-05T14:38:45.810036Z",
     "iopub.status.idle": "2023-11-05T14:38:45.834363Z",
     "shell.execute_reply": "2023-11-05T14:38:45.833990Z",
     "shell.execute_reply.started": "2023-11-05T14:38:45.810036Z"
    }
   },
   "outputs": [],
   "source": [
    "froze_layers = [0, 1, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "210e5538-b70f-45a0-a952-1b364a739588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:45:27.348184Z",
     "iopub.status.busy": "2023-11-05T14:45:27.348184Z",
     "iopub.status.idle": "2023-11-05T14:45:27.364906Z",
     "shell.execute_reply": "2023-11-05T14:45:27.363933Z",
     "shell.execute_reply.started": "2023-11-05T14:45:27.348184Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in froze_layers:\n",
    "    # for layer in net[i]:\n",
    "        # layer.requires_grad\n",
    "    net[i][0].requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64fffbd5-e347-411e-955e-dadd499fb2be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:50:48.762533Z",
     "iopub.status.busy": "2023-11-05T14:50:48.762533Z",
     "iopub.status.idle": "2023-11-05T14:50:48.771732Z",
     "shell.execute_reply": "2023-11-05T14:50:48.771732Z",
     "shell.execute_reply.started": "2023-11-05T14:50:48.762533Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->name: 0.0.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 0.0.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 0.1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 0.1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv4.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv4.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv4.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv4.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv4.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv4.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv4.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv4.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.0.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.0.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.5.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.5.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.6.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.6.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.8.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.8.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.9.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.9.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.11.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.11.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.12.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.12.bias\n",
      "-->grad_requirs: True\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "for name, parms in net.named_parameters():\t\n",
    "                print('-->name:', name)\n",
    "                # print('-->para:', parms)\n",
    "                print('-->grad_requirs:',parms.requires_grad)\n",
    "                # print('-->grad_value:',parms.grad)\n",
    "                print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00b455a5-38fa-4ff0-a9f9-99788965d19b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:46:54.701988Z",
     "iopub.status.busy": "2023-11-05T14:46:54.701988Z",
     "iopub.status.idle": "2023-11-05T14:46:55.967530Z",
     "shell.execute_reply": "2023-11-05T14:46:55.967530Z",
     "shell.execute_reply.started": "2023-11-05T14:46:54.701988Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.0.weight', Parameter containing:\n",
      "tensor([[[ 1.0662e+00, -1.8183e+00,  3.2301e-01,  1.2849e+00,  1.6269e+00,\n",
      "          -5.6602e-01,  7.8567e-02]],\n",
      "\n",
      "        [[-9.2795e-01,  4.3454e-01, -3.2425e+00, -4.1567e-01, -1.0057e-01,\n",
      "           1.1143e+00, -4.3434e+00]],\n",
      "\n",
      "        [[-8.2731e+00, -1.6682e+00,  2.2557e+00, -7.9624e-01,  3.1884e+00,\n",
      "          -4.6849e+00, -4.9949e+00]],\n",
      "\n",
      "        [[-4.9478e-01,  1.4131e+00, -1.8306e+00, -1.9092e+00,  2.2144e+00,\n",
      "          -1.5456e+00,  5.6138e-01]],\n",
      "\n",
      "        [[-2.9477e+00,  1.0234e+00,  1.8573e+00,  3.7806e+00, -1.4187e-01,\n",
      "           2.7734e+00, -2.5726e+00]],\n",
      "\n",
      "        [[ 1.1664e+00,  5.6129e+00,  6.3587e-02, -1.1763e+00, -2.3483e+00,\n",
      "           3.0351e+00, -2.8662e-02]],\n",
      "\n",
      "        [[-1.6109e+00,  1.6069e+00,  2.3268e+00,  2.4874e+00, -3.3771e-02,\n",
      "          -9.1275e-01, -1.9885e+00]],\n",
      "\n",
      "        [[-2.6765e+00,  4.2590e-01, -3.5757e+00, -2.0706e+00, -1.3494e+00,\n",
      "           5.4474e+00, -1.1713e+00]],\n",
      "\n",
      "        [[ 3.9476e-01, -3.7831e-01, -4.6797e-01, -3.4451e-01,  5.6203e+00,\n",
      "           5.9250e-01,  5.2336e-01]],\n",
      "\n",
      "        [[ 3.2973e+00,  2.6465e+00, -3.4362e+00,  1.1663e+00,  1.4446e+00,\n",
      "           3.2279e+00, -1.3083e+00]],\n",
      "\n",
      "        [[ 1.6878e+00, -2.8138e+00,  2.1642e+00, -1.9960e+00, -6.6696e-01,\n",
      "           2.1449e+00,  1.0549e+00]],\n",
      "\n",
      "        [[-2.6756e+00, -3.5129e+00, -6.5580e-01, -1.1864e+00, -1.9611e+00,\n",
      "           1.8068e+00,  4.3871e-01]],\n",
      "\n",
      "        [[-2.0411e+00, -2.3844e+00, -2.5502e+00, -1.1725e+00,  1.7208e+00,\n",
      "          -2.9487e+00, -4.1335e+00]],\n",
      "\n",
      "        [[-5.3626e-02,  1.4307e-01,  4.4430e-01,  5.3980e-01,  4.3665e+00,\n",
      "          -2.6146e-01, -2.5893e-01]],\n",
      "\n",
      "        [[ 4.8118e+00,  4.8612e+00, -2.5517e+00, -6.2735e+00, -2.8236e+00,\n",
      "           8.9966e+00, -1.5383e+00]],\n",
      "\n",
      "        [[-2.7379e+00, -1.6699e+00, -4.3803e-01, -3.8062e+00, -1.1297e-01,\n",
      "           2.1249e+00, -3.5559e+00]],\n",
      "\n",
      "        [[ 9.6872e-01,  1.4939e-01, -2.2276e+00,  2.7967e-01,  6.1436e-01,\n",
      "           4.4170e+00,  1.2653e+00]],\n",
      "\n",
      "        [[-2.1452e-01, -6.6520e-01, -1.8228e-01, -1.3548e-01,  5.2375e+00,\n",
      "           4.0652e+00,  2.5694e+00]],\n",
      "\n",
      "        [[ 2.1821e+00, -1.8043e+00, -4.8320e-01, -2.4731e+00, -6.0296e-01,\n",
      "           1.3991e+00, -2.6135e+00]],\n",
      "\n",
      "        [[-5.2344e-01,  2.6847e+00, -5.3381e-01, -1.5300e+00,  2.8760e+00,\n",
      "          -1.8188e-01, -1.4798e+00]],\n",
      "\n",
      "        [[-5.1030e+00, -1.1618e+00,  4.0170e+00, -1.8469e+00,  1.9959e-01,\n",
      "           1.4307e+00,  1.6178e+00]],\n",
      "\n",
      "        [[-2.2733e+00,  1.7687e+00,  1.2641e+00,  2.4414e+00, -5.2076e-01,\n",
      "           1.6702e+00,  1.5450e+00]],\n",
      "\n",
      "        [[-2.9404e+00, -2.2969e+00,  6.7407e-01,  9.6950e-01, -1.3904e-01,\n",
      "          -1.6521e+00, -2.2213e+00]],\n",
      "\n",
      "        [[-6.2528e-01, -4.1723e-02,  1.1785e-01,  5.0883e-01, -5.5334e-02,\n",
      "          -4.9755e-01, -1.5025e+00]],\n",
      "\n",
      "        [[-8.1008e-01,  1.9986e+00, -8.4333e-01,  7.1883e-01,  2.3741e+00,\n",
      "           1.6258e+00,  3.2194e-01]],\n",
      "\n",
      "        [[-3.6328e+00,  3.2159e-01, -4.1155e-02,  9.2709e-02,  8.9293e-01,\n",
      "          -1.4013e+00, -3.2633e+00]],\n",
      "\n",
      "        [[ 2.3727e+00,  1.0289e-01, -1.4613e+00,  2.1921e+00, -1.2605e+00,\n",
      "          -1.0222e+00, -5.2770e-01]],\n",
      "\n",
      "        [[ 1.2953e+00,  7.5535e-01, -3.8142e-01, -8.3221e-01, -1.7142e+00,\n",
      "           1.3735e-01,  1.1128e+00]],\n",
      "\n",
      "        [[-3.9758e+00, -1.7489e-01,  2.5740e+00,  2.0489e+00,  1.9619e+00,\n",
      "          -5.3221e+00,  1.3278e+00]],\n",
      "\n",
      "        [[ 5.0780e+00, -1.0336e+00,  1.0253e+00,  3.6799e+00, -1.3559e+00,\n",
      "           1.1926e+00, -5.7238e-01]],\n",
      "\n",
      "        [[-1.6778e+00,  3.5147e+00,  1.4888e-01, -1.4358e+00, -8.3466e-01,\n",
      "          -1.1007e+00, -1.5350e+00]],\n",
      "\n",
      "        [[-2.8452e-01,  3.0267e+00, -9.3022e-01, -8.2894e-01,  1.7836e+00,\n",
      "           2.1693e+00, -1.6979e+00]],\n",
      "\n",
      "        [[-5.3601e+00,  1.5761e+00, -1.0648e+00,  2.6047e+00, -2.6206e+00,\n",
      "          -4.8807e-01,  3.6972e-01]],\n",
      "\n",
      "        [[-6.6817e+00, -3.4823e-01,  7.3590e-01, -1.5826e+00, -2.9551e+00,\n",
      "          -1.4598e-01,  2.1045e-01]],\n",
      "\n",
      "        [[-8.0786e-01, -9.1969e-01,  2.2246e+00, -4.4290e-01, -1.4466e-01,\n",
      "          -3.5991e+00,  1.9383e+00]],\n",
      "\n",
      "        [[ 6.4573e-01, -1.4993e+00, -1.3685e+00, -1.3164e+00,  2.0435e+00,\n",
      "           2.0472e+00,  4.3975e-01]],\n",
      "\n",
      "        [[-2.0158e+00,  8.6153e-01,  1.4394e+00, -7.7791e-01,  1.0075e+00,\n",
      "           1.1134e-01, -2.4251e+00]],\n",
      "\n",
      "        [[ 8.0296e-01, -3.9398e+00, -6.5839e-01,  2.3178e+00, -4.5208e-01,\n",
      "          -2.7400e+00, -1.0684e+00]],\n",
      "\n",
      "        [[-1.0611e+00, -3.6474e+00,  1.9826e+00, -7.3775e-01, -5.2416e-01,\n",
      "           1.1344e-01,  1.2001e+00]],\n",
      "\n",
      "        [[-2.4699e-01, -1.6265e+00, -1.1258e+00, -3.1299e+00,  2.0305e+00,\n",
      "           1.1011e+00, -4.7664e-01]],\n",
      "\n",
      "        [[ 1.7664e+00, -1.9236e+00, -7.2422e-01,  4.7815e-01,  1.2081e+00,\n",
      "           6.9704e-01,  2.4107e+00]],\n",
      "\n",
      "        [[-2.9562e+00,  3.5995e+00, -9.8124e-01,  8.3707e-01,  2.9811e+00,\n",
      "           2.6105e+00, -1.3983e-01]],\n",
      "\n",
      "        [[-2.7958e+00, -1.3403e-02,  4.9900e-01, -7.3155e-01,  8.4741e-01,\n",
      "          -3.3783e-01,  1.6789e+00]],\n",
      "\n",
      "        [[-1.4177e+00,  9.3170e-01,  5.3521e+00, -7.7700e-01,  1.8118e+00,\n",
      "          -2.7658e+00,  8.3126e-01]],\n",
      "\n",
      "        [[ 9.6372e-01, -6.7242e+00,  1.0930e+00,  3.7188e-01, -2.0542e+00,\n",
      "          -2.2451e+00, -5.3613e-01]],\n",
      "\n",
      "        [[ 3.9441e+00,  8.2332e-01, -1.2193e+00,  6.5654e-01,  1.3946e-01,\n",
      "           1.5308e+00,  1.2330e+00]],\n",
      "\n",
      "        [[-1.6917e+00,  1.5221e+00,  8.1350e-01, -1.3005e+00,  3.7801e-01,\n",
      "           3.0675e-01,  9.3223e-01]],\n",
      "\n",
      "        [[ 1.8307e-01,  3.4791e+00, -2.8362e-01, -4.9453e-01, -1.9794e+00,\n",
      "          -9.9387e-01,  1.5971e-01]],\n",
      "\n",
      "        [[-2.7819e+00,  6.2395e+00, -4.1783e+00,  1.2613e-01,  4.3557e+00,\n",
      "           2.6328e+00, -1.8097e+00]],\n",
      "\n",
      "        [[ 2.9135e+00,  1.0775e+00,  2.0795e+00,  8.1022e-03,  3.1617e-01,\n",
      "          -1.0141e+00, -1.7037e+00]],\n",
      "\n",
      "        [[ 5.9068e-01, -4.5823e-01,  8.1945e-01, -5.1954e-01,  4.2779e+00,\n",
      "          -1.0081e+00, -2.3371e-01]],\n",
      "\n",
      "        [[-1.2162e+00, -7.7556e-01, -5.5385e-01,  4.1055e+00,  1.6048e-02,\n",
      "           2.7242e+00,  2.0175e+00]],\n",
      "\n",
      "        [[-2.1917e+00, -3.1640e+00, -3.1741e+00, -1.3556e+00,  1.0358e-01,\n",
      "          -2.9299e+00, -2.5620e-01]],\n",
      "\n",
      "        [[-5.2760e+00,  2.9901e+00,  1.6710e+00,  9.2094e-01,  1.1190e+00,\n",
      "          -4.0539e+00,  9.4185e-01]],\n",
      "\n",
      "        [[ 2.9887e-02, -1.8279e+00,  3.1737e-01, -2.1219e+00, -2.5310e-01,\n",
      "           1.8857e+00,  3.6146e+00]],\n",
      "\n",
      "        [[-1.0777e+00,  3.5028e-01,  4.9099e+00, -2.5112e+00, -1.3917e+00,\n",
      "           5.7300e-01,  1.7394e+00]],\n",
      "\n",
      "        [[ 1.2159e+00,  9.9630e-01, -1.7397e-01, -1.1684e+00, -5.8900e-01,\n",
      "          -6.5046e-01, -2.8402e-01]],\n",
      "\n",
      "        [[ 5.2006e-01, -5.2428e-01, -3.0737e+00,  5.2687e-02,  1.9156e-01,\n",
      "          -1.4828e+00,  3.2246e+00]],\n",
      "\n",
      "        [[ 1.2114e+00,  2.0874e+00,  2.3974e-01,  1.1522e+00, -6.1907e-01,\n",
      "           7.7051e-02,  8.3225e-01]],\n",
      "\n",
      "        [[ 1.3143e+00,  6.7653e-01, -1.2840e+00, -6.7906e+00, -7.8775e-01,\n",
      "           1.7433e-01, -2.5269e+00]],\n",
      "\n",
      "        [[ 6.8335e-01,  2.1463e-01,  5.3061e-01,  2.5437e+00,  2.0331e+00,\n",
      "          -4.3984e-01,  4.3251e-01]],\n",
      "\n",
      "        [[-2.4165e+00,  5.1308e+00,  5.8574e+00,  8.9454e-01,  1.4464e+00,\n",
      "          -2.0096e+00,  7.7243e-01]],\n",
      "\n",
      "        [[ 1.5361e+00, -2.1348e+00,  1.0647e+00, -7.1354e-01, -7.7577e-01,\n",
      "          -3.8217e+00, -2.8465e+00]],\n",
      "\n",
      "        [[ 2.7937e+00, -4.0920e+00,  3.0073e+00, -2.9927e+00, -3.8192e+00,\n",
      "          -8.5702e-01, -2.4600e+00]]], device='cuda:0', requires_grad=True))\n",
      "('0.0.bias', Parameter containing:\n",
      "tensor([ 0.1990,  0.3374, -0.0521, -0.0402, -0.2976,  0.2825, -0.1674, -0.0850,\n",
      "         0.2974, -0.1722,  0.0723, -0.1001,  0.2155, -0.1436,  0.0439,  0.2759,\n",
      "        -0.3677, -0.0833,  0.3336,  0.3188,  0.2248,  0.3120,  0.3719, -0.3034,\n",
      "        -0.2015,  0.0883, -0.0377, -0.1346,  0.3303,  0.1905, -0.1002,  0.3548,\n",
      "        -0.1685,  0.1523,  0.3175,  0.3115, -0.2500,  0.2400, -0.2908, -0.0341,\n",
      "        -0.1706, -0.3303, -0.3328, -0.3276,  0.0121, -0.1293,  0.1634, -0.1106,\n",
      "        -0.3029, -0.0758,  0.0093, -0.1482,  0.2827, -0.3001,  0.1880, -0.0324,\n",
      "        -0.1743,  0.2013, -0.0967,  0.0760, -0.3777, -0.1019,  0.2182, -0.2760],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('0.1.weight', Parameter containing:\n",
      "tensor([ 0.7187, -0.0130,  0.8510,  0.2460,  0.9019,  1.5194,  0.8404,  1.0542,\n",
      "         1.8706,  0.6923,  1.3498,  0.8049,  0.9271, -1.4672,  0.3897,  1.2802,\n",
      "        -0.5774,  0.5760,  1.3388,  0.3433,  2.0481,  0.6850,  0.8586,  0.1715,\n",
      "         0.8308,  0.0022,  1.7029, -0.9568,  0.8594,  1.0121,  0.4477,  1.0986,\n",
      "         1.0994, -0.5911,  1.0296,  0.9948,  0.1026,  0.3717,  0.9438, -0.2785,\n",
      "         0.7488,  0.5598,  0.0284, -0.9051,  1.8576,  1.8368,  0.7326,  1.6094,\n",
      "         1.5570,  1.1258,  1.3092,  1.5774,  1.7317,  1.1031,  0.6298,  0.8246,\n",
      "         0.6002,  1.1854,  1.2639,  1.0648,  1.0775, -0.2982,  1.3425,  0.5922],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('0.1.bias', Parameter containing:\n",
      "tensor([-1.3759e-03, -9.4109e-01,  5.1619e-01, -1.2081e+00,  3.3232e-01,\n",
      "         1.9352e-01,  1.4838e-01,  3.0913e-01,  2.6086e-01,  2.0177e-01,\n",
      "         1.0237e-01,  1.7292e-01,  1.6680e-01, -1.2089e-01,  5.2760e-01,\n",
      "         2.6681e-01, -5.4190e-02,  2.3184e-01, -8.5272e-02,  5.2898e-01,\n",
      "         5.0798e-01,  4.9389e-02, -1.3228e-01, -1.1877e+00,  2.9945e-01,\n",
      "        -1.3295e+00,  2.1871e-01, -1.6728e+00, -1.7163e-01, -4.0396e-01,\n",
      "        -5.8383e-01,  1.2641e+00, -6.7802e-01, -3.0389e-01, -2.5006e-01,\n",
      "         5.5123e-01,  4.4610e-01, -7.9541e-01, -3.4749e-01,  3.9708e-01,\n",
      "         2.7433e-01, -6.0592e-01, -5.2897e-01,  1.7282e-01,  2.9552e-01,\n",
      "         3.1604e-01,  9.0820e-02,  5.5524e-01,  5.8889e-01,  5.8915e-01,\n",
      "        -4.0015e-01, -2.0785e+00, -5.0505e-01,  8.8379e-01,  2.8723e-01,\n",
      "         5.4015e-01,  1.0906e-01, -8.9906e-01,  3.0260e-01, -7.8548e-01,\n",
      "         2.2938e-02, -8.6379e-01, -1.0067e-01,  4.4617e-01], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('1.0.conv1.weight', Parameter containing:\n",
      "tensor([[[-1.7980],\n",
      "         [-0.7131],\n",
      "         [ 0.8750],\n",
      "         ...,\n",
      "         [-1.7810],\n",
      "         [-0.2288],\n",
      "         [ 0.0283]],\n",
      "\n",
      "        [[-1.8993],\n",
      "         [ 2.6725],\n",
      "         [ 1.1298],\n",
      "         ...,\n",
      "         [-1.4882],\n",
      "         [ 1.1712],\n",
      "         [ 1.6674]],\n",
      "\n",
      "        [[-3.4622],\n",
      "         [-0.5260],\n",
      "         [ 1.6215],\n",
      "         ...,\n",
      "         [ 0.8062],\n",
      "         [-4.0729],\n",
      "         [-0.9002]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6211],\n",
      "         [ 3.1073],\n",
      "         [-1.4553],\n",
      "         ...,\n",
      "         [ 0.4177],\n",
      "         [-0.2015],\n",
      "         [-1.5309]],\n",
      "\n",
      "        [[-2.4251],\n",
      "         [ 0.3362],\n",
      "         [ 1.2072],\n",
      "         ...,\n",
      "         [-0.1034],\n",
      "         [ 0.7746],\n",
      "         [ 0.5104]],\n",
      "\n",
      "        [[-0.6519],\n",
      "         [-1.0352],\n",
      "         [ 0.7380],\n",
      "         ...,\n",
      "         [-2.1469],\n",
      "         [ 0.8682],\n",
      "         [ 0.8985]]], device='cuda:0', requires_grad=True))\n",
      "('1.0.conv1.bias', Parameter containing:\n",
      "tensor([ 0.0034, -0.0751, -0.1127, -0.0294, -0.0844,  0.1185, -0.0438, -0.0986,\n",
      "        -0.0504, -0.0194, -0.1016,  0.1011, -0.0777, -0.0796,  0.0275, -0.1209,\n",
      "        -0.0622,  0.0876,  0.0100,  0.0538, -0.0258,  0.0163,  0.0231, -0.0533,\n",
      "        -0.0464, -0.0492, -0.1089, -0.0334, -0.0536,  0.0074,  0.1014, -0.1117,\n",
      "         0.0052,  0.1121,  0.0806, -0.1201,  0.0306, -0.0541, -0.0293,  0.0221,\n",
      "         0.1177,  0.0096,  0.0583,  0.0659, -0.0585, -0.0981,  0.1024, -0.0077,\n",
      "         0.0914,  0.0712, -0.0513, -0.0094, -0.0731, -0.0715,  0.0035, -0.0994,\n",
      "        -0.0634, -0.0193,  0.1211,  0.0573, -0.1067, -0.1014, -0.0087, -0.0873],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.0.conv2.weight', Parameter containing:\n",
      "tensor([[[ 2.3013e+00,  4.0364e-02, -1.7890e+00],\n",
      "         [ 4.5484e-01, -3.5357e-01, -7.2026e-01],\n",
      "         [-2.0150e-01, -2.0902e-01,  1.6176e+00],\n",
      "         ...,\n",
      "         [-5.2922e-01, -5.4444e-01,  7.2173e-01],\n",
      "         [ 5.0604e-01,  1.0552e+00, -6.3596e-01],\n",
      "         [-8.5992e-02, -1.4004e+00, -1.5675e+00]],\n",
      "\n",
      "        [[-7.3867e-01,  1.7912e+00,  1.0192e+00],\n",
      "         [ 3.9897e-01,  2.2282e+00, -1.0114e+00],\n",
      "         [ 3.4348e-01, -6.5210e-01,  1.3887e-01],\n",
      "         ...,\n",
      "         [ 4.2218e-01,  1.6191e+00,  1.7087e+00],\n",
      "         [-5.8682e-01, -4.9567e-01,  3.1436e-01],\n",
      "         [ 2.9440e-01, -4.8702e-02,  3.0199e+00]],\n",
      "\n",
      "        [[-8.0796e-01, -2.4539e-02,  7.6131e-01],\n",
      "         [-1.8452e+00,  7.7193e-01, -1.0588e+00],\n",
      "         [ 1.2463e-02,  6.4126e-01, -7.5635e-01],\n",
      "         ...,\n",
      "         [ 8.0980e-01,  3.1188e+00,  4.6467e-01],\n",
      "         [-8.5002e-01,  2.2226e-02,  5.3548e-01],\n",
      "         [ 2.0036e+00,  2.6868e-01,  1.4742e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.7057e+00,  2.0998e-01, -1.2475e+00],\n",
      "         [-1.8797e-01, -6.9584e-01, -9.1558e-01],\n",
      "         [ 1.9085e+00,  1.5063e+00,  6.7906e-01],\n",
      "         ...,\n",
      "         [ 6.6151e-01,  1.7201e+00,  1.1074e+00],\n",
      "         [ 1.3474e+00,  1.3724e-01,  2.3749e-01],\n",
      "         [-1.1022e+00,  9.3341e-01,  2.7601e+00]],\n",
      "\n",
      "        [[ 7.9267e-01,  2.5227e+00,  1.7062e-01],\n",
      "         [ 2.2241e+00,  8.3441e-01, -3.5701e-01],\n",
      "         [-1.1316e+00, -1.5163e+00,  1.6716e+00],\n",
      "         ...,\n",
      "         [-2.2383e+00,  1.7759e-01, -1.9854e-02],\n",
      "         [ 1.2173e-01, -1.5610e+00, -5.7499e-01],\n",
      "         [ 1.5385e-01, -1.2647e-01, -1.8517e+00]],\n",
      "\n",
      "        [[-1.1237e+00, -8.0501e-01,  5.8147e-01],\n",
      "         [ 8.2664e-02, -4.5223e-01,  1.9232e-01],\n",
      "         [-2.1600e+00, -9.3004e-01, -2.0446e+00],\n",
      "         ...,\n",
      "         [ 1.2405e+00,  1.1035e+00, -1.0193e+00],\n",
      "         [ 5.3503e-02, -1.5593e+00,  4.8705e-04],\n",
      "         [-7.0675e-01, -1.1444e+00, -8.1084e-01]]], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('1.0.conv2.bias', Parameter containing:\n",
      "tensor([ 0.0045,  0.0235,  0.0455, -0.0179,  0.0291, -0.0165, -0.0166,  0.0542,\n",
      "         0.0652, -0.0674, -0.0224, -0.0487, -0.0319, -0.0153,  0.0692, -0.0707,\n",
      "         0.0142,  0.0639, -0.0520,  0.0463, -0.0050,  0.0282,  0.0200, -0.0570,\n",
      "         0.0618,  0.0696,  0.0023,  0.0423,  0.0569,  0.0668, -0.0670, -0.0074,\n",
      "         0.0721,  0.0106, -0.0361,  0.0209,  0.0281, -0.0332, -0.0497, -0.0023,\n",
      "         0.0499, -0.0616, -0.0034, -0.0614,  0.0431, -0.0321,  0.0690,  0.0028,\n",
      "        -0.0208,  0.0715, -0.0449,  0.0377,  0.0001, -0.0488, -0.0342,  0.0553,\n",
      "         0.0276, -0.0419, -0.0198, -0.0492, -0.0433,  0.0187,  0.0491, -0.0663],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.0.conv3.weight', Parameter containing:\n",
      "tensor([[[-0.7238],\n",
      "         [-0.1517],\n",
      "         [-0.0180],\n",
      "         ...,\n",
      "         [ 0.4306],\n",
      "         [-0.2325],\n",
      "         [-0.9043]],\n",
      "\n",
      "        [[-0.2600],\n",
      "         [-0.2581],\n",
      "         [ 0.8828],\n",
      "         ...,\n",
      "         [ 0.2848],\n",
      "         [-0.0712],\n",
      "         [-0.1528]],\n",
      "\n",
      "        [[ 0.3260],\n",
      "         [-0.0660],\n",
      "         [-0.5268],\n",
      "         ...,\n",
      "         [-0.0233],\n",
      "         [-0.0255],\n",
      "         [ 0.2183]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0169],\n",
      "         [-0.0845],\n",
      "         [-0.3279],\n",
      "         ...,\n",
      "         [ 0.3128],\n",
      "         [ 0.0972],\n",
      "         [ 0.1372]],\n",
      "\n",
      "        [[ 0.0680],\n",
      "         [ 1.1760],\n",
      "         [ 0.3460],\n",
      "         ...,\n",
      "         [ 0.0660],\n",
      "         [-0.6610],\n",
      "         [ 0.3038]],\n",
      "\n",
      "        [[-0.4212],\n",
      "         [ 1.2505],\n",
      "         [ 0.8007],\n",
      "         ...,\n",
      "         [-1.2540],\n",
      "         [ 0.7730],\n",
      "         [-0.3108]]], device='cuda:0', requires_grad=True))\n",
      "('1.0.conv3.bias', Parameter containing:\n",
      "tensor([-0.0479,  0.0204, -0.0730,  0.1200,  0.0384, -0.1227, -0.0995,  0.0955,\n",
      "         0.0947, -0.1196,  0.1065, -0.0050,  0.0131, -0.0430,  0.0109,  0.0524,\n",
      "         0.0160,  0.0437, -0.0463, -0.0826,  0.0078, -0.0165, -0.0823, -0.0456,\n",
      "        -0.0163, -0.0577, -0.0995,  0.0856, -0.1151,  0.0968,  0.0204, -0.0756,\n",
      "         0.0181, -0.1074,  0.0448, -0.0045, -0.1200,  0.0061,  0.0269, -0.0949,\n",
      "        -0.0397,  0.0702, -0.0677,  0.0269,  0.0336, -0.0746, -0.0287,  0.0214,\n",
      "         0.0060,  0.0886, -0.0241,  0.0711,  0.0941,  0.0363, -0.0899,  0.0695,\n",
      "         0.0855, -0.0060, -0.0140,  0.0075, -0.0283,  0.0239, -0.0312,  0.0381,\n",
      "         0.0004, -0.0983,  0.0452,  0.0600,  0.0609,  0.0823,  0.1148, -0.1146,\n",
      "         0.1140,  0.1100, -0.0960, -0.0283, -0.0293, -0.0983, -0.1029,  0.0142,\n",
      "        -0.1238, -0.0332,  0.1152,  0.0980, -0.0438,  0.0738,  0.1153,  0.0844,\n",
      "         0.1024,  0.0591,  0.0194, -0.0502,  0.0616, -0.0385,  0.0547, -0.1019,\n",
      "         0.0288, -0.0641, -0.0518, -0.0848, -0.0048, -0.1063, -0.0194,  0.0821,\n",
      "         0.1063,  0.1248, -0.0611,  0.0581,  0.1085,  0.0202,  0.0134,  0.0641,\n",
      "         0.0199, -0.0896,  0.0746, -0.0447, -0.0903, -0.1020, -0.0154,  0.0158,\n",
      "         0.0256,  0.1186,  0.0267, -0.0424,  0.0523,  0.0774,  0.0308,  0.0360,\n",
      "        -0.0286,  0.0983,  0.1057, -0.0050, -0.0477, -0.0084,  0.1200, -0.0886,\n",
      "        -0.0789,  0.0130,  0.0926, -0.0999,  0.0286,  0.0548,  0.0091,  0.0501,\n",
      "        -0.1197, -0.0153,  0.0449, -0.1151,  0.0597, -0.0961,  0.0941, -0.0128,\n",
      "         0.0381,  0.0076, -0.0261,  0.1209,  0.0189,  0.0551, -0.0966, -0.0721,\n",
      "         0.0819,  0.0710,  0.0824, -0.0018,  0.0744,  0.0998, -0.0692,  0.0977,\n",
      "         0.0818,  0.1007,  0.0014,  0.1171,  0.1051,  0.0887, -0.0247, -0.0722,\n",
      "        -0.1045, -0.0527, -0.1225,  0.1005,  0.0047,  0.0687,  0.0885,  0.1055,\n",
      "         0.0705, -0.0265, -0.0019,  0.0570,  0.0281,  0.0989,  0.1193, -0.1132,\n",
      "         0.1083, -0.0252, -0.0962,  0.0544, -0.1190,  0.0057,  0.0598, -0.0031,\n",
      "         0.1093, -0.1169, -0.1238, -0.0165, -0.1081,  0.0434, -0.0816, -0.0613,\n",
      "        -0.0335,  0.0377,  0.1204, -0.1075, -0.0617, -0.0372, -0.0285,  0.1046,\n",
      "         0.0912, -0.0330, -0.0697,  0.0104, -0.0209, -0.0366,  0.0483,  0.0022,\n",
      "        -0.1076, -0.0132,  0.0369, -0.0384, -0.0238, -0.0161,  0.0081,  0.0534,\n",
      "        -0.0793, -0.0046,  0.0267, -0.0143, -0.0179, -0.0115,  0.0412,  0.0101,\n",
      "        -0.1049, -0.0182,  0.0233,  0.0069,  0.0272,  0.0862,  0.0561,  0.0222,\n",
      "        -0.0598, -0.0621, -0.1107, -0.0660,  0.0868,  0.0546,  0.0811,  0.0195],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.0.conv4.weight', Parameter containing:\n",
      "tensor([[[ 0.2118],\n",
      "         [-0.1835],\n",
      "         [ 0.1732],\n",
      "         ...,\n",
      "         [-0.0807],\n",
      "         [ 0.0781],\n",
      "         [-0.0718]],\n",
      "\n",
      "        [[ 0.0410],\n",
      "         [ 0.0159],\n",
      "         [-0.0157],\n",
      "         ...,\n",
      "         [-0.0407],\n",
      "         [-0.2703],\n",
      "         [-0.0319]],\n",
      "\n",
      "        [[-0.2457],\n",
      "         [ 0.3696],\n",
      "         [-0.3975],\n",
      "         ...,\n",
      "         [ 0.4250],\n",
      "         [-0.2305],\n",
      "         [ 0.0098]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2464],\n",
      "         [-0.3511],\n",
      "         [-0.4273],\n",
      "         ...,\n",
      "         [ 0.3251],\n",
      "         [-0.5418],\n",
      "         [-0.7757]],\n",
      "\n",
      "        [[ 0.2760],\n",
      "         [-0.0769],\n",
      "         [-0.0074],\n",
      "         ...,\n",
      "         [ 0.1480],\n",
      "         [ 0.0583],\n",
      "         [-0.0156]],\n",
      "\n",
      "        [[ 0.1477],\n",
      "         [-0.1646],\n",
      "         [-0.0563],\n",
      "         ...,\n",
      "         [-0.0194],\n",
      "         [-0.2543],\n",
      "         [-0.8194]]], device='cuda:0', requires_grad=True))\n",
      "('1.0.conv4.bias', Parameter containing:\n",
      "tensor([-8.1909e-03, -2.2308e-01,  2.1313e-01, -9.7543e-02,  1.6817e-01,\n",
      "         1.0190e-01,  7.5521e-02, -4.3221e-01,  8.6701e-02,  2.4052e-01,\n",
      "         3.4070e-01, -2.3999e-01, -3.1137e-01,  2.4911e-01,  7.5350e-03,\n",
      "        -1.0181e-01, -3.0574e-02, -3.4841e-01,  3.5144e-01, -2.9460e-01,\n",
      "        -4.7678e-02, -3.3286e-01, -7.5354e-02,  4.4362e-02,  8.3743e-02,\n",
      "        -3.9889e-01,  4.7463e-01,  4.3497e-01, -3.3710e-01,  1.5793e-01,\n",
      "        -2.7181e-01,  1.6502e-01,  3.2107e-01, -1.3045e-01, -5.2005e-02,\n",
      "         1.4661e-01,  1.3356e-01,  4.7790e-04,  3.0408e-02,  2.5753e-01,\n",
      "        -3.8074e-01,  3.8645e-01, -3.1151e-01, -3.6038e-01, -3.7133e-01,\n",
      "         4.3398e-01, -1.6997e-01, -3.0729e-01, -1.5531e-01,  2.6709e-01,\n",
      "         1.0176e-01, -1.2718e-01, -3.5237e-01,  6.6700e-01,  3.2598e-01,\n",
      "         2.7017e-01, -6.3589e-02,  4.9043e-02, -2.8164e-01,  1.6539e-02,\n",
      "         8.4378e-02, -6.0676e-02,  4.8874e-02, -2.3972e-02,  1.5261e-01,\n",
      "        -1.0899e-01, -4.7808e-02,  3.2071e-01,  8.3647e-02, -3.4147e-01,\n",
      "        -1.1460e-01,  6.3495e-03, -2.0971e-01, -4.3041e-02, -3.5596e-01,\n",
      "         1.4025e-01,  1.8265e-01, -4.5381e-02, -1.1265e-01, -2.0361e-01,\n",
      "        -1.4022e-01, -1.5985e-01, -2.8816e-01,  1.2772e-01, -1.2334e-01,\n",
      "         4.7765e-01, -1.0043e-01, -1.2701e-01, -3.0841e-01, -2.5380e-01,\n",
      "        -1.4349e-01,  6.4121e-02, -1.3623e-01,  3.8672e-01,  4.2804e-01,\n",
      "         3.5572e-01,  2.4918e-01, -2.8340e-01, -4.2984e-01,  1.2713e-01,\n",
      "         3.4708e-02, -1.4362e-02,  1.9292e-01,  2.3272e-01,  7.4575e-02,\n",
      "         1.6424e-01, -6.6023e-02,  1.1591e-01, -4.4935e-02, -2.4570e-01,\n",
      "        -1.8707e-01,  2.0837e-01,  2.8233e-01,  2.0633e-01,  1.1170e-01,\n",
      "         5.8924e-01, -4.9661e-02,  1.4898e-02, -2.0756e-01, -3.0658e-02,\n",
      "        -3.0486e-01,  1.5649e-01, -1.0957e-01, -4.9684e-02, -2.0480e-03,\n",
      "         2.0242e-01,  2.8843e-01,  3.1037e-02, -1.4573e-01, -2.6207e-02,\n",
      "         1.4010e-02, -1.2366e-02,  3.8777e-02, -3.8095e-01, -3.6292e-01,\n",
      "        -2.7943e-01, -2.9415e-01,  5.6825e-01, -3.0574e-01,  5.6598e-01,\n",
      "         8.4614e-02,  2.5123e-01, -2.2758e-01, -1.7497e-02,  2.4309e-01,\n",
      "         9.3771e-02,  5.8090e-02,  3.3650e-01,  2.1778e-01, -1.1790e-01,\n",
      "         2.3350e-01,  9.5716e-02, -1.9235e-01,  4.4746e-01,  8.7149e-02,\n",
      "         4.2826e-01, -1.5738e-01,  4.2846e-02,  6.6771e-02,  2.9200e-01,\n",
      "        -1.1431e-01,  8.2715e-02,  6.2535e-02,  3.5334e-01, -3.5809e-01,\n",
      "         1.1823e-01,  5.6761e-01,  4.6144e-01, -1.6616e-02, -8.1377e-02,\n",
      "        -7.9141e-02, -6.8251e-02,  3.9215e-01, -6.6960e-02,  2.2059e-02,\n",
      "        -4.2939e-01, -8.2501e-03,  1.8537e-01,  8.7483e-02, -5.6713e-01,\n",
      "         5.4177e-01,  2.0135e-01, -1.8632e-01, -1.2853e-01, -7.1860e-02,\n",
      "        -2.4116e-01,  1.1692e-02, -6.4046e-02,  2.1130e-01,  6.7172e-01,\n",
      "         4.8555e-02, -6.6944e-02,  1.5935e-01,  3.2879e-01,  1.4403e-01,\n",
      "        -1.6511e-01,  3.6608e-01, -1.0960e-01, -1.3396e-01,  1.8145e-01,\n",
      "         1.6262e-01, -4.9504e-02,  1.6043e-01, -2.9554e-01,  1.4821e-01,\n",
      "         1.1225e-01, -3.9587e-03,  4.7913e-01,  2.1698e-01,  2.9593e-01,\n",
      "        -6.9010e-02, -3.2472e-01, -3.6191e-01, -2.3329e-01, -2.3411e-01,\n",
      "         2.9821e-02,  2.2231e-01, -2.6176e-02, -1.6561e-01, -3.8865e-01,\n",
      "         9.2878e-02, -2.9879e-01, -1.1420e-01,  6.4717e-02,  1.5778e-01,\n",
      "         3.3998e-01, -1.6226e-02, -1.3156e-01, -1.8085e-01, -7.2508e-02,\n",
      "        -1.2738e-01,  4.9908e-02, -1.8340e-01,  3.0465e-01, -2.5205e-01,\n",
      "         1.3312e-01,  4.4958e-01,  6.7746e-02, -2.1027e-01, -1.8310e-01,\n",
      "        -9.5145e-02, -2.5614e-01,  1.1336e-01,  2.1570e-01, -9.2203e-02,\n",
      "         8.2693e-02,  2.7195e-01, -2.5016e-01, -3.7261e-02,  1.9501e-01,\n",
      "        -9.2117e-02, -1.6680e-01,  5.3598e-02, -3.8583e-01, -5.7376e-02,\n",
      "        -9.0370e-02], device='cuda:0', requires_grad=True))\n",
      "('1.0.bn1.weight', Parameter containing:\n",
      "tensor([ 1.7236,  0.7719,  1.8950,  2.1393,  0.5721, -0.2883,  0.8958,  0.5804,\n",
      "         0.8795, -0.2755,  1.3887,  1.7883, -0.4194,  0.3891,  1.2786,  0.9728,\n",
      "         1.8555,  1.5307, -1.1238,  1.6279, -0.0660,  0.5638,  0.2628,  1.6844,\n",
      "         0.4434,  0.5641,  1.6343,  1.8662,  0.9393,  3.2571,  0.6786,  0.2595,\n",
      "         2.2674,  1.6264,  1.2190,  1.7189, -0.2562,  0.9275,  1.4763,  1.0131,\n",
      "         0.0366,  0.8814,  1.3349,  2.0397,  2.3473,  0.5178,  0.8706,  0.7275,\n",
      "         0.9990,  1.9122,  0.8803,  0.8810,  0.6920,  0.0071,  0.0716,  0.5552,\n",
      "         1.4578,  1.8518,  0.3505,  2.8040,  1.3746, -0.0424,  0.8650,  1.2693],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.0.bn1.bias', Parameter containing:\n",
      "tensor([ 0.6134, -0.6619,  0.0970,  0.9795,  0.0614, -0.6677,  0.2708,  0.5552,\n",
      "        -0.3981,  0.0718,  0.2989,  0.7438, -0.5693, -0.1028,  1.0520, -0.3608,\n",
      "         1.6152,  0.6932, -1.6111, -0.2523, -1.0491, -0.5680, -0.9225,  0.1447,\n",
      "        -1.4373, -0.2975,  0.4527,  0.7616,  0.4480,  1.4720,  0.2817, -1.4427,\n",
      "         0.7194,  0.8223, -0.1093,  1.0731, -1.4247, -0.0841,  1.1580,  0.1409,\n",
      "        -0.4385,  0.4326,  0.2226,  0.4801,  1.1275, -0.4153, -0.5721, -0.8061,\n",
      "         0.1021,  0.2366,  0.9292,  0.0304,  1.1626, -0.7143, -0.3444, -0.8535,\n",
      "         0.4514,  0.7035, -1.1063,  0.8396, -0.3076, -0.3470,  0.3874, -0.1116],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.0.bn2.weight', Parameter containing:\n",
      "tensor([ 0.1918,  2.7064,  1.1958, -0.2682,  0.1525,  0.2969,  0.8579,  0.2390,\n",
      "         1.4030,  1.7118,  0.9421,  0.5754,  2.3357,  1.8708,  0.8860,  0.9350,\n",
      "         1.5029,  1.6211,  1.0366,  0.1533,  0.5433,  0.9460,  1.2361,  1.4427,\n",
      "         0.3429,  0.4915,  1.6845,  0.3390,  1.9976,  0.9065,  1.3496,  0.5000,\n",
      "         0.2085,  1.6605,  0.9006,  0.7574,  1.0933,  1.1328,  0.5272,  1.1550,\n",
      "         0.7285,  0.7830,  0.7397,  1.3658,  0.4481,  0.7080,  0.4793,  2.5943,\n",
      "         1.3035,  1.8934,  1.9816,  1.5579,  0.2402,  0.8517,  1.8334, -0.8176,\n",
      "         1.0890,  1.2820,  0.7169,  1.0476,  1.7578,  0.7598,  0.1190,  0.3879],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.0.bn2.bias', Parameter containing:\n",
      "tensor([-4.7962e-02,  1.9527e+00,  4.0213e-01, -7.5554e-01, -1.0008e+00,\n",
      "         2.4913e-01, -3.2746e-03,  7.1841e-02,  4.8242e-01,  1.2248e-01,\n",
      "         3.3647e-01, -7.7480e-02,  7.1844e-01,  8.4340e-01,  2.1383e-01,\n",
      "         1.1658e+00, -1.2379e-01,  1.3748e-01, -3.4958e-01, -3.7720e-01,\n",
      "        -1.8388e-01, -5.3950e-01,  3.1893e-01,  7.3271e-01, -4.8742e-01,\n",
      "        -9.0042e-01,  5.3883e-01, -1.1986e+00,  1.4301e+00, -3.0405e-02,\n",
      "         1.7389e-01,  4.4609e-01, -1.5082e-01,  4.4321e-03,  1.1940e+00,\n",
      "         6.5060e-01, -3.6043e-01, -8.5321e-01,  5.2997e-01,  4.8525e-01,\n",
      "        -6.2064e-01,  2.3901e-01,  2.9170e-01,  1.0004e+00, -6.3918e-01,\n",
      "        -2.7161e-02, -1.1754e+00,  6.2803e-01,  7.6973e-03,  1.9729e-01,\n",
      "         8.4383e-01,  5.6125e-01, -2.7635e-02, -2.8789e-01,  2.4629e-01,\n",
      "        -8.9203e-01, -1.3769e-03,  9.0392e-02, -3.5115e-01, -5.0236e-01,\n",
      "        -1.5010e-01, -3.3943e-01, -4.0646e-01,  2.6453e-01], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('1.0.bn3.weight', Parameter containing:\n",
      "tensor([1.3537, 1.1322, 1.2778, 0.9433, 1.3813, 1.1641, 0.5418, 0.7573, 0.1991,\n",
      "        1.0629, 0.7455, 0.4648, 1.0441, 1.0442, 0.7865, 1.0223, 0.9308, 0.8941,\n",
      "        1.4034, 0.6034, 0.8050, 0.3261, 0.6134, 1.0068, 0.8245, 0.5094, 1.0795,\n",
      "        1.0662, 0.6994, 1.1692, 0.4162, 0.9048, 0.9185, 0.7568, 1.0973, 1.2197,\n",
      "        0.6279, 0.9209, 0.6212, 0.7131, 0.9601, 0.8542, 0.2386, 0.4946, 0.8370,\n",
      "        1.2374, 0.8760, 0.9210, 0.9001, 1.2001, 0.8121, 0.8342, 0.4746, 1.0444,\n",
      "        0.4834, 0.8716, 0.5372, 1.0552, 0.8915, 0.8223, 0.8113, 1.3620, 0.8817,\n",
      "        0.7120, 0.8486, 1.1279, 0.8403, 0.5928, 0.6880, 0.7668, 0.6652, 1.2467,\n",
      "        0.7101, 0.4920, 0.8235, 0.7570, 1.0720, 0.7973, 0.6900, 0.8654, 1.0337,\n",
      "        1.0056, 0.6271, 0.7002, 0.6696, 0.7058, 1.1955, 1.1085, 0.9075, 0.6148,\n",
      "        0.7167, 1.2774, 0.8887, 0.6717, 1.3904, 1.3272, 1.0851, 0.9139, 0.4177,\n",
      "        1.2121, 0.8172, 0.6503, 1.0302, 0.8316, 1.4582, 1.3446, 1.1073, 1.0482,\n",
      "        0.9879, 0.4356, 0.7092, 1.0332, 0.9343, 0.8982, 1.0401, 1.0782, 1.0460,\n",
      "        0.6748, 0.7827, 0.8789, 0.7688, 1.0210, 0.8118, 1.0661, 0.6869, 1.2787,\n",
      "        0.9966, 0.8225, 0.5961, 1.0556, 1.1977, 0.6876, 1.0318, 0.8774, 0.9163,\n",
      "        0.6363, 0.8376, 1.1528, 1.1950, 1.2460, 0.6797, 0.7788, 1.2624, 1.0188,\n",
      "        1.0772, 0.9499, 1.1826, 1.1847, 0.7763, 0.7302, 1.3669, 1.2756, 0.7666,\n",
      "        1.1932, 0.5310, 1.3486, 0.8021, 0.9854, 1.1711, 1.1599, 0.8351, 0.7493,\n",
      "        0.8490, 1.1951, 0.6891, 1.2300, 1.1631, 0.9447, 1.1714, 0.9487, 0.7395,\n",
      "        0.9143, 1.3043, 0.5581, 1.0045, 0.7511, 0.9422, 1.3256, 0.8932, 0.5679,\n",
      "        1.0934, 1.2724, 0.9830, 0.8721, 1.0309, 0.8688, 0.9883, 0.6909, 0.7157,\n",
      "        1.3371, 0.6559, 0.8217, 1.1397, 0.8232, 0.7917, 0.9032, 1.2464, 0.9441,\n",
      "        0.6533, 0.8030, 1.2676, 0.6959, 1.0423, 0.5817, 0.9735, 0.9063, 0.9857,\n",
      "        1.0775, 0.6502, 1.1204, 1.0669, 1.0981, 0.4871, 0.8865, 0.9260, 1.0649,\n",
      "        0.8610, 0.9249, 0.5304, 0.7219, 0.6687, 0.2287, 1.0614, 0.8757, 0.6339,\n",
      "        1.1459, 0.8459, 1.0451, 0.8567, 0.9058, 0.8731, 0.6400, 0.7715, 0.7713,\n",
      "        0.6172, 0.7167, 0.9644, 1.1279, 1.1048, 1.0341, 0.5435, 0.6148, 1.0502,\n",
      "        1.0874, 0.8700, 1.3361, 0.8205, 0.8478, 1.4433, 0.6823, 0.7356, 0.8007,\n",
      "        0.9473, 0.4593, 1.1705, 1.0278], device='cuda:0', requires_grad=True))\n",
      "('1.0.bn3.bias', Parameter containing:\n",
      "tensor([ 0.0532, -0.2178,  0.1719, -0.1789,  0.0555,  0.0566,  0.1834, -0.4297,\n",
      "        -0.0357,  0.3271,  0.3710, -0.2437, -0.2187,  0.2005,  0.0100, -0.0161,\n",
      "        -0.0112, -0.3906,  0.4728, -0.2698, -0.0281, -0.3565,  0.0113, -0.0477,\n",
      "         0.1765, -0.4348,  0.4080,  0.3696, -0.2934,  0.2615, -0.1706,  0.0767,\n",
      "         0.2279, -0.0379, -0.0791,  0.1986,  0.0686, -0.0526, -0.0825,  0.1707,\n",
      "        -0.2924,  0.2636, -0.1888, -0.2851, -0.2811,  0.3591, -0.0618, -0.2302,\n",
      "        -0.1141,  0.1527,  0.0242, -0.1016, -0.4726,  0.6287,  0.2203,  0.2364,\n",
      "        -0.0699, -0.0044, -0.2205,  0.0880,  0.0298, -0.0688,  0.0014, -0.0392,\n",
      "         0.0978, -0.0493, -0.1178,  0.2872,  0.1389, -0.2261, -0.1539,  0.0318,\n",
      "        -0.1160,  0.0159, -0.3539,  0.0768,  0.1179, -0.1194, -0.0200, -0.2018,\n",
      "        -0.1100, -0.1139, -0.3004,  0.0519, -0.1978,  0.4421, -0.0305, -0.1391,\n",
      "        -0.3617, -0.3187, -0.2423,  0.1286, -0.1146,  0.3479,  0.4537,  0.3429,\n",
      "         0.2560, -0.2537, -0.3230,  0.0365,  0.0389,  0.0369,  0.2237,  0.2266,\n",
      "         0.0042,  0.0586, -0.0494,  0.1946, -0.0582, -0.3655, -0.1845,  0.1885,\n",
      "         0.1738,  0.1544,  0.1389,  0.4734, -0.0163,  0.0924, -0.2136, -0.1007,\n",
      "        -0.3029,  0.1751, -0.0426, -0.0928, -0.0633,  0.1881,  0.1880,  0.1428,\n",
      "        -0.2244,  0.0494,  0.0509,  0.0242, -0.0227, -0.3104, -0.3605, -0.2323,\n",
      "        -0.2072,  0.5154, -0.1931,  0.5386,  0.0269,  0.1944, -0.1188, -0.0799,\n",
      "         0.1583,  0.1694, -0.0188,  0.2613,  0.2320, -0.0764,  0.1612,  0.2002,\n",
      "        -0.2737,  0.3765,  0.0361,  0.3360, -0.2207,  0.0911,  0.0569,  0.2030,\n",
      "        -0.1549,  0.1575, -0.0314,  0.3133, -0.4092,  0.0230,  0.4483,  0.4187,\n",
      "         0.0436, -0.0342, -0.1768, -0.0111,  0.3565,  0.0437, -0.0243, -0.3497,\n",
      "        -0.1050,  0.0693,  0.0436, -0.5508,  0.5035,  0.2061, -0.0893, -0.0751,\n",
      "         0.0463, -0.3357, -0.0026, -0.0356,  0.2275,  0.6210, -0.0500, -0.0794,\n",
      "         0.2135,  0.3105,  0.1721, -0.1841,  0.2839, -0.1934, -0.0386,  0.2175,\n",
      "         0.2167,  0.0562,  0.0726, -0.2897,  0.1708,  0.0441, -0.0346,  0.4045,\n",
      "         0.1085,  0.2292,  0.0273, -0.2026, -0.4007, -0.3571, -0.1506,  0.0563,\n",
      "         0.1118, -0.0755, -0.1035, -0.3954,  0.1684, -0.4235, -0.0599,  0.0083,\n",
      "         0.0345,  0.4175, -0.1171, -0.1624, -0.1391, -0.1548, -0.2210,  0.1276,\n",
      "        -0.2734,  0.1854, -0.1881,  0.1229,  0.4143,  0.1692, -0.1649, -0.1840,\n",
      "        -0.0080, -0.1974,  0.2252,  0.2383, -0.1059,  0.1112,  0.2545, -0.1271,\n",
      "         0.0827,  0.1377, -0.0478, -0.2507, -0.0139, -0.3451,  0.0462, -0.0510],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.1.conv1.weight', Parameter containing:\n",
      "tensor([[[-0.7543],\n",
      "         [-0.5580],\n",
      "         [-0.9421],\n",
      "         ...,\n",
      "         [-0.1316],\n",
      "         [-1.0077],\n",
      "         [ 0.7024]],\n",
      "\n",
      "        [[-1.0985],\n",
      "         [ 0.8882],\n",
      "         [-0.3165],\n",
      "         ...,\n",
      "         [-1.0112],\n",
      "         [ 0.1854],\n",
      "         [-1.2170]],\n",
      "\n",
      "        [[ 0.3641],\n",
      "         [ 2.3753],\n",
      "         [-0.0355],\n",
      "         ...,\n",
      "         [ 1.3239],\n",
      "         [ 0.4719],\n",
      "         [-0.4478]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7632],\n",
      "         [ 0.5473],\n",
      "         [-1.4720],\n",
      "         ...,\n",
      "         [-1.3844],\n",
      "         [-1.2453],\n",
      "         [ 2.2169]],\n",
      "\n",
      "        [[ 0.3570],\n",
      "         [-1.3731],\n",
      "         [ 0.8895],\n",
      "         ...,\n",
      "         [ 0.2584],\n",
      "         [ 0.0140],\n",
      "         [ 0.1578]],\n",
      "\n",
      "        [[-0.1959],\n",
      "         [-0.7622],\n",
      "         [ 1.0668],\n",
      "         ...,\n",
      "         [-0.3829],\n",
      "         [ 0.4455],\n",
      "         [-0.5888]]], device='cuda:0', requires_grad=True))\n",
      "('1.1.conv1.bias', Parameter containing:\n",
      "tensor([-0.0540,  0.0187, -0.0370, -0.0122,  0.0356,  0.0188, -0.0406, -0.0501,\n",
      "         0.0420,  0.0257,  0.0592, -0.0306, -0.0230, -0.0033, -0.0176, -0.0459,\n",
      "        -0.0445, -0.0162, -0.0283, -0.0257, -0.0217,  0.0338,  0.0523,  0.0509,\n",
      "         0.0502, -0.0593, -0.0475,  0.0304,  0.0471,  0.0504,  0.0294,  0.0188,\n",
      "        -0.0178, -0.0508,  0.0192,  0.0569, -0.0620, -0.0384,  0.0617,  0.0096,\n",
      "         0.0339, -0.0172,  0.0429, -0.0140,  0.0503,  0.0498,  0.0503, -0.0508,\n",
      "        -0.0365, -0.0612,  0.0420,  0.0247, -0.0443,  0.0357, -0.0203,  0.0057,\n",
      "        -0.0065, -0.0519,  0.0488,  0.0358, -0.0508,  0.0089, -0.0319,  0.0413],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.1.conv2.weight', Parameter containing:\n",
      "tensor([[[ 0.0599,  0.2341,  0.2935],\n",
      "         [ 0.5356,  0.3058, -0.1161],\n",
      "         [ 0.2853,  0.6813, -1.2039],\n",
      "         ...,\n",
      "         [-0.0888, -0.2499, -0.2654],\n",
      "         [ 0.4124, -0.3184,  0.3595],\n",
      "         [-0.4294,  0.6567, -0.7604]],\n",
      "\n",
      "        [[ 0.7982,  0.4851, -0.3510],\n",
      "         [ 0.0686, -0.9475, -0.0917],\n",
      "         [-0.5153, -0.7933,  1.0449],\n",
      "         ...,\n",
      "         [-0.3719, -0.2639,  0.2804],\n",
      "         [ 0.6887,  0.5182,  0.3544],\n",
      "         [ 0.3522, -0.1024,  0.6006]],\n",
      "\n",
      "        [[ 0.5903, -0.1198, -0.1256],\n",
      "         [ 0.6605,  0.6438,  1.2943],\n",
      "         [ 0.0077,  0.9078,  0.1192],\n",
      "         ...,\n",
      "         [ 0.1177, -0.2981, -0.2519],\n",
      "         [-0.9360,  0.5950,  0.2939],\n",
      "         [ 0.4204,  0.6585, -0.7329]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0230, -0.8389, -0.9002],\n",
      "         [-0.2911,  0.4961,  1.4068],\n",
      "         [-1.1630,  1.4884,  0.4221],\n",
      "         ...,\n",
      "         [ 0.1489,  2.1116,  0.9033],\n",
      "         [ 0.3321,  0.0071, -1.0388],\n",
      "         [-0.0389,  1.0329, -0.8110]],\n",
      "\n",
      "        [[-0.0304,  0.0564, -0.4627],\n",
      "         [-0.2595, -0.1546,  0.1047],\n",
      "         [-0.2406,  0.6565, -0.1313],\n",
      "         ...,\n",
      "         [ 1.2068,  0.9066,  0.2730],\n",
      "         [-0.3360, -0.5614,  0.0798],\n",
      "         [-0.7255, -0.3486, -0.5810]],\n",
      "\n",
      "        [[ 0.4225, -1.1866, -0.7045],\n",
      "         [-0.3606,  1.0078, -0.0276],\n",
      "         [-0.6661,  1.3018, -0.7168],\n",
      "         ...,\n",
      "         [-0.4177,  0.8045,  0.6702],\n",
      "         [-0.3417,  1.2450,  0.0545],\n",
      "         [-0.5887, -0.3381, -0.6730]]], device='cuda:0', requires_grad=True))\n",
      "('1.1.conv2.bias', Parameter containing:\n",
      "tensor([ 0.0720,  0.0673,  0.0282,  0.0016,  0.0421, -0.0154,  0.0106,  0.0211,\n",
      "         0.0350, -0.0049, -0.0603, -0.0422,  0.0442,  0.0364,  0.0226, -0.0199,\n",
      "         0.0550, -0.0306,  0.0214, -0.0547, -0.0186, -0.0107, -0.0085, -0.0268,\n",
      "        -0.0149,  0.0048, -0.0194, -0.0264, -0.0096, -0.0271,  0.0549,  0.0557,\n",
      "        -0.0673, -0.0449,  0.0284,  0.0668, -0.0399,  0.0004, -0.0453, -0.0327,\n",
      "         0.0089,  0.0312, -0.0462, -0.0245, -0.0604,  0.0187, -0.0357, -0.0519,\n",
      "        -0.0208,  0.0384, -0.0344, -0.0030, -0.0238, -0.0254,  0.0191,  0.0460,\n",
      "         0.0348,  0.0459, -0.0527,  0.0151, -0.0342,  0.0403, -0.0444, -0.0489],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.1.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.2788],\n",
      "         [-0.1323],\n",
      "         [-0.2234],\n",
      "         ...,\n",
      "         [-0.4670],\n",
      "         [-0.0361],\n",
      "         [ 0.1948]],\n",
      "\n",
      "        [[-0.1704],\n",
      "         [-0.1600],\n",
      "         [ 0.0411],\n",
      "         ...,\n",
      "         [-0.2655],\n",
      "         [-0.2366],\n",
      "         [ 0.0716]],\n",
      "\n",
      "        [[ 0.1431],\n",
      "         [ 0.3944],\n",
      "         [-0.0551],\n",
      "         ...,\n",
      "         [-0.2398],\n",
      "         [-0.0515],\n",
      "         [-0.2404]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4241],\n",
      "         [-0.4375],\n",
      "         [ 0.0698],\n",
      "         ...,\n",
      "         [ 0.2584],\n",
      "         [ 0.1626],\n",
      "         [-0.0374]],\n",
      "\n",
      "        [[-0.0007],\n",
      "         [-0.0983],\n",
      "         [-0.1073],\n",
      "         ...,\n",
      "         [-0.1411],\n",
      "         [ 0.4351],\n",
      "         [-0.3591]],\n",
      "\n",
      "        [[ 0.1894],\n",
      "         [-0.4817],\n",
      "         [ 0.2152],\n",
      "         ...,\n",
      "         [ 0.5993],\n",
      "         [-0.2261],\n",
      "         [ 0.0067]]], device='cuda:0', requires_grad=True))\n",
      "('1.1.conv3.bias', Parameter containing:\n",
      "tensor([-0.0251,  0.1094,  0.1222,  0.0705,  0.0352,  0.0833, -0.0740, -0.0755,\n",
      "         0.0857,  0.0614,  0.0159,  0.1059,  0.0650,  0.0421,  0.1160,  0.0916,\n",
      "         0.0486, -0.1138, -0.0341,  0.0169, -0.0240,  0.0371, -0.1047, -0.0349,\n",
      "        -0.0447, -0.0228,  0.1206, -0.0886, -0.0192, -0.0065,  0.0281,  0.0160,\n",
      "         0.0611,  0.1066,  0.0204,  0.0109, -0.0306,  0.0149,  0.0895, -0.0833,\n",
      "         0.1112,  0.1178,  0.0802, -0.0232, -0.0289,  0.0995, -0.0901,  0.0933,\n",
      "        -0.0594,  0.0241, -0.0948, -0.0086,  0.0780, -0.0705, -0.1107,  0.0074,\n",
      "         0.0737, -0.0702, -0.0027, -0.0663,  0.0348,  0.0198,  0.1187, -0.0162,\n",
      "        -0.0685,  0.1009, -0.0699,  0.0764, -0.0731,  0.1140, -0.0515,  0.0385,\n",
      "         0.0514, -0.1134,  0.1062,  0.0607,  0.1128,  0.0177, -0.0134, -0.0638,\n",
      "         0.0256, -0.0452,  0.1192,  0.0155,  0.0995,  0.0181, -0.0896, -0.1240,\n",
      "        -0.0723, -0.0007, -0.0841, -0.1160,  0.0686, -0.0422,  0.1222, -0.0726,\n",
      "         0.0704, -0.0525,  0.0042,  0.0471, -0.0872, -0.0710,  0.1136, -0.0408,\n",
      "         0.0096, -0.0995,  0.0220,  0.0813,  0.0121, -0.0558, -0.0446, -0.0342,\n",
      "         0.0857, -0.1167, -0.0769, -0.0548,  0.0381,  0.0608,  0.0171,  0.0821,\n",
      "         0.0648, -0.0771, -0.1156,  0.0023, -0.0005,  0.0380, -0.0985, -0.0101,\n",
      "        -0.0819, -0.0741,  0.0858, -0.0050,  0.0620, -0.0829, -0.1224,  0.1068,\n",
      "         0.0086, -0.1023,  0.0635,  0.0617, -0.0058, -0.1162, -0.0512, -0.0822,\n",
      "         0.0574, -0.0346,  0.1190,  0.1152,  0.0496,  0.0002,  0.0040,  0.0344,\n",
      "         0.1072,  0.1067,  0.0408,  0.0423, -0.0340, -0.0175,  0.0306,  0.0165,\n",
      "         0.0956,  0.1219,  0.0630, -0.0764,  0.0596, -0.1078, -0.0067, -0.0235,\n",
      "        -0.0696,  0.0132,  0.1193, -0.0623, -0.0516, -0.0456,  0.1082, -0.0515,\n",
      "         0.0043,  0.0520, -0.0157,  0.0821,  0.0482,  0.0520, -0.0544,  0.1195,\n",
      "        -0.0562,  0.1137, -0.0575,  0.0383,  0.0999,  0.0181,  0.0043,  0.1216,\n",
      "         0.0967,  0.0238, -0.1214, -0.0728,  0.0056, -0.1067, -0.0798,  0.1037,\n",
      "        -0.1016,  0.0842, -0.0202,  0.0048,  0.0068,  0.0369,  0.0285,  0.0623,\n",
      "         0.1156, -0.0391, -0.0905, -0.0619,  0.0500,  0.0026,  0.0007,  0.0466,\n",
      "        -0.0949, -0.0375,  0.0436,  0.0194, -0.1073, -0.0913, -0.1031, -0.0753,\n",
      "        -0.0231,  0.0180, -0.1231,  0.0522,  0.0982,  0.0007,  0.0537, -0.0753,\n",
      "        -0.0462, -0.1098,  0.0622, -0.0113,  0.1070, -0.0623,  0.0808, -0.0599,\n",
      "        -0.0549,  0.0737,  0.0546, -0.0652,  0.1094,  0.0839, -0.0385, -0.0023,\n",
      "         0.0650, -0.0832,  0.0724,  0.0295,  0.1173, -0.0941, -0.0112,  0.1058],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.1.bn1.weight', Parameter containing:\n",
      "tensor([1.3421, 0.5511, 0.7079, 0.6991, 2.0166, 1.6234, 0.4802, 1.0424, 1.3006,\n",
      "        1.3653, 1.0973, 0.8158, 1.2847, 0.5409, 1.6049, 1.7254, 0.8973, 1.4837,\n",
      "        0.1349, 0.7095, 0.9156, 0.8562, 0.1766, 1.5945, 0.5581, 1.0756, 1.6440,\n",
      "        1.4667, 0.4080, 0.3213, 1.3581, 0.3033, 1.1013, 0.9698, 0.8650, 0.5609,\n",
      "        0.3602, 1.5414, 1.5920, 0.9832, 2.2975, 0.9550, 1.0662, 0.7880, 0.9744,\n",
      "        0.7566, 1.7567, 0.9312, 0.0541, 1.3681, 1.4123, 0.7625, 0.5310, 0.9225,\n",
      "        1.3149, 1.3248, 0.4725, 1.3208, 0.7226, 0.4385, 1.1249, 1.2934, 1.0010,\n",
      "        2.1040], device='cuda:0', requires_grad=True))\n",
      "('1.1.bn1.bias', Parameter containing:\n",
      "tensor([ 0.4826, -0.3549, -0.3336, -0.0928,  0.5411,  0.4411, -0.4777, -0.0074,\n",
      "         0.3467,  0.5613, -0.7585, -0.2740,  0.4267, -0.0765,  0.6632,  0.4668,\n",
      "        -0.4340,  0.6332, -0.4282, -0.1826, -0.2812,  0.0012, -0.8522,  0.6379,\n",
      "        -0.5806,  0.4039,  0.7063,  0.4876, -0.3006, -0.3712, -0.4528, -0.5314,\n",
      "         0.0125,  0.5158, -0.0475, -0.6424, -0.1802,  0.2387,  0.3016, -0.5603,\n",
      "         1.1157,  0.1736, -0.2189, -0.1542, -0.2402, -0.1593,  0.1104,  0.5505,\n",
      "        -0.1522,  0.1338,  0.4164,  0.2270, -0.3552, -0.0609, -0.1738,  0.6318,\n",
      "         0.1566, -0.1176,  0.0736, -0.3192,  0.4379,  0.0037, -0.4767,  0.4503],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.1.bn2.weight', Parameter containing:\n",
      "tensor([1.1680, 1.0128, 1.2188, 1.1871, 0.6307, 1.3431, 0.7623, 1.3832, 1.3078,\n",
      "        1.2811, 1.0657, 1.3564, 0.4926, 0.1140, 1.5550, 1.4257, 0.9335, 0.4430,\n",
      "        1.1133, 0.8897, 0.8581, 0.9598, 1.0045, 1.1447, 1.5158, 1.2097, 1.0833,\n",
      "        1.3080, 1.3734, 1.1286, 1.2519, 1.0237, 0.4588, 1.1775, 1.0525, 0.9494,\n",
      "        0.7760, 1.0290, 0.9941, 1.7024, 1.1719, 0.4895, 1.2098, 0.9833, 0.8063,\n",
      "        1.0151, 1.3949, 1.1309, 1.4557, 1.2226, 1.5556, 0.8016, 1.0750, 0.8048,\n",
      "        0.3524, 0.9295, 1.1149, 1.1494, 1.0480, 1.0199, 1.0544, 1.2990, 0.7017,\n",
      "        1.0853], device='cuda:0', requires_grad=True))\n",
      "('1.1.bn2.bias', Parameter containing:\n",
      "tensor([-1.8486e-01,  1.0146e-01,  9.3403e-02,  4.1421e-01,  1.4607e-01,\n",
      "        -1.6792e-01, -3.5964e-01,  1.1413e+00,  5.4032e-01,  3.8797e-01,\n",
      "         1.4389e-01, -2.5061e-04,  1.4445e-02, -7.7565e-01, -3.5955e-02,\n",
      "         4.6671e-01,  1.6797e-01, -3.5370e-01,  2.5219e-01, -3.6719e-01,\n",
      "        -2.7525e-01,  3.4658e-01, -1.8002e-01,  8.9344e-02,  2.3268e-01,\n",
      "        -4.1711e-01, -1.0209e-01,  2.6150e-01,  3.6471e-01, -3.8930e-01,\n",
      "         7.5260e-01,  5.4566e-01, -3.6423e-01,  3.5190e-01, -9.9158e-02,\n",
      "        -6.7194e-01, -2.8465e-01,  1.3557e-01,  5.5442e-02,  3.9778e-01,\n",
      "         1.3808e-01, -2.4971e-01,  1.5412e-01,  3.0011e-01, -4.7735e-01,\n",
      "        -3.4596e-01,  2.2985e-01,  4.1353e-02,  7.4373e-01,  3.9170e-01,\n",
      "         3.1037e-01, -2.1760e-01,  1.8477e-02, -6.5862e-02, -5.2128e-01,\n",
      "         3.9811e-01,  5.9197e-01,  2.7308e-01, -2.4247e-01, -6.6218e-02,\n",
      "        -1.8371e-01,  2.1878e-01, -2.7345e-01, -1.4982e-01], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('1.1.bn3.weight', Parameter containing:\n",
      "tensor([1.1650, 0.8823, 0.7537, 0.5182, 0.8043, 1.0694, 0.9449, 0.8866, 0.8283,\n",
      "        0.7003, 0.6877, 1.0026, 1.0824, 1.2651, 0.7480, 0.9220, 0.8169, 0.9387,\n",
      "        0.5940, 0.7864, 0.9697, 1.0762, 1.1596, 1.0811, 1.0083, 0.7799, 0.6568,\n",
      "        0.8797, 1.1605, 0.9936, 0.6757, 0.6136, 0.4285, 0.8514, 0.7029, 0.9253,\n",
      "        1.0188, 0.9420, 0.8281, 0.9749, 1.1245, 0.7254, 0.9440, 0.6080, 0.8884,\n",
      "        0.7680, 0.9657, 1.1099, 1.0397, 1.1355, 0.4098, 0.5856, 0.7776, 0.9334,\n",
      "        0.7090, 1.0178, 0.9634, 0.6058, 1.0184, 0.8763, 1.0795, 1.1095, 0.7726,\n",
      "        0.9454, 0.8396, 1.0078, 0.8195, 0.6562, 0.6503, 1.2112, 0.8760, 0.9811,\n",
      "        0.9466, 1.1491, 0.9031, 0.9492, 0.7451, 1.0041, 0.5921, 0.9579, 0.8115,\n",
      "        0.8598, 1.0297, 0.7220, 1.1501, 0.8640, 0.9944, 1.0216, 0.9111, 1.2405,\n",
      "        0.7854, 0.8403, 0.8418, 1.1715, 1.1319, 0.6504, 0.4972, 0.9599, 0.9860,\n",
      "        0.9207, 0.8951, 0.9766, 0.9200, 0.8926, 0.8301, 1.0714, 0.8576, 1.0717,\n",
      "        0.9766, 0.8924, 0.7977, 0.8393, 1.0014, 0.7713, 0.7856, 1.0405, 1.0224,\n",
      "        0.6407, 0.9787, 0.7450, 0.7365, 0.7792, 0.8141, 1.0054, 0.9196, 0.8184,\n",
      "        1.1407, 1.0331, 0.9624, 0.8172, 0.7961, 0.8084, 0.7211, 0.9814, 1.0231,\n",
      "        0.9108, 0.6792, 0.8498, 1.0608, 0.9966, 1.0364, 0.5035, 0.7970, 0.8318,\n",
      "        0.8451, 0.7861, 0.9573, 0.8782, 0.5487, 1.0054, 0.7665, 1.0258, 1.0953,\n",
      "        1.0799, 0.7921, 1.0434, 1.3034, 0.9466, 0.7008, 0.8229, 0.9783, 0.9418,\n",
      "        1.0812, 0.9404, 0.9361, 0.9507, 0.9547, 0.7279, 0.9215, 0.7073, 0.9478,\n",
      "        1.0131, 0.9850, 0.5911, 0.8934, 0.9421, 1.1002, 0.5029, 1.0269, 0.6837,\n",
      "        0.9941, 0.6844, 0.8499, 0.9345, 0.8894, 0.7469, 0.9557, 0.9676, 0.5146,\n",
      "        0.7001, 0.8511, 0.8963, 0.7030, 0.8292, 0.7248, 1.0065, 0.5723, 1.2766,\n",
      "        0.6685, 0.7804, 0.8076, 1.0329, 0.8761, 1.3027, 0.6941, 0.9229, 1.1025,\n",
      "        0.9093, 0.7761, 0.6630, 0.8963, 0.7205, 1.2229, 0.8405, 1.1350, 1.1598,\n",
      "        0.8390, 0.8766, 0.5890, 1.0545, 0.6840, 0.7407, 1.0319, 0.9834, 0.8764,\n",
      "        0.7844, 0.8969, 1.1300, 1.2173, 0.8599, 1.1218, 0.5212, 1.0949, 1.2819,\n",
      "        0.9708, 0.6520, 0.5838, 1.1201, 0.9234, 0.6093, 0.7614, 1.2014, 0.9649,\n",
      "        0.6920, 1.2534, 0.7865, 0.9272, 0.6872, 0.9152, 0.9003, 0.8574, 0.9253,\n",
      "        0.9170, 0.8627, 0.8681, 0.8210], device='cuda:0', requires_grad=True))\n",
      "('1.1.bn3.bias', Parameter containing:\n",
      "tensor([-0.0169, -0.1871, -0.0666, -0.0029, -0.1203, -0.0699, -0.0293, -0.2124,\n",
      "         0.0333,  0.2689,  0.0758, -0.0758, -0.0729,  0.0967, -0.0866,  0.0601,\n",
      "        -0.1692,  0.0190,  0.0704, -0.1355,  0.0724, -0.0968,  0.0276, -0.0361,\n",
      "        -0.0244, -0.0590, -0.0831, -0.0046, -0.1563,  0.1628, -0.1166,  0.1428,\n",
      "        -0.0180, -0.2072, -0.0226, -0.1106, -0.0367, -0.0813,  0.1305,  0.0017,\n",
      "         0.0103,  0.0464, -0.1315, -0.1810, -0.0667,  0.1326, -0.0162, -0.1105,\n",
      "         0.0226,  0.0345, -0.1280, -0.0099, -0.1418,  0.0406, -0.0687,  0.1236,\n",
      "        -0.0443, -0.0211, -0.0930, -0.1647, -0.1482, -0.0459, -0.2055, -0.1998,\n",
      "        -0.1012,  0.0920,  0.0323,  0.0380, -0.0460,  0.0914, -0.3163, -0.1134,\n",
      "        -0.0106, -0.0540,  0.1097, -0.1390, -0.0845,  0.0413, -0.0904, -0.0122,\n",
      "        -0.0678, -0.1000,  0.0010, -0.0207,  0.1304,  0.0919, -0.0902, -0.0850,\n",
      "        -0.2188, -0.0102,  0.0457,  0.2143,  0.0153,  0.1545,  0.0909, -0.0244,\n",
      "         0.1092, -0.0984, -0.0014, -0.1074,  0.0664,  0.0732,  0.1735,  0.0625,\n",
      "        -0.1430,  0.0339,  0.0128,  0.0268, -0.1088, -0.3334, -0.2245, -0.2306,\n",
      "         0.0209, -0.0342,  0.0336,  0.2070, -0.0450, -0.0489, -0.1308, -0.1800,\n",
      "        -0.2621, -0.1199,  0.1411,  0.1862,  0.0291,  0.0704,  0.1195,  0.1495,\n",
      "         0.0262, -0.1732, -0.1969,  0.1006, -0.1171,  0.1307, -0.0072, -0.0831,\n",
      "        -0.2423,  0.1341, -0.0680,  0.0905,  0.0310, -0.0403, -0.2080, -0.0570,\n",
      "        -0.0173,  0.1664, -0.2320,  0.0364,  0.0394,  0.2163, -0.2110,  0.0190,\n",
      "        -0.0558,  0.0042,  0.0487, -0.1277, -0.0116,  0.1337, -0.2938,  0.0123,\n",
      "         0.0431,  0.1431, -0.2053,  0.0039, -0.0860, -0.1448,  0.1180, -0.0324,\n",
      "        -0.0521, -0.0076, -0.1544,  0.0107,  0.1495, -0.3512,  0.0028, -0.1409,\n",
      "         0.0505, -0.1241, -0.0161,  0.0319, -0.0116,  0.0412, -0.1098,  0.1036,\n",
      "        -0.0611, -0.1555, -0.0500, -0.0277,  0.0689, -0.0262, -0.0594, -0.1387,\n",
      "         0.1384,  0.0439,  0.1312,  0.0994,  0.0733,  0.0111, -0.1186,  0.0440,\n",
      "         0.0325, -0.0092,  0.0864, -0.1916,  0.0406,  0.0395,  0.0849,  0.1121,\n",
      "         0.0776,  0.0873, -0.0277,  0.0188,  0.0269, -0.0163,  0.1387, -0.0034,\n",
      "         0.0350, -0.0128, -0.2634, -0.0199,  0.0270,  0.0827,  0.1364, -0.0161,\n",
      "        -0.0666,  0.0579, -0.0138, -0.0202, -0.1235, -0.2461,  0.0768, -0.0895,\n",
      "        -0.0492,  0.0012,  0.1290,  0.0201,  0.0959,  0.0048,  0.0150, -0.2115,\n",
      "        -0.1468,  0.0718, -0.0653,  0.1403,  0.1615, -0.1972, -0.1421,  0.0626,\n",
      "        -0.0907, -0.0070, -0.1468,  0.0259,  0.0396, -0.0155, -0.2159,  0.0038],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.2.conv1.weight', Parameter containing:\n",
      "tensor([[[ 0.0612],\n",
      "         [ 0.8296],\n",
      "         [ 0.0921],\n",
      "         ...,\n",
      "         [ 0.2322],\n",
      "         [ 0.1895],\n",
      "         [ 0.2105]],\n",
      "\n",
      "        [[-0.6659],\n",
      "         [-0.1577],\n",
      "         [ 0.0160],\n",
      "         ...,\n",
      "         [-0.6384],\n",
      "         [-0.3947],\n",
      "         [ 0.1380]],\n",
      "\n",
      "        [[-0.1557],\n",
      "         [-0.0855],\n",
      "         [ 0.8496],\n",
      "         ...,\n",
      "         [-0.3910],\n",
      "         [ 0.3241],\n",
      "         [ 0.7732]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7867],\n",
      "         [-0.4760],\n",
      "         [ 0.4753],\n",
      "         ...,\n",
      "         [ 0.8017],\n",
      "         [-0.1639],\n",
      "         [-0.3406]],\n",
      "\n",
      "        [[-1.2348],\n",
      "         [ 0.1622],\n",
      "         [-0.3207],\n",
      "         ...,\n",
      "         [-0.5247],\n",
      "         [-1.1731],\n",
      "         [-0.1035]],\n",
      "\n",
      "        [[ 0.6993],\n",
      "         [-0.6182],\n",
      "         [-0.5054],\n",
      "         ...,\n",
      "         [ 0.6296],\n",
      "         [-0.8175],\n",
      "         [-0.1370]]], device='cuda:0', requires_grad=True))\n",
      "('1.2.conv1.bias', Parameter containing:\n",
      "tensor([ 0.0253,  0.0284, -0.0126,  0.0553,  0.0090,  0.0546, -0.0610, -0.0407,\n",
      "         0.0396, -0.0459, -0.0164, -0.0147, -0.0174, -0.0240,  0.0072, -0.0175,\n",
      "        -0.0471,  0.0046, -0.0244, -0.0423,  0.0619,  0.0472,  0.0603, -0.0423,\n",
      "         0.0226, -0.0037,  0.0051,  0.0570,  0.0299, -0.0567,  0.0563,  0.0519,\n",
      "         0.0329, -0.0105, -0.0206, -0.0326,  0.0315,  0.0020,  0.0033,  0.0276,\n",
      "         0.0447,  0.0585,  0.0494,  0.0039,  0.0387,  0.0328,  0.0329,  0.0349,\n",
      "         0.0174,  0.0567, -0.0353, -0.0432,  0.0329,  0.0078, -0.0391, -0.0290,\n",
      "        -0.0465, -0.0587,  0.0189,  0.0124, -0.0123,  0.0272, -0.0262,  0.0129],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.2.conv2.weight', Parameter containing:\n",
      "tensor([[[-0.0968,  0.6608,  0.2563],\n",
      "         [ 0.1310,  0.1359, -0.4034],\n",
      "         [-0.2930, -0.0716, -0.0510],\n",
      "         ...,\n",
      "         [ 0.5403, -0.0634, -0.0036],\n",
      "         [-0.1877, -0.1665,  0.3506],\n",
      "         [-0.5734, -1.0821, -0.3178]],\n",
      "\n",
      "        [[-0.6006,  0.0252, -0.4659],\n",
      "         [-0.1865, -0.1512,  0.3809],\n",
      "         [-0.4664,  0.2097,  0.3130],\n",
      "         ...,\n",
      "         [-0.4085, -0.6021, -0.2438],\n",
      "         [-0.9586, -0.1594, -0.0612],\n",
      "         [-0.5212, -0.3549, -0.8550]],\n",
      "\n",
      "        [[ 0.5207,  0.1716, -0.2452],\n",
      "         [ 0.0227, -0.1005, -0.8023],\n",
      "         [-0.1789, -0.6253,  0.2657],\n",
      "         ...,\n",
      "         [-0.3308, -0.9757,  0.2116],\n",
      "         [-0.9521,  0.2430, -0.8017],\n",
      "         [-0.2750, -0.7451,  0.1784]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1111, -0.0680,  0.1399],\n",
      "         [-0.4688,  0.2958, -1.0932],\n",
      "         [-0.3865,  0.4644, -0.3174],\n",
      "         ...,\n",
      "         [-0.2460,  0.0192,  0.1239],\n",
      "         [ 0.3909,  0.2710, -0.2996],\n",
      "         [-0.1056, -0.5554,  0.1342]],\n",
      "\n",
      "        [[-0.0510,  0.6981,  0.0153],\n",
      "         [ 0.5321, -0.1228,  0.2493],\n",
      "         [ 0.0160,  0.8478,  0.2959],\n",
      "         ...,\n",
      "         [-0.3324,  0.3533, -0.1725],\n",
      "         [-0.3832,  0.4595, -0.1216],\n",
      "         [ 0.3312, -0.7171, -0.6922]],\n",
      "\n",
      "        [[ 0.7546,  0.0816,  0.4382],\n",
      "         [ 0.4027,  0.5066, -0.0543],\n",
      "         [ 0.1526,  0.1513,  0.1223],\n",
      "         ...,\n",
      "         [ 0.2355,  0.3095,  0.7223],\n",
      "         [-0.5470,  0.2381, -0.1520],\n",
      "         [-0.0965,  0.0271, -0.0144]]], device='cuda:0', requires_grad=True))\n",
      "('1.2.conv2.bias', Parameter containing:\n",
      "tensor([ 0.0020,  0.0365,  0.0511,  0.0527, -0.0088,  0.0359,  0.0132,  0.0198,\n",
      "        -0.0048,  0.0337,  0.0283, -0.0530, -0.0505,  0.0590, -0.0545, -0.0200,\n",
      "        -0.0618, -0.0538,  0.0418, -0.0150, -0.0040,  0.0522,  0.0606, -0.0176,\n",
      "        -0.0391, -0.0429,  0.0383, -0.0279,  0.0633, -0.0005,  0.0353,  0.0593,\n",
      "        -0.0091,  0.0343, -0.0609,  0.0006,  0.0114, -0.0504, -0.0383, -0.0257,\n",
      "         0.0076,  0.0203, -0.0043,  0.0409,  0.0552,  0.0407,  0.0155, -0.0570,\n",
      "         0.0143,  0.0480, -0.0231, -0.0138,  0.0411,  0.0113, -0.0503,  0.0024,\n",
      "        -0.0716, -0.0194,  0.0636, -0.0049,  0.0061,  0.0693,  0.0678, -0.0716],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.2.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.2075],\n",
      "         [-0.1948],\n",
      "         [-0.1416],\n",
      "         ...,\n",
      "         [-0.1507],\n",
      "         [ 0.1763],\n",
      "         [ 0.1812]],\n",
      "\n",
      "        [[-0.1265],\n",
      "         [ 0.1219],\n",
      "         [ 0.0122],\n",
      "         ...,\n",
      "         [ 0.0405],\n",
      "         [ 0.1449],\n",
      "         [ 0.2000]],\n",
      "\n",
      "        [[ 0.0762],\n",
      "         [-0.0890],\n",
      "         [-0.0968],\n",
      "         ...,\n",
      "         [ 0.3981],\n",
      "         [-0.2972],\n",
      "         [-0.1084]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0498],\n",
      "         [ 0.0551],\n",
      "         [-0.0227],\n",
      "         ...,\n",
      "         [ 0.3446],\n",
      "         [ 0.0065],\n",
      "         [ 0.0622]],\n",
      "\n",
      "        [[-0.1603],\n",
      "         [-0.1186],\n",
      "         [ 0.0608],\n",
      "         ...,\n",
      "         [-0.0328],\n",
      "         [ 0.1177],\n",
      "         [ 0.0966]],\n",
      "\n",
      "        [[ 0.0630],\n",
      "         [ 0.1116],\n",
      "         [ 0.1931],\n",
      "         ...,\n",
      "         [ 0.1684],\n",
      "         [ 0.2430],\n",
      "         [-0.1863]]], device='cuda:0', requires_grad=True))\n",
      "('1.2.conv3.bias', Parameter containing:\n",
      "tensor([-0.1009, -0.0386,  0.0106,  0.0706, -0.0655, -0.0389, -0.0317, -0.0302,\n",
      "        -0.0388,  0.0918, -0.1015, -0.0208, -0.1144, -0.1181,  0.0826, -0.0431,\n",
      "         0.1191,  0.0128, -0.0787,  0.0114, -0.1170, -0.0795, -0.1225,  0.1119,\n",
      "         0.1011,  0.0533,  0.0744, -0.0540, -0.0120, -0.0615, -0.0206, -0.0942,\n",
      "        -0.0817,  0.0349, -0.0475, -0.0611,  0.0519, -0.0589,  0.0326, -0.0479,\n",
      "         0.1183, -0.0646, -0.1078, -0.0752, -0.0821, -0.0857,  0.0195,  0.1050,\n",
      "        -0.0173, -0.0464, -0.1132, -0.1018, -0.0829, -0.0641, -0.0014, -0.0897,\n",
      "         0.0066,  0.0651,  0.1160, -0.0746,  0.0844,  0.0616,  0.0042, -0.1057,\n",
      "         0.1061, -0.0767, -0.0844,  0.0549,  0.0864,  0.0198, -0.1071, -0.0280,\n",
      "         0.0474,  0.0912,  0.0686, -0.0472, -0.0657, -0.0176, -0.0914, -0.0045,\n",
      "         0.0252, -0.0674, -0.0333, -0.1213,  0.0671,  0.1155,  0.0121,  0.0658,\n",
      "        -0.0698,  0.0656,  0.0737,  0.0686,  0.1249,  0.0911,  0.0789,  0.0227,\n",
      "         0.1155,  0.0934, -0.0565,  0.1069, -0.0429,  0.1024, -0.1203, -0.1191,\n",
      "         0.0784, -0.0445,  0.0219, -0.0710, -0.0130, -0.0239,  0.0316,  0.0930,\n",
      "         0.1108,  0.0348,  0.0047, -0.0526,  0.0027,  0.1022, -0.0844, -0.1097,\n",
      "        -0.0600,  0.0028, -0.0970,  0.0321, -0.0011,  0.0560,  0.0111, -0.1008,\n",
      "        -0.0527, -0.1189, -0.0425,  0.0885, -0.1093,  0.1189,  0.0193,  0.0961,\n",
      "        -0.0324,  0.0065, -0.0758,  0.0024, -0.0531, -0.0271,  0.0831, -0.1145,\n",
      "        -0.1059, -0.0268, -0.1146,  0.1106, -0.0453, -0.0845, -0.0295, -0.0167,\n",
      "        -0.0513,  0.0136,  0.0581,  0.0300,  0.0473,  0.0215, -0.0334,  0.0546,\n",
      "         0.0142,  0.1155, -0.1012, -0.0775,  0.0175, -0.0873, -0.0836,  0.0036,\n",
      "         0.0345, -0.1078,  0.0125,  0.0092, -0.0051,  0.0916,  0.0919,  0.0246,\n",
      "         0.1050, -0.0487,  0.0962, -0.1156, -0.1127, -0.0989,  0.0457,  0.1054,\n",
      "        -0.1216,  0.0774, -0.0468,  0.1169, -0.0124,  0.1144, -0.1221,  0.0541,\n",
      "         0.0267,  0.1118, -0.0292, -0.0596,  0.0871, -0.1186, -0.0362, -0.0920,\n",
      "         0.1101,  0.0232,  0.1148,  0.0339,  0.0134, -0.0245, -0.0474,  0.0523,\n",
      "         0.1044, -0.0476,  0.0048,  0.0355,  0.0897, -0.0934, -0.0171, -0.0695,\n",
      "         0.0257, -0.0631, -0.0545, -0.0540, -0.0486, -0.0608, -0.0553,  0.1148,\n",
      "        -0.0509, -0.0961, -0.0681,  0.0667,  0.1134,  0.0221, -0.0837,  0.0729,\n",
      "        -0.0124, -0.0107, -0.1069, -0.0073, -0.0344,  0.0437,  0.0175,  0.0915,\n",
      "         0.0850,  0.0484, -0.0844, -0.0635, -0.0566,  0.1179,  0.0909, -0.0507,\n",
      "        -0.0313, -0.0471,  0.0164, -0.0865, -0.1232,  0.0422,  0.0488, -0.0549],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.2.bn1.weight', Parameter containing:\n",
      "tensor([1.0439, 1.0309, 1.1806, 1.2467, 1.1592, 1.2462, 1.1371, 1.2056, 1.0894,\n",
      "        1.3846, 0.9452, 0.9417, 0.9494, 0.8333, 1.5915, 0.9695, 1.1391, 1.0700,\n",
      "        1.0270, 0.7012, 1.3013, 0.9715, 0.8967, 0.7655, 0.7755, 1.0051, 1.0992,\n",
      "        0.8471, 0.9020, 1.4332, 0.9961, 1.1933, 0.9823, 1.0830, 0.8173, 1.0235,\n",
      "        1.5358, 1.2149, 1.2147, 1.3505, 0.8754, 1.0789, 1.0528, 1.2945, 0.0923,\n",
      "        1.2716, 0.4589, 1.1869, 1.1498, 1.5226, 1.2501, 1.0062, 0.9068, 1.3562,\n",
      "        1.5811, 0.7341, 1.2382, 1.6018, 0.8806, 1.1903, 0.8639, 1.1101, 0.2718,\n",
      "        0.8763], device='cuda:0', requires_grad=True))\n",
      "('1.2.bn1.bias', Parameter containing:\n",
      "tensor([ 0.2027,  0.2198,  0.1507,  0.4831,  0.4304,  0.2679, -0.0100,  0.2415,\n",
      "        -0.1979,  0.2381,  0.0161,  0.3891,  0.5283,  0.1063,  0.5581,  0.0206,\n",
      "         0.7348, -0.0573,  0.7459, -0.3506, -0.0668,  0.0008, -0.0073,  0.0796,\n",
      "        -0.2645, -0.3043, -0.4368,  0.0020, -0.5312,  0.6249,  0.1381,  0.0796,\n",
      "         0.0090,  0.1179, -0.3866,  0.1825,  0.1201, -0.3163,  0.1460,  0.1492,\n",
      "        -0.4056, -0.1451, -0.0376,  0.4136, -0.2996,  0.4100, -0.3615,  0.0807,\n",
      "         0.2628,  0.0852,  0.1006,  0.2661,  0.3001, -0.0778, -0.0736,  0.0570,\n",
      "         0.1683,  0.2524, -0.0260, -0.0456, -0.0117, -0.5291, -0.3388, -0.0276],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('1.2.bn2.weight', Parameter containing:\n",
      "tensor([1.2150, 0.9158, 0.9618, 1.0942, 0.8970, 0.9799, 0.6494, 0.9284, 1.3296,\n",
      "        1.0411, 0.9122, 1.3024, 1.0610, 1.1274, 1.2123, 0.9705, 1.1802, 1.2895,\n",
      "        1.1758, 1.3506, 1.0641, 1.0672, 1.1859, 0.5445, 1.4137, 1.1706, 0.9795,\n",
      "        1.0321, 0.7807, 0.5102, 1.1844, 0.7276, 0.8310, 1.0733, 0.9687, 0.8273,\n",
      "        1.2021, 1.2368, 1.1841, 1.2366, 1.1954, 1.0447, 1.1147, 1.2248, 1.1288,\n",
      "        1.2810, 0.9718, 1.1577, 0.9030, 1.1135, 1.1681, 1.2425, 1.2026, 1.3016,\n",
      "        1.3598, 1.0061, 1.1410, 1.0674, 1.1546, 1.1676, 0.8407, 1.0241, 1.1583,\n",
      "        0.9657], device='cuda:0', requires_grad=True))\n",
      "('1.2.bn2.bias', Parameter containing:\n",
      "tensor([ 7.4357e-02, -3.6039e-01,  2.3190e-01, -3.8344e-02, -1.4268e-01,\n",
      "        -2.6018e-01, -4.2114e-01, -7.1005e-02,  4.6821e-01,  1.0495e-01,\n",
      "        -7.0190e-02,  2.0402e-01,  2.8478e-01, -2.4752e-01,  1.1278e-01,\n",
      "         3.7592e-01,  2.3484e-01,  3.7081e-01,  3.3709e-02,  2.6126e-01,\n",
      "        -9.5143e-02, -1.9344e-01,  7.0326e-02, -4.0460e-01,  3.4239e-02,\n",
      "         2.6633e-02,  4.9215e-02,  2.4328e-01, -1.0018e-01, -5.0031e-01,\n",
      "         6.0200e-02, -2.3978e-01, -2.3172e-01,  9.2230e-02,  3.8663e-02,\n",
      "        -2.5086e-01,  1.7123e-01, -2.1613e-02, -2.0421e-01,  2.9615e-01,\n",
      "         4.2051e-01, -7.7274e-02, -2.2880e-01,  3.2616e-03,  5.1019e-02,\n",
      "        -2.1746e-01,  5.3638e-02,  9.7179e-05,  1.2818e-01,  2.0477e-01,\n",
      "        -6.9020e-02,  5.0351e-02,  3.2826e-01, -1.1490e-01,  1.0347e-01,\n",
      "        -6.2111e-02, -2.0454e-01, -7.1128e-02, -5.6550e-02, -6.4599e-02,\n",
      "         2.6619e-03, -1.9320e-01,  2.3796e-01, -5.8307e-02], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('1.2.bn3.weight', Parameter containing:\n",
      "tensor([0.7997, 1.1975, 0.8955, 0.8970, 0.7401, 0.9303, 0.9698, 0.8897, 0.9894,\n",
      "        0.8401, 1.0233, 0.8072, 0.8396, 0.8667, 0.8693, 0.8317, 0.7722, 0.9238,\n",
      "        0.9815, 0.9818, 1.0247, 0.9007, 1.0928, 1.0922, 0.8573, 0.8483, 1.1196,\n",
      "        0.5041, 0.8129, 0.9234, 0.8726, 0.8753, 0.9254, 1.0184, 0.9974, 0.7399,\n",
      "        0.7628, 0.9944, 0.9460, 0.7093, 0.9223, 0.6454, 0.7644, 1.2104, 0.9285,\n",
      "        0.8858, 0.8107, 0.9766, 0.8957, 0.7411, 0.7358, 0.6211, 1.0629, 0.9520,\n",
      "        0.9102, 0.7893, 1.2197, 0.7503, 0.8871, 0.7896, 0.9227, 0.8160, 0.6366,\n",
      "        0.7690, 0.8107, 0.9636, 1.0732, 0.9292, 0.8985, 0.9482, 0.9212, 0.8971,\n",
      "        0.9680, 0.9327, 0.9715, 0.9183, 0.9097, 0.8754, 0.8950, 0.9160, 0.9848,\n",
      "        0.7813, 1.0962, 0.9667, 0.8103, 0.8483, 1.1519, 0.9203, 1.0562, 1.0705,\n",
      "        1.0185, 0.9527, 0.7711, 0.9652, 0.8550, 0.8697, 0.6176, 0.9306, 1.0374,\n",
      "        0.8321, 0.9792, 0.8254, 0.8810, 0.9712, 1.1071, 0.8731, 1.0668, 0.6348,\n",
      "        0.8077, 0.9379, 1.0173, 1.0586, 1.0421, 0.9723, 0.8532, 0.8579, 0.9376,\n",
      "        1.0094, 1.0272, 1.0127, 1.0788, 0.8173, 0.9625, 1.0159, 0.9278, 1.0124,\n",
      "        0.8570, 0.8228, 0.9336, 0.8382, 0.9181, 0.7036, 0.9335, 1.1073, 0.9351,\n",
      "        1.0239, 1.0116, 0.7494, 1.0525, 1.0103, 0.7768, 0.9790, 0.9955, 0.9027,\n",
      "        0.8208, 0.8157, 0.9896, 1.0088, 0.7915, 0.8760, 0.7552, 0.8536, 0.9935,\n",
      "        1.0766, 0.7985, 0.9190, 0.8373, 1.1747, 1.0925, 0.6794, 0.8884, 1.1953,\n",
      "        0.8451, 0.7345, 1.0026, 1.0317, 0.7584, 1.0748, 0.8802, 0.8817, 0.8898,\n",
      "        0.9773, 0.7193, 0.8737, 0.7658, 0.9047, 0.9231, 0.9537, 1.0990, 1.0367,\n",
      "        0.8922, 0.9396, 0.8543, 0.7351, 0.8331, 0.6161, 0.9243, 0.9184, 0.8037,\n",
      "        0.7931, 0.7319, 0.6656, 0.9428, 0.7083, 1.0175, 0.7843, 0.8615, 0.9132,\n",
      "        1.2253, 0.6480, 0.9906, 0.7144, 0.9527, 0.8242, 0.8313, 0.8149, 0.9059,\n",
      "        0.6988, 0.8274, 0.7613, 0.9238, 0.9396, 0.6498, 0.9945, 0.7682, 1.0027,\n",
      "        0.8543, 0.9035, 0.9175, 0.8161, 1.0187, 0.9728, 0.8371, 0.8734, 0.7452,\n",
      "        0.9179, 0.9810, 0.9424, 0.7768, 0.8072, 0.8387, 0.7973, 0.8787, 0.8620,\n",
      "        1.0576, 0.7660, 0.9436, 0.8033, 0.9363, 1.0925, 0.7810, 0.8602, 0.9806,\n",
      "        0.7938, 0.8438, 0.9401, 0.7482, 0.8069, 0.8553, 0.8226, 1.0353, 1.0034,\n",
      "        1.0510, 1.1665, 0.8910, 0.7867], device='cuda:0', requires_grad=True))\n",
      "('1.2.bn3.bias', Parameter containing:\n",
      "tensor([ 0.0210, -0.0122, -0.0135, -0.0192,  0.0454,  0.0097,  0.0166, -0.0922,\n",
      "        -0.0404,  0.0510,  0.0114,  0.0022, -0.0518,  0.0558,  0.0264, -0.0784,\n",
      "        -0.0528, -0.0017,  0.0442,  0.0898, -0.0222, -0.0425, -0.0296, -0.0078,\n",
      "        -0.0381,  0.0273,  0.0427,  0.0080,  0.0338,  0.0194, -0.0769, -0.0371,\n",
      "         0.0209, -0.0159, -0.0491, -0.0340,  0.0272,  0.1082, -0.0440,  0.0036,\n",
      "        -0.0292,  0.0018, -0.0900, -0.0870,  0.0062,  0.0296, -0.0513, -0.0396,\n",
      "        -0.0081, -0.0424, -0.0018, -0.0012,  0.0060,  0.0035, -0.0351, -0.0465,\n",
      "         0.0248, -0.0051,  0.0431, -0.0209, -0.0103, -0.0811, -0.0505, -0.1440,\n",
      "        -0.0303,  0.0289, -0.0245,  0.0484, -0.0188, -0.0845,  0.0276,  0.0114,\n",
      "        -0.0830,  0.0015, -0.1172, -0.0106, -0.0143,  0.0485, -0.1461,  0.0148,\n",
      "        -0.0854, -0.0748, -0.0183, -0.0828, -0.0056, -0.0125,  0.0133, -0.1598,\n",
      "        -0.0099, -0.0095, -0.0527,  0.0369, -0.0170, -0.0079,  0.0155, -0.0023,\n",
      "         0.0131, -0.0687,  0.0392,  0.0987,  0.0635, -0.0443, -0.0028,  0.0168,\n",
      "        -0.0083,  0.0457, -0.0080, -0.0056, -0.0518,  0.0447, -0.0391,  0.0242,\n",
      "        -0.0055, -0.0579,  0.0046,  0.0105, -0.0754, -0.0640, -0.0459, -0.0284,\n",
      "        -0.0883,  0.0477,  0.0261, -0.0406,  0.0170,  0.0173,  0.0257,  0.0389,\n",
      "        -0.0206, -0.0005, -0.0264,  0.0027, -0.0589,  0.0781,  0.0090, -0.1381,\n",
      "        -0.1191, -0.0264, -0.0571,  0.0454, -0.0011,  0.0089, -0.1266, -0.0448,\n",
      "        -0.0313,  0.0536,  0.0313, -0.0004,  0.0054,  0.0583, -0.0952,  0.0294,\n",
      "         0.0339, -0.0200, -0.0048, -0.0203,  0.0011, -0.0341, -0.0901, -0.0574,\n",
      "        -0.0361,  0.0701, -0.1405, -0.0158, -0.0126, -0.0848, -0.0004, -0.0040,\n",
      "         0.0452, -0.0420, -0.0019, -0.0665, -0.0151, -0.0854, -0.0370, -0.0108,\n",
      "        -0.0295, -0.0160,  0.0668, -0.0010,  0.0024,  0.0042, -0.1093, -0.0234,\n",
      "        -0.1122, -0.0815,  0.0719, -0.0351,  0.0519, -0.0365, -0.0047, -0.1440,\n",
      "         0.0320,  0.0254,  0.0366, -0.0613, -0.0348, -0.0364,  0.0530, -0.0191,\n",
      "        -0.0087,  0.0472, -0.0135, -0.0744,  0.0105, -0.0927, -0.0109,  0.0007,\n",
      "         0.0247, -0.0003, -0.0909, -0.1061, -0.1640,  0.2115, -0.0621,  0.0027,\n",
      "        -0.0339, -0.0725,  0.0064, -0.0627,  0.0191, -0.0290, -0.0849, -0.1005,\n",
      "         0.0453, -0.0218,  0.0084, -0.0390, -0.0598, -0.1072, -0.0459, -0.0537,\n",
      "         0.0206,  0.0494,  0.0233,  0.0075,  0.0461,  0.0383, -0.0248, -0.0280,\n",
      "         0.0129,  0.0346, -0.0181,  0.0742,  0.0214, -0.0208, -0.0046, -0.0401,\n",
      "        -0.0183,  0.0249, -0.0994,  0.0651, -0.0532, -0.0729, -0.0849, -0.0257],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.0.conv1.weight', Parameter containing:\n",
      "tensor([[[-0.1971],\n",
      "         [-0.4652],\n",
      "         [-0.2987],\n",
      "         ...,\n",
      "         [-0.1317],\n",
      "         [-0.4197],\n",
      "         [ 0.0589]],\n",
      "\n",
      "        [[-0.1909],\n",
      "         [-0.0281],\n",
      "         [ 0.2215],\n",
      "         ...,\n",
      "         [ 0.1874],\n",
      "         [-0.2450],\n",
      "         [-0.0840]],\n",
      "\n",
      "        [[ 0.1287],\n",
      "         [ 0.4942],\n",
      "         [-0.1003],\n",
      "         ...,\n",
      "         [-0.2400],\n",
      "         [ 0.4463],\n",
      "         [-0.0758]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1951],\n",
      "         [-0.3369],\n",
      "         [ 0.4013],\n",
      "         ...,\n",
      "         [ 0.3432],\n",
      "         [-0.5137],\n",
      "         [ 0.1304]],\n",
      "\n",
      "        [[-0.5703],\n",
      "         [ 0.1234],\n",
      "         [ 0.0291],\n",
      "         ...,\n",
      "         [ 0.0822],\n",
      "         [-0.1962],\n",
      "         [ 0.2039]],\n",
      "\n",
      "        [[-0.4162],\n",
      "         [-0.0739],\n",
      "         [-0.3273],\n",
      "         ...,\n",
      "         [ 0.0307],\n",
      "         [ 0.1324],\n",
      "         [ 0.1868]]], device='cuda:0', requires_grad=True))\n",
      "('3.0.conv1.bias', Parameter containing:\n",
      "tensor([-0.0514,  0.0358,  0.0340,  0.0036,  0.0609,  0.0357, -0.0240,  0.0556,\n",
      "        -0.0418,  0.0493, -0.0172, -0.0609,  0.0285,  0.0429,  0.0397,  0.0105,\n",
      "        -0.0331,  0.0036,  0.0541, -0.0387, -0.0141,  0.0521, -0.0072,  0.0562,\n",
      "         0.0309,  0.0098, -0.0161,  0.0267, -0.0262,  0.0434, -0.0470,  0.0128,\n",
      "        -0.0495, -0.0103, -0.0340, -0.0369,  0.0040, -0.0177,  0.0368, -0.0262,\n",
      "        -0.0491,  0.0152, -0.0002, -0.0611, -0.0403,  0.0610,  0.0053, -0.0005,\n",
      "        -0.0262,  0.0113, -0.0245, -0.0271,  0.0368,  0.0577, -0.0405, -0.0578,\n",
      "         0.0441,  0.0606,  0.0480,  0.0112,  0.0132, -0.0073, -0.0577,  0.0066,\n",
      "         0.0398,  0.0117,  0.0381, -0.0145,  0.0346, -0.0036,  0.0569, -0.0156,\n",
      "         0.0273, -0.0276,  0.0518, -0.0231,  0.0606,  0.0453, -0.0164, -0.0268,\n",
      "        -0.0459,  0.0002, -0.0238,  0.0079, -0.0582, -0.0516, -0.0246,  0.0451,\n",
      "         0.0350,  0.0617,  0.0341, -0.0306,  0.0116,  0.0304, -0.0132, -0.0104,\n",
      "        -0.0122,  0.0407, -0.0433,  0.0602, -0.0524,  0.0162,  0.0046,  0.0323,\n",
      "        -0.0548,  0.0329,  0.0572, -0.0294,  0.0184,  0.0618, -0.0122,  0.0539,\n",
      "        -0.0388, -0.0247, -0.0231,  0.0161,  0.0080, -0.0370,  0.0387, -0.0586,\n",
      "        -0.0009,  0.0187, -0.0117,  0.0450,  0.0330, -0.0344,  0.0463,  0.0580],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.0.conv2.weight', Parameter containing:\n",
      "tensor([[[-0.0474, -0.3608, -0.0689],\n",
      "         [-0.1749, -0.1524,  0.2016],\n",
      "         [ 0.2034, -0.0095,  0.0763],\n",
      "         ...,\n",
      "         [ 0.2440,  0.1895, -0.0049],\n",
      "         [-0.2347,  0.1462,  0.2597],\n",
      "         [-0.2376, -0.1377,  0.0617]],\n",
      "\n",
      "        [[ 0.2783, -0.2807, -0.1471],\n",
      "         [ 0.4470, -0.2617, -0.1485],\n",
      "         [-0.0615,  0.0765,  0.3537],\n",
      "         ...,\n",
      "         [ 0.2704,  0.0513, -0.1100],\n",
      "         [ 0.0264,  0.3197,  0.0013],\n",
      "         [-0.2447, -0.2466,  0.0643]],\n",
      "\n",
      "        [[ 0.1246,  0.1148,  0.0350],\n",
      "         [-0.2584, -0.1808,  0.1875],\n",
      "         [-0.2625,  0.1379,  0.0896],\n",
      "         ...,\n",
      "         [ 0.5412,  0.3518, -0.0540],\n",
      "         [-0.1725, -0.0707, -0.1803],\n",
      "         [-0.0051,  0.0909,  0.1787]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1852,  0.2849,  0.1004],\n",
      "         [ 0.2169, -0.1012, -0.2051],\n",
      "         [-0.2052,  0.2490,  0.2920],\n",
      "         ...,\n",
      "         [ 0.0105, -0.1206, -0.2253],\n",
      "         [ 0.2332,  0.1456, -0.3678],\n",
      "         [-0.2549, -0.2635,  0.1613]],\n",
      "\n",
      "        [[ 0.3448, -0.1749,  0.0745],\n",
      "         [ 0.1027, -0.2018,  0.0900],\n",
      "         [-0.3148,  0.1520, -0.0246],\n",
      "         ...,\n",
      "         [ 0.6157, -0.0361, -0.1205],\n",
      "         [ 0.1174,  0.1307,  0.2250],\n",
      "         [-0.0299,  0.2318,  0.0174]],\n",
      "\n",
      "        [[-0.2606,  0.1474, -0.1259],\n",
      "         [-0.1444, -0.1595,  0.0094],\n",
      "         [-0.1528,  0.2012, -0.0254],\n",
      "         ...,\n",
      "         [ 0.3331,  0.1518,  0.0028],\n",
      "         [ 0.0299,  0.2462,  0.0914],\n",
      "         [ 0.0064, -0.0061,  0.3275]]], device='cuda:0', requires_grad=True))\n",
      "('3.0.conv2.bias', Parameter containing:\n",
      "tensor([-0.0490, -0.0009, -0.0262,  0.0053,  0.0257, -0.0262,  0.0273, -0.0340,\n",
      "        -0.0090, -0.0219, -0.0335, -0.0253, -0.0121, -0.0036,  0.0496,  0.0250,\n",
      "         0.0242,  0.0055,  0.0018,  0.0353, -0.0368, -0.0460, -0.0490,  0.0013,\n",
      "        -0.0277,  0.0156, -0.0493, -0.0268, -0.0106,  0.0375, -0.0066, -0.0200,\n",
      "         0.0232,  0.0186,  0.0477,  0.0163, -0.0420,  0.0493,  0.0003,  0.0145,\n",
      "        -0.0407, -0.0357, -0.0162,  0.0299, -0.0049,  0.0119,  0.0431,  0.0489,\n",
      "         0.0028,  0.0068,  0.0274,  0.0091, -0.0478, -0.0148,  0.0150, -0.0129,\n",
      "         0.0456,  0.0170, -0.0194, -0.0502, -0.0315, -0.0123,  0.0369, -0.0051,\n",
      "         0.0424, -0.0285, -0.0417,  0.0206, -0.0440, -0.0408,  0.0434, -0.0152,\n",
      "        -0.0442, -0.0131, -0.0383,  0.0317, -0.0352,  0.0319, -0.0215, -0.0387,\n",
      "         0.0231, -0.0298,  0.0188,  0.0265,  0.0042,  0.0038,  0.0379, -0.0422,\n",
      "        -0.0304, -0.0007,  0.0081, -0.0167, -0.0221, -0.0322, -0.0239,  0.0445,\n",
      "        -0.0115, -0.0250, -0.0195, -0.0003,  0.0033, -0.0399,  0.0224, -0.0342,\n",
      "        -0.0039,  0.0060,  0.0264,  0.0507,  0.0479,  0.0159,  0.0094,  0.0071,\n",
      "        -0.0207, -0.0347,  0.0077, -0.0321,  0.0219, -0.0262,  0.0224, -0.0372,\n",
      "         0.0501, -0.0156, -0.0070,  0.0211, -0.0450,  0.0206,  0.0036, -0.0318],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.0.conv3.weight', Parameter containing:\n",
      "tensor([[[-0.1427],\n",
      "         [ 0.1599],\n",
      "         [-0.0982],\n",
      "         ...,\n",
      "         [-0.1162],\n",
      "         [-0.3143],\n",
      "         [ 0.2007]],\n",
      "\n",
      "        [[ 0.0330],\n",
      "         [ 0.2354],\n",
      "         [-0.0367],\n",
      "         ...,\n",
      "         [-0.0362],\n",
      "         [-0.1805],\n",
      "         [ 0.0654]],\n",
      "\n",
      "        [[ 0.1241],\n",
      "         [-0.0677],\n",
      "         [ 0.0212],\n",
      "         ...,\n",
      "         [-0.1037],\n",
      "         [-0.0370],\n",
      "         [-0.0614]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2110],\n",
      "         [ 0.1225],\n",
      "         [ 0.1704],\n",
      "         ...,\n",
      "         [-0.0737],\n",
      "         [ 0.0560],\n",
      "         [-0.0400]],\n",
      "\n",
      "        [[-0.1938],\n",
      "         [-0.3393],\n",
      "         [-0.1914],\n",
      "         ...,\n",
      "         [ 0.0076],\n",
      "         [-0.0347],\n",
      "         [-0.0105]],\n",
      "\n",
      "        [[ 0.2064],\n",
      "         [ 0.1941],\n",
      "         [ 0.1532],\n",
      "         ...,\n",
      "         [ 0.1547],\n",
      "         [-0.0350],\n",
      "         [-0.0469]]], device='cuda:0', requires_grad=True))\n",
      "('3.0.conv3.bias', Parameter containing:\n",
      "tensor([ 0.0823,  0.0147,  0.0465,  0.0056,  0.0072, -0.0108,  0.0022,  0.0608,\n",
      "        -0.0376,  0.0124, -0.0213,  0.0048,  0.0550, -0.0037,  0.0768, -0.0686,\n",
      "        -0.0100,  0.0445, -0.0465,  0.0005,  0.0521, -0.0670,  0.0470, -0.0156,\n",
      "         0.0305,  0.0327, -0.0735,  0.0168, -0.0127,  0.0873, -0.0696, -0.0342,\n",
      "         0.0421, -0.0857,  0.0727, -0.0274, -0.0570, -0.0603, -0.0833,  0.0597,\n",
      "        -0.0814,  0.0429, -0.0721, -0.0161, -0.0557,  0.0504,  0.0766,  0.0760,\n",
      "        -0.0160, -0.0128, -0.0695, -0.0745, -0.0391, -0.0662, -0.0090, -0.0678,\n",
      "        -0.0229,  0.0401,  0.0543, -0.0278, -0.0629,  0.0419, -0.0732, -0.0041,\n",
      "         0.0277,  0.0652,  0.0252, -0.0825,  0.0046,  0.0795, -0.0035,  0.0423,\n",
      "        -0.0518,  0.0740, -0.0554,  0.0449,  0.0506, -0.0142,  0.0749,  0.0817,\n",
      "         0.0524,  0.0866,  0.0098,  0.0790, -0.0612,  0.0070, -0.0165, -0.0194,\n",
      "         0.0183,  0.0772,  0.0131, -0.0286,  0.0855, -0.0334,  0.0599,  0.0519,\n",
      "        -0.0100, -0.0148,  0.0196, -0.0372, -0.0377, -0.0859,  0.0884,  0.0559,\n",
      "         0.0773,  0.0093,  0.0053,  0.0653, -0.0014,  0.0271, -0.0164, -0.0556,\n",
      "         0.0483, -0.0822,  0.0458,  0.0376,  0.0542, -0.0362, -0.0881,  0.0234,\n",
      "        -0.0518,  0.0395, -0.0855, -0.0375, -0.0505, -0.0705, -0.0311,  0.0278,\n",
      "        -0.0618,  0.0872,  0.0354, -0.0776, -0.0464, -0.0067,  0.0602, -0.0588,\n",
      "         0.0122, -0.0249,  0.0224, -0.0049, -0.0612, -0.0835,  0.0681, -0.0414,\n",
      "         0.0465, -0.0763, -0.0291,  0.0694,  0.0185, -0.0565, -0.0590, -0.0814,\n",
      "        -0.0376,  0.0826, -0.0310, -0.0612, -0.0519,  0.0199,  0.0428,  0.0242,\n",
      "        -0.0433, -0.0239, -0.0125,  0.0272,  0.0701, -0.0609,  0.0043,  0.0013,\n",
      "        -0.0816, -0.0758, -0.0176,  0.0428, -0.0093, -0.0504,  0.0500,  0.0399,\n",
      "         0.0349, -0.0129, -0.0131,  0.0778, -0.0390,  0.0864, -0.0777,  0.0453,\n",
      "        -0.0758, -0.0098,  0.0814, -0.0002,  0.0654, -0.0786, -0.0762,  0.0135,\n",
      "         0.0823, -0.0753, -0.0171, -0.0783, -0.0014,  0.0554,  0.0414, -0.0337,\n",
      "         0.0285,  0.0047,  0.0638, -0.0123, -0.0090,  0.0827,  0.0310,  0.0683,\n",
      "        -0.0812, -0.0600,  0.0531,  0.0368,  0.0375,  0.0863,  0.0776,  0.0519,\n",
      "        -0.0133,  0.0669, -0.0873, -0.0102, -0.0369, -0.0489, -0.0815,  0.0170,\n",
      "        -0.0847, -0.0532, -0.0136,  0.0875, -0.0403,  0.0061,  0.0064, -0.0642,\n",
      "        -0.0162,  0.0598, -0.0431, -0.0497,  0.0730,  0.0806, -0.0705, -0.0042,\n",
      "         0.0673,  0.0195, -0.0244,  0.0349,  0.0083,  0.0863, -0.0879,  0.0088,\n",
      "        -0.0698, -0.0278, -0.0465, -0.0362, -0.0291, -0.0723,  0.0274,  0.0473,\n",
      "         0.0528,  0.0312,  0.0571,  0.0493,  0.0347,  0.0004, -0.0171,  0.0054,\n",
      "        -0.0369,  0.0830,  0.0262, -0.0154,  0.0858,  0.0403,  0.0212, -0.0379,\n",
      "        -0.0378,  0.0523,  0.0240, -0.0883,  0.0332,  0.0277, -0.0191,  0.0644,\n",
      "        -0.0213, -0.0431,  0.0069, -0.0570,  0.0304, -0.0572, -0.0322, -0.0565,\n",
      "         0.0667, -0.0611, -0.0060,  0.0784,  0.0001,  0.0235,  0.0444,  0.0092,\n",
      "         0.0790,  0.0759, -0.0237,  0.0551, -0.0128,  0.0216, -0.0535,  0.0799,\n",
      "        -0.0186,  0.0574, -0.0629,  0.0644, -0.0309,  0.0115,  0.0559, -0.0085,\n",
      "         0.0619, -0.0847, -0.0776,  0.0171, -0.0030,  0.0734,  0.0839, -0.0254,\n",
      "         0.0344, -0.0644,  0.0115,  0.0084,  0.0232,  0.0047, -0.0410,  0.0065,\n",
      "        -0.0656, -0.0074,  0.0677,  0.0672,  0.0505, -0.0119, -0.0031, -0.0574,\n",
      "        -0.0883, -0.0721,  0.0561,  0.0707, -0.0772,  0.0153, -0.0335,  0.0669,\n",
      "        -0.0711, -0.0645,  0.0189, -0.0232, -0.0879, -0.0022, -0.0019, -0.0114,\n",
      "         0.0463, -0.0281, -0.0691, -0.0501, -0.0321, -0.0755, -0.0229,  0.0270,\n",
      "        -0.0187,  0.0658, -0.0763, -0.0506,  0.0208,  0.0763,  0.0385,  0.0129,\n",
      "        -0.0191,  0.0361,  0.0544,  0.0431,  0.0052,  0.0224, -0.0785,  0.0833,\n",
      "         0.0095, -0.0652, -0.0792,  0.0474, -0.0847,  0.0640,  0.0328, -0.0269,\n",
      "         0.0813, -0.0753, -0.0840,  0.0777, -0.0127,  0.0093,  0.0772,  0.0289,\n",
      "         0.0826,  0.0383,  0.0379,  0.0511, -0.0513, -0.0875, -0.0783,  0.0482,\n",
      "        -0.0234, -0.0502, -0.0642, -0.0757,  0.0753,  0.0520,  0.0332,  0.0492,\n",
      "        -0.0608, -0.0064,  0.0216, -0.0780, -0.0159,  0.0385,  0.0331, -0.0164,\n",
      "         0.0630,  0.0616, -0.0627,  0.0171, -0.0504,  0.0758, -0.0708, -0.0038,\n",
      "        -0.0412,  0.0123, -0.0242,  0.0068,  0.0555,  0.0558,  0.0166,  0.0182,\n",
      "         0.0548, -0.0725, -0.0180,  0.0159,  0.0451,  0.0099,  0.0150, -0.0130,\n",
      "         0.0256,  0.0745,  0.0332, -0.0078, -0.0035,  0.0601, -0.0498, -0.0271,\n",
      "        -0.0725, -0.0525, -0.0143, -0.0173, -0.0190,  0.0172,  0.0454,  0.0154,\n",
      "        -0.0615, -0.0780, -0.0348,  0.0258, -0.0724,  0.0239,  0.0785,  0.0636,\n",
      "         0.0529, -0.0707, -0.0599,  0.0391, -0.0414,  0.0826,  0.0637,  0.0137,\n",
      "         0.0198, -0.0710,  0.0160,  0.0263,  0.0122, -0.0525,  0.0808, -0.0235,\n",
      "         0.0811,  0.0057,  0.0557, -0.0054, -0.0473, -0.0786,  0.0186, -0.0706,\n",
      "        -0.0643, -0.0091,  0.0504, -0.0192, -0.0672, -0.0259,  0.0202,  0.0748,\n",
      "         0.0341,  0.0247,  0.0596, -0.0242,  0.0389, -0.0258, -0.0102,  0.0771,\n",
      "         0.0390, -0.0534,  0.0546, -0.0666,  0.0869, -0.0326, -0.0347, -0.0766],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.0.conv4.weight', Parameter containing:\n",
      "tensor([[[ 0.1730],\n",
      "         [ 0.0408],\n",
      "         [-0.0750],\n",
      "         ...,\n",
      "         [ 0.0615],\n",
      "         [ 0.0416],\n",
      "         [-0.0020]],\n",
      "\n",
      "        [[-0.0408],\n",
      "         [ 0.0540],\n",
      "         [ 0.2406],\n",
      "         ...,\n",
      "         [-0.1237],\n",
      "         [ 0.0573],\n",
      "         [-0.0833]],\n",
      "\n",
      "        [[-0.1474],\n",
      "         [ 0.0355],\n",
      "         [-0.0044],\n",
      "         ...,\n",
      "         [-0.2164],\n",
      "         [-0.1116],\n",
      "         [-0.0240]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0642],\n",
      "         [ 0.0110],\n",
      "         [ 0.0194],\n",
      "         ...,\n",
      "         [-0.0319],\n",
      "         [ 0.0418],\n",
      "         [-0.1262]],\n",
      "\n",
      "        [[ 0.0797],\n",
      "         [ 0.2360],\n",
      "         [ 0.0455],\n",
      "         ...,\n",
      "         [-0.1109],\n",
      "         [ 0.0372],\n",
      "         [ 0.1259]],\n",
      "\n",
      "        [[ 0.0422],\n",
      "         [ 0.1048],\n",
      "         [-0.0524],\n",
      "         ...,\n",
      "         [-0.0525],\n",
      "         [ 0.0804],\n",
      "         [-0.0928]]], device='cuda:0', requires_grad=True))\n",
      "('3.0.conv4.bias', Parameter containing:\n",
      "tensor([-2.6528e-02,  4.4710e-02, -8.6931e-02, -1.3666e-02, -6.2502e-02,\n",
      "         7.1884e-02,  5.2802e-02,  5.9193e-02,  5.8015e-02, -4.6092e-02,\n",
      "        -4.7622e-02, -5.7006e-03, -2.3415e-02, -1.4276e-02,  4.8631e-02,\n",
      "        -1.7953e-02, -5.3229e-04, -5.6476e-03, -8.6802e-02,  5.7155e-03,\n",
      "         1.4547e-02, -6.3068e-02,  5.3491e-02, -2.3222e-02, -1.1556e-02,\n",
      "         3.5085e-02,  1.5844e-02, -4.7499e-02,  3.2850e-02, -1.1448e-02,\n",
      "        -7.4699e-02,  1.2164e-01, -2.4428e-02,  5.5197e-02,  5.1666e-02,\n",
      "        -1.9871e-02,  6.2552e-02,  1.2185e-02,  1.0749e-01, -7.3989e-02,\n",
      "        -1.5150e-03,  1.9366e-02,  5.8884e-02,  4.0791e-02,  1.0017e-01,\n",
      "         8.2986e-02, -7.3789e-03,  4.8614e-03, -2.8543e-02, -6.5857e-02,\n",
      "        -1.1818e-01,  2.0588e-02, -4.0855e-03, -5.5531e-02,  8.6626e-02,\n",
      "        -4.9048e-02,  2.0523e-02,  4.0375e-02, -1.1677e-01, -4.6421e-02,\n",
      "         5.1128e-02,  1.2421e-02, -1.0393e-01, -6.3377e-02,  1.0601e-02,\n",
      "         4.1132e-02,  4.3081e-02, -5.2312e-02,  4.9705e-02,  1.9439e-02,\n",
      "         2.4697e-02, -2.2633e-02, -9.3388e-03, -7.9562e-02, -4.8333e-02,\n",
      "        -9.5467e-04, -8.1374e-02,  7.0259e-02, -5.4939e-03,  7.0288e-02,\n",
      "        -3.8317e-02,  8.4571e-02,  1.8404e-02, -6.6063e-02, -6.2838e-02,\n",
      "        -5.2910e-02,  2.4078e-02, -2.3211e-03,  7.7905e-02, -4.5180e-02,\n",
      "         2.3870e-02, -3.9855e-02,  1.9933e-02, -5.8994e-02, -3.7008e-02,\n",
      "         6.2480e-02,  7.2165e-02,  6.2916e-02,  1.1759e-02, -3.1569e-02,\n",
      "        -3.9382e-02,  9.4362e-03, -1.3737e-02, -3.6756e-02,  1.6510e-02,\n",
      "         5.0686e-02, -3.0334e-02, -9.1589e-03, -1.5150e-02, -4.5160e-02,\n",
      "         6.2044e-02,  5.4752e-02, -7.4453e-02,  4.3423e-02, -4.2822e-02,\n",
      "         1.0360e-02, -2.2438e-02, -5.0373e-03,  8.9645e-03, -2.7376e-02,\n",
      "        -6.6284e-02, -2.5733e-02,  2.6104e-02,  1.1484e-02,  7.7075e-02,\n",
      "        -4.9794e-02,  2.1402e-02,  2.3334e-02, -1.1420e-02,  4.3807e-02,\n",
      "        -1.7415e-02, -2.4374e-02,  3.0525e-02,  2.8476e-02, -5.8570e-02,\n",
      "         1.8962e-02,  3.4550e-02, -3.2746e-02, -1.6545e-02,  3.4676e-02,\n",
      "         8.6504e-03,  3.2395e-02,  2.3251e-02,  1.7114e-02,  1.0802e-01,\n",
      "        -1.1585e-02, -6.0048e-02,  2.6494e-02, -1.0016e-02,  5.9312e-02,\n",
      "        -2.7941e-02, -1.8584e-02,  1.0176e-02, -6.4167e-03,  2.2356e-02,\n",
      "        -2.5984e-02,  8.2228e-02, -5.3470e-02, -3.5367e-02,  1.3929e-02,\n",
      "        -9.2872e-03, -7.4422e-03,  4.5817e-02,  1.0265e-01,  1.7373e-02,\n",
      "         3.3250e-04,  1.1854e-02, -1.1311e-02,  2.3869e-02, -2.4551e-03,\n",
      "        -3.2013e-02, -2.8395e-02, -7.3638e-03,  1.1790e-02, -3.8885e-02,\n",
      "        -3.2893e-02,  7.3139e-02, -1.1308e-02,  4.8437e-02,  1.0795e-03,\n",
      "         5.3822e-02,  1.5901e-02,  2.4729e-02,  1.9039e-02, -1.7552e-02,\n",
      "        -9.6685e-02, -1.7439e-02,  9.3501e-02,  3.8740e-02, -2.8280e-02,\n",
      "        -1.4519e-02, -3.6819e-03, -4.5047e-02, -8.3814e-03, -2.2579e-02,\n",
      "        -1.1732e-02, -2.5138e-02, -5.3922e-03,  5.5807e-02, -8.1892e-02,\n",
      "         8.9120e-02,  2.6660e-04,  1.1674e-02, -1.7569e-02,  4.3694e-02,\n",
      "        -2.9242e-02, -1.3983e-01, -4.2798e-02, -2.4927e-02,  9.5312e-03,\n",
      "        -5.1329e-02,  4.0971e-02, -3.3717e-03,  8.6595e-02,  5.6854e-02,\n",
      "        -1.2118e-01, -7.3334e-02,  4.3067e-02,  6.7187e-02, -3.1834e-02,\n",
      "         8.5122e-04,  2.7227e-02, -6.0945e-02, -8.0056e-03,  6.4610e-03,\n",
      "        -2.3638e-03, -6.2294e-02,  5.0447e-03,  2.6541e-02,  3.4780e-02,\n",
      "         1.4109e-02,  1.6142e-02,  1.9175e-02, -7.7119e-02, -2.6701e-02,\n",
      "         4.5665e-02, -5.5468e-02, -4.8574e-02,  3.6834e-02,  2.8790e-02,\n",
      "        -3.4767e-02, -5.1613e-02, -3.5348e-02, -9.2752e-04,  5.2471e-02,\n",
      "         4.3018e-02, -3.9077e-03,  1.2499e-02,  7.8450e-03, -2.9962e-02,\n",
      "        -3.0633e-02, -1.0229e-02, -3.3389e-02, -1.5583e-02,  3.7277e-02,\n",
      "         6.9509e-03,  4.9470e-02, -6.4262e-02, -5.7033e-02,  1.5603e-02,\n",
      "         2.7745e-02,  3.3078e-02,  2.6909e-02, -4.8704e-03, -1.3739e-02,\n",
      "         6.9699e-02,  2.8078e-02, -4.3772e-02, -4.3516e-02,  4.0252e-02,\n",
      "        -6.2545e-02, -3.6070e-02, -1.6339e-02, -6.3758e-02, -2.8998e-03,\n",
      "         3.8685e-02, -4.5618e-02,  5.2003e-02, -8.3529e-02,  9.3945e-02,\n",
      "        -4.3246e-02,  4.6647e-02,  3.8996e-02, -1.4433e-02, -4.4597e-02,\n",
      "        -2.5916e-02, -2.3375e-02, -4.8633e-03,  6.3511e-02, -1.0821e-02,\n",
      "         5.0541e-02,  1.4420e-02, -7.3775e-02, -6.0867e-02,  4.5767e-02,\n",
      "        -2.1606e-02,  5.0039e-02, -6.2522e-02,  1.4340e-02, -2.1639e-03,\n",
      "        -4.7077e-03, -3.5950e-02,  5.2008e-02,  2.7656e-03,  1.1096e-03,\n",
      "        -8.0060e-02, -9.3938e-02, -2.2199e-03,  1.5668e-02, -8.4974e-02,\n",
      "         3.2843e-02, -6.4274e-02, -5.2989e-02, -1.4374e-03, -3.2218e-02,\n",
      "        -5.3319e-02, -4.5213e-02, -3.0372e-02,  2.4117e-02, -1.7008e-02,\n",
      "         3.5453e-03, -3.5661e-02,  2.2033e-02, -4.0011e-02,  2.0022e-02,\n",
      "        -6.8187e-02,  7.5010e-02, -6.5690e-03,  5.3777e-02,  1.2226e-03,\n",
      "         1.9673e-02,  2.4172e-02,  1.7691e-02,  4.3489e-02,  8.5400e-02,\n",
      "        -3.0759e-02,  1.0780e-02,  1.5472e-02, -6.9840e-03,  2.4838e-02,\n",
      "         7.0783e-02, -4.4232e-03,  3.5413e-03,  2.4288e-02,  2.4340e-02,\n",
      "        -1.9126e-02,  3.2640e-02,  1.9081e-02,  2.5069e-02,  6.6750e-02,\n",
      "        -7.6960e-02,  5.0760e-02, -8.2411e-02,  7.3161e-02,  3.5548e-04,\n",
      "         4.0021e-02,  1.8658e-02, -8.9411e-03, -4.7883e-02,  1.0198e-01,\n",
      "         2.2061e-02, -1.8007e-02,  3.6305e-03,  3.3955e-02,  1.4193e-01,\n",
      "         4.3978e-02,  2.3183e-02,  1.0688e-02, -6.5021e-02,  5.9465e-02,\n",
      "        -5.3293e-03, -1.9200e-03, -2.6097e-03, -1.8399e-03,  4.6013e-03,\n",
      "         2.1775e-04, -1.1994e-01, -4.6885e-02,  1.0206e-02, -2.4724e-02,\n",
      "         6.8317e-02, -1.9058e-02,  4.3173e-02, -8.2774e-02,  4.4408e-02,\n",
      "        -4.2340e-02, -2.1119e-02, -6.8337e-02, -9.8087e-02,  1.0240e-01,\n",
      "         3.1459e-03, -2.6780e-02,  1.3045e-02,  5.5352e-02, -6.8340e-02,\n",
      "        -1.2125e-02,  2.0196e-02,  4.1536e-02, -1.3746e-02,  4.3401e-02,\n",
      "         9.8160e-03, -3.0785e-02, -7.2979e-04,  6.3778e-02, -7.4420e-02,\n",
      "         8.0040e-02,  6.4695e-02,  2.3744e-02, -5.8762e-02,  2.1226e-02,\n",
      "        -2.8199e-02,  1.5132e-02,  3.9566e-02, -1.2290e-05,  4.3094e-02,\n",
      "        -4.4867e-02, -6.1558e-02, -3.9958e-03, -5.7902e-02,  5.6890e-02,\n",
      "         3.6456e-02, -9.0615e-03, -4.1610e-02, -4.8038e-02,  2.2746e-02,\n",
      "         4.5521e-02, -1.1248e-01, -1.1544e-02, -5.3054e-02, -8.5980e-03,\n",
      "         1.8294e-03,  4.2845e-02,  1.6120e-02,  5.3409e-02, -4.5737e-02,\n",
      "        -1.5249e-02, -2.7569e-02, -2.5931e-02,  4.3942e-02, -1.6272e-02,\n",
      "        -9.9052e-03,  4.0670e-02,  3.2794e-02, -9.3505e-02,  6.2738e-02,\n",
      "         3.8578e-02, -7.4786e-02,  1.0140e-01, -1.7802e-02, -7.8360e-02,\n",
      "        -6.9897e-02, -7.3492e-02, -2.3781e-02, -7.9891e-02, -8.0255e-02,\n",
      "        -5.5238e-03,  6.2499e-03,  5.5477e-02, -1.4524e-02, -3.6245e-02,\n",
      "         2.9956e-02,  6.5320e-02,  7.6774e-02, -3.7956e-02,  2.3528e-03,\n",
      "         9.7159e-02,  2.0578e-02,  7.0879e-02,  2.1403e-02,  6.0859e-02,\n",
      "         3.6258e-02, -1.0066e-01, -5.1616e-02,  4.5382e-03, -7.3060e-03,\n",
      "         2.4961e-02, -3.4159e-02,  2.1520e-02,  2.7717e-03, -1.4803e-02,\n",
      "         5.9973e-02, -3.3075e-02, -1.9484e-02,  1.8195e-02, -3.3426e-02,\n",
      "        -8.4613e-03,  3.5954e-02,  9.9877e-02, -3.0269e-02,  6.1048e-02,\n",
      "        -1.4985e-02,  3.0399e-02,  2.9803e-02, -1.0076e-02, -4.1470e-02,\n",
      "         8.0904e-04, -5.7959e-02,  1.0188e-01, -1.0148e-02,  4.1085e-02,\n",
      "         2.4364e-02,  2.4140e-02,  5.1555e-04,  2.4140e-02, -4.0023e-02,\n",
      "        -5.3340e-02,  4.9791e-02, -3.8755e-02,  7.9139e-02,  7.2369e-02,\n",
      "         1.2911e-01,  2.2875e-02], device='cuda:0', requires_grad=True))\n",
      "('3.0.bn1.weight', Parameter containing:\n",
      "tensor([0.9554, 0.7564, 0.9498, 1.1320, 1.1957, 0.9461, 0.9435, 1.3010, 1.1979,\n",
      "        0.8510, 1.0528, 0.9802, 1.0748, 1.0862, 0.9590, 0.7986, 0.7746, 1.1740,\n",
      "        1.0143, 1.2052, 1.1258, 1.0767, 0.9757, 0.9347, 0.9690, 1.2067, 0.9149,\n",
      "        0.9250, 0.8779, 0.9122, 0.9949, 0.8781, 0.8712, 1.0777, 1.0459, 1.0726,\n",
      "        0.9729, 0.9614, 0.8097, 1.1771, 1.1194, 1.0386, 0.9584, 0.9203, 1.0886,\n",
      "        0.8106, 1.1555, 0.9227, 1.1006, 1.0947, 0.9528, 1.4361, 1.0559, 1.1283,\n",
      "        0.9337, 1.3225, 1.0287, 0.9607, 0.9679, 1.0512, 1.1892, 1.1660, 1.1108,\n",
      "        1.2820, 1.0054, 0.7451, 0.8212, 1.3141, 0.9651, 0.8387, 1.1528, 0.9014,\n",
      "        0.8993, 0.9156, 1.0271, 1.0697, 1.1353, 0.9970, 1.1943, 0.9589, 1.1931,\n",
      "        1.0191, 1.0307, 1.1668, 0.9434, 1.1377, 1.0509, 0.6695, 1.0702, 0.6563,\n",
      "        1.0928, 1.1524, 0.9099, 0.9948, 0.8756, 0.9120, 1.0242, 0.9585, 0.9771,\n",
      "        1.2448, 0.9459, 1.1058, 1.1382, 0.9396, 1.0939, 0.8915, 1.1020, 0.9607,\n",
      "        1.0146, 1.1013, 0.9762, 1.1532, 1.0578, 1.3047, 1.0957, 1.2020, 1.1400,\n",
      "        0.9079, 0.9216, 1.0540, 0.8446, 0.8472, 0.8018, 0.8692, 0.8962, 0.8371,\n",
      "        1.0034, 0.9794], device='cuda:0', requires_grad=True))\n",
      "('3.0.bn1.bias', Parameter containing:\n",
      "tensor([-0.1311, -0.0017, -0.0024,  0.1760,  0.1335, -0.1182,  0.1926,  0.0800,\n",
      "         0.1266,  0.0295, -0.0279, -0.0589,  0.1162,  0.0771, -0.0096, -0.1607,\n",
      "        -0.2304,  0.1793, -0.0930,  0.0240,  0.0460,  0.1025, -0.1831,  0.0498,\n",
      "        -0.1077, -0.1686, -0.0493,  0.0067, -0.3430, -0.1643, -0.0908, -0.1206,\n",
      "        -0.0028, -0.0096,  0.0719, -0.0959, -0.0736, -0.1259, -0.1893,  0.0777,\n",
      "         0.0637, -0.1387,  0.0014, -0.0956,  0.0555,  0.0228, -0.0790,  0.0160,\n",
      "        -0.0648, -0.1255,  0.0932,  0.1746, -0.0229, -0.0370, -0.1619,  0.2590,\n",
      "        -0.0378, -0.0952, -0.0528,  0.1100,  0.0338,  0.1651,  0.1330, -0.0852,\n",
      "        -0.1431, -0.2128, -0.0114, -0.1081,  0.0869,  0.0722,  0.0913, -0.0497,\n",
      "        -0.1637, -0.0936, -0.1188,  0.0852,  0.0185,  0.2447,  0.1558, -0.1025,\n",
      "        -0.0657,  0.0064, -0.1561, -0.0660, -0.1357, -0.1324, -0.0818, -0.1270,\n",
      "        -0.1931, -0.2067, -0.0587,  0.0978, -0.1930,  0.0118, -0.0654, -0.0132,\n",
      "        -0.0179, -0.3315,  0.0532,  0.0875, -0.0883, -0.0938,  0.0726, -0.2714,\n",
      "         0.2482, -0.0868, -0.1982,  0.1160,  0.1317,  0.1881, -0.1316, -0.0588,\n",
      "        -0.0450,  0.1013,  0.0771,  0.0406,  0.3528,  0.0675, -0.0806,  0.1487,\n",
      "         0.0440, -0.1598, -0.0703, -0.0559, -0.1803, -0.0568, -0.2027, -0.0977],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.0.bn2.weight', Parameter containing:\n",
      "tensor([1.1270, 1.0225, 0.9316, 0.9983, 1.1775, 0.9602, 1.1003, 0.9526, 0.9256,\n",
      "        0.9605, 1.0378, 1.0292, 0.9782, 1.0205, 1.0993, 0.8919, 1.0811, 1.1391,\n",
      "        0.7949, 0.9945, 1.0813, 1.0522, 1.0490, 0.7871, 1.0528, 0.8468, 1.1397,\n",
      "        0.9300, 1.0502, 0.9622, 0.9877, 1.0269, 1.1848, 1.0726, 0.9497, 0.9812,\n",
      "        1.0445, 1.0879, 1.1049, 1.0646, 0.8721, 1.0373, 1.0589, 0.9213, 1.0955,\n",
      "        0.9366, 0.8850, 0.9436, 0.9830, 1.0533, 1.0849, 1.0388, 1.0524, 0.9843,\n",
      "        0.9859, 1.0768, 0.9308, 0.8633, 1.0901, 1.0018, 1.0775, 0.8862, 1.0964,\n",
      "        1.0092, 1.0605, 0.9607, 1.0093, 0.9953, 0.9467, 1.0163, 1.0497, 0.9243,\n",
      "        0.9416, 0.8493, 1.0539, 1.0041, 1.0011, 0.7819, 1.1757, 1.0348, 1.0742,\n",
      "        1.0505, 1.0844, 0.8968, 1.0370, 0.8828, 0.9321, 0.9766, 1.0713, 0.9675,\n",
      "        1.0645, 0.9959, 1.0319, 1.1901, 1.0159, 0.9949, 0.8578, 1.0359, 1.0369,\n",
      "        1.0614, 0.9768, 0.9428, 1.0549, 1.0462, 1.2100, 1.1267, 1.0071, 1.0812,\n",
      "        1.0375, 1.1195, 0.9957, 1.0154, 0.7625, 1.0020, 0.9960, 1.0279, 1.1826,\n",
      "        1.0945, 0.9289, 1.0032, 0.9700, 1.0479, 0.8301, 0.9850, 0.8921, 0.9432,\n",
      "        1.0534, 1.0951], device='cuda:0', requires_grad=True))\n",
      "('3.0.bn2.bias', Parameter containing:\n",
      "tensor([-0.3055, -0.2012, -0.1729, -0.0950, -0.1039, -0.1150, -0.0480, -0.0419,\n",
      "        -0.0538,  0.0414, -0.1774, -0.0588, -0.0754, -0.0382, -0.1730, -0.0005,\n",
      "        -0.1062, -0.0538, -0.0299, -0.0770, -0.0804, -0.1242, -0.2225, -0.2344,\n",
      "        -0.2776, -0.3166, -0.0326, -0.2346, -0.0827, -0.2920, -0.2012, -0.1362,\n",
      "        -0.1687, -0.2758, -0.0093, -0.0941, -0.0852, -0.0550,  0.0183,  0.0526,\n",
      "        -0.1060, -0.1583,  0.0708,  0.1987,  0.0803, -0.0449, -0.2774, -0.2196,\n",
      "        -0.1726, -0.1384,  0.0106, -0.1044, -0.0961, -0.0276, -0.0961, -0.1171,\n",
      "        -0.1361, -0.1417, -0.0807, -0.1428, -0.1231, -0.1572, -0.1091, -0.1729,\n",
      "        -0.1467, -0.0778, -0.1533, -0.1310, -0.3377, -0.0283, -0.0996, -0.1229,\n",
      "        -0.1300, -0.1268, -0.0008,  0.0060, -0.0995, -0.3163,  0.0407, -0.0532,\n",
      "         0.0178, -0.0718, -0.0415, -0.1902,  0.0353, -0.1255, -0.0315, -0.0701,\n",
      "        -0.1183, -0.1506,  0.0538, -0.2089, -0.1052, -0.1261, -0.0155,  0.0458,\n",
      "        -0.2754, -0.1214, -0.1112,  0.0004, -0.1034, -0.2391, -0.0722, -0.0981,\n",
      "         0.0820, -0.0706, -0.0953, -0.0199, -0.1203, -0.0481, -0.1582, -0.0244,\n",
      "        -0.3007, -0.0067, -0.1050, -0.0994, -0.0873, -0.1418,  0.0348, -0.1340,\n",
      "        -0.0892, -0.1845, -0.1191, -0.1943, -0.1087, -0.0240, -0.2081, -0.1530],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.0.bn3.weight', Parameter containing:\n",
      "tensor([1.1563, 1.1346, 0.9911, 1.0417, 0.9971, 1.0618, 1.0116, 1.1355, 1.1462,\n",
      "        1.0770, 0.9395, 1.0854, 0.9482, 0.9585, 0.9985, 0.9877, 0.9249, 1.0966,\n",
      "        0.9802, 0.9687, 0.9618, 0.9258, 1.0537, 0.9640, 1.2032, 1.2630, 0.9967,\n",
      "        1.0048, 1.0518, 1.0633, 1.0032, 1.1574, 1.1163, 0.9781, 1.0174, 1.1144,\n",
      "        1.1322, 1.0816, 1.0454, 0.9601, 1.1030, 1.0230, 1.1569, 1.0625, 1.0897,\n",
      "        1.2739, 1.0409, 1.1638, 0.9895, 0.9945, 0.9295, 1.1885, 0.9815, 1.0333,\n",
      "        1.1426, 1.0064, 1.0841, 1.0482, 1.0005, 1.2125, 1.1115, 1.1637, 0.9430,\n",
      "        0.9884, 1.1338, 1.0981, 1.0736, 0.9781, 1.0571, 1.2254, 1.0708, 0.9580,\n",
      "        1.0160, 1.0346, 1.0658, 0.9891, 0.9799, 1.2176, 0.9947, 1.0789, 0.9791,\n",
      "        1.0090, 1.0561, 1.0291, 1.1351, 0.9208, 1.1514, 0.9634, 1.3294, 0.9960,\n",
      "        1.1423, 0.9786, 0.9764, 0.9717, 1.0291, 1.0840, 1.0670, 1.0969, 1.0053,\n",
      "        1.1393, 0.9283, 0.9067, 1.0572, 1.0075, 1.0735, 0.9866, 1.0182, 0.9536,\n",
      "        0.9947, 1.1747, 1.2833, 1.1207, 0.9673, 1.2553, 1.2279, 0.9503, 0.9974,\n",
      "        1.0235, 1.0135, 1.0148, 0.9550, 0.9601, 0.9856, 1.0339, 1.2052, 0.9760,\n",
      "        1.2155, 1.1955, 0.9795, 1.1058, 1.2720, 0.9731, 0.9456, 1.1448, 0.9808,\n",
      "        1.0791, 1.0231, 1.0610, 1.1276, 1.0127, 1.1772, 1.0326, 1.0013, 0.9753,\n",
      "        1.2305, 1.1568, 1.0412, 0.9784, 1.0209, 1.0096, 1.0633, 1.0316, 1.0561,\n",
      "        0.9901, 1.0339, 0.9526, 1.1860, 1.0063, 0.9800, 1.0646, 1.1210, 1.0801,\n",
      "        1.0269, 1.0104, 0.9963, 0.9929, 1.1407, 0.9435, 1.0344, 1.0338, 1.0529,\n",
      "        1.0316, 0.8725, 0.9296, 0.9343, 0.9544, 1.0928, 1.0204, 1.0042, 0.9434,\n",
      "        1.0482, 1.1060, 1.0506, 0.9759, 1.1336, 0.9032, 1.0048, 0.9538, 0.9808,\n",
      "        1.1889, 0.9413, 0.9951, 1.0109, 1.1346, 1.0350, 1.0752, 1.0963, 1.0078,\n",
      "        1.0112, 0.9340, 1.0460, 1.0671, 0.9907, 1.0981, 1.1297, 0.9824, 1.0184,\n",
      "        1.1060, 1.0445, 0.9954, 1.0601, 0.9045, 1.0270, 1.0854, 1.0984, 1.0252,\n",
      "        0.9142, 0.9261, 1.1417, 0.9485, 1.0160, 1.0805, 1.0097, 0.9617, 0.9661,\n",
      "        1.1098, 0.9585, 0.9768, 1.1651, 1.1776, 1.0157, 1.1640, 1.0474, 0.9888,\n",
      "        0.9648, 1.1589, 0.9757, 0.9653, 1.2789, 1.1149, 0.9312, 0.9441, 1.2419,\n",
      "        0.9927, 1.1547, 0.9986, 0.9825, 0.9814, 1.0737, 1.0942, 0.9863, 0.9239,\n",
      "        1.0246, 0.9825, 1.3172, 1.0200, 1.1692, 0.9463, 1.0422, 1.0083, 1.0216,\n",
      "        0.9967, 1.1004, 1.0244, 0.9773, 1.1484, 1.0747, 0.9659, 0.9809, 0.9154,\n",
      "        0.9594, 1.1316, 0.9986, 1.1209, 1.0320, 0.9993, 1.0323, 1.2794, 0.9404,\n",
      "        1.1270, 0.9680, 1.1603, 0.9929, 0.9468, 1.0735, 0.9647, 1.0302, 0.9996,\n",
      "        1.1019, 1.1268, 0.9701, 1.0862, 0.9361, 0.9799, 1.0573, 1.0529, 1.0062,\n",
      "        1.0411, 1.0386, 0.9712, 1.0160, 1.0590, 1.0703, 1.0392, 0.9177, 0.9508,\n",
      "        0.9928, 1.1893, 0.9925, 0.9179, 1.1204, 0.9841, 0.9635, 1.1570, 0.9641,\n",
      "        0.9428, 1.0149, 0.9626, 0.9516, 1.1460, 1.1103, 0.9970, 0.9664, 0.9653,\n",
      "        1.0103, 0.9352, 1.1348, 1.0280, 1.1531, 0.9757, 1.2065, 1.1022, 1.0096,\n",
      "        1.0392, 1.1272, 0.9266, 1.0798, 1.0783, 1.1355, 0.9255, 1.1812, 1.0655,\n",
      "        0.9749, 1.0162, 1.2680, 0.9249, 1.0336, 1.0552, 1.0774, 1.0106, 0.9213,\n",
      "        0.9866, 0.9153, 1.2591, 1.0750, 1.0095, 0.9750, 1.2309, 1.0592, 1.2236,\n",
      "        1.0415, 0.9047, 1.0998, 1.0875, 1.2675, 0.9755, 1.3695, 0.9808, 0.9829,\n",
      "        1.0558, 1.0119, 1.0615, 0.9722, 1.2467, 1.1286, 1.0796, 1.0615, 0.9962,\n",
      "        1.1373, 1.0179, 1.0766, 1.0091, 0.9906, 0.9746, 1.0584, 1.2358, 1.0561,\n",
      "        0.9671, 0.8710, 1.0088, 1.1180, 0.9733, 1.0085, 1.1821, 0.9435, 1.0665,\n",
      "        1.1775, 1.1536, 1.0049, 1.0362, 0.9704, 0.9544, 0.9975, 1.2909, 0.9713,\n",
      "        1.1771, 1.0248, 1.1592, 1.0017, 0.9696, 0.9054, 1.2091, 1.0729, 0.9585,\n",
      "        1.0810, 1.0409, 0.9147, 1.1331, 1.0981, 1.0800, 1.0435, 1.2334, 1.0415,\n",
      "        1.0858, 1.1432, 1.1146, 0.9381, 0.9424, 0.9748, 1.0053, 0.9802, 1.0191,\n",
      "        1.1694, 1.1570, 0.9855, 0.9244, 1.0107, 1.0937, 1.1250, 0.9961, 1.0566,\n",
      "        1.0166, 0.9750, 1.0111, 0.9788, 1.0277, 0.9678, 1.0828, 1.0258, 0.9251,\n",
      "        1.0113, 0.9629, 1.0290, 1.0216, 1.0592, 1.1393, 1.0550, 1.2162, 0.9197,\n",
      "        0.9506, 1.0888, 1.0866, 1.1570, 1.1520, 0.9590, 1.1561, 1.0895, 1.1299,\n",
      "        0.9865, 1.1629, 1.1120, 0.9037, 0.9992, 0.9218, 0.9769, 1.0873, 0.9770,\n",
      "        1.1475, 0.9519, 0.9627, 1.2302, 1.2613, 0.9419, 1.1078, 1.0304, 0.8694,\n",
      "        1.1722, 1.0320, 1.1448, 1.1218, 0.9555, 0.9668, 1.0476, 1.0726, 1.0286,\n",
      "        1.2240, 1.0050, 1.1739, 1.2097, 1.2492, 0.9997, 0.9982, 1.1528, 1.1070,\n",
      "        1.1863, 0.9454, 1.0863, 1.0345, 1.1975, 1.1497, 1.3215, 1.0148],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.0.bn3.bias', Parameter containing:\n",
      "tensor([ 2.8257e-03, -3.1052e-03, -3.6971e-02,  4.3699e-03, -6.1682e-03,\n",
      "         1.0587e-02,  3.6861e-03,  3.9931e-02,  2.8291e-03,  7.6696e-03,\n",
      "        -2.3972e-02,  3.5306e-02, -3.0170e-02, -4.2405e-02, -3.5336e-03,\n",
      "        -2.6639e-02, -5.5045e-02,  3.9174e-02, -5.7227e-02, -7.8833e-03,\n",
      "        -3.5887e-02, -4.6055e-02,  2.1810e-02, -6.1323e-02,  4.2120e-02,\n",
      "         4.2844e-02, -3.5655e-03, -2.9277e-02,  1.5069e-02,  4.0494e-02,\n",
      "        -8.7994e-02,  6.3188e-02,  1.3602e-02,  2.5708e-02,  3.4459e-02,\n",
      "         7.0030e-03,  2.9811e-02,  5.4888e-02,  9.4646e-02, -6.3696e-02,\n",
      "         9.8690e-03,  6.7700e-03,  4.3114e-02,  4.6773e-02,  4.8253e-02,\n",
      "         2.3144e-02,  3.2715e-03,  3.5535e-02, -2.1640e-02, -5.6909e-03,\n",
      "        -6.3279e-02,  8.0255e-03, -3.9019e-03, -2.1173e-02,  5.5395e-02,\n",
      "        -5.3127e-02,  5.2659e-02,  1.2531e-02, -6.7787e-02,  5.1623e-03,\n",
      "         1.7642e-02,  3.1911e-02, -4.2444e-02, -2.5400e-02,  9.0325e-03,\n",
      "         1.0046e-02,  2.1177e-02, -5.8420e-03,  1.5470e-02,  1.0646e-02,\n",
      "         1.1960e-02, -2.4653e-02, -2.3940e-02, -7.5987e-02, -1.5153e-02,\n",
      "        -3.5163e-02, -1.9009e-02,  5.7504e-02, -3.6003e-02,  2.1896e-02,\n",
      "        -8.5891e-03,  2.6594e-02,  1.5293e-02, -3.1208e-02, -4.8892e-03,\n",
      "        -3.0263e-02,  2.5009e-02, -2.2654e-02,  3.7248e-02, -9.7943e-02,\n",
      "         4.9069e-02, -5.9879e-03, -1.8775e-02, -3.3492e-02, -1.9415e-03,\n",
      "         4.3489e-02,  1.2036e-02,  1.8334e-02, -1.3624e-02,  9.8104e-03,\n",
      "        -1.5002e-02, -2.6757e-02,  2.1937e-02, -2.7309e-03, -9.8678e-04,\n",
      "        -9.6187e-03, -3.0651e-02, -2.3422e-02, -8.7604e-03,  5.9846e-04,\n",
      "         5.4807e-02,  1.2301e-02, -1.3220e-02,  2.1321e-02,  1.7719e-03,\n",
      "        -7.7297e-03, -2.1236e-02, -1.9769e-02,  5.5295e-03, -1.7871e-02,\n",
      "        -6.8359e-03, -2.3266e-02, -1.6606e-02, -1.1909e-02,  5.2838e-02,\n",
      "        -3.4505e-02,  6.2602e-02,  3.2300e-03,  7.6055e-03,  3.3634e-02,\n",
      "         8.3118e-03, -4.8992e-03, -1.5435e-02,  4.4563e-03, -3.9788e-02,\n",
      "        -1.4420e-02, -2.7743e-03,  9.5224e-03,  2.5875e-02, -2.3805e-03,\n",
      "         1.9001e-02, -4.6633e-03, -2.6070e-02,  3.1576e-04,  4.7535e-02,\n",
      "        -7.0526e-05, -3.0777e-03, -7.5946e-03,  2.2351e-02,  1.9549e-02,\n",
      "         2.5702e-02, -4.6440e-02,  1.6563e-02,  5.2134e-03,  9.4605e-03,\n",
      "         1.3058e-03,  3.9162e-02, -5.7420e-02, -9.7419e-03,  2.2373e-02,\n",
      "        -2.1963e-03,  1.5616e-02, -8.1085e-03,  4.0846e-02, -4.3283e-02,\n",
      "        -2.8787e-03,  3.8229e-02, -3.6475e-02,  2.9596e-03,  9.2666e-04,\n",
      "        -6.4186e-02, -3.8429e-03, -2.4034e-02, -2.2463e-02, -4.2482e-02,\n",
      "        -4.5468e-02,  2.7377e-02,  4.2756e-02, -7.7255e-03, -4.0070e-02,\n",
      "         1.6094e-02,  6.5208e-03,  3.4562e-02, -3.0734e-02,  1.5843e-02,\n",
      "        -1.0236e-01, -3.2505e-02,  4.1669e-02, -6.6750e-03,  1.1359e-02,\n",
      "        -5.1249e-03, -1.7650e-02, -2.2709e-02,  1.0262e-02, -2.3509e-02,\n",
      "         7.5145e-03,  2.2690e-02, -1.6256e-02,  4.0953e-03, -6.4200e-02,\n",
      "         2.7423e-02,  2.3770e-02, -1.6388e-02,  1.1108e-02,  1.9654e-02,\n",
      "        -1.7770e-02, -8.1914e-02,  1.7318e-02,  2.1895e-02, -1.3812e-02,\n",
      "         2.9662e-03,  6.5961e-03, -8.4397e-03,  4.1000e-02,  3.6044e-03,\n",
      "        -6.9677e-02, -6.5186e-02,  4.6084e-02,  3.1451e-02, -3.9517e-02,\n",
      "        -1.1322e-03,  3.9797e-04,  6.8502e-04, -3.9854e-02, -5.1500e-02,\n",
      "         4.3335e-02, -5.9255e-02, -1.1726e-02,  1.9730e-02,  2.9179e-02,\n",
      "        -1.2564e-02,  3.8932e-02,  5.2719e-02, -2.4230e-02, -4.8587e-03,\n",
      "         1.2893e-02, -1.0323e-02, -7.7280e-02,  2.5817e-02,  2.9288e-02,\n",
      "        -6.4115e-02, -8.6266e-02,  7.1553e-03,  2.2727e-02,  1.9937e-02,\n",
      "        -1.4034e-02, -1.6605e-03, -6.5469e-03,  1.2257e-02,  1.2582e-02,\n",
      "        -8.5193e-03, -5.9729e-02,  1.4494e-02,  2.4349e-03,  3.8835e-02,\n",
      "         4.9025e-02,  8.2486e-02, -2.4328e-02, -1.9372e-02, -7.1758e-03,\n",
      "         3.0737e-02, -2.6329e-02,  2.2096e-02,  4.8935e-02, -1.2646e-02,\n",
      "         3.2087e-02,  2.8918e-02, -2.9622e-02, -1.6314e-02, -2.7587e-03,\n",
      "        -5.0622e-02,  2.4448e-02,  5.8918e-04, -9.8721e-03,  3.3048e-03,\n",
      "         3.4955e-03,  1.4304e-02,  8.6258e-02, -4.3686e-02,  5.8714e-02,\n",
      "        -4.9271e-03,  1.6920e-02, -3.3849e-03, -2.6092e-02,  1.3604e-02,\n",
      "        -1.8281e-02, -5.0582e-03,  7.7847e-03,  9.9077e-03,  7.4912e-03,\n",
      "        -6.9081e-03,  7.7342e-03, -2.3684e-02, -5.7762e-03,  1.0822e-02,\n",
      "         2.9337e-02,  4.6241e-02, -2.6959e-02,  5.1177e-02, -4.2927e-02,\n",
      "        -1.6908e-02, -4.0709e-03,  2.9595e-03, -4.9520e-03, -4.8569e-02,\n",
      "        -4.6551e-02, -5.2675e-02,  4.5147e-03, -1.8582e-02, -3.7130e-02,\n",
      "         1.7143e-02, -1.8181e-02, -1.3605e-02,  1.1254e-02, -1.6089e-02,\n",
      "        -2.0313e-02, -4.9485e-03, -2.3120e-02, -1.2107e-02,  2.2455e-02,\n",
      "         4.4694e-02, -8.6420e-03,  1.0114e-02, -1.0166e-01,  4.1408e-02,\n",
      "        -6.8653e-02,  2.5855e-02, -2.1876e-02,  5.6097e-03, -8.4937e-03,\n",
      "         5.2859e-02,  1.4239e-02, -3.6288e-02, -1.8312e-02,  2.8900e-02,\n",
      "         8.1402e-03,  1.9829e-02, -1.3617e-02,  1.5554e-02, -2.5527e-02,\n",
      "         2.8750e-02,  2.7086e-02, -2.3996e-02,  2.9633e-02,  2.0994e-02,\n",
      "        -5.8440e-02, -2.8482e-03,  2.8004e-02,  3.6064e-02,  4.6941e-03,\n",
      "        -6.5401e-02, -1.3828e-03, -4.2890e-02,  5.0336e-02,  5.7531e-02,\n",
      "         6.6623e-03, -2.9792e-02,  3.5054e-02, -1.0702e-02,  4.2872e-02,\n",
      "        -1.1906e-02, -2.2170e-02,  4.9235e-02,  4.6528e-03,  9.6284e-02,\n",
      "         1.2426e-02,  1.7942e-02, -1.9893e-02, -8.9934e-03,  3.8404e-02,\n",
      "        -7.0380e-03, -9.1542e-04, -3.8315e-03,  7.4647e-03,  8.1494e-03,\n",
      "         5.6543e-02, -9.3629e-02, -1.5421e-02,  1.9943e-03, -4.4141e-02,\n",
      "         2.0188e-02, -8.4272e-03,  2.0891e-02, -4.9537e-02,  1.3589e-02,\n",
      "         1.5402e-02, -1.5385e-02, -1.4772e-02, -8.2296e-02,  4.4498e-02,\n",
      "         1.3846e-03, -4.1809e-02, -4.8522e-04,  5.5721e-02, -6.1221e-02,\n",
      "        -4.9195e-03,  4.2875e-03,  3.1635e-02, -5.3059e-02, -9.1185e-03,\n",
      "        -1.7120e-02, -3.7572e-02, -1.0269e-02,  6.3876e-03, -2.2510e-02,\n",
      "         1.7643e-02,  7.8166e-02,  4.9265e-02, -1.1035e-02, -2.3912e-02,\n",
      "        -5.8349e-03,  5.0318e-02,  4.1485e-03, -3.2864e-02,  2.1952e-02,\n",
      "        -4.9438e-02, -7.7507e-02,  3.3596e-02,  1.1886e-03,  6.8326e-02,\n",
      "         4.2005e-03,  2.9481e-03, -1.0292e-02, -1.4505e-02,  6.7877e-02,\n",
      "         1.7941e-02, -7.0526e-02, -4.5609e-02, -4.8442e-03, -3.4658e-02,\n",
      "        -2.5658e-02,  3.0255e-02,  1.4039e-02,  8.0877e-02, -2.3518e-03,\n",
      "        -1.0142e-02,  2.8145e-03, -8.1590e-03,  1.8125e-02, -1.9460e-03,\n",
      "         3.1827e-02, -5.0532e-04, -1.2125e-02, -4.4476e-02,  1.0853e-03,\n",
      "         4.3084e-02, -1.6863e-02,  5.6105e-02, -6.7299e-03, -2.3050e-02,\n",
      "        -3.3734e-02, -2.3048e-02,  2.4052e-02, -3.5445e-02, -2.5445e-02,\n",
      "         2.0106e-02, -4.5120e-04,  4.7332e-02, -5.6348e-02, -4.4828e-02,\n",
      "         7.6823e-03,  1.6992e-02,  3.9400e-02,  2.1923e-02, -1.9182e-03,\n",
      "         4.5048e-02,  2.6641e-02,  9.1579e-03, -3.8226e-03,  3.9983e-02,\n",
      "        -1.0307e-02, -1.0634e-01, -6.9327e-04, -3.6521e-02, -1.4437e-02,\n",
      "         1.9845e-02, -3.0218e-02,  5.2846e-02, -1.7756e-02, -3.7453e-02,\n",
      "         4.8621e-02,  2.1699e-02, -1.0435e-02,  3.2782e-02, -6.2872e-03,\n",
      "        -4.0383e-02,  3.1541e-02,  7.3801e-02,  8.6696e-03,  6.3058e-02,\n",
      "        -1.1199e-02, -1.0407e-02,  1.8375e-03,  2.9699e-03, -3.9467e-02,\n",
      "         4.7354e-02, -1.6061e-02,  4.9451e-02,  3.1260e-03,  7.3043e-03,\n",
      "        -2.9186e-02, -2.2511e-04,  1.7969e-02,  6.7568e-02,  9.0587e-03,\n",
      "        -3.5733e-03,  1.0522e-02, -2.0011e-03,  2.2084e-02,  3.4368e-02,\n",
      "         7.6368e-02, -2.1389e-02], device='cuda:0', requires_grad=True))\n",
      "('3.1.conv1.weight', Parameter containing:\n",
      "tensor([[[-1.4836e-01],\n",
      "         [-4.3100e-02],\n",
      "         [-5.2837e-02],\n",
      "         ...,\n",
      "         [-2.4254e-01],\n",
      "         [-2.2366e-01],\n",
      "         [ 1.0399e-01]],\n",
      "\n",
      "        [[ 1.1459e-01],\n",
      "         [-2.8015e-02],\n",
      "         [ 2.8790e-01],\n",
      "         ...,\n",
      "         [ 3.0971e-01],\n",
      "         [-8.7434e-02],\n",
      "         [ 8.0661e-02]],\n",
      "\n",
      "        [[ 5.2729e-02],\n",
      "         [-1.1302e-01],\n",
      "         [ 1.7196e-01],\n",
      "         ...,\n",
      "         [-1.1462e-01],\n",
      "         [ 7.0029e-02],\n",
      "         [-6.8171e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.3610e-02],\n",
      "         [-2.1701e-01],\n",
      "         [-2.7111e-03],\n",
      "         ...,\n",
      "         [ 4.3785e-02],\n",
      "         [ 2.2517e-01],\n",
      "         [-1.7892e-01]],\n",
      "\n",
      "        [[-6.9808e-02],\n",
      "         [-2.0705e-01],\n",
      "         [ 1.7641e-01],\n",
      "         ...,\n",
      "         [ 1.7588e-01],\n",
      "         [ 1.0810e-01],\n",
      "         [-5.3312e-01]],\n",
      "\n",
      "        [[-9.4998e-05],\n",
      "         [ 2.1546e-01],\n",
      "         [ 1.5320e-01],\n",
      "         ...,\n",
      "         [-1.8439e-01],\n",
      "         [ 3.2980e-01],\n",
      "         [ 4.1868e-01]]], device='cuda:0', requires_grad=True))\n",
      "('3.1.conv1.bias', Parameter containing:\n",
      "tensor([ 0.0366,  0.0209,  0.0405, -0.0183, -0.0073, -0.0223,  0.0200, -0.0126,\n",
      "         0.0358,  0.0152, -0.0016,  0.0140, -0.0325, -0.0242,  0.0383,  0.0051,\n",
      "        -0.0382, -0.0034, -0.0371, -0.0121,  0.0089,  0.0309,  0.0032, -0.0291,\n",
      "         0.0062, -0.0091,  0.0220,  0.0342, -0.0440, -0.0167,  0.0417, -0.0187,\n",
      "         0.0174,  0.0287,  0.0395, -0.0384, -0.0258, -0.0240,  0.0169, -0.0070,\n",
      "         0.0201, -0.0067,  0.0249, -0.0067,  0.0377,  0.0185, -0.0281, -0.0427,\n",
      "        -0.0082, -0.0346,  0.0294, -0.0423, -0.0160, -0.0305, -0.0423, -0.0225,\n",
      "        -0.0028,  0.0045, -0.0266, -0.0427,  0.0235, -0.0387, -0.0078,  0.0138,\n",
      "         0.0331, -0.0208,  0.0302, -0.0208,  0.0045,  0.0138,  0.0263,  0.0338,\n",
      "         0.0153,  0.0116,  0.0260, -0.0171, -0.0171, -0.0124,  0.0261,  0.0072,\n",
      "         0.0224, -0.0135,  0.0011,  0.0404, -0.0383, -0.0317,  0.0269,  0.0079,\n",
      "         0.0406, -0.0011,  0.0162,  0.0106, -0.0306, -0.0300, -0.0144,  0.0251,\n",
      "         0.0008,  0.0400,  0.0108, -0.0068,  0.0062, -0.0435,  0.0305, -0.0267,\n",
      "        -0.0200, -0.0082, -0.0073, -0.0438, -0.0071,  0.0436,  0.0377,  0.0279,\n",
      "        -0.0179,  0.0238, -0.0400,  0.0253,  0.0055, -0.0256, -0.0037, -0.0245,\n",
      "         0.0028,  0.0148,  0.0331,  0.0337,  0.0208, -0.0129, -0.0248,  0.0346],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.1.conv2.weight', Parameter containing:\n",
      "tensor([[[ 1.8684e-01,  2.3631e-01,  4.3396e-01],\n",
      "         [-7.6138e-03, -1.6759e-01, -2.0947e-02],\n",
      "         [ 1.0966e-02, -5.7293e-02,  3.8950e-02],\n",
      "         ...,\n",
      "         [ 1.6326e-01,  1.5013e-02, -4.8432e-03],\n",
      "         [ 3.0107e-01, -2.4533e-02,  1.6391e-03],\n",
      "         [ 2.3864e-01, -2.2373e-03,  1.1433e-02]],\n",
      "\n",
      "        [[-1.4081e-01,  1.4800e-01,  9.1445e-02],\n",
      "         [-2.2440e-01,  1.5003e-01,  8.7814e-02],\n",
      "         [-2.8895e-01, -1.6940e-01, -5.2807e-02],\n",
      "         ...,\n",
      "         [-1.1306e-03, -8.5808e-02,  3.0202e-01],\n",
      "         [ 2.2575e-01,  1.6076e-01, -2.0567e-01],\n",
      "         [ 1.8449e-01,  7.2867e-02, -2.3231e-01]],\n",
      "\n",
      "        [[ 1.0447e-01, -4.5394e-02,  8.5340e-02],\n",
      "         [-1.6348e-01,  1.3337e-01, -2.5860e-01],\n",
      "         [-2.7773e-01, -4.0179e-02,  1.9476e-02],\n",
      "         ...,\n",
      "         [-1.1118e-01, -2.8186e-01,  9.6236e-02],\n",
      "         [ 3.2430e-02, -2.1184e-01,  1.1612e-01],\n",
      "         [ 7.0227e-02,  5.9867e-02,  1.6590e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.0457e-02,  4.6597e-02, -8.6167e-02],\n",
      "         [ 5.1975e-02,  7.1584e-02, -7.0166e-02],\n",
      "         [ 1.4373e-02, -2.9517e-01, -8.5107e-02],\n",
      "         ...,\n",
      "         [ 1.6467e-02,  1.2741e-04, -6.9695e-02],\n",
      "         [ 8.8352e-02,  4.5920e-02, -2.4460e-01],\n",
      "         [ 4.9426e-02,  6.9296e-02, -2.3058e-01]],\n",
      "\n",
      "        [[ 2.2814e-01, -6.4203e-02,  1.7720e-02],\n",
      "         [-2.9983e-02, -2.8896e-02, -1.2406e-01],\n",
      "         [ 2.4430e-01, -1.3399e-01, -6.2435e-02],\n",
      "         ...,\n",
      "         [ 7.6250e-03,  1.3556e-01,  3.0706e-01],\n",
      "         [ 8.1755e-02,  3.0759e-02, -3.7148e-01],\n",
      "         [ 1.6997e-01,  1.0479e-01,  1.9606e-01]],\n",
      "\n",
      "        [[ 1.9131e-01,  5.0940e-01,  1.6245e-01],\n",
      "         [ 2.1509e-01,  8.4538e-03,  1.8544e-01],\n",
      "         [ 1.3354e-01,  7.3093e-02, -2.9809e-02],\n",
      "         ...,\n",
      "         [-2.7119e-02, -4.3395e-02, -1.3341e-02],\n",
      "         [ 2.9101e-02, -4.7358e-01, -1.2248e-01],\n",
      "         [ 2.5596e-01,  1.7730e-01, -2.0504e-01]]], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('3.1.conv2.bias', Parameter containing:\n",
      "tensor([-4.6541e-02,  5.1410e-03,  2.9709e-02,  2.1472e-02, -3.9059e-02,\n",
      "        -4.6786e-02,  1.9183e-02, -3.0568e-02,  3.0826e-02, -4.8799e-03,\n",
      "         3.5753e-02, -3.8399e-02, -4.3365e-02,  3.4054e-02,  5.0803e-02,\n",
      "         2.9371e-02,  5.0696e-02, -7.0888e-04, -2.9955e-02,  1.9214e-02,\n",
      "         2.7288e-02,  2.4691e-02,  4.1556e-02,  2.5510e-02, -3.1463e-02,\n",
      "        -1.8182e-02, -2.7084e-02, -8.3822e-03, -3.8970e-02, -1.9031e-02,\n",
      "         3.6616e-02, -4.4172e-02, -3.5901e-02,  2.8266e-02, -4.8170e-02,\n",
      "         1.8255e-02,  2.7866e-02,  1.1941e-02,  2.6015e-02,  8.3441e-03,\n",
      "        -1.3738e-02, -2.2917e-03,  4.1272e-02, -2.8126e-02, -4.3715e-02,\n",
      "        -3.4795e-02,  4.0834e-02, -1.4249e-02,  1.3955e-02, -4.2944e-02,\n",
      "         3.4225e-02, -3.1223e-02, -5.0034e-03, -2.7710e-02, -1.8545e-02,\n",
      "        -4.5245e-02, -2.5686e-02,  1.6839e-02, -7.3243e-03, -2.7722e-02,\n",
      "         2.7772e-02, -2.3811e-03, -2.3029e-02,  4.3399e-02,  2.6873e-02,\n",
      "         7.2825e-03, -4.2285e-02, -1.5205e-02,  2.0412e-02, -2.4078e-03,\n",
      "        -1.0153e-02, -3.6129e-03, -3.2017e-02,  1.6771e-02,  6.2763e-03,\n",
      "         1.1057e-02, -1.5525e-02, -1.7487e-02, -4.6043e-02,  3.0903e-02,\n",
      "        -1.7668e-02, -5.0253e-02,  3.1187e-02, -6.1161e-03,  3.6656e-02,\n",
      "        -8.0545e-03, -3.9212e-02,  1.8121e-02, -2.1464e-02, -2.6264e-02,\n",
      "        -4.6939e-02,  3.0751e-05,  2.6951e-02, -3.9754e-02,  4.4450e-02,\n",
      "        -1.2022e-02, -3.0305e-02, -4.0177e-02, -4.3883e-02, -4.6182e-02,\n",
      "         3.8350e-03,  2.6602e-02, -1.5385e-02, -1.4275e-02, -1.8483e-02,\n",
      "         4.6380e-02,  4.6671e-02, -2.4100e-02,  2.7751e-02, -4.4324e-02,\n",
      "        -3.6603e-02, -2.6631e-02, -9.2026e-03,  3.1722e-02,  4.9848e-02,\n",
      "         5.0685e-02, -2.8106e-02, -8.5416e-03,  3.5026e-02, -1.5548e-02,\n",
      "         1.2435e-03,  2.9274e-02,  4.5395e-02,  1.9912e-02, -1.5234e-02,\n",
      "        -6.5744e-03, -3.5940e-02, -3.8303e-02], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('3.1.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.0904],\n",
      "         [-0.0554],\n",
      "         [ 0.1176],\n",
      "         ...,\n",
      "         [ 0.0948],\n",
      "         [ 0.0459],\n",
      "         [ 0.1426]],\n",
      "\n",
      "        [[-0.0361],\n",
      "         [ 0.0440],\n",
      "         [ 0.0990],\n",
      "         ...,\n",
      "         [-0.0616],\n",
      "         [ 0.1063],\n",
      "         [-0.0889]],\n",
      "\n",
      "        [[ 0.0027],\n",
      "         [ 0.1203],\n",
      "         [ 0.0175],\n",
      "         ...,\n",
      "         [-0.0642],\n",
      "         [-0.0109],\n",
      "         [ 0.0325]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0420],\n",
      "         [-0.0489],\n",
      "         [ 0.1555],\n",
      "         ...,\n",
      "         [ 0.1167],\n",
      "         [ 0.0369],\n",
      "         [ 0.1150]],\n",
      "\n",
      "        [[-0.0505],\n",
      "         [-0.0984],\n",
      "         [-0.0921],\n",
      "         ...,\n",
      "         [ 0.0573],\n",
      "         [-0.1524],\n",
      "         [-0.1073]],\n",
      "\n",
      "        [[ 0.0140],\n",
      "         [-0.1353],\n",
      "         [ 0.0694],\n",
      "         ...,\n",
      "         [ 0.0797],\n",
      "         [ 0.0064],\n",
      "         [ 0.0289]]], device='cuda:0', requires_grad=True))\n",
      "('3.1.conv3.bias', Parameter containing:\n",
      "tensor([ 0.0792, -0.0398, -0.0130, -0.0467,  0.0553, -0.0675,  0.0613, -0.0437,\n",
      "         0.0199, -0.0389,  0.0153,  0.0070,  0.0244,  0.0526,  0.0769,  0.0166,\n",
      "        -0.0647,  0.0067, -0.0505,  0.0375, -0.0290, -0.0116, -0.0162, -0.0118,\n",
      "        -0.0689, -0.0747, -0.0788,  0.0583, -0.0185,  0.0199,  0.0108,  0.0619,\n",
      "         0.0641, -0.0791,  0.0110, -0.0558,  0.0032, -0.0472,  0.0758, -0.0513,\n",
      "         0.0353,  0.0610,  0.0869, -0.0729,  0.0032, -0.0508, -0.0428,  0.0370,\n",
      "        -0.0221, -0.0585,  0.0260,  0.0865,  0.0386,  0.0236, -0.0423,  0.0813,\n",
      "         0.0366,  0.0384,  0.0494,  0.0268,  0.0628,  0.0777,  0.0750,  0.0761,\n",
      "        -0.0588,  0.0509, -0.0500, -0.0276, -0.0522,  0.0489, -0.0739,  0.0839,\n",
      "        -0.0018, -0.0706,  0.0291, -0.0612, -0.0751,  0.0037, -0.0830,  0.0832,\n",
      "         0.0166,  0.0231,  0.0708, -0.0791, -0.0566,  0.0801, -0.0617, -0.0357,\n",
      "         0.0501,  0.0025, -0.0534, -0.0042, -0.0410,  0.0418,  0.0358, -0.0313,\n",
      "         0.0715, -0.0557, -0.0707,  0.0845, -0.0114, -0.0282, -0.0731,  0.0803,\n",
      "        -0.0821, -0.0362,  0.0720, -0.0659, -0.0677,  0.0416, -0.0590,  0.0662,\n",
      "         0.0853, -0.0486,  0.0564, -0.0402,  0.0419,  0.0750,  0.0455,  0.0554,\n",
      "        -0.0348,  0.0439, -0.0013,  0.0255,  0.0601,  0.0836, -0.0523,  0.0494,\n",
      "         0.0391, -0.0211,  0.0459,  0.0138, -0.0356, -0.0882, -0.0087, -0.0217,\n",
      "         0.0220, -0.0464, -0.0614,  0.0352,  0.0878, -0.0060, -0.0574,  0.0101,\n",
      "        -0.0815, -0.0628,  0.0630,  0.0387,  0.0290, -0.0034, -0.0138,  0.0822,\n",
      "         0.0438, -0.0132, -0.0396, -0.0732,  0.0356, -0.0503, -0.0327, -0.0527,\n",
      "        -0.0516,  0.0698,  0.0549, -0.0650, -0.0126,  0.0027,  0.0768, -0.0493,\n",
      "        -0.0123,  0.0458,  0.0379, -0.0567, -0.0473,  0.0873, -0.0115,  0.0342,\n",
      "        -0.0285, -0.0330, -0.0736, -0.0774, -0.0432, -0.0734, -0.0673, -0.0534,\n",
      "         0.0803,  0.0168, -0.0682,  0.0810,  0.0640,  0.0019,  0.0540, -0.0521,\n",
      "         0.0285, -0.0332,  0.0286, -0.0827, -0.0584,  0.0383, -0.0583, -0.0353,\n",
      "        -0.0014, -0.0074,  0.0614, -0.0707, -0.0741,  0.0490,  0.0753,  0.0630,\n",
      "         0.0530, -0.0447, -0.0297,  0.0584, -0.0060, -0.0637, -0.0326,  0.0549,\n",
      "        -0.0762,  0.0349,  0.0489, -0.0360, -0.0204,  0.0391, -0.0529, -0.0343,\n",
      "         0.0540, -0.0746,  0.0436,  0.0395, -0.0638, -0.0762, -0.0215, -0.0266,\n",
      "         0.0336, -0.0474, -0.0418,  0.0281, -0.0505,  0.0856,  0.0718,  0.0137,\n",
      "        -0.0882, -0.0552, -0.0367,  0.0578, -0.0579,  0.0151,  0.0376, -0.0002,\n",
      "        -0.0858,  0.0270, -0.0535,  0.0372,  0.0363,  0.0463,  0.0577,  0.0093,\n",
      "        -0.0399,  0.0561,  0.0873,  0.0014,  0.0233, -0.0635,  0.0173, -0.0022,\n",
      "         0.0824, -0.0036, -0.0808,  0.0445,  0.0486,  0.0442,  0.0515, -0.0209,\n",
      "        -0.0186,  0.0550,  0.0475, -0.0582, -0.0312,  0.0435, -0.0066,  0.0155,\n",
      "        -0.0405,  0.0650, -0.0569, -0.0613, -0.0768,  0.0250,  0.0056,  0.0675,\n",
      "        -0.0154,  0.0574, -0.0764,  0.0172, -0.0058,  0.0135,  0.0747, -0.0057,\n",
      "        -0.0057, -0.0358,  0.0691, -0.0276, -0.0051,  0.0644,  0.0383,  0.0563,\n",
      "        -0.0075,  0.0762,  0.0318, -0.0009, -0.0555, -0.0138,  0.0811, -0.0586,\n",
      "         0.0498, -0.0323,  0.0230, -0.0286,  0.0298, -0.0288,  0.0812,  0.0444,\n",
      "         0.0595, -0.0651,  0.0058,  0.0815, -0.0202,  0.0330,  0.0695,  0.0051,\n",
      "        -0.0196,  0.0553,  0.0725, -0.0541,  0.0779,  0.0039,  0.0242,  0.0024,\n",
      "         0.0060, -0.0716,  0.0680,  0.0144,  0.0149, -0.0452,  0.0272, -0.0358,\n",
      "        -0.0287,  0.0211,  0.0789,  0.0543,  0.0517, -0.0248,  0.0408,  0.0714,\n",
      "        -0.0051, -0.0090, -0.0200, -0.0645,  0.0414, -0.0666,  0.0882, -0.0660,\n",
      "         0.0158,  0.0298, -0.0477, -0.0409,  0.0793,  0.0044,  0.0030, -0.0711,\n",
      "         0.0199,  0.0155,  0.0838, -0.0498,  0.0495, -0.0206, -0.0515, -0.0222,\n",
      "        -0.0296, -0.0648,  0.0740,  0.0536,  0.0826, -0.0250,  0.0723,  0.0699,\n",
      "        -0.0764, -0.0016,  0.0672, -0.0342,  0.0460, -0.0023, -0.0604,  0.0635,\n",
      "        -0.0647,  0.0367, -0.0472,  0.0003,  0.0283, -0.0518,  0.0086,  0.0874,\n",
      "         0.0784,  0.0815,  0.0027, -0.0585,  0.0633,  0.0778,  0.0811, -0.0238,\n",
      "        -0.0685, -0.0062,  0.0408, -0.0170, -0.0114, -0.0234, -0.0030, -0.0378,\n",
      "         0.0575, -0.0673, -0.0186,  0.0506, -0.0245, -0.0501,  0.0099,  0.0199,\n",
      "         0.0409, -0.0682, -0.0215, -0.0793, -0.0558, -0.0792,  0.0858,  0.0121,\n",
      "         0.0492, -0.0097,  0.0711, -0.0743,  0.0572, -0.0705,  0.0007,  0.0148,\n",
      "        -0.0864, -0.0252, -0.0565,  0.0830,  0.0101,  0.0407,  0.0689, -0.0819,\n",
      "         0.0094, -0.0706, -0.0429,  0.0135,  0.0835,  0.0574, -0.0039, -0.0168,\n",
      "         0.0794,  0.0830, -0.0359,  0.0085,  0.0133, -0.0322, -0.0190, -0.0470,\n",
      "        -0.0597,  0.0802, -0.0679, -0.0838, -0.0081,  0.0019,  0.0719,  0.0752,\n",
      "        -0.0148,  0.0262, -0.0150,  0.0762,  0.0104,  0.0160, -0.0604, -0.0225,\n",
      "        -0.0825, -0.0539,  0.0415, -0.0429,  0.0346,  0.0546,  0.0754, -0.0098,\n",
      "        -0.0033,  0.0551,  0.0797, -0.0254, -0.0554,  0.0651,  0.0762, -0.0089,\n",
      "         0.0409, -0.0261,  0.0307, -0.0257, -0.0050,  0.0710, -0.0233,  0.0729,\n",
      "        -0.0525,  0.0054,  0.0781,  0.0035, -0.0200,  0.0414, -0.0424, -0.0877],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.1.bn1.weight', Parameter containing:\n",
      "tensor([0.8430, 0.9435, 1.1147, 0.9108, 1.0343, 1.0540, 1.0024, 1.1248, 1.1656,\n",
      "        1.1390, 1.1439, 0.8318, 0.8619, 0.9584, 0.9683, 0.9995, 0.8482, 1.0402,\n",
      "        0.9278, 1.1985, 0.9722, 1.0710, 1.0468, 1.1587, 0.8972, 0.8927, 0.9870,\n",
      "        0.9538, 0.9797, 1.0380, 1.1169, 1.0230, 1.0632, 0.8813, 0.8378, 1.1214,\n",
      "        1.1001, 0.8714, 1.3275, 0.9639, 1.0244, 0.8476, 1.1036, 0.8958, 1.1466,\n",
      "        0.9160, 1.0112, 1.0697, 0.9641, 0.9679, 0.9092, 1.0529, 1.0164, 0.9740,\n",
      "        1.2120, 0.9261, 0.7236, 0.9249, 0.9108, 0.9785, 1.0970, 1.0297, 0.9990,\n",
      "        1.2253, 0.9148, 1.0017, 1.1851, 0.8154, 0.8210, 0.8480, 1.0379, 0.9238,\n",
      "        1.1239, 1.0999, 0.8480, 1.1850, 1.0073, 0.8048, 1.1737, 1.1031, 0.9188,\n",
      "        1.2501, 1.2528, 1.0021, 1.0957, 1.0291, 0.7916, 1.1400, 1.1648, 0.9894,\n",
      "        1.1347, 0.9151, 0.9685, 1.0019, 1.0082, 1.2095, 0.9395, 0.9741, 0.9679,\n",
      "        0.7408, 1.0592, 0.8919, 0.9957, 0.9841, 0.9144, 0.8728, 0.9087, 1.0712,\n",
      "        0.9081, 0.8294, 1.0700, 0.9396, 0.8609, 0.9641, 0.9555, 0.8655, 0.9963,\n",
      "        1.0112, 0.9128, 1.1094, 0.9958, 1.0745, 1.1460, 1.0107, 0.9655, 1.2457,\n",
      "        1.3091, 1.1562], device='cuda:0', requires_grad=True))\n",
      "('3.1.bn1.bias', Parameter containing:\n",
      "tensor([-0.0497, -0.1500,  0.1625, -0.1623,  0.0785,  0.0603, -0.0372, -0.0042,\n",
      "        -0.0498,  0.0297, -0.1301, -0.2001, -0.0382, -0.1952,  0.0394, -0.0329,\n",
      "        -0.0376, -0.0801, -0.1134, -0.0057,  0.1224,  0.0006, -0.1729, -0.0157,\n",
      "        -0.0408, -0.0742, -0.0753, -0.0533, -0.0286, -0.0839,  0.1111, -0.1067,\n",
      "        -0.1444,  0.0967,  0.1169, -0.1092, -0.0818,  0.0224, -0.0525, -0.0598,\n",
      "         0.0413,  0.0821, -0.0267, -0.1641, -0.1649, -0.0502, -0.0295,  0.0471,\n",
      "        -0.2597, -0.1586, -0.0258,  0.0577, -0.0389, -0.0782,  0.0518, -0.0576,\n",
      "        -0.2857, -0.1424, -0.1732, -0.0525, -0.0302,  0.0198, -0.1243, -0.0012,\n",
      "        -0.1162, -0.1362, -0.1263,  0.0412, -0.1483, -0.2198, -0.1978, -0.1107,\n",
      "         0.0299,  0.0335, -0.0774, -0.0041, -0.1006, -0.1261,  0.0261, -0.1522,\n",
      "        -0.0346, -0.0081,  0.0199, -0.0299,  0.0679, -0.1069,  0.1264,  0.0467,\n",
      "         0.1008, -0.0227, -0.1588, -0.1064, -0.1457,  0.0257, -0.0542,  0.1035,\n",
      "        -0.0944, -0.0463, -0.1266, -0.0707, -0.1254, -0.1477, -0.1296, -0.1514,\n",
      "        -0.1584, -0.0474,  0.0587,  0.1623,  0.0372, -0.1934, -0.0029,  0.0059,\n",
      "         0.0160, -0.0611,  0.1836, -0.1716, -0.0386, -0.1121, -0.0304, -0.0041,\n",
      "        -0.0867,  0.0456,  0.0475,  0.0939, -0.2493, -0.1079,  0.0206, -0.1048],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.1.bn2.weight', Parameter containing:\n",
      "tensor([1.0173, 0.9730, 0.9539, 1.0576, 0.9505, 1.0087, 1.0434, 1.0546, 0.9416,\n",
      "        1.0860, 1.0655, 1.1218, 0.8421, 1.1319, 1.0919, 0.8143, 1.0187, 1.0189,\n",
      "        0.9340, 0.9196, 0.9592, 1.0761, 0.9618, 0.9766, 0.9227, 1.0629, 1.0087,\n",
      "        1.0034, 1.1045, 0.9995, 0.9652, 1.0862, 1.0125, 1.1131, 0.9468, 1.0048,\n",
      "        0.8973, 1.0035, 1.0120, 1.1023, 0.9962, 1.0369, 1.1102, 1.0982, 0.9958,\n",
      "        0.9931, 0.9707, 0.9066, 1.0435, 0.9220, 1.0398, 0.9945, 1.0650, 1.0560,\n",
      "        1.0620, 1.0842, 0.9470, 0.8114, 0.9876, 0.9141, 1.0815, 0.9090, 1.0017,\n",
      "        0.9528, 0.9216, 0.8805, 1.0515, 1.1323, 0.9535, 0.9258, 1.0880, 0.9507,\n",
      "        1.0043, 0.9438, 0.9601, 1.0000, 0.8852, 0.9508, 0.8685, 0.9386, 1.1230,\n",
      "        0.7909, 1.0387, 1.0552, 0.7248, 0.9986, 1.0844, 1.1726, 0.8774, 1.0542,\n",
      "        1.0440, 0.9305, 0.9556, 1.0082, 0.9208, 1.1665, 1.0087, 1.1065, 1.0241,\n",
      "        1.0714, 0.9993, 0.9060, 1.0876, 0.9584, 0.9433, 1.0317, 1.1557, 0.9177,\n",
      "        1.0555, 0.8770, 1.1392, 1.0084, 0.9667, 1.0777, 1.0825, 0.9851, 0.9539,\n",
      "        1.0203, 1.0091, 1.1158, 1.1445, 1.0477, 0.9957, 0.9700, 0.9179, 1.1358,\n",
      "        0.9308, 0.9771], device='cuda:0', requires_grad=True))\n",
      "('3.1.bn2.bias', Parameter containing:\n",
      "tensor([-4.2299e-02, -9.4986e-02, -1.7331e-01, -3.8289e-02, -2.1995e-01,\n",
      "        -1.4626e-01, -8.9982e-02, -1.2363e-01, -2.2767e-01, -1.3150e-01,\n",
      "        -1.0808e-01, -2.6256e-02, -1.3898e-01, -2.1444e-01, -1.2684e-01,\n",
      "        -1.7382e-01, -3.4147e-02,  1.2133e-02, -1.4128e-01, -8.5945e-02,\n",
      "        -1.0174e-02, -3.7644e-02,  2.5072e-02, -1.2174e-01, -1.4336e-01,\n",
      "        -3.1377e-02, -1.5849e-01, -1.9206e-01, -2.6735e-02, -5.1736e-05,\n",
      "        -1.1574e-01, -1.0172e-01, -2.5457e-01,  1.9058e-02, -1.4412e-01,\n",
      "        -2.4606e-01, -1.4070e-01, -6.2172e-02, -1.6660e-01, -7.5039e-02,\n",
      "        -2.2061e-01, -5.3299e-02, -1.6278e-01, -5.6681e-02, -1.3304e-01,\n",
      "        -1.7901e-01, -8.4494e-02, -1.2430e-01, -4.2258e-02, -2.3854e-01,\n",
      "        -1.1107e-01, -2.3424e-02, -8.7631e-02, -4.8071e-02, -1.1036e-01,\n",
      "        -8.3096e-02,  1.3198e-02, -2.5387e-01, -1.5853e-01, -1.8206e-01,\n",
      "         7.0904e-03, -2.2890e-02, -6.5745e-02, -1.7688e-01, -1.5914e-01,\n",
      "        -6.2736e-02, -1.8554e-03, -1.4260e-01, -6.9891e-02, -2.1485e-01,\n",
      "        -1.3612e-01, -1.6433e-01,  5.1362e-03, -1.0639e-01, -1.3101e-01,\n",
      "        -7.3571e-02, -1.9332e-01, -1.2956e-01, -9.9065e-02,  3.9014e-02,\n",
      "        -1.0872e-01, -8.0071e-02, -1.1573e-01, -1.1674e-01, -2.3389e-01,\n",
      "        -2.0844e-01, -4.5328e-02, -1.8246e-01, -6.8584e-02, -1.0509e-01,\n",
      "        -1.2429e-01, -1.8844e-01,  5.4927e-03, -2.1388e-01, -8.8170e-02,\n",
      "        -1.8159e-01, -1.0045e-01, -8.2419e-02, -1.5640e-01, -2.6836e-02,\n",
      "        -1.2419e-01, -7.2496e-02, -2.4726e-02, -1.1340e-02, -6.0436e-02,\n",
      "        -9.5669e-02, -2.2915e-01, -1.3005e-01,  2.4739e-02, -1.6264e-01,\n",
      "        -4.6825e-03, -7.3629e-02, -1.8768e-01, -1.1381e-01, -1.8266e-01,\n",
      "        -1.3924e-01, -1.5428e-01, -8.3178e-02, -1.3870e-01, -1.6551e-01,\n",
      "        -1.3847e-01, -2.2170e-01, -1.3353e-01, -1.1644e-01, -2.0292e-01,\n",
      "        -1.4828e-01, -1.6196e-01, -1.2860e-01], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('3.1.bn3.weight', Parameter containing:\n",
      "tensor([0.9479, 0.9733, 1.0984, 1.0331, 1.0498, 0.9779, 1.0808, 0.9199, 0.9600,\n",
      "        1.0060, 1.0791, 1.0457, 1.1534, 1.0489, 0.9783, 1.1125, 0.9797, 0.9841,\n",
      "        1.0846, 1.0312, 1.1529, 1.0840, 1.0517, 1.0683, 1.0315, 1.0133, 1.0845,\n",
      "        1.0498, 0.9551, 0.9849, 1.0598, 1.0364, 0.9732, 0.9279, 1.0193, 0.9982,\n",
      "        1.0117, 1.0900, 1.0755, 1.1028, 0.9826, 0.9936, 0.9979, 1.0051, 1.0384,\n",
      "        0.9131, 1.0492, 0.9850, 0.9894, 1.0019, 1.0804, 0.9785, 1.1092, 1.1054,\n",
      "        1.0614, 1.0175, 0.9977, 1.0978, 0.9658, 0.9622, 0.9672, 1.0008, 1.0894,\n",
      "        1.1123, 0.9226, 0.9325, 1.0212, 1.1239, 1.0356, 1.0757, 0.9465, 1.0021,\n",
      "        1.0243, 1.1549, 1.0501, 1.0072, 0.9285, 1.1127, 1.0598, 1.0589, 1.0003,\n",
      "        1.0659, 1.0161, 1.0064, 1.0000, 1.2115, 1.0309, 1.0450, 0.9833, 1.1213,\n",
      "        1.0730, 1.0813, 1.0892, 1.0263, 1.1410, 0.9841, 1.0264, 1.0245, 1.0879,\n",
      "        1.0030, 1.0313, 1.0263, 0.9547, 1.0837, 0.9005, 1.0858, 1.0388, 1.0140,\n",
      "        1.1027, 0.9881, 1.0297, 1.0811, 1.0457, 1.0288, 1.0133, 1.1205, 1.1615,\n",
      "        1.0600, 0.9435, 1.1904, 1.0422, 1.0475, 1.0441, 1.0393, 1.0216, 1.0976,\n",
      "        0.9864, 0.9627, 1.0343, 0.9711, 0.9800, 1.0494, 1.0572, 0.9593, 1.0799,\n",
      "        1.0469, 1.0755, 0.9760, 0.9921, 0.9932, 1.0059, 1.0548, 1.0493, 1.0226,\n",
      "        1.0555, 0.9872, 1.0950, 1.0633, 1.0018, 1.0468, 0.9254, 1.0699, 0.9653,\n",
      "        1.0779, 0.9716, 0.9583, 1.0198, 1.0380, 1.0774, 0.9679, 0.9561, 0.9881,\n",
      "        1.0913, 0.9469, 1.0968, 1.0404, 1.0458, 1.0636, 1.0387, 1.0272, 0.9657,\n",
      "        1.0467, 1.0377, 0.9993, 1.0243, 1.0888, 0.9954, 0.9901, 1.1012, 0.9880,\n",
      "        1.0277, 0.9886, 1.0076, 1.0642, 0.9576, 0.9770, 1.0242, 1.0482, 1.0465,\n",
      "        0.8897, 1.0550, 1.1077, 1.0696, 1.0267, 1.0763, 1.0019, 0.9123, 1.0882,\n",
      "        1.0044, 1.0308, 1.0655, 1.0476, 1.0555, 0.9518, 0.9078, 1.1376, 1.0640,\n",
      "        0.9719, 0.9971, 1.0102, 0.9901, 1.0684, 0.9992, 1.0676, 0.9892, 1.0292,\n",
      "        1.1022, 0.9747, 1.0877, 1.1005, 1.0395, 1.0083, 1.0274, 1.0329, 1.0011,\n",
      "        1.0271, 1.0812, 1.0787, 1.0021, 1.0325, 1.1360, 0.9581, 0.9329, 1.0230,\n",
      "        1.0276, 1.0055, 1.0596, 1.0298, 0.9978, 0.9142, 1.0603, 1.0822, 1.0617,\n",
      "        1.0526, 0.9766, 1.1022, 1.0625, 1.0706, 0.9456, 1.0229, 1.0602, 1.0523,\n",
      "        0.9801, 1.1053, 1.0438, 1.1038, 1.0487, 0.9589, 1.1136, 0.9561, 1.0992,\n",
      "        1.0863, 1.0257, 1.0140, 1.0650, 1.0832, 0.9780, 0.9648, 1.0698, 1.0791,\n",
      "        1.0376, 0.9965, 1.0730, 1.0258, 1.0059, 1.0025, 1.0973, 1.0420, 1.0600,\n",
      "        1.0181, 1.0261, 0.9957, 1.0305, 1.0974, 0.9319, 1.0617, 1.0003, 1.0289,\n",
      "        1.0016, 1.0279, 1.0095, 1.0159, 1.0352, 1.0357, 1.0358, 0.9918, 1.0076,\n",
      "        1.1049, 0.9929, 1.1053, 1.0258, 1.0744, 1.0759, 1.1112, 1.1350, 1.1111,\n",
      "        0.9892, 0.9022, 1.1091, 1.0715, 1.0966, 1.0775, 1.0322, 0.9718, 1.0662,\n",
      "        0.9695, 1.1245, 1.0763, 1.0466, 1.0413, 1.0078, 1.0118, 1.0589, 1.0158,\n",
      "        1.0340, 1.0129, 0.9917, 1.1356, 0.9693, 1.1429, 0.9636, 0.9858, 1.0818,\n",
      "        1.0026, 0.9916, 1.0974, 0.9401, 1.1191, 1.0187, 1.1696, 1.0306, 1.0419,\n",
      "        1.1054, 1.0926, 1.0809, 1.0180, 1.0997, 1.0035, 1.0892, 0.9722, 0.9026,\n",
      "        1.0478, 1.0909, 0.9647, 1.0010, 1.0556, 1.0515, 1.0549, 0.9816, 0.9868,\n",
      "        1.1160, 0.9858, 0.9937, 1.0394, 1.1285, 0.9811, 0.9574, 1.0742, 1.0762,\n",
      "        0.9405, 1.0366, 0.9810, 1.0797, 0.9359, 1.0723, 0.9765, 1.0246, 1.1661,\n",
      "        0.9549, 1.0775, 1.0304, 1.0063, 0.9644, 1.0619, 0.9876, 1.0229, 1.0359,\n",
      "        1.0491, 1.0585, 0.9265, 0.9316, 0.9928, 1.0324, 1.0331, 1.0346, 1.0243,\n",
      "        1.0101, 0.9406, 1.0612, 1.0697, 1.0665, 1.0813, 1.0970, 0.8260, 1.1204,\n",
      "        1.0578, 1.1468, 1.0207, 0.9934, 1.0692, 1.1027, 1.0819, 1.0234, 1.0610,\n",
      "        1.0225, 1.1195, 1.0984, 0.9925, 1.0737, 1.0531, 1.0211, 1.0172, 1.0590,\n",
      "        1.0269, 1.0573, 1.0325, 1.0281, 1.0351, 1.1504, 1.0403, 1.1405, 1.0146,\n",
      "        1.0415, 1.0722, 1.1087, 0.9733, 1.0970, 0.9502, 1.0361, 1.0050, 1.1865,\n",
      "        0.8961, 1.0077, 1.1221, 0.9913, 1.0344, 1.0871, 1.0602, 1.0519, 1.0046,\n",
      "        1.0613, 1.0442, 1.0480, 1.1702, 1.0634, 1.0184, 0.9650, 1.0222, 1.1199,\n",
      "        1.0804, 0.9630, 1.0496, 1.0487, 0.9411, 1.0994, 1.0511, 1.0001, 0.9627,\n",
      "        0.9979, 1.0793, 0.9183, 1.0444, 1.0587, 1.1071, 1.0423, 0.9408, 1.0129,\n",
      "        0.9440, 1.0527, 1.0657, 1.0427, 0.9962, 0.9879, 0.9802, 0.9182, 1.0396,\n",
      "        1.0179, 1.0049, 0.9153, 1.1163, 1.0446, 1.0626, 0.9949, 1.0751, 1.0534,\n",
      "        1.0041, 1.0586, 1.0518, 1.0421, 1.0155, 1.0763, 1.0918, 0.9287, 1.0163,\n",
      "        0.9686, 1.1421, 0.9935, 1.0798, 0.9168, 1.0108, 0.9630, 1.1300],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.1.bn3.bias', Parameter containing:\n",
      "tensor([-1.0619e-02,  1.2780e-02, -1.7390e-02, -1.5057e-02,  1.0285e-02,\n",
      "         2.9295e-02,  7.3346e-03,  1.3690e-02,  3.4434e-03, -2.2258e-03,\n",
      "         3.7898e-03,  2.0362e-02,  3.8078e-02,  1.2917e-03,  2.7740e-03,\n",
      "         3.9984e-02, -4.9229e-02,  2.1192e-02, -5.3056e-02, -6.1844e-02,\n",
      "         4.0464e-02, -7.4066e-02,  1.6455e-02,  2.8511e-03,  1.3053e-02,\n",
      "        -1.6807e-02, -1.5544e-02, -2.0229e-02, -1.3180e-02,  1.1684e-03,\n",
      "        -1.1595e-02, -1.3372e-02,  8.0820e-03,  2.2953e-02,  7.2861e-03,\n",
      "         1.6465e-02,  1.6862e-02,  3.1957e-02, -3.5175e-04,  2.3136e-02,\n",
      "        -3.2093e-02,  1.6003e-02, -4.1898e-04,  3.1579e-02,  1.4564e-02,\n",
      "         9.7143e-03,  1.6426e-02,  4.6787e-03, -6.1573e-02,  5.5258e-03,\n",
      "        -1.4363e-02, -2.4940e-02, -1.6754e-02, -1.6217e-02,  2.2368e-02,\n",
      "        -2.4136e-02,  6.6543e-03,  1.3526e-02, -5.0795e-02,  4.4132e-03,\n",
      "         9.3188e-03,  4.0406e-03, -9.9331e-03,  4.1112e-02, -2.8075e-02,\n",
      "        -1.7400e-02,  3.0945e-03,  5.4318e-03,  1.8775e-02, -8.7016e-04,\n",
      "        -1.2749e-03,  9.7603e-04, -8.3675e-03, -1.4062e-02, -3.7164e-02,\n",
      "        -2.6657e-02, -5.2918e-02,  1.5576e-02,  6.5949e-02, -1.9665e-02,\n",
      "        -3.0990e-02,  3.3605e-02, -2.9027e-03, -3.4155e-02, -4.1476e-04,\n",
      "         5.2008e-02, -1.1425e-02,  3.1943e-03, -5.1344e-03,  5.6674e-03,\n",
      "        -3.5839e-03,  5.5275e-03,  4.4261e-04, -5.0211e-02,  2.9334e-02,\n",
      "         1.4506e-02, -1.2575e-02, -1.6579e-02,  2.9974e-02,  9.7662e-04,\n",
      "        -1.3470e-02,  6.2086e-03, -7.6416e-03, -6.4001e-02, -1.2980e-02,\n",
      "         5.9515e-02, -3.8027e-02, -5.4218e-02,  7.6849e-03, -7.9987e-03,\n",
      "         1.8806e-02,  4.7244e-03,  4.2704e-03,  3.3942e-02, -1.1461e-03,\n",
      "         5.4225e-02,  6.9160e-02, -2.2499e-02, -1.0556e-02,  7.6096e-03,\n",
      "         9.7489e-03,  3.9419e-02, -4.5947e-02, -1.2819e-02,  2.4377e-02,\n",
      "         4.3148e-03,  1.3734e-02, -7.8524e-03,  2.1217e-02,  1.8391e-02,\n",
      "        -6.2639e-04, -4.8073e-02,  3.2717e-02,  1.4042e-02,  1.8070e-02,\n",
      "         6.6594e-02, -4.4516e-02, -1.7043e-03,  2.5245e-03, -7.6866e-03,\n",
      "        -2.2941e-02,  1.5852e-02,  1.7238e-02,  2.0215e-02, -1.3429e-02,\n",
      "        -8.7982e-03,  1.5725e-02,  2.0691e-02, -1.8637e-02,  2.1348e-02,\n",
      "        -3.2592e-02, -2.5125e-02,  3.9939e-03,  2.8384e-02, -9.8556e-04,\n",
      "        -8.3323e-03,  2.7819e-02,  1.9235e-03, -1.3822e-02, -1.0912e-02,\n",
      "         1.9517e-02,  3.4538e-02, -1.1798e-02,  2.9277e-03, -8.5539e-03,\n",
      "        -6.4788e-03,  2.0369e-02, -6.4908e-02,  4.9371e-02, -1.5133e-02,\n",
      "        -3.6065e-02,  3.3264e-03, -9.6869e-03,  7.5497e-03, -3.5131e-02,\n",
      "        -3.7316e-03,  4.4041e-02,  2.9575e-02,  3.0127e-02, -8.0026e-02,\n",
      "         2.9192e-02,  1.1464e-02,  3.1634e-02,  1.5832e-02, -2.3064e-02,\n",
      "        -1.9964e-02, -3.0799e-02,  1.7178e-02, -3.7054e-02, -7.3010e-03,\n",
      "        -9.7797e-03,  3.0183e-02,  3.5401e-02, -1.4001e-02,  7.4293e-03,\n",
      "        -3.1172e-02, -6.6597e-03,  5.4538e-02, -3.5809e-02, -2.7440e-02,\n",
      "         2.5554e-02,  8.7723e-03,  5.0187e-02,  4.6868e-03, -4.8547e-02,\n",
      "         5.0779e-02, -6.4313e-03, -1.9708e-02,  2.2167e-02, -2.0791e-02,\n",
      "         2.0283e-03,  8.1574e-02, -4.5569e-02, -1.7421e-03,  1.3127e-02,\n",
      "         4.4634e-02, -6.4393e-04, -6.3527e-03,  2.5087e-02,  1.4525e-02,\n",
      "        -1.7743e-02, -6.1653e-03,  4.3015e-03,  1.0569e-02, -5.7381e-02,\n",
      "         1.0035e-02,  1.7634e-02,  8.2672e-03, -1.8689e-02, -1.5765e-02,\n",
      "        -2.0862e-02, -5.1202e-03, -1.5871e-02, -3.3526e-02,  1.9278e-02,\n",
      "         1.4088e-03,  3.3314e-02,  2.5933e-04,  7.9375e-03, -8.4981e-03,\n",
      "        -4.5755e-03,  2.0504e-02,  1.1310e-02,  1.5418e-02, -3.0786e-03,\n",
      "         3.6991e-02,  6.4215e-03, -2.6642e-02, -1.5219e-02,  2.4270e-03,\n",
      "        -4.4839e-02,  1.6771e-02, -1.0754e-02,  1.0526e-02,  3.4464e-02,\n",
      "         4.8531e-03, -3.4867e-02, -6.6559e-03,  6.1579e-02,  9.9881e-03,\n",
      "         3.2778e-02,  2.5172e-02,  3.6049e-02, -1.2859e-03,  6.3024e-03,\n",
      "         1.3063e-02, -7.2025e-03, -4.3279e-03,  3.4297e-02,  1.4492e-02,\n",
      "         6.0234e-03,  2.5896e-02, -1.4007e-02, -1.2864e-02, -6.1512e-04,\n",
      "         4.1533e-03,  4.7168e-03,  3.1071e-02,  1.3229e-02,  3.8994e-02,\n",
      "         7.3684e-04,  2.3851e-02,  1.6842e-03,  3.5816e-03,  5.9516e-03,\n",
      "         2.4111e-02,  1.3799e-02,  2.6403e-02,  3.0734e-02, -1.7674e-05,\n",
      "         1.1709e-02,  1.9515e-02, -4.3046e-02, -7.9185e-02, -1.2345e-03,\n",
      "        -1.5818e-02,  6.5045e-03,  8.7153e-03,  8.4537e-03,  6.3739e-03,\n",
      "         3.0321e-02,  2.0700e-02, -1.2581e-02,  6.7840e-02, -9.6363e-03,\n",
      "         9.5129e-02, -5.3082e-02, -2.4407e-03,  1.8473e-02,  8.1547e-02,\n",
      "         1.2967e-02,  1.3956e-02, -6.7156e-02,  7.5564e-03,  1.8544e-02,\n",
      "         1.7145e-02,  7.1066e-02, -1.5856e-02, -4.7095e-02,  1.4473e-02,\n",
      "        -8.8826e-03,  9.7749e-03, -2.0270e-02,  9.8312e-03,  1.6033e-02,\n",
      "        -1.7542e-02, -2.4331e-02,  1.6554e-02,  3.2339e-05, -3.0749e-02,\n",
      "        -2.0823e-03, -2.0048e-02,  3.8692e-02,  1.5892e-02,  7.8037e-03,\n",
      "        -1.9214e-02,  7.7698e-03,  1.8150e-02,  1.7418e-02,  4.4658e-02,\n",
      "        -3.5498e-03,  3.0333e-03,  3.1651e-02, -7.0438e-03, -1.4253e-04,\n",
      "         2.7818e-02,  1.0617e-03,  1.6505e-02,  3.1921e-02, -8.9294e-03,\n",
      "        -3.9054e-02, -5.4924e-02, -2.1482e-02, -3.1021e-03, -9.7618e-03,\n",
      "        -2.5201e-02,  7.1254e-02,  5.3401e-03, -5.6364e-03,  1.2264e-02,\n",
      "         6.8364e-02,  5.4399e-03,  1.6330e-02,  4.3164e-03,  1.7147e-02,\n",
      "        -2.5916e-02,  1.7035e-02, -2.2213e-03, -1.7856e-03,  2.9654e-02,\n",
      "         4.6156e-02, -1.2420e-02, -3.0122e-03,  8.0234e-04,  8.9776e-03,\n",
      "         7.0607e-03, -2.3721e-02,  2.5215e-02, -2.1539e-02,  7.1490e-03,\n",
      "        -7.9204e-03, -8.0796e-03,  8.9935e-03,  8.8876e-03,  3.2253e-02,\n",
      "         3.1346e-02, -1.8225e-03, -4.7005e-04,  9.8393e-03, -1.5493e-03,\n",
      "         3.3943e-03, -3.3727e-03, -5.6371e-02,  1.7360e-02, -1.9447e-02,\n",
      "        -3.2176e-02,  8.6646e-04, -7.1912e-03, -2.4114e-02, -2.3722e-02,\n",
      "        -7.1290e-03,  3.8908e-02,  9.0804e-03,  1.8539e-03, -2.9330e-02,\n",
      "        -1.2427e-02,  4.8266e-02,  2.0711e-02, -2.2953e-02,  7.7655e-04,\n",
      "         9.6556e-03,  5.0929e-02,  1.1560e-04,  4.5864e-03,  4.3666e-03,\n",
      "        -1.7734e-02,  1.4164e-02,  1.5628e-02,  3.4866e-03, -2.9601e-02,\n",
      "         1.2449e-02,  7.7740e-03,  7.4382e-03, -4.0041e-02,  5.6046e-02,\n",
      "        -1.2494e-02,  2.5785e-02,  2.5876e-02,  2.6266e-02,  3.9116e-03,\n",
      "         6.3318e-03,  3.8119e-03, -3.3017e-03,  4.0851e-03,  4.2387e-02,\n",
      "        -1.8163e-02,  4.8174e-02, -3.6464e-03, -1.5830e-05,  2.4895e-02,\n",
      "         3.7610e-02, -4.4061e-02, -8.8546e-03, -5.2166e-03, -4.1169e-02,\n",
      "         6.3240e-04,  6.9757e-02,  1.1305e-02, -3.5767e-02, -7.1948e-02,\n",
      "         3.0649e-02, -2.3892e-02, -7.2467e-03,  6.3189e-02,  2.8814e-02,\n",
      "        -8.5485e-03,  2.2628e-03,  3.1224e-02,  5.5240e-02,  1.0230e-02,\n",
      "         1.3634e-02, -8.3612e-03,  1.8389e-02, -1.9556e-02,  7.0983e-02,\n",
      "         9.5425e-03,  1.4940e-02, -1.0564e-02,  6.2289e-03,  4.9245e-03,\n",
      "         5.6208e-03, -1.0340e-01,  5.0101e-04, -1.2817e-02,  4.1241e-02,\n",
      "        -1.2533e-02,  1.8702e-02, -3.7977e-02,  4.8368e-02,  4.9280e-02,\n",
      "         1.7140e-03,  4.1759e-03, -3.7684e-02, -1.1755e-02, -5.5171e-02,\n",
      "        -8.4547e-02, -1.9427e-02, -1.1100e-02, -3.0905e-03, -1.0204e-02,\n",
      "         1.1856e-03,  3.3345e-02,  3.5464e-02,  1.2165e-03, -1.9665e-02,\n",
      "         1.3407e-02, -2.1068e-03, -2.1717e-02, -1.2727e-03,  8.1636e-03,\n",
      "         1.4552e-03, -1.5037e-02, -2.1276e-02,  1.3639e-02, -2.0352e-02,\n",
      "         3.0378e-02, -6.5537e-03,  1.9882e-02,  4.4838e-03,  1.7570e-02,\n",
      "         1.3499e-02,  2.9908e-03], device='cuda:0', requires_grad=True))\n",
      "('3.2.conv1.weight', Parameter containing:\n",
      "tensor([[[-3.6292e-02],\n",
      "         [-7.2363e-02],\n",
      "         [-1.5416e-01],\n",
      "         ...,\n",
      "         [-6.6992e-02],\n",
      "         [-6.7616e-02],\n",
      "         [-2.3510e-01]],\n",
      "\n",
      "        [[-3.7060e-02],\n",
      "         [ 1.2773e-01],\n",
      "         [-3.0717e-02],\n",
      "         ...,\n",
      "         [ 1.1876e-01],\n",
      "         [-2.8528e-01],\n",
      "         [-7.8330e-02]],\n",
      "\n",
      "        [[-3.0507e-02],\n",
      "         [-7.5253e-02],\n",
      "         [-1.3216e-01],\n",
      "         ...,\n",
      "         [ 1.1821e-01],\n",
      "         [-5.2150e-05],\n",
      "         [-9.6839e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.7719e-02],\n",
      "         [-5.6425e-02],\n",
      "         [-6.9082e-02],\n",
      "         ...,\n",
      "         [ 1.8027e-01],\n",
      "         [-4.1906e-02],\n",
      "         [-1.8132e-01]],\n",
      "\n",
      "        [[ 8.5492e-03],\n",
      "         [-2.7158e-02],\n",
      "         [-1.1252e-01],\n",
      "         ...,\n",
      "         [ 1.4887e-01],\n",
      "         [-7.6254e-02],\n",
      "         [-3.5635e-02]],\n",
      "\n",
      "        [[-6.9424e-04],\n",
      "         [-1.9835e-02],\n",
      "         [ 4.0537e-02],\n",
      "         ...,\n",
      "         [ 7.4993e-02],\n",
      "         [ 3.3509e-02],\n",
      "         [-1.3086e-01]]], device='cuda:0', requires_grad=True))\n",
      "('3.2.conv1.bias', Parameter containing:\n",
      "tensor([ 0.0178, -0.0018,  0.0081, -0.0426, -0.0051, -0.0197, -0.0431, -0.0247,\n",
      "         0.0026, -0.0033, -0.0289,  0.0134,  0.0091,  0.0066, -0.0397,  0.0056,\n",
      "        -0.0392, -0.0433,  0.0149,  0.0186, -0.0204,  0.0093, -0.0161, -0.0074,\n",
      "         0.0212,  0.0208,  0.0104, -0.0203, -0.0090, -0.0416, -0.0165,  0.0351,\n",
      "         0.0198, -0.0120, -0.0084,  0.0136,  0.0298, -0.0122, -0.0106, -0.0439,\n",
      "         0.0437,  0.0080,  0.0077,  0.0015, -0.0235, -0.0252,  0.0199, -0.0106,\n",
      "         0.0424,  0.0264, -0.0120,  0.0144, -0.0132, -0.0056,  0.0072, -0.0004,\n",
      "         0.0173,  0.0076,  0.0009, -0.0387,  0.0053,  0.0082, -0.0333,  0.0141,\n",
      "         0.0312,  0.0389, -0.0249, -0.0205,  0.0162,  0.0245,  0.0024,  0.0299,\n",
      "        -0.0031,  0.0287, -0.0112, -0.0404,  0.0309,  0.0164, -0.0097,  0.0327,\n",
      "         0.0036,  0.0042, -0.0365, -0.0120, -0.0058, -0.0381,  0.0255,  0.0341,\n",
      "         0.0061,  0.0144, -0.0076, -0.0189, -0.0098,  0.0410, -0.0390,  0.0232,\n",
      "        -0.0378,  0.0103,  0.0408,  0.0211,  0.0254, -0.0208, -0.0329, -0.0387,\n",
      "         0.0108, -0.0261,  0.0048,  0.0216,  0.0178,  0.0158,  0.0435,  0.0216,\n",
      "        -0.0157, -0.0093, -0.0324,  0.0370, -0.0326, -0.0260, -0.0126, -0.0380,\n",
      "        -0.0137, -0.0221,  0.0013, -0.0003, -0.0318, -0.0333, -0.0006, -0.0330],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.2.conv2.weight', Parameter containing:\n",
      "tensor([[[-0.0568, -0.0360, -0.0312],\n",
      "         [ 0.0894,  0.1090,  0.0378],\n",
      "         [ 0.0392,  0.0262, -0.1931],\n",
      "         ...,\n",
      "         [-0.1195, -0.1776,  0.2488],\n",
      "         [ 0.1114, -0.0914,  0.0037],\n",
      "         [-0.0042,  0.0130, -0.0105]],\n",
      "\n",
      "        [[-0.1026, -0.1030,  0.0508],\n",
      "         [ 0.0243,  0.1549, -0.0558],\n",
      "         [-0.1382, -0.1135, -0.1652],\n",
      "         ...,\n",
      "         [ 0.1320, -0.0977, -0.0422],\n",
      "         [-0.1040, -0.0442, -0.0873],\n",
      "         [ 0.0387, -0.1830,  0.0151]],\n",
      "\n",
      "        [[ 0.0975,  0.0895,  0.1335],\n",
      "         [-0.0127, -0.0701, -0.0242],\n",
      "         [-0.1557,  0.0903, -0.0482],\n",
      "         ...,\n",
      "         [-0.0338, -0.1291, -0.0395],\n",
      "         [-0.0178,  0.1798,  0.0010],\n",
      "         [-0.0354,  0.0544, -0.0291]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0042, -0.1338, -0.0863],\n",
      "         [-0.0175,  0.0910, -0.0132],\n",
      "         [-0.0923, -0.0125, -0.0662],\n",
      "         ...,\n",
      "         [ 0.0733, -0.0658,  0.0394],\n",
      "         [-0.1105,  0.1432, -0.0096],\n",
      "         [-0.1026, -0.1322,  0.1580]],\n",
      "\n",
      "        [[-0.1412,  0.1433, -0.1490],\n",
      "         [-0.0568,  0.0648,  0.1173],\n",
      "         [ 0.0901, -0.1122, -0.1152],\n",
      "         ...,\n",
      "         [-0.1497,  0.0732, -0.1619],\n",
      "         [-0.0308, -0.1140, -0.0465],\n",
      "         [-0.0900,  0.0648, -0.0756]],\n",
      "\n",
      "        [[ 0.0295,  0.2851,  0.0690],\n",
      "         [ 0.0360, -0.0037,  0.2222],\n",
      "         [ 0.0469,  0.0725, -0.1263],\n",
      "         ...,\n",
      "         [-0.1829, -0.0209,  0.0110],\n",
      "         [-0.0610, -0.1100,  0.0982],\n",
      "         [-0.1515,  0.1089, -0.1176]]], device='cuda:0', requires_grad=True))\n",
      "('3.2.conv2.bias', Parameter containing:\n",
      "tensor([ 1.3047e-02, -1.1184e-02, -4.6502e-02, -4.3395e-02,  4.0477e-02,\n",
      "         4.2573e-02,  1.5926e-02,  1.5783e-02, -2.8102e-02, -2.6932e-02,\n",
      "         1.8485e-02, -4.6867e-02, -1.2954e-02, -1.9810e-02,  3.5343e-04,\n",
      "         4.8954e-02, -3.3993e-02, -1.0986e-02,  4.9598e-02,  5.0540e-02,\n",
      "         2.7447e-03, -4.2475e-02, -2.7792e-03,  4.8543e-02,  2.3130e-02,\n",
      "         3.0895e-02,  1.6618e-02,  3.6895e-02, -9.3539e-03, -2.9620e-03,\n",
      "        -1.6063e-02,  4.5454e-02,  3.9962e-02, -1.7050e-03,  4.8794e-02,\n",
      "         1.1012e-02,  2.0225e-02,  6.3694e-03,  4.7540e-02,  9.4928e-03,\n",
      "        -2.0131e-02,  1.6924e-02, -2.2219e-02,  3.8288e-02,  2.0817e-02,\n",
      "         4.0283e-02,  4.4322e-02, -4.7841e-02, -2.9468e-02, -1.3253e-02,\n",
      "        -2.4390e-02, -4.6500e-02,  4.2656e-02, -5.0801e-02,  5.5066e-03,\n",
      "         2.1616e-02, -4.2744e-02, -4.0759e-02,  2.4017e-02,  3.6947e-02,\n",
      "        -2.5819e-02, -3.7446e-02, -4.0178e-02,  4.6558e-02,  7.3954e-04,\n",
      "        -1.4599e-02,  2.4854e-03, -4.8436e-02,  1.6681e-02, -1.4736e-02,\n",
      "        -2.9237e-02, -3.6063e-02,  2.8826e-02,  2.8626e-02, -1.4040e-02,\n",
      "        -4.9060e-02, -1.4225e-02, -1.9443e-02,  4.6428e-02,  2.4613e-03,\n",
      "        -4.8420e-02, -2.8836e-02, -1.9140e-02,  1.1346e-02,  1.3060e-02,\n",
      "         4.8144e-02,  9.7830e-03,  8.4413e-03, -4.4138e-02, -1.3217e-02,\n",
      "         3.0786e-02, -7.9795e-05,  1.9054e-02, -1.5681e-02,  1.8929e-02,\n",
      "        -4.3521e-02,  4.2563e-02, -3.9946e-02, -4.7890e-03,  3.7014e-02,\n",
      "        -1.1630e-02, -1.0007e-02,  4.3055e-02,  1.0793e-02, -5.6967e-03,\n",
      "         4.5767e-03, -1.7033e-02, -3.3721e-02,  1.0381e-03,  1.1061e-02,\n",
      "         3.4277e-02,  4.3204e-02, -3.5712e-02, -5.5268e-03,  2.1560e-02,\n",
      "         1.5529e-02,  2.6870e-02, -4.1103e-02,  3.8729e-02,  3.4523e-02,\n",
      "         4.3138e-02,  2.5383e-02,  3.5177e-02,  2.9849e-02,  2.5818e-02,\n",
      "        -1.7563e-02,  1.3729e-02, -4.7914e-02], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('3.2.conv3.weight', Parameter containing:\n",
      "tensor([[[-0.0457],\n",
      "         [-0.0510],\n",
      "         [-0.0886],\n",
      "         ...,\n",
      "         [-0.0775],\n",
      "         [ 0.0748],\n",
      "         [-0.0504]],\n",
      "\n",
      "        [[-0.0050],\n",
      "         [-0.0446],\n",
      "         [-0.0516],\n",
      "         ...,\n",
      "         [ 0.0982],\n",
      "         [-0.1473],\n",
      "         [ 0.0311]],\n",
      "\n",
      "        [[ 0.0266],\n",
      "         [-0.0373],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [ 0.0819],\n",
      "         [-0.0434],\n",
      "         [ 0.0936]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0100],\n",
      "         [ 0.1175],\n",
      "         [ 0.1698],\n",
      "         ...,\n",
      "         [-0.0561],\n",
      "         [ 0.0472],\n",
      "         [-0.0571]],\n",
      "\n",
      "        [[ 0.0824],\n",
      "         [ 0.0160],\n",
      "         [-0.0563],\n",
      "         ...,\n",
      "         [ 0.0376],\n",
      "         [ 0.0984],\n",
      "         [-0.1045]],\n",
      "\n",
      "        [[-0.0858],\n",
      "         [ 0.0379],\n",
      "         [ 0.0613],\n",
      "         ...,\n",
      "         [-0.0706],\n",
      "         [-0.0900],\n",
      "         [ 0.0637]]], device='cuda:0', requires_grad=True))\n",
      "('3.2.conv3.bias', Parameter containing:\n",
      "tensor([-0.0333, -0.0182,  0.0306, -0.0503,  0.0009,  0.0250, -0.0838,  0.0239,\n",
      "         0.0555, -0.0239,  0.0660,  0.0218,  0.0834, -0.0010, -0.0057,  0.0498,\n",
      "         0.0290,  0.0790,  0.0386, -0.0882, -0.0255,  0.0022, -0.0293,  0.0356,\n",
      "         0.0570,  0.0295, -0.0069, -0.0198,  0.0199, -0.0019, -0.0037,  0.0777,\n",
      "        -0.0157, -0.0008,  0.0666,  0.0005, -0.0066, -0.0717, -0.0585,  0.0047,\n",
      "         0.0291,  0.0173,  0.0856,  0.0604, -0.0373, -0.0417,  0.0850,  0.0230,\n",
      "        -0.0411, -0.0126,  0.0093,  0.0095,  0.0080,  0.0729,  0.0733,  0.0868,\n",
      "         0.0492, -0.0242, -0.0524,  0.0166, -0.0497, -0.0434, -0.0730, -0.0167,\n",
      "         0.0272, -0.0779, -0.0111,  0.0751,  0.0664, -0.0569,  0.0865, -0.0823,\n",
      "         0.0109, -0.0686, -0.0493, -0.0649,  0.0801,  0.0622,  0.0777,  0.0044,\n",
      "        -0.0037,  0.0496, -0.0817,  0.0717, -0.0356,  0.0098,  0.0094, -0.0811,\n",
      "        -0.0038, -0.0591, -0.0307,  0.0149, -0.0779,  0.0484, -0.0057,  0.0087,\n",
      "        -0.0193,  0.0176, -0.0010,  0.0160, -0.0060,  0.0164, -0.0531,  0.0255,\n",
      "         0.0369, -0.0337,  0.0337, -0.0727, -0.0817, -0.0374,  0.0041, -0.0551,\n",
      "        -0.0087,  0.0629, -0.0124,  0.0156,  0.0869, -0.0093, -0.0168, -0.0067,\n",
      "        -0.0837, -0.0750,  0.0869, -0.0512,  0.0370, -0.0437, -0.0054,  0.0860,\n",
      "        -0.0181,  0.0171, -0.0491,  0.0313, -0.0067,  0.0814,  0.0113,  0.0114,\n",
      "         0.0730, -0.0722, -0.0506,  0.0503,  0.0070,  0.0339, -0.0813,  0.0013,\n",
      "        -0.0342, -0.0228,  0.0850,  0.0850,  0.0248,  0.0821,  0.0151,  0.0769,\n",
      "         0.0259,  0.0010, -0.0249,  0.0472,  0.0341, -0.0168,  0.0549, -0.0404,\n",
      "        -0.0006, -0.0162,  0.0249,  0.0065, -0.0610,  0.0411, -0.0446,  0.0243,\n",
      "        -0.0635,  0.0618, -0.0309,  0.0816,  0.0506, -0.0170, -0.0396,  0.0386,\n",
      "         0.0518,  0.0305, -0.0009, -0.0101, -0.0443,  0.0673,  0.0386,  0.0745,\n",
      "        -0.0362,  0.0776,  0.0496, -0.0520,  0.0662,  0.0533, -0.0337, -0.0283,\n",
      "         0.0414,  0.0621, -0.0341, -0.0415, -0.0658, -0.0036, -0.0231,  0.0813,\n",
      "        -0.0068,  0.0734,  0.0193,  0.0062,  0.0876,  0.0418,  0.0674,  0.0006,\n",
      "         0.0858,  0.0466, -0.0810, -0.0175,  0.0334, -0.0346,  0.0057, -0.0313,\n",
      "        -0.0011,  0.0198, -0.0444,  0.0852, -0.0584, -0.0807, -0.0442, -0.0176,\n",
      "        -0.0153, -0.0106, -0.0360, -0.0622, -0.0298, -0.0248,  0.0008, -0.0544,\n",
      "        -0.0130,  0.0878,  0.0765, -0.0195,  0.0882,  0.0643,  0.0462, -0.0258,\n",
      "        -0.0602,  0.0633, -0.0327,  0.0157,  0.0531,  0.0676,  0.0080, -0.0493,\n",
      "         0.0039,  0.0287,  0.0117,  0.0788, -0.0787,  0.0178, -0.0001,  0.0729,\n",
      "         0.0054, -0.0147, -0.0132, -0.0362,  0.0398, -0.0416,  0.0287,  0.0493,\n",
      "        -0.0011, -0.0536, -0.0136, -0.0311,  0.0824, -0.0131, -0.0734, -0.0131,\n",
      "        -0.0136, -0.0013, -0.0481,  0.0418,  0.0146, -0.0528,  0.0329, -0.0314,\n",
      "         0.0100,  0.0840, -0.0722, -0.0379,  0.0608, -0.0046,  0.0507, -0.0807,\n",
      "        -0.0388, -0.0742, -0.0322,  0.0306, -0.0641,  0.0441,  0.0497,  0.0535,\n",
      "        -0.0790, -0.0689, -0.0451, -0.0075,  0.0553,  0.0148, -0.0858, -0.0761,\n",
      "         0.0845,  0.0597,  0.0683,  0.0111,  0.0528,  0.0764,  0.0857,  0.0354,\n",
      "         0.0671,  0.0348, -0.0605, -0.0835,  0.0770, -0.0322,  0.0072, -0.0122,\n",
      "        -0.0316,  0.0796, -0.0338,  0.0660, -0.0305, -0.0305, -0.0797,  0.0483,\n",
      "         0.0570,  0.0799,  0.0451,  0.0386, -0.0308,  0.0106, -0.0358, -0.0613,\n",
      "        -0.0155,  0.0092, -0.0103, -0.0539, -0.0731, -0.0064, -0.0820, -0.0521,\n",
      "        -0.0040,  0.0557, -0.0435,  0.0595,  0.0605,  0.0084,  0.0327, -0.0540,\n",
      "        -0.0784,  0.0282,  0.0677, -0.0560, -0.0390,  0.0595,  0.0378, -0.0490,\n",
      "         0.0333,  0.0512,  0.0654,  0.0563,  0.0149,  0.0425, -0.0633,  0.0093,\n",
      "        -0.0500,  0.0553,  0.0397,  0.0370, -0.0256,  0.0149, -0.0611,  0.0772,\n",
      "         0.0026, -0.0061, -0.0640, -0.0571,  0.0276, -0.0796, -0.0589,  0.0379,\n",
      "         0.0829,  0.0653,  0.0711,  0.0465,  0.0273, -0.0711, -0.0496, -0.0201,\n",
      "         0.0611,  0.0620,  0.0290, -0.0442,  0.0234, -0.0302,  0.0819, -0.0851,\n",
      "         0.0353,  0.0432,  0.0843, -0.0080, -0.0093,  0.0284,  0.0226,  0.0417,\n",
      "        -0.0146,  0.0704, -0.0314,  0.0019,  0.0611,  0.0232,  0.0714,  0.0871,\n",
      "         0.0285, -0.0433, -0.0720,  0.0555,  0.0446,  0.0175,  0.0510, -0.0150,\n",
      "         0.0212,  0.0539, -0.0286, -0.0227,  0.0201, -0.0669,  0.0161,  0.0816,\n",
      "        -0.0413, -0.0200,  0.0631, -0.0145, -0.0575, -0.0443, -0.0229,  0.0633,\n",
      "         0.0171, -0.0169, -0.0640,  0.0155,  0.0693, -0.0829, -0.0322, -0.0060,\n",
      "         0.0274,  0.0063,  0.0806, -0.0144,  0.0690,  0.0601,  0.0527, -0.0706,\n",
      "         0.0079,  0.0785, -0.0187, -0.0307, -0.0227,  0.0777,  0.0419,  0.0778,\n",
      "         0.0728, -0.0834, -0.0259,  0.0335, -0.0881, -0.0289,  0.0713, -0.0454,\n",
      "        -0.0725, -0.0218,  0.0146, -0.0238,  0.0081,  0.0130,  0.0442,  0.0514,\n",
      "        -0.0398, -0.0226,  0.0327, -0.0817, -0.0057, -0.0535, -0.0523, -0.0006,\n",
      "         0.0175, -0.0878, -0.0694, -0.0459, -0.0799, -0.0356,  0.0753, -0.0094,\n",
      "        -0.0117,  0.0369, -0.0012, -0.0400, -0.0675, -0.0760, -0.0460,  0.0363,\n",
      "        -0.0664,  0.0625, -0.0077, -0.0032,  0.0096, -0.0756,  0.0689,  0.0085],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.2.bn1.weight', Parameter containing:\n",
      "tensor([1.0807, 0.9736, 0.9462, 1.0312, 0.7807, 0.9087, 1.0252, 1.1079, 0.9105,\n",
      "        1.0704, 1.1794, 0.9101, 1.1071, 1.2359, 1.0349, 1.2090, 0.9438, 1.0541,\n",
      "        1.0050, 0.8934, 1.0811, 0.8828, 0.9420, 1.0988, 0.8284, 1.0112, 1.0334,\n",
      "        0.9091, 1.0864, 0.9369, 1.0081, 0.9040, 1.0079, 1.0741, 1.0852, 0.9786,\n",
      "        1.0208, 1.1330, 0.8939, 0.8575, 1.0757, 1.0833, 0.8681, 1.1770, 1.0612,\n",
      "        1.1065, 1.0786, 0.8882, 0.8939, 0.9656, 1.0615, 0.7886, 1.0608, 1.0113,\n",
      "        0.9899, 0.9967, 0.9975, 1.0669, 0.7904, 0.8729, 0.8897, 0.9082, 1.0763,\n",
      "        1.1131, 1.1796, 1.1712, 1.1729, 1.1320, 0.9448, 0.9382, 0.9503, 0.9795,\n",
      "        1.0324, 0.9499, 0.9427, 0.7871, 0.9772, 0.9000, 1.0837, 1.1143, 0.8766,\n",
      "        0.8820, 1.0074, 0.9169, 0.9529, 0.8727, 0.8838, 0.8508, 1.1070, 1.0658,\n",
      "        1.1301, 0.9782, 0.9418, 0.9427, 0.7913, 1.1279, 0.9799, 1.0892, 1.0678,\n",
      "        0.8664, 0.8040, 1.0422, 0.8982, 1.1295, 1.2035, 1.0000, 1.0587, 0.9256,\n",
      "        1.0644, 1.1259, 1.1156, 1.0477, 1.0341, 1.1231, 1.1575, 1.0878, 0.8605,\n",
      "        1.2019, 1.0703, 0.9467, 1.0554, 1.0449, 1.0397, 1.0165, 0.9485, 0.9392,\n",
      "        0.9216, 0.9013], device='cuda:0', requires_grad=True))\n",
      "('3.2.bn1.bias', Parameter containing:\n",
      "tensor([-0.1454, -0.1050, -0.0821, -0.1602, -0.0610, -0.1217, -0.0909, -0.2110,\n",
      "        -0.0468, -0.0723,  0.0647, -0.1624, -0.1016, -0.2560, -0.1276, -0.0071,\n",
      "        -0.0720, -0.1829, -0.1142, -0.1563, -0.2545, -0.2190, -0.0403, -0.0552,\n",
      "        -0.0579, -0.0725,  0.0094, -0.0486,  0.0352,  0.0249, -0.1407, -0.0048,\n",
      "        -0.1767, -0.0514, -0.2509, -0.0429, -0.1089, -0.0308, -0.0028, -0.1316,\n",
      "         0.0154, -0.0934, -0.1336,  0.0595,  0.0007, -0.0073, -0.0858, -0.1485,\n",
      "        -0.0463, -0.1660, -0.1276, -0.1190, -0.1992,  0.0095, -0.1044, -0.1080,\n",
      "        -0.0668, -0.1707, -0.1542, -0.1031, -0.0712, -0.1875, -0.1522, -0.0941,\n",
      "        -0.0934, -0.1375, -0.0565, -0.0312, -0.0889, -0.2086, -0.1602, -0.1337,\n",
      "        -0.2297,  0.0075,  0.0272, -0.0524, -0.0608, -0.0941, -0.1265, -0.1104,\n",
      "        -0.0512, -0.0516, -0.0175,  0.1024, -0.0046, -0.0512, -0.1542, -0.2314,\n",
      "        -0.0836, -0.1917, -0.0501, -0.1440,  0.1463, -0.0450, -0.0852, -0.1904,\n",
      "        -0.1344, -0.0245, -0.1455,  0.0084, -0.1554, -0.0744, -0.1416, -0.1426,\n",
      "        -0.1813, -0.1618, -0.0090, -0.0894, -0.1515, -0.1359,  0.0699, -0.0535,\n",
      "        -0.1748, -0.1542, -0.1652, -0.1293, -0.0690,  0.0421, -0.1249,  0.0725,\n",
      "         0.0235, -0.0132, -0.1565, -0.0400,  0.0418, -0.1705, -0.2156, -0.1124],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.2.bn2.weight', Parameter containing:\n",
      "tensor([0.9800, 0.9459, 0.9859, 0.9855, 1.0331, 0.9851, 1.1349, 1.1480, 1.0345,\n",
      "        1.0016, 1.2006, 0.9354, 1.0661, 0.9770, 1.0639, 1.0315, 0.9990, 1.0199,\n",
      "        1.0937, 0.9941, 0.9540, 1.0146, 1.0217, 0.8702, 0.9573, 1.0277, 0.9573,\n",
      "        0.8934, 0.9954, 1.0045, 0.9192, 1.0917, 0.9924, 0.9693, 0.9711, 1.1010,\n",
      "        1.0179, 0.9728, 0.9502, 1.0428, 0.9500, 0.9119, 0.9791, 1.1090, 0.8993,\n",
      "        0.9138, 0.9632, 0.9824, 1.0262, 0.9208, 0.9622, 0.9827, 0.9558, 0.9968,\n",
      "        0.9857, 0.9576, 0.9991, 0.8869, 1.0332, 0.9601, 0.9866, 1.0553, 1.0066,\n",
      "        0.9694, 1.0391, 1.0651, 0.9388, 1.0085, 0.9243, 0.9883, 0.9265, 1.0823,\n",
      "        0.9727, 1.0807, 1.0840, 1.0512, 0.9872, 1.0089, 1.0012, 1.0347, 1.0286,\n",
      "        0.9104, 0.9418, 0.8203, 0.9878, 0.8785, 1.0066, 1.0006, 1.1267, 1.0827,\n",
      "        1.0969, 1.0080, 0.9598, 0.9767, 1.0757, 0.9132, 1.0571, 0.9534, 0.9190,\n",
      "        1.0547, 0.9687, 1.0594, 0.9392, 1.1089, 0.9879, 1.0518, 1.0921, 0.9349,\n",
      "        0.9085, 1.0075, 0.9210, 0.8358, 1.0483, 0.9993, 1.0864, 0.9516, 0.9726,\n",
      "        1.0108, 1.0183, 0.9588, 1.0553, 1.0430, 0.9781, 1.0395, 0.9171, 1.1494,\n",
      "        1.0627, 1.0665], device='cuda:0', requires_grad=True))\n",
      "('3.2.bn2.bias', Parameter containing:\n",
      "tensor([-0.1627, -0.1473, -0.0645, -0.1251, -0.1318, -0.1305, -0.0969, -0.1324,\n",
      "        -0.1456, -0.1185, -0.0981, -0.0767, -0.0869, -0.2135, -0.2448, -0.0495,\n",
      "        -0.2888, -0.1147, -0.2552, -0.0860, -0.0251, -0.1286, -0.0884, -0.2289,\n",
      "        -0.1255, -0.0736, -0.1630, -0.1143, -0.1160, -0.1105, -0.0988, -0.1828,\n",
      "        -0.1486, -0.1102, -0.2223, -0.0408, -0.0825, -0.2652, -0.0806, -0.1310,\n",
      "        -0.1057, -0.2231, -0.0464, -0.0976, -0.1680, -0.2003, -0.0746, -0.1776,\n",
      "        -0.1236, -0.0564, -0.2085, -0.1558, -0.1624, -0.1548, -0.1401, -0.1762,\n",
      "        -0.0445, -0.1298, -0.0118, -0.2420, -0.0866, -0.1542, -0.0860, -0.0825,\n",
      "        -0.1739, -0.1565, -0.0902, -0.2123, -0.2053, -0.1996, -0.1506, -0.0894,\n",
      "        -0.1579, -0.1829, -0.2273, -0.1247, -0.2148, -0.2179, -0.1566, -0.1014,\n",
      "        -0.0362, -0.1515, -0.1934, -0.0322, -0.1404, -0.0676, -0.2139, -0.1323,\n",
      "        -0.2312, -0.2080, -0.1037, -0.0266, -0.1148, -0.2002, -0.0494, -0.1479,\n",
      "        -0.1463, -0.2176, -0.1038, -0.2085, -0.1782, -0.0344, -0.0526, -0.1773,\n",
      "        -0.1087, -0.1605, -0.0686, -0.2284, -0.1074, -0.0184, -0.1150, -0.1194,\n",
      "        -0.1885, -0.0796, -0.1760, -0.0888, -0.1244, -0.0332, -0.1095, -0.0876,\n",
      "        -0.0044, -0.1206, -0.2643, -0.1336, -0.1783,  0.0605, -0.0400, -0.1155],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.2.bn3.weight', Parameter containing:\n",
      "tensor([1.0247, 0.9668, 1.0309, 1.1037, 1.0379, 0.9894, 1.0511, 0.9759, 1.0418,\n",
      "        1.0099, 1.0366, 0.9222, 1.0916, 1.0138, 1.1052, 1.0099, 1.0723, 0.9770,\n",
      "        1.0666, 1.0793, 1.0563, 1.0579, 0.9478, 1.0444, 1.0257, 0.9106, 1.0161,\n",
      "        1.0885, 0.9902, 0.9400, 1.0040, 0.9782, 0.9690, 0.9829, 1.0485, 1.0204,\n",
      "        1.0135, 0.9708, 1.0410, 1.0508, 1.0651, 1.0125, 0.9587, 1.0495, 1.0471,\n",
      "        1.0121, 1.0311, 0.9922, 1.0531, 1.0815, 1.0414, 0.9760, 1.0395, 1.0200,\n",
      "        1.0521, 0.9641, 1.0241, 1.0429, 1.1246, 1.0640, 1.0308, 0.9972, 1.0144,\n",
      "        1.0267, 0.9806, 0.9116, 1.0305, 1.0265, 1.0144, 1.0317, 0.9862, 1.0232,\n",
      "        1.0053, 1.0434, 1.0969, 0.9644, 1.1106, 0.9944, 1.0586, 0.9348, 0.9793,\n",
      "        1.0735, 0.9312, 1.0876, 1.0135, 0.9699, 0.9729, 1.0580, 0.9979, 1.0426,\n",
      "        1.0014, 1.0352, 1.0002, 1.0097, 1.0785, 0.9690, 0.9727, 0.9795, 1.0878,\n",
      "        0.9336, 1.0024, 0.9403, 1.0479, 1.1240, 0.9159, 1.0400, 1.0503, 0.9897,\n",
      "        1.0069, 0.9544, 0.9750, 0.9880, 0.9955, 0.9819, 1.0223, 0.9993, 0.9647,\n",
      "        0.9750, 1.0629, 1.1177, 0.9982, 0.9794, 1.0885, 1.0043, 1.0293, 1.0124,\n",
      "        1.0148, 1.0458, 1.0688, 0.9177, 0.9800, 1.0002, 1.0487, 1.0353, 1.0581,\n",
      "        1.0602, 1.0914, 1.0459, 0.9680, 0.8876, 1.0177, 1.0603, 1.0366, 1.0901,\n",
      "        0.9735, 1.0441, 1.0225, 1.0346, 1.0790, 0.9895, 1.0381, 1.0819, 0.9919,\n",
      "        1.0626, 0.9977, 0.9521, 0.9507, 1.0649, 0.9823, 1.0223, 0.9785, 0.9463,\n",
      "        1.0607, 1.0110, 1.1029, 1.0892, 0.9211, 1.0308, 1.1517, 1.0038, 1.1007,\n",
      "        1.0148, 1.0046, 1.0907, 1.0580, 1.0529, 1.0226, 0.9706, 1.0849, 1.1366,\n",
      "        0.9732, 0.8808, 0.9882, 1.0496, 1.0074, 1.0783, 1.0454, 1.0113, 0.9703,\n",
      "        0.9679, 0.9863, 0.9575, 1.0581, 0.9924, 1.0199, 0.9736, 0.9537, 1.0216,\n",
      "        0.9616, 1.1011, 0.9207, 1.0624, 1.0320, 1.0227, 0.9431, 1.0525, 1.0921,\n",
      "        0.9896, 1.0102, 0.9725, 0.8533, 1.0481, 1.0373, 0.9720, 1.0130, 1.0320,\n",
      "        1.0207, 1.0016, 0.9973, 1.0947, 1.0362, 0.9759, 1.0057, 1.0335, 1.0860,\n",
      "        0.9878, 1.0582, 1.0098, 1.0578, 1.0149, 1.0589, 0.9968, 1.0182, 1.0532,\n",
      "        1.0241, 1.0324, 1.0836, 1.1051, 0.9736, 0.9754, 1.0119, 1.0207, 0.9669,\n",
      "        1.0226, 0.9718, 1.0536, 0.9933, 1.0292, 1.0464, 0.9536, 1.0533, 1.0097,\n",
      "        0.9532, 1.0651, 0.9813, 1.0430, 1.0032, 1.0011, 1.1134, 1.0019, 0.9613,\n",
      "        1.0574, 0.9517, 1.0024, 1.0440, 0.9892, 1.0068, 1.0612, 1.0419, 1.0312,\n",
      "        1.0330, 0.9932, 0.9965, 0.9485, 1.0064, 0.8750, 1.0030, 1.0709, 1.0719,\n",
      "        0.9991, 1.0412, 0.9860, 1.0849, 1.0823, 0.9680, 1.0653, 1.0952, 1.0350,\n",
      "        0.9918, 0.9689, 1.0149, 0.9867, 1.0262, 1.0970, 0.9759, 1.0827, 1.0281,\n",
      "        1.0954, 1.0454, 1.0974, 1.0341, 1.0139, 1.0632, 1.0029, 1.1521, 1.0732,\n",
      "        1.1258, 0.8793, 1.0207, 0.9693, 1.0192, 1.0757, 1.0623, 0.9845, 1.0287,\n",
      "        1.1351, 1.0282, 1.0741, 1.0390, 0.9909, 1.0115, 0.9947, 1.0394, 1.0294,\n",
      "        1.0139, 1.0410, 0.9870, 1.0316, 1.0348, 1.0339, 0.9331, 0.9065, 1.0513,\n",
      "        0.9454, 1.0087, 0.9819, 0.9453, 1.0340, 0.8872, 1.0437, 0.9876, 1.0517,\n",
      "        1.0446, 1.1175, 0.9920, 1.0359, 0.9771, 1.0066, 1.1113, 0.9607, 1.0837,\n",
      "        1.0476, 1.0501, 1.0416, 0.9909, 1.0616, 1.1144, 0.9475, 0.9941, 1.0308,\n",
      "        1.0525, 0.9704, 1.0147, 0.9652, 1.0187, 0.9214, 0.9131, 1.0103, 1.0110,\n",
      "        1.0189, 1.0162, 0.9846, 1.0400, 1.0905, 0.8675, 1.0129, 1.1079, 1.0408,\n",
      "        0.9957, 0.9886, 0.9763, 1.0035, 1.0350, 1.0069, 1.0035, 0.9643, 0.9977,\n",
      "        1.0705, 1.0479, 1.0887, 0.9853, 1.0359, 0.9863, 0.9482, 0.9588, 1.0356,\n",
      "        0.9184, 0.8882, 1.0672, 0.9423, 1.0080, 1.0094, 1.0462, 1.0095, 1.0410,\n",
      "        0.9654, 1.0108, 0.9675, 1.0025, 1.0180, 1.0702, 0.9600, 0.9420, 1.0472,\n",
      "        1.0366, 1.0793, 1.0370, 0.8979, 0.9643, 1.0580, 1.0239, 0.9839, 0.9803,\n",
      "        1.0655, 1.0066, 1.0087, 1.1486, 1.0866, 1.0806, 0.9962, 1.0538, 1.0013,\n",
      "        1.0316, 1.0951, 1.0030, 0.9856, 1.1419, 0.9755, 1.0458, 1.0963, 0.9785,\n",
      "        0.9235, 1.0728, 1.0277, 1.0068, 0.9672, 1.1257, 1.0247, 1.0607, 1.0112,\n",
      "        0.9987, 1.0617, 0.9962, 1.0454, 1.1669, 0.9253, 1.0912, 1.0108, 1.0299,\n",
      "        1.0729, 0.9265, 0.8992, 1.0182, 1.0343, 1.0511, 1.0360, 0.9835, 1.0224,\n",
      "        0.9487, 1.0007, 0.9624, 1.0304, 1.0126, 1.0374, 1.0205, 0.9837, 1.1417,\n",
      "        1.0034, 1.0701, 1.0361, 0.9951, 0.9965, 1.0991, 0.9294, 1.0649, 1.0769,\n",
      "        0.9925, 1.0531, 1.0241, 1.0155, 0.9687, 0.9830, 1.0266, 1.1260, 1.0721,\n",
      "        0.9984, 1.0472, 1.0396, 0.9642, 0.9756, 1.0085, 1.0863, 1.0281, 1.0791,\n",
      "        0.9072, 1.0479, 0.9769, 1.1321, 0.9581, 0.9909, 1.0106, 1.0867],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.2.bn3.bias', Parameter containing:\n",
      "tensor([-4.7324e-03, -7.5535e-03, -2.6026e-02,  7.3423e-02, -1.5780e-02,\n",
      "         5.3184e-03,  1.9212e-02,  3.6324e-03, -1.9993e-03, -5.9670e-04,\n",
      "         4.0554e-03, -1.1412e-03,  1.5057e-02, -4.1110e-02,  9.7150e-03,\n",
      "         4.3533e-03, -4.6750e-02, -4.5802e-03, -1.9696e-02,  3.2609e-02,\n",
      "         1.4620e-02, -2.2212e-02, -1.6435e-03, -4.1513e-03,  1.3343e-02,\n",
      "         2.8407e-03,  2.6746e-02, -3.8664e-02, -2.4331e-04,  1.3579e-02,\n",
      "         2.1784e-02, -5.9456e-03, -7.4567e-04,  1.1040e-02,  1.2801e-02,\n",
      "        -6.7045e-03,  2.4506e-02,  8.1901e-03, -1.7976e-02, -7.1736e-02,\n",
      "        -1.4479e-02, -3.0953e-03,  1.6635e-02, -6.5011e-03, -2.7544e-04,\n",
      "         5.1416e-03,  1.6771e-02,  7.2563e-03, -2.5948e-02,  2.9758e-02,\n",
      "        -2.2345e-02, -5.9796e-03, -2.7555e-02, -3.3229e-02, -4.0212e-03,\n",
      "        -1.1110e-02,  3.8282e-03,  2.1723e-03, -1.2273e-03, -4.9000e-04,\n",
      "        -9.5994e-03, -6.0414e-03, -1.5248e-02,  2.0217e-02, -2.1347e-02,\n",
      "        -9.6357e-03,  9.5151e-03,  1.2179e-02,  6.6683e-03,  7.4781e-03,\n",
      "        -5.4346e-03, -1.7322e-02, -2.2278e-02, -2.0957e-02, -2.0936e-02,\n",
      "        -3.5420e-02, -3.5245e-02,  3.9103e-03,  5.1951e-03, -1.0885e-02,\n",
      "        -2.2238e-02,  8.9155e-03,  1.1619e-02, -3.2717e-02,  7.8108e-03,\n",
      "        -1.1997e-02,  1.4434e-02, -1.4303e-02, -5.7368e-03,  5.3660e-03,\n",
      "         1.5315e-02, -2.7969e-02, -1.9796e-02, -6.6346e-02, -3.3064e-02,\n",
      "         5.9671e-03,  2.8997e-03, -2.0509e-02,  1.1672e-03, -7.5156e-03,\n",
      "         3.3727e-03, -3.4389e-02,  1.0340e-03, -5.1361e-02,  3.0493e-03,\n",
      "         2.1536e-02, -1.2899e-02, -1.5705e-02, -2.4063e-02, -1.6237e-02,\n",
      "         7.2358e-03,  7.2497e-03,  4.1022e-02,  9.4609e-03,  9.2456e-05,\n",
      "         9.6033e-03, -8.2626e-03, -2.6123e-02,  9.0815e-03,  3.6182e-02,\n",
      "        -3.1994e-02,  4.1345e-02, -2.4270e-02, -6.0602e-02, -6.2267e-03,\n",
      "        -6.0424e-02, -4.5819e-03,  1.7176e-03, -4.9846e-02,  7.3795e-03,\n",
      "        -1.9322e-02, -4.1369e-02, -2.0850e-02,  5.8037e-03,  7.4232e-03,\n",
      "         1.4040e-02, -7.0489e-02, -4.4699e-03,  1.2662e-02,  4.3998e-03,\n",
      "        -7.0186e-05,  1.1741e-03, -5.7507e-04, -9.8062e-05, -1.2272e-02,\n",
      "        -5.0924e-03, -3.9225e-02, -2.4681e-02,  8.7943e-03,  1.2463e-02,\n",
      "        -4.3221e-03, -1.8349e-02,  4.6021e-03,  2.0947e-03, -1.1752e-02,\n",
      "        -8.1246e-03, -8.9728e-04,  1.7981e-02, -7.5017e-04,  8.8625e-03,\n",
      "        -7.9166e-03,  9.2075e-03, -1.7185e-02,  9.9712e-03, -1.0061e-03,\n",
      "        -9.3773e-03, -1.0018e-02, -2.4135e-02,  3.5858e-02,  4.3620e-03,\n",
      "        -6.5729e-03, -5.5042e-02,  1.0525e-02,  2.0494e-02, -2.4743e-02,\n",
      "         2.4687e-02,  1.5686e-03,  7.1884e-03, -2.8925e-02, -2.1550e-02,\n",
      "         5.0938e-03,  5.9415e-03,  2.4530e-02,  2.3793e-02, -1.0881e-02,\n",
      "         4.1621e-05,  1.3316e-02,  2.4057e-02, -2.3249e-02,  4.0817e-03,\n",
      "         1.9348e-03, -2.3626e-02, -1.2112e-02, -1.3490e-02, -1.0487e-03,\n",
      "        -1.8839e-04,  3.4748e-03,  2.3766e-02,  7.1196e-03, -1.2976e-02,\n",
      "         1.8220e-02,  9.7057e-03, -1.7431e-02,  6.3525e-03, -2.2472e-04,\n",
      "        -2.9097e-03, -1.4034e-02, -1.1841e-02,  8.5820e-03, -1.9720e-02,\n",
      "         3.3723e-03,  4.3190e-04, -2.3615e-02,  3.7277e-04,  6.9472e-04,\n",
      "        -9.6210e-03, -1.2480e-02, -3.5699e-03,  8.0247e-03,  1.6152e-02,\n",
      "        -2.4629e-02,  5.2347e-03,  4.9949e-02,  1.7645e-02,  2.2795e-02,\n",
      "        -1.3062e-02,  1.9793e-02, -4.4898e-02,  3.5104e-03,  2.9855e-03,\n",
      "        -7.3342e-02, -1.0577e-02,  3.0254e-04, -2.1411e-02,  1.6169e-02,\n",
      "         5.4477e-04,  1.4177e-02,  3.0257e-02, -1.1481e-02,  8.6035e-03,\n",
      "        -3.5498e-02, -1.3924e-02,  7.8677e-03,  1.1624e-02,  9.8409e-03,\n",
      "        -2.5334e-02, -5.6598e-03, -1.4369e-02,  3.3781e-03,  9.5870e-03,\n",
      "        -2.8927e-02, -1.4066e-02, -3.3433e-03,  5.5093e-02,  4.2814e-03,\n",
      "         2.9360e-04, -7.0265e-03, -2.2050e-02,  5.2558e-02, -1.2797e-02,\n",
      "         6.9580e-03,  2.1204e-02,  1.3652e-02,  2.3138e-04, -1.2405e-02,\n",
      "        -1.1329e-02, -2.3684e-02,  2.1637e-02,  1.8425e-02,  1.5523e-02,\n",
      "         4.0867e-04, -5.6199e-03,  1.5654e-02, -6.1986e-04, -9.0737e-03,\n",
      "         6.3713e-03,  1.1434e-02,  1.9878e-02,  1.7738e-02, -3.9353e-04,\n",
      "         1.7844e-02,  1.2398e-03, -9.7122e-03,  2.2672e-02, -4.4971e-03,\n",
      "        -1.4890e-02, -3.2995e-02, -2.3816e-03, -8.1952e-03, -9.8043e-03,\n",
      "        -9.7301e-03,  1.2291e-02, -1.5073e-02, -3.8160e-02,  2.5036e-02,\n",
      "         1.5466e-03,  1.0240e-02,  1.6253e-03, -5.5519e-03,  1.7723e-02,\n",
      "         1.4082e-02,  7.8778e-03,  2.7033e-02,  3.4872e-02, -3.5450e-02,\n",
      "         3.2640e-02, -1.9486e-02,  1.0060e-02,  3.9409e-03, -5.5620e-04,\n",
      "        -3.9016e-03, -2.0703e-04, -5.1497e-02,  7.7537e-03, -5.7625e-04,\n",
      "         5.8771e-03, -1.4201e-02,  1.3550e-02, -4.8697e-02, -1.0325e-02,\n",
      "         1.1314e-02, -3.2743e-02, -2.0725e-02, -2.5649e-02,  4.8605e-03,\n",
      "         8.2989e-03, -6.7838e-03,  6.4734e-03,  7.6394e-03, -1.6929e-02,\n",
      "        -1.9757e-02,  7.9034e-04, -1.5455e-05,  3.6651e-02,  1.0593e-02,\n",
      "         4.7489e-02,  3.0356e-03,  4.0173e-02, -2.9037e-03,  8.2961e-03,\n",
      "         1.5687e-02,  5.5805e-03,  1.0276e-02, -7.5664e-04, -5.1392e-04,\n",
      "         1.0204e-02, -2.3156e-02,  1.5906e-03,  9.0533e-03,  1.6531e-02,\n",
      "        -6.8659e-02,  6.0402e-03,  2.9112e-02, -6.3351e-03, -8.1766e-03,\n",
      "        -4.6963e-02,  5.7861e-02,  1.6158e-02,  2.6799e-03,  1.0436e-02,\n",
      "         2.5623e-02, -4.3523e-02,  9.0290e-03,  1.3164e-02, -1.1389e-02,\n",
      "        -1.5157e-02,  1.1039e-03, -6.7709e-03, -1.0756e-02,  1.2603e-02,\n",
      "         2.6391e-02,  4.9318e-03,  2.0571e-02, -9.2090e-05,  1.2394e-02,\n",
      "         3.2046e-02, -1.6519e-03,  1.6689e-02,  9.8351e-04, -1.7799e-02,\n",
      "        -6.8635e-03, -3.4435e-02,  4.6612e-03,  1.7741e-02,  5.3504e-03,\n",
      "         4.9766e-03, -3.1034e-02,  1.1964e-02, -3.6606e-02, -6.4641e-03,\n",
      "        -1.9118e-03,  8.6212e-04, -4.7056e-02, -8.4690e-04, -2.9578e-02,\n",
      "        -4.7595e-02,  3.6275e-03, -3.0123e-03,  6.9370e-03, -1.4792e-02,\n",
      "        -1.8271e-02,  2.4258e-02, -2.8465e-02,  7.0917e-03, -4.0250e-03,\n",
      "        -1.5836e-02,  2.9864e-02, -7.5700e-03,  4.8090e-03, -5.9246e-02,\n",
      "         2.7346e-02, -2.6419e-03,  5.7806e-03,  8.7177e-03,  1.6530e-02,\n",
      "         1.7287e-02,  4.2492e-02, -5.1084e-03,  1.8481e-03, -2.1615e-03,\n",
      "         3.4279e-03,  1.6143e-02, -3.7134e-02, -2.3307e-02,  2.7887e-02,\n",
      "         3.0347e-04,  1.6112e-02, -1.2220e-02,  3.4759e-02, -9.4765e-03,\n",
      "        -8.1181e-04,  7.7620e-03,  5.5560e-03,  1.9755e-03, -1.3477e-02,\n",
      "        -5.6870e-03,  1.8013e-02, -1.0257e-02,  1.0211e-03,  1.1796e-02,\n",
      "         3.4170e-03, -2.0099e-02, -1.7372e-02, -2.2889e-03, -2.7138e-02,\n",
      "         1.2678e-02,  3.9928e-02, -3.9172e-03, -4.8419e-02, -6.1287e-02,\n",
      "         1.3437e-02, -4.6192e-02,  3.1872e-03,  3.0221e-02,  6.6311e-03,\n",
      "        -1.9409e-02, -7.3258e-03, -2.9475e-03, -1.7622e-02,  4.2319e-03,\n",
      "         5.7127e-03, -1.3616e-02,  5.5129e-03,  1.0323e-02,  2.7808e-02,\n",
      "        -2.6755e-03, -9.0783e-03, -6.3824e-05, -3.7925e-03,  2.6553e-03,\n",
      "         2.0941e-03, -7.6849e-03, -6.2872e-02, -4.4906e-02,  1.0717e-02,\n",
      "        -7.7782e-03,  5.4100e-04, -9.4247e-03,  5.1622e-02,  2.0110e-02,\n",
      "        -3.4770e-03, -5.9976e-03,  3.5145e-03, -2.7679e-03, -5.7700e-04,\n",
      "        -9.8031e-02,  6.2937e-03, -1.2035e-02, -1.5520e-05, -3.5770e-05,\n",
      "        -4.3239e-02, -9.9070e-03,  1.7875e-02,  4.1077e-03, -3.7517e-02,\n",
      "        -7.8991e-03, -1.8561e-02, -1.3686e-02, -5.3864e-03,  3.9257e-04,\n",
      "         2.2929e-03,  1.4580e-02,  1.5102e-02, -2.8425e-03, -2.3099e-02,\n",
      "        -1.9274e-02, -9.4926e-03,  4.0063e-02, -3.0345e-03, -6.5537e-03,\n",
      "        -1.4129e-02,  1.7891e-02], device='cuda:0', requires_grad=True))\n",
      "('3.3.conv1.weight', Parameter containing:\n",
      "tensor([[[-0.1359],\n",
      "         [ 0.1200],\n",
      "         [ 0.0478],\n",
      "         ...,\n",
      "         [-0.1216],\n",
      "         [-0.0120],\n",
      "         [-0.0598]],\n",
      "\n",
      "        [[-0.0197],\n",
      "         [ 0.1219],\n",
      "         [-0.0030],\n",
      "         ...,\n",
      "         [ 0.0442],\n",
      "         [-0.0143],\n",
      "         [-0.0107]],\n",
      "\n",
      "        [[-0.0354],\n",
      "         [-0.0569],\n",
      "         [-0.0511],\n",
      "         ...,\n",
      "         [-0.1025],\n",
      "         [-0.1555],\n",
      "         [-0.1196]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0804],\n",
      "         [-0.0189],\n",
      "         [ 0.0132],\n",
      "         ...,\n",
      "         [ 0.1981],\n",
      "         [-0.0260],\n",
      "         [-0.0337]],\n",
      "\n",
      "        [[ 0.2775],\n",
      "         [ 0.1222],\n",
      "         [ 0.0529],\n",
      "         ...,\n",
      "         [-0.0888],\n",
      "         [ 0.0303],\n",
      "         [ 0.1619]],\n",
      "\n",
      "        [[-0.1125],\n",
      "         [ 0.0131],\n",
      "         [-0.1332],\n",
      "         ...,\n",
      "         [ 0.0726],\n",
      "         [ 0.0603],\n",
      "         [-0.0447]]], device='cuda:0', requires_grad=True))\n",
      "('3.3.conv1.bias', Parameter containing:\n",
      "tensor([ 0.0250,  0.0120,  0.0404, -0.0399, -0.0303, -0.0180,  0.0022, -0.0353,\n",
      "        -0.0196, -0.0366, -0.0302,  0.0144, -0.0204,  0.0056,  0.0034, -0.0353,\n",
      "        -0.0104, -0.0404, -0.0110, -0.0342,  0.0397,  0.0403,  0.0414,  0.0234,\n",
      "        -0.0237, -0.0432,  0.0089,  0.0406, -0.0126, -0.0096,  0.0156, -0.0082,\n",
      "        -0.0106,  0.0401, -0.0026,  0.0027, -0.0259,  0.0123,  0.0170, -0.0380,\n",
      "         0.0341,  0.0058, -0.0416,  0.0225,  0.0405,  0.0133, -0.0009, -0.0179,\n",
      "        -0.0008,  0.0134,  0.0010, -0.0359, -0.0175, -0.0375,  0.0292, -0.0284,\n",
      "         0.0129, -0.0316,  0.0293, -0.0295, -0.0364, -0.0332,  0.0265,  0.0420,\n",
      "        -0.0097,  0.0067,  0.0266, -0.0305,  0.0188,  0.0122,  0.0345, -0.0315,\n",
      "        -0.0182, -0.0109,  0.0386,  0.0169, -0.0339,  0.0282, -0.0046,  0.0093,\n",
      "        -0.0016,  0.0236,  0.0399, -0.0414,  0.0224,  0.0341,  0.0068, -0.0015,\n",
      "        -0.0247, -0.0244,  0.0082, -0.0118, -0.0421,  0.0384, -0.0188,  0.0020,\n",
      "        -0.0051,  0.0177, -0.0193, -0.0262, -0.0109, -0.0049, -0.0314, -0.0051,\n",
      "        -0.0412, -0.0408,  0.0136, -0.0160,  0.0293,  0.0410, -0.0279,  0.0180,\n",
      "         0.0290,  0.0373,  0.0254, -0.0041,  0.0385,  0.0188, -0.0259, -0.0004,\n",
      "         0.0347, -0.0160,  0.0348,  0.0360, -0.0324,  0.0098,  0.0352,  0.0051],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.3.conv2.weight', Parameter containing:\n",
      "tensor([[[-0.1588, -0.1010, -0.1340],\n",
      "         [-0.0833, -0.0037,  0.1142],\n",
      "         [ 0.0430,  0.1371, -0.0554],\n",
      "         ...,\n",
      "         [ 0.0996,  0.0541,  0.0516],\n",
      "         [ 0.1034,  0.1698, -0.0363],\n",
      "         [-0.2007, -0.0382,  0.2145]],\n",
      "\n",
      "        [[-0.0997, -0.0236, -0.0283],\n",
      "         [ 0.1091, -0.0040,  0.0640],\n",
      "         [-0.0891, -0.0084, -0.0139],\n",
      "         ...,\n",
      "         [-0.0194, -0.0005,  0.0383],\n",
      "         [ 0.0150, -0.1066,  0.0967],\n",
      "         [ 0.0443, -0.0904, -0.1526]],\n",
      "\n",
      "        [[-0.0196,  0.0862, -0.1287],\n",
      "         [-0.1003,  0.1992,  0.0462],\n",
      "         [ 0.1008,  0.0548, -0.0461],\n",
      "         ...,\n",
      "         [-0.0825, -0.1307, -0.0053],\n",
      "         [ 0.1344, -0.0122,  0.2213],\n",
      "         [-0.0361,  0.0429,  0.1205]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0861, -0.0117, -0.0103],\n",
      "         [ 0.0062,  0.0802,  0.0512],\n",
      "         [ 0.1637, -0.1276,  0.0067],\n",
      "         ...,\n",
      "         [-0.0122,  0.0781, -0.1010],\n",
      "         [ 0.0886,  0.1639,  0.0019],\n",
      "         [-0.0327,  0.0202, -0.0004]],\n",
      "\n",
      "        [[-0.0772, -0.0909,  0.0759],\n",
      "         [-0.0105,  0.0039,  0.0040],\n",
      "         [ 0.0582, -0.0060,  0.0067],\n",
      "         ...,\n",
      "         [ 0.0008,  0.0050,  0.0122],\n",
      "         [ 0.0503,  0.0490,  0.0765],\n",
      "         [-0.0244,  0.0397,  0.0669]],\n",
      "\n",
      "        [[ 0.0242, -0.0167,  0.0597],\n",
      "         [-0.1056, -0.0011, -0.1271],\n",
      "         [-0.0018, -0.0773, -0.0236],\n",
      "         ...,\n",
      "         [-0.1001, -0.0577, -0.0214],\n",
      "         [-0.2290,  0.0664,  0.0316],\n",
      "         [-0.0728, -0.0141, -0.1661]]], device='cuda:0', requires_grad=True))\n",
      "('3.3.conv2.bias', Parameter containing:\n",
      "tensor([ 0.0186,  0.0101, -0.0070, -0.0242, -0.0320, -0.0310,  0.0281,  0.0353,\n",
      "        -0.0214, -0.0230,  0.0468,  0.0501,  0.0327, -0.0412, -0.0471,  0.0288,\n",
      "        -0.0223,  0.0258, -0.0120,  0.0025,  0.0049,  0.0320,  0.0439, -0.0239,\n",
      "        -0.0020,  0.0365,  0.0220, -0.0506,  0.0297, -0.0171, -0.0178, -0.0219,\n",
      "         0.0401, -0.0400, -0.0117,  0.0484,  0.0139,  0.0028, -0.0187,  0.0030,\n",
      "        -0.0094,  0.0072, -0.0141,  0.0403,  0.0304, -0.0319,  0.0410, -0.0406,\n",
      "        -0.0039,  0.0291, -0.0365, -0.0035,  0.0070, -0.0222, -0.0411,  0.0275,\n",
      "        -0.0201,  0.0310,  0.0022, -0.0464,  0.0313,  0.0439,  0.0077, -0.0322,\n",
      "         0.0492, -0.0021, -0.0331,  0.0258,  0.0403, -0.0062,  0.0315, -0.0321,\n",
      "        -0.0091,  0.0505, -0.0160,  0.0116, -0.0437, -0.0107,  0.0489, -0.0505,\n",
      "        -0.0393, -0.0469, -0.0431, -0.0413,  0.0315, -0.0075, -0.0003,  0.0239,\n",
      "         0.0051,  0.0203,  0.0462,  0.0212, -0.0488, -0.0423,  0.0350,  0.0081,\n",
      "        -0.0437,  0.0487,  0.0092,  0.0363, -0.0042, -0.0462, -0.0273,  0.0214,\n",
      "         0.0340,  0.0215, -0.0039,  0.0166,  0.0023, -0.0224, -0.0092,  0.0374,\n",
      "        -0.0237,  0.0470, -0.0069,  0.0139,  0.0306, -0.0339,  0.0108,  0.0132,\n",
      "        -0.0058,  0.0025,  0.0200,  0.0443,  0.0032, -0.0337,  0.0308,  0.0489],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.3.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.0598],\n",
      "         [-0.0840],\n",
      "         [ 0.0585],\n",
      "         ...,\n",
      "         [ 0.0319],\n",
      "         [-0.0328],\n",
      "         [-0.1703]],\n",
      "\n",
      "        [[ 0.1046],\n",
      "         [ 0.0405],\n",
      "         [-0.1165],\n",
      "         ...,\n",
      "         [ 0.0476],\n",
      "         [-0.0167],\n",
      "         [ 0.1173]],\n",
      "\n",
      "        [[-0.0282],\n",
      "         [-0.0581],\n",
      "         [ 0.1112],\n",
      "         ...,\n",
      "         [ 0.0820],\n",
      "         [-0.1657],\n",
      "         [ 0.1163]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0445],\n",
      "         [ 0.0464],\n",
      "         [ 0.0797],\n",
      "         ...,\n",
      "         [-0.1129],\n",
      "         [ 0.0104],\n",
      "         [-0.0502]],\n",
      "\n",
      "        [[ 0.0781],\n",
      "         [-0.0299],\n",
      "         [-0.0606],\n",
      "         ...,\n",
      "         [-0.0666],\n",
      "         [-0.0211],\n",
      "         [-0.1397]],\n",
      "\n",
      "        [[ 0.0092],\n",
      "         [-0.1274],\n",
      "         [-0.0927],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [ 0.1575],\n",
      "         [ 0.0711]]], device='cuda:0', requires_grad=True))\n",
      "('3.3.conv3.bias', Parameter containing:\n",
      "tensor([ 0.0373,  0.0383, -0.0875,  0.0673,  0.0676, -0.0176, -0.0126, -0.0277,\n",
      "         0.0752, -0.0645,  0.0073,  0.0166, -0.0095,  0.0499, -0.0233, -0.0372,\n",
      "        -0.0871, -0.0855, -0.0313,  0.0844,  0.0576, -0.0650,  0.0656,  0.0863,\n",
      "        -0.0536, -0.0701,  0.0868, -0.0305, -0.0169, -0.0539,  0.0804, -0.0065,\n",
      "         0.0123, -0.0414, -0.0251,  0.0388, -0.0386, -0.0702,  0.0050, -0.0072,\n",
      "         0.0413,  0.0182,  0.0048,  0.0880, -0.0688,  0.0659,  0.0835,  0.0051,\n",
      "         0.0464,  0.0656,  0.0239,  0.0537, -0.0520,  0.0271, -0.0046, -0.0004,\n",
      "         0.0004, -0.0205, -0.0287,  0.0799,  0.0499, -0.0611, -0.0686, -0.0032,\n",
      "        -0.0056, -0.0262,  0.0578,  0.0778,  0.0702, -0.0141, -0.0643, -0.0331,\n",
      "        -0.0134,  0.0841,  0.0385,  0.0364,  0.0522, -0.0722, -0.0760,  0.0653,\n",
      "         0.0478,  0.0794,  0.0725, -0.0097,  0.0169, -0.0652,  0.0178, -0.0674,\n",
      "        -0.0500,  0.0587, -0.0713, -0.0494, -0.0098, -0.0251,  0.0605, -0.0550,\n",
      "        -0.0443, -0.0707,  0.0234,  0.0412,  0.0495, -0.0687,  0.0843,  0.0275,\n",
      "         0.0134, -0.0844, -0.0801,  0.0834, -0.0663, -0.0011, -0.0042,  0.0878,\n",
      "        -0.0693, -0.0524, -0.0638,  0.0617, -0.0196, -0.0506, -0.0209, -0.0529,\n",
      "         0.0381,  0.0650, -0.0822, -0.0034, -0.0236, -0.0502,  0.0418, -0.0690,\n",
      "        -0.0320, -0.0845, -0.0518,  0.0471, -0.0456,  0.0040,  0.0170,  0.0223,\n",
      "         0.0209, -0.0207, -0.0850,  0.0594, -0.0585, -0.0651,  0.0862,  0.0328,\n",
      "         0.0539, -0.0597,  0.0513, -0.0631,  0.0142,  0.0430,  0.0500, -0.0814,\n",
      "        -0.0641,  0.0389, -0.0235,  0.0709,  0.0292,  0.0708, -0.0682, -0.0384,\n",
      "         0.0603, -0.0258, -0.0260,  0.0432, -0.0062, -0.0113, -0.0539, -0.0287,\n",
      "        -0.0477,  0.0367,  0.0720, -0.0745, -0.0036, -0.0557, -0.0671,  0.0327,\n",
      "        -0.0436,  0.0034,  0.0446, -0.0605, -0.0193, -0.0332, -0.0809, -0.0035,\n",
      "         0.0846,  0.0475,  0.0399,  0.0340,  0.0746,  0.0176,  0.0727, -0.0659,\n",
      "        -0.0602,  0.0265, -0.0267, -0.0153, -0.0080, -0.0447, -0.0549,  0.0010,\n",
      "        -0.0081,  0.0762, -0.0500,  0.0352,  0.0740, -0.0673, -0.0137, -0.0727,\n",
      "        -0.0046, -0.0724,  0.0747,  0.0188, -0.0382,  0.0256, -0.0630,  0.0212,\n",
      "        -0.0337, -0.0536, -0.0351, -0.0044,  0.0867, -0.0074,  0.0613,  0.0622,\n",
      "         0.0539, -0.0290,  0.0367, -0.0211,  0.0552,  0.0537, -0.0573,  0.0317,\n",
      "         0.0775, -0.0276,  0.0350,  0.0250,  0.0296, -0.0064, -0.0228,  0.0621,\n",
      "        -0.0430, -0.0415, -0.0547,  0.0752,  0.0390, -0.0401,  0.0317, -0.0802,\n",
      "         0.0391,  0.0097, -0.0679,  0.0058,  0.0073, -0.0031,  0.0521, -0.0120,\n",
      "        -0.0181, -0.0128, -0.0473, -0.0627,  0.0605,  0.0269, -0.0685,  0.0081,\n",
      "        -0.0704,  0.0753, -0.0389, -0.0374, -0.0236, -0.0883, -0.0087,  0.0454,\n",
      "         0.0650,  0.0270,  0.0752,  0.0283,  0.0141,  0.0039, -0.0031, -0.0505,\n",
      "         0.0834, -0.0847,  0.0515,  0.0540,  0.0503,  0.0073, -0.0158,  0.0265,\n",
      "        -0.0589,  0.0022,  0.0751,  0.0685, -0.0281,  0.0136, -0.0754, -0.0633,\n",
      "        -0.0600, -0.0144,  0.0475,  0.0095, -0.0648,  0.0173,  0.0239,  0.0011,\n",
      "         0.0446, -0.0622,  0.0262,  0.0227, -0.0800,  0.0429,  0.0066, -0.0693,\n",
      "        -0.0416,  0.0851, -0.0395,  0.0074,  0.0623, -0.0286, -0.0168, -0.0463,\n",
      "        -0.0834, -0.0359, -0.0438, -0.0332,  0.0311, -0.0771,  0.0443,  0.0398,\n",
      "         0.0359,  0.0317, -0.0538, -0.0695,  0.0346,  0.0629,  0.0155,  0.0016,\n",
      "        -0.0208, -0.0850, -0.0874,  0.0582, -0.0356, -0.0035, -0.0748, -0.0435,\n",
      "         0.0695, -0.0669,  0.0814, -0.0378, -0.0862,  0.0463,  0.0869, -0.0240,\n",
      "        -0.0315,  0.0251, -0.0333, -0.0810, -0.0879,  0.0776, -0.0719,  0.0406,\n",
      "        -0.0002, -0.0076,  0.0128,  0.0178,  0.0576,  0.0127,  0.0828, -0.0561,\n",
      "         0.0314,  0.0061,  0.0818, -0.0623,  0.0057,  0.0852, -0.0874,  0.0215,\n",
      "        -0.0304,  0.0634,  0.0652, -0.0007,  0.0650, -0.0465, -0.0246,  0.0297,\n",
      "        -0.0090,  0.0623,  0.0298, -0.0725, -0.0746, -0.0337, -0.0199, -0.0264,\n",
      "         0.0081, -0.0079, -0.0472, -0.0622, -0.0800, -0.0295,  0.0699,  0.0455,\n",
      "         0.0873, -0.0426,  0.0455,  0.0501, -0.0454, -0.0727, -0.0285, -0.0604,\n",
      "        -0.0700, -0.0756,  0.0337,  0.0423, -0.0354, -0.0143, -0.0762, -0.0056,\n",
      "        -0.0695, -0.0025,  0.0440, -0.0724, -0.0645, -0.0605,  0.0844,  0.0132,\n",
      "        -0.0366, -0.0007, -0.0829, -0.0817, -0.0664,  0.0468,  0.0223, -0.0400,\n",
      "         0.0027,  0.0385, -0.0227, -0.0256, -0.0477, -0.0002,  0.0466, -0.0749,\n",
      "        -0.0305, -0.0647, -0.0145,  0.0788, -0.0043, -0.0035,  0.0638, -0.0379,\n",
      "         0.0698,  0.0218, -0.0457,  0.0211,  0.0437, -0.0246, -0.0752, -0.0668,\n",
      "         0.0581, -0.0679,  0.0471,  0.0300, -0.0267,  0.0814,  0.0737, -0.0727,\n",
      "        -0.0490,  0.0008,  0.0590, -0.0136,  0.0499,  0.0876, -0.0509,  0.0414,\n",
      "        -0.0382,  0.0303,  0.0284,  0.0171, -0.0126,  0.0681, -0.0849,  0.0325,\n",
      "        -0.0516,  0.0771,  0.0209, -0.0155,  0.0379, -0.0566, -0.0207, -0.0784,\n",
      "         0.0585, -0.0114, -0.0256, -0.0411,  0.0279,  0.0813, -0.0129, -0.0097,\n",
      "        -0.0847, -0.0627,  0.0145,  0.0832,  0.0489,  0.0724, -0.0806,  0.0058,\n",
      "        -0.0718, -0.0727, -0.0840, -0.0249,  0.0336, -0.0391,  0.0146, -0.0663],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.3.bn1.weight', Parameter containing:\n",
      "tensor([1.0586, 0.9691, 0.9492, 0.9739, 0.9286, 0.9961, 1.0432, 0.9684, 0.9122,\n",
      "        0.9597, 1.0116, 1.0615, 1.0068, 1.1058, 1.1229, 0.9771, 1.1082, 0.9524,\n",
      "        0.9154, 1.0789, 1.0819, 0.9498, 0.8957, 1.1447, 0.9137, 0.9135, 1.0367,\n",
      "        0.9022, 0.9910, 1.0880, 0.8439, 1.0260, 1.0452, 1.0272, 1.0217, 0.9504,\n",
      "        0.9968, 1.1198, 0.9837, 1.0464, 1.0863, 0.8934, 0.8958, 1.0006, 0.8964,\n",
      "        1.1147, 0.9558, 0.9445, 0.9226, 0.9191, 0.9839, 1.0343, 1.1442, 0.9269,\n",
      "        0.8165, 0.8469, 1.0532, 1.0642, 0.9597, 1.1039, 1.0433, 1.0792, 0.9699,\n",
      "        0.9558, 1.0020, 1.0169, 0.9056, 0.9684, 1.0537, 0.8664, 0.9705, 0.9662,\n",
      "        0.9148, 1.0234, 0.9881, 0.9472, 1.0363, 0.9735, 1.0984, 1.0268, 0.9024,\n",
      "        0.9108, 1.0205, 1.0290, 1.1069, 0.9874, 1.1225, 0.8438, 0.9045, 1.0377,\n",
      "        0.9675, 1.2087, 1.0484, 1.0929, 1.1228, 0.9715, 1.1824, 0.8436, 1.0506,\n",
      "        1.0294, 1.1356, 1.0268, 0.9913, 1.0082, 1.0466, 1.0032, 0.9948, 0.9449,\n",
      "        0.8510, 1.0250, 0.9974, 1.1338, 0.9651, 1.0375, 1.1134, 0.9296, 1.0112,\n",
      "        1.0709, 1.0631, 1.1335, 1.0664, 0.7633, 0.9666, 1.1012, 0.8762, 0.9540,\n",
      "        1.0755, 0.9081], device='cuda:0', requires_grad=True))\n",
      "('3.3.bn1.bias', Parameter containing:\n",
      "tensor([ 0.0175, -0.1444, -0.1229, -0.1292, -0.0767, -0.1410, -0.0643, -0.1379,\n",
      "        -0.0673, -0.0809, -0.1732, -0.1567, -0.0581, -0.0060, -0.0653, -0.2210,\n",
      "        -0.0826, -0.0954, -0.0896, -0.0993, -0.1164, -0.1260, -0.1252, -0.1841,\n",
      "        -0.1375, -0.1102, -0.0164, -0.1536, -0.0363, -0.0776, -0.1707, -0.0859,\n",
      "        -0.0027, -0.1096, -0.0669, -0.1503, -0.2101, -0.1088, -0.0638, -0.1546,\n",
      "        -0.1425, -0.1421, -0.1338, -0.0456, -0.1766, -0.1674, -0.0177, -0.0903,\n",
      "        -0.0725, -0.1383, -0.1020, -0.0820, -0.1248, -0.0918, -0.1478, -0.1047,\n",
      "        -0.0660, -0.0966, -0.0464, -0.0332, -0.1216, -0.1548, -0.0787, -0.1475,\n",
      "        -0.0857, -0.0755, -0.1110, -0.1628, -0.0499, -0.0751, -0.1204, -0.2543,\n",
      "        -0.0061, -0.0605, -0.0711, -0.1382, -0.1088, -0.0844, -0.0313, -0.0890,\n",
      "        -0.1990, -0.2406,  0.0109, -0.0831, -0.0252, -0.0622, -0.0875, -0.1741,\n",
      "        -0.1542, -0.2507, -0.0035, -0.0828, -0.1133, -0.0364, -0.0485, -0.0325,\n",
      "        -0.0871, -0.0705, -0.0899, -0.1500, -0.0551, -0.1385, -0.0878, -0.1021,\n",
      "        -0.1466, -0.1145, -0.1484, -0.0973, -0.0767, -0.0005, -0.0158, -0.0784,\n",
      "        -0.2546, -0.0556, -0.2633, -0.0835, -0.1226, -0.2078, -0.2402, -0.1309,\n",
      "        -0.1638, -0.2159, -0.1547, -0.0908, -0.2060, -0.1158, -0.1460, -0.1090],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.3.bn2.weight', Parameter containing:\n",
      "tensor([1.0049, 1.0587, 0.9315, 0.9732, 1.0944, 0.9872, 1.0056, 1.0517, 0.9496,\n",
      "        0.9745, 1.1383, 0.9548, 0.9815, 0.9950, 0.9891, 1.0064, 1.0094, 1.0333,\n",
      "        0.9075, 0.9778, 1.0021, 0.9268, 0.9908, 1.0408, 0.9556, 1.0353, 1.0581,\n",
      "        0.8927, 1.0155, 0.9566, 1.0420, 0.9509, 1.1445, 1.0010, 1.0276, 0.9581,\n",
      "        0.9122, 0.9641, 0.9850, 0.9391, 1.0499, 0.9667, 0.9635, 0.8711, 0.9413,\n",
      "        0.9775, 1.0817, 1.0353, 1.0098, 1.0214, 0.9622, 1.0265, 1.0112, 1.0271,\n",
      "        0.9348, 1.0557, 1.0142, 0.8635, 1.0040, 0.9904, 0.9833, 1.0570, 1.0579,\n",
      "        1.0581, 0.9985, 0.9302, 1.0688, 0.9721, 0.9912, 1.0524, 0.9296, 0.9719,\n",
      "        1.0771, 0.9432, 0.9995, 1.1321, 0.9585, 0.9767, 0.9459, 0.9777, 1.0551,\n",
      "        1.0050, 0.9757, 0.9807, 0.9896, 0.9855, 0.9479, 0.9580, 1.0289, 0.9820,\n",
      "        0.9771, 1.0282, 1.0813, 0.8571, 1.0191, 0.9893, 1.0085, 0.9816, 1.0157,\n",
      "        0.9665, 1.0143, 0.9590, 1.0804, 0.9583, 0.9794, 1.0380, 0.9498, 0.9353,\n",
      "        0.9967, 1.0463, 1.1262, 1.0007, 1.0241, 1.1385, 1.0521, 1.0869, 1.0467,\n",
      "        1.0102, 0.9188, 0.9970, 1.0153, 1.0384, 1.0057, 0.9336, 1.0312, 1.0261,\n",
      "        0.8932, 0.9962], device='cuda:0', requires_grad=True))\n",
      "('3.3.bn2.bias', Parameter containing:\n",
      "tensor([-0.1430, -0.0214, -0.2089, -0.1669, -0.1860, -0.1765, -0.2047, -0.1645,\n",
      "        -0.0813, -0.0690, -0.1761, -0.1663, -0.0914, -0.2760, -0.1070, -0.0785,\n",
      "        -0.1250, -0.0811, -0.1349, -0.1547, -0.1090, -0.1264, -0.1264, -0.2080,\n",
      "        -0.1250, -0.1814, -0.1941, -0.3165, -0.0777, -0.1875, -0.2264, -0.1848,\n",
      "        -0.1363, -0.1481, -0.2435, -0.1407, -0.1838, -0.1090, -0.1757, -0.1010,\n",
      "        -0.1493, -0.0653, -0.1344, -0.2104, -0.1752, -0.0839, -0.1324, -0.2157,\n",
      "        -0.1489, -0.1477, -0.1301, -0.0744, -0.1689, -0.0914, -0.1121, -0.1270,\n",
      "        -0.0844, -0.0991, -0.1473, -0.0555, -0.1773, -0.0852, -0.1089, -0.0556,\n",
      "        -0.1667, -0.0629, -0.0878, -0.1430, -0.1104, -0.0326, -0.1747, -0.1198,\n",
      "        -0.0836, -0.1316, -0.1521, -0.0644, -0.1613, -0.1866, -0.0696, -0.1072,\n",
      "        -0.0707, -0.0699, -0.1025, -0.1547, -0.2704, -0.1221, -0.1038, -0.1624,\n",
      "        -0.1733, -0.2319, -0.2155, -0.1561, -0.1315, -0.1696, -0.1415, -0.1211,\n",
      "        -0.1299, -0.0759, -0.1112, -0.1004, -0.0460, -0.0456, -0.2516, -0.1625,\n",
      "        -0.1769, -0.1792, -0.1266, -0.0976, -0.0856, -0.0586, -0.0059, -0.0478,\n",
      "        -0.0032, -0.1398, -0.1457, -0.1400, -0.0937, -0.1490, -0.1798, -0.1656,\n",
      "        -0.1321, -0.1478, -0.1652, -0.1825, -0.1409, -0.0786, -0.1078, -0.0885],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.3.bn3.weight', Parameter containing:\n",
      "tensor([1.0139, 0.9717, 1.1055, 1.0085, 1.0197, 0.9960, 0.9897, 0.8657, 1.0282,\n",
      "        0.9476, 1.0497, 0.9757, 1.0203, 1.0443, 1.0711, 0.9976, 1.0090, 0.9911,\n",
      "        1.0823, 1.0303, 1.0986, 0.9989, 1.0368, 1.0585, 0.9724, 1.0207, 1.0070,\n",
      "        0.9988, 0.9813, 0.9982, 1.1019, 1.0099, 1.0421, 0.9854, 0.9854, 1.0039,\n",
      "        0.9440, 0.9218, 0.9803, 1.0263, 1.0154, 0.9847, 0.9485, 1.0172, 1.0005,\n",
      "        1.0058, 1.0503, 0.9520, 1.0605, 1.0698, 1.0436, 0.9747, 1.0399, 1.0397,\n",
      "        1.0670, 1.0253, 0.9449, 0.9572, 1.0240, 0.9916, 0.9692, 0.9817, 1.0313,\n",
      "        0.9993, 0.9701, 1.0043, 1.0664, 0.9826, 1.0551, 0.9594, 0.9877, 0.9831,\n",
      "        1.0445, 1.0472, 0.9725, 1.0736, 1.1016, 0.9616, 1.0075, 1.0284, 0.9892,\n",
      "        1.0166, 0.9817, 1.0073, 0.9631, 0.9739, 1.0468, 1.0518, 0.9829, 1.0175,\n",
      "        0.9614, 1.0215, 1.0701, 1.0346, 1.0844, 0.9778, 0.9863, 0.9934, 1.1820,\n",
      "        0.9829, 0.9690, 1.0179, 0.9965, 1.0003, 1.0025, 0.9927, 1.0454, 1.0061,\n",
      "        0.9982, 0.9467, 1.0193, 1.0366, 0.9624, 1.0477, 1.0043, 0.9617, 1.0389,\n",
      "        1.0471, 0.9198, 0.9776, 1.0046, 0.9847, 0.9244, 1.0715, 1.0343, 0.9877,\n",
      "        0.9591, 0.9805, 1.0589, 0.9641, 0.9518, 1.0576, 1.0899, 0.9554, 1.0333,\n",
      "        1.0431, 1.0283, 1.0243, 0.9622, 1.0535, 0.9525, 1.0118, 1.0137, 1.0353,\n",
      "        0.9917, 0.9983, 0.9997, 0.9973, 1.0023, 0.9603, 0.9215, 1.0162, 1.0085,\n",
      "        1.0496, 1.0009, 0.9626, 0.9407, 1.0504, 0.9773, 1.0231, 0.9739, 0.9523,\n",
      "        1.0267, 0.9385, 1.0220, 1.0208, 1.0051, 0.9917, 0.9894, 1.0641, 1.0429,\n",
      "        1.0222, 0.9887, 1.0594, 1.0238, 1.0240, 0.9896, 0.9566, 1.0645, 1.0407,\n",
      "        0.9001, 0.9329, 1.0341, 1.0393, 0.9691, 1.0322, 0.9954, 0.9245, 1.0161,\n",
      "        0.9726, 1.0326, 1.0223, 1.0626, 0.9902, 0.9936, 1.0060, 0.9996, 1.0164,\n",
      "        1.0653, 1.0311, 0.9803, 0.9803, 1.0724, 0.9636, 0.9899, 1.0414, 1.0498,\n",
      "        0.9793, 0.9824, 1.0783, 0.9456, 1.0291, 1.0490, 1.0136, 1.0181, 1.0662,\n",
      "        1.0411, 0.9223, 0.9443, 1.0462, 1.0625, 0.8828, 1.0951, 1.0076, 1.0630,\n",
      "        1.0258, 0.9734, 1.0644, 0.9964, 0.9648, 1.1165, 0.9589, 0.9653, 0.9857,\n",
      "        0.9603, 1.0543, 1.0314, 1.0208, 0.9870, 1.0315, 1.0447, 1.0384, 1.0005,\n",
      "        0.9791, 0.9478, 1.0099, 1.0519, 0.9968, 0.9949, 0.9790, 1.0210, 1.0690,\n",
      "        0.9203, 0.9944, 0.9551, 1.0265, 0.9757, 0.9873, 0.9696, 0.9620, 0.9525,\n",
      "        1.0101, 0.9551, 0.9972, 0.9778, 1.0071, 0.9436, 0.9876, 1.0660, 1.0234,\n",
      "        1.0354, 1.0054, 1.0651, 0.9419, 0.9476, 0.8664, 0.9861, 1.0647, 1.0943,\n",
      "        1.0227, 1.0466, 0.9772, 1.0183, 1.0242, 0.9485, 1.0301, 0.9863, 0.9706,\n",
      "        0.9589, 0.9208, 0.9570, 1.0256, 1.0871, 1.0087, 0.9816, 1.0131, 0.9503,\n",
      "        0.9665, 0.9641, 1.0223, 1.0103, 1.0933, 1.0006, 0.9752, 0.9743, 0.9523,\n",
      "        1.0667, 1.0451, 1.0386, 1.0412, 0.9405, 0.9742, 1.1446, 0.9716, 0.9770,\n",
      "        0.9951, 1.0473, 1.0352, 1.0477, 1.0461, 1.0100, 1.0798, 1.0192, 1.0803,\n",
      "        0.9344, 1.0524, 1.0056, 1.0027, 0.9302, 0.9485, 0.9633, 0.9920, 1.0503,\n",
      "        0.9565, 0.9927, 0.9994, 0.9527, 1.0206, 1.0068, 0.9984, 0.9153, 1.0058,\n",
      "        1.0534, 1.0232, 1.0061, 1.0088, 1.0281, 0.9726, 1.0246, 0.9755, 1.0373,\n",
      "        1.0599, 1.0362, 0.9246, 1.0524, 0.9773, 1.0172, 1.0266, 1.0175, 0.9323,\n",
      "        0.9623, 1.0747, 0.9816, 0.9925, 0.9898, 1.0344, 0.9778, 1.0412, 1.0430,\n",
      "        0.9831, 1.0557, 0.9721, 0.9766, 0.9674, 1.0528, 1.0126, 0.9444, 1.0162,\n",
      "        0.9886, 1.0559, 0.9491, 1.0213, 0.9632, 1.0280, 1.0077, 1.0038, 1.0480,\n",
      "        0.9617, 0.9818, 1.0061, 1.0509, 1.0739, 1.0505, 0.9743, 0.9790, 1.0047,\n",
      "        1.0154, 0.9794, 1.0339, 0.9784, 1.0613, 1.0173, 1.0964, 0.9778, 1.0338,\n",
      "        0.9606, 0.9458, 0.9324, 1.0260, 1.1039, 1.0088, 1.0163, 0.9986, 1.0447,\n",
      "        1.0092, 1.0561, 0.9486, 0.9485, 0.9773, 0.9914, 1.0027, 1.0110, 1.0131,\n",
      "        1.0251, 0.9317, 0.9820, 1.0710, 1.0403, 0.9566, 1.0717, 0.9872, 1.0239,\n",
      "        0.9096, 1.0192, 0.9931, 0.9679, 1.0886, 0.9727, 0.9820, 1.0268, 0.9534,\n",
      "        0.9462, 1.0162, 1.0109, 1.0521, 0.9870, 1.0178, 1.0106, 1.0216, 1.0217,\n",
      "        0.9969, 1.0396, 1.0166, 0.9961, 0.9855, 0.9668, 1.0113, 0.9880, 0.9793,\n",
      "        0.9650, 1.0505, 0.9882, 0.9743, 1.0068, 1.0319, 1.0455, 0.9538, 1.0214,\n",
      "        0.9638, 0.9332, 0.9380, 0.9839, 1.0091, 0.9503, 1.0250, 0.9597, 1.0178,\n",
      "        0.9934, 1.0204, 1.0259, 0.9805, 0.9482, 1.0499, 0.9357, 1.1030, 1.0777,\n",
      "        0.9701, 0.9201, 1.0686, 0.9620, 1.0335, 1.0476, 1.0014, 0.9936, 1.0206,\n",
      "        0.9027, 1.0424, 0.9409, 0.9509, 0.9841, 0.9945, 1.0385, 0.9796, 0.9923,\n",
      "        0.9775, 0.9904, 0.9948, 1.0537, 0.9646, 0.9795, 1.0020, 0.9615],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('3.3.bn3.bias', Parameter containing:\n",
      "tensor([-5.6618e-03,  4.3155e-03, -6.6800e-03, -4.8483e-03, -3.8554e-03,\n",
      "        -8.3052e-05, -1.4664e-02,  3.7015e-03, -7.8744e-03,  1.5913e-03,\n",
      "        -1.9783e-02, -3.2768e-03, -1.9713e-03, -3.6573e-02,  8.2077e-03,\n",
      "         1.4681e-02, -4.8976e-02, -2.0627e-04,  1.4757e-02, -1.2860e-02,\n",
      "         1.3963e-02, -1.3104e-02, -1.6535e-03,  6.1755e-04,  2.4943e-03,\n",
      "        -1.6446e-03,  1.5050e-02, -1.1958e-02,  1.6720e-03, -1.9703e-03,\n",
      "         8.3108e-03, -2.7140e-03, -5.1600e-03, -2.9548e-04,  5.8822e-03,\n",
      "         8.8708e-05,  3.1236e-03,  2.5135e-03, -6.0589e-03,  4.5599e-04,\n",
      "         8.6068e-04,  7.8012e-03,  2.4388e-03, -8.4176e-03,  2.9960e-03,\n",
      "        -8.6728e-03,  1.6732e-03, -8.8944e-03,  9.3463e-03, -2.6340e-03,\n",
      "        -1.6775e-02,  9.2444e-05, -3.8229e-03, -2.2539e-02,  2.9885e-03,\n",
      "        -4.6875e-03, -3.5456e-04, -3.9881e-04, -2.1446e-02,  2.7716e-03,\n",
      "        -7.8067e-04,  1.6715e-03, -4.8197e-03, -2.0013e-02,  2.7455e-04,\n",
      "         1.3300e-04,  3.9606e-03, -2.8271e-02,  2.8015e-03,  6.8916e-03,\n",
      "        -1.1154e-02, -1.5259e-02, -1.5768e-02,  1.5484e-02,  3.3661e-03,\n",
      "         1.3792e-02,  1.9448e-02,  4.1807e-03, -2.0887e-02, -2.8174e-03,\n",
      "        -6.5528e-03,  4.5828e-03,  3.1778e-03, -7.0777e-03,  1.3065e-03,\n",
      "        -6.5834e-03,  2.6356e-03, -1.0039e-02,  6.5205e-04,  1.0313e-02,\n",
      "         1.8392e-03, -1.2651e-02,  1.1812e-02, -1.9195e-02, -3.0083e-02,\n",
      "         4.7555e-04, -4.8829e-04, -5.9608e-03, -2.9649e-02, -1.3864e-03,\n",
      "        -2.9220e-03, -9.3827e-03,  4.9648e-04, -1.3589e-02, -7.6591e-04,\n",
      "         1.0023e-02,  4.8270e-03, -1.5228e-02,  3.3422e-03, -4.5336e-04,\n",
      "         2.5927e-03,  4.5290e-03,  3.7106e-02, -1.1941e-03,  7.0162e-03,\n",
      "        -2.2660e-02,  2.2248e-03,  1.7788e-03, -8.0915e-03,  3.3608e-03,\n",
      "        -1.9761e-02,  1.1267e-02, -3.6688e-03, -9.9428e-03, -3.7582e-03,\n",
      "        -1.6746e-02,  4.5286e-03,  7.1041e-03, -1.5385e-02,  3.2458e-03,\n",
      "         2.1111e-03,  1.2268e-04,  2.2579e-02,  4.9506e-03,  1.4090e-02,\n",
      "        -9.7234e-03, -2.6001e-02,  6.1363e-03,  1.4667e-03, -1.6279e-03,\n",
      "        -4.9827e-03, -7.3885e-03, -2.9727e-02, -6.7587e-03, -2.0118e-03,\n",
      "         4.3499e-03, -1.1566e-02, -1.4761e-02,  2.5203e-03,  2.9842e-03,\n",
      "        -6.9896e-04, -4.7259e-03,  3.4815e-03,  1.5520e-03,  2.1868e-03,\n",
      "        -7.2261e-03, -1.6387e-03, -1.6979e-02,  1.1893e-02,  2.8692e-03,\n",
      "         5.5184e-03,  2.3939e-03,  1.4734e-02, -4.4784e-03, -1.5144e-02,\n",
      "         1.5459e-02,  3.1487e-03, -1.6898e-02, -1.6835e-03, -6.5612e-03,\n",
      "         3.5811e-03, -1.5658e-02, -2.1718e-02,  4.5676e-03, -2.4010e-02,\n",
      "         1.1532e-02,  8.2546e-03,  4.0881e-03, -1.5953e-02, -1.3687e-02,\n",
      "         4.0107e-03, -1.9893e-03,  7.4166e-03, -1.3976e-02, -6.7006e-03,\n",
      "        -2.0641e-02,  1.6520e-03,  4.0765e-03,  1.4214e-02,  8.2479e-04,\n",
      "        -2.2207e-02, -5.8324e-03, -9.6139e-03, -6.5889e-03, -1.0452e-03,\n",
      "         1.4207e-03,  2.3880e-03,  6.1577e-03,  2.0607e-03, -1.6644e-02,\n",
      "         5.4968e-03, -8.2697e-03, -1.0224e-03,  9.3208e-03, -4.8533e-03,\n",
      "         5.2351e-03,  5.8345e-03, -2.0352e-03,  1.0396e-02, -3.2024e-03,\n",
      "         5.6167e-03,  3.1655e-02,  1.5986e-02, -4.7710e-03,  4.1123e-03,\n",
      "        -1.1892e-02, -9.6597e-03, -6.8410e-03, -2.8186e-04, -1.3340e-02,\n",
      "        -3.7619e-02, -4.4257e-03, -2.5178e-02, -2.7531e-02,  2.3257e-02,\n",
      "        -7.3417e-03, -1.3422e-03, -1.6502e-03, -3.2161e-04, -2.6371e-05,\n",
      "        -8.6875e-03, -1.1807e-02, -9.0213e-04, -6.6886e-03, -1.6287e-02,\n",
      "         3.9064e-03,  1.5199e-02, -7.6633e-03, -1.4089e-03,  3.2861e-03,\n",
      "        -1.1579e-03,  6.7278e-03,  6.5686e-03, -1.6604e-03,  2.9503e-03,\n",
      "        -2.3647e-02,  1.5966e-03, -7.4076e-03,  5.6499e-04,  1.4192e-05,\n",
      "         1.0338e-02, -1.1404e-02,  3.5815e-03,  2.5239e-03,  1.0142e-03,\n",
      "         8.4442e-04,  9.6997e-03, -9.9159e-03, -4.7607e-03, -6.2531e-03,\n",
      "        -3.2267e-03, -1.9519e-03,  7.7556e-03, -4.3874e-03,  6.4900e-03,\n",
      "        -2.1634e-03, -5.7015e-03,  1.9927e-02, -5.6519e-03, -3.4295e-02,\n",
      "         9.1580e-03,  1.0238e-02,  9.4682e-04, -1.2811e-03, -1.0893e-03,\n",
      "         3.6434e-03,  6.4253e-03,  6.0085e-04,  2.4510e-04, -2.9950e-03,\n",
      "         1.8378e-02, -1.0014e-02, -8.3095e-03,  1.4667e-02, -5.7360e-03,\n",
      "        -5.0560e-03,  7.1529e-03,  8.8753e-04, -1.0438e-04,  4.6321e-03,\n",
      "        -8.6595e-04, -2.7364e-03, -1.2431e-02, -2.4565e-02,  7.9840e-03,\n",
      "        -7.2309e-03, -1.8218e-03,  1.0927e-02,  5.5254e-03, -2.0339e-02,\n",
      "        -2.1140e-02,  1.1674e-02, -3.1308e-03,  6.0026e-03, -2.8652e-02,\n",
      "         3.3692e-03, -2.7206e-02,  2.2799e-03, -6.5832e-04, -1.8078e-02,\n",
      "        -5.7567e-03, -1.2559e-02,  9.0225e-03,  5.6243e-03,  5.2600e-03,\n",
      "        -3.2359e-03, -1.8048e-02,  1.7780e-02, -1.9761e-02,  2.7445e-03,\n",
      "         5.8167e-03,  9.5299e-03,  8.6806e-03,  3.5657e-03, -1.3188e-03,\n",
      "        -3.1570e-03,  2.4775e-04, -5.7872e-03, -4.0922e-04, -2.2289e-02,\n",
      "        -5.8799e-03,  4.0180e-03,  3.2322e-03, -2.5932e-03,  6.8809e-03,\n",
      "         3.3181e-02, -4.9137e-04,  8.7560e-03,  1.5778e-03, -1.8838e-02,\n",
      "        -2.9931e-03,  3.3840e-03,  2.1593e-02, -5.0156e-03, -7.0703e-03,\n",
      "         1.3554e-02, -5.0128e-03,  5.9885e-03,  1.0042e-03, -5.1323e-04,\n",
      "        -2.3545e-02,  1.0743e-02, -1.5663e-02,  1.6665e-03,  4.0011e-03,\n",
      "        -1.7974e-02, -1.1238e-02,  1.3718e-03, -2.9754e-04,  2.5561e-03,\n",
      "         3.8807e-03, -1.3695e-02,  9.2450e-03,  3.3088e-04, -2.0176e-04,\n",
      "        -3.6298e-03, -3.4683e-03, -1.1725e-02, -2.8260e-02,  1.1146e-04,\n",
      "        -6.8754e-03,  2.0064e-03,  2.1310e-02,  9.8240e-03,  6.7274e-03,\n",
      "         2.4726e-03,  1.7039e-02,  1.2036e-02, -4.2260e-03,  2.7766e-02,\n",
      "        -2.3802e-03, -2.6593e-02, -1.6285e-03,  1.4929e-03, -5.4724e-03,\n",
      "         5.9650e-03, -2.0353e-02, -2.0028e-03,  2.5376e-02, -1.5904e-03,\n",
      "         3.8988e-03, -4.0635e-03, -3.4002e-02,  2.5214e-04, -1.7701e-03,\n",
      "        -1.1458e-02, -6.7374e-03,  3.6805e-03, -8.1124e-03, -8.2638e-03,\n",
      "        -2.1411e-02,  4.7605e-03,  1.7138e-03, -2.7125e-04, -1.7299e-02,\n",
      "        -6.7819e-03,  2.9347e-03, -1.0621e-03,  1.1998e-02, -1.6897e-02,\n",
      "        -4.8903e-03, -2.4869e-03,  5.1610e-03, -8.8319e-03, -1.6276e-03,\n",
      "         3.2610e-03,  4.0940e-02, -6.6856e-04,  1.8147e-03,  7.3605e-04,\n",
      "        -6.4776e-04,  4.4590e-03, -1.7663e-02, -1.4564e-02,  5.2634e-03,\n",
      "         3.6761e-03, -1.1443e-02,  1.1526e-02,  8.5283e-03,  8.4190e-03,\n",
      "        -3.0842e-02,  3.9399e-03,  2.0200e-04,  3.3793e-03, -5.8743e-03,\n",
      "        -1.7901e-03,  5.9497e-04, -5.9383e-04,  3.0989e-03,  1.7223e-02,\n",
      "        -7.3988e-03,  6.3846e-03, -6.2493e-03, -3.5427e-02, -1.1245e-02,\n",
      "         2.8555e-03, -1.2114e-02,  2.5132e-03, -9.6592e-03, -3.0665e-02,\n",
      "         1.2294e-02, -3.0613e-02, -1.0912e-04,  2.1276e-02, -3.2324e-04,\n",
      "        -3.1346e-05,  1.5042e-03, -3.4013e-03,  8.3983e-03,  4.1248e-03,\n",
      "         7.2213e-03, -3.4276e-03,  2.3417e-03,  5.4810e-03,  1.2350e-02,\n",
      "        -3.8163e-03, -3.2381e-03,  2.3575e-03,  6.0453e-03,  2.5452e-03,\n",
      "         4.0265e-03, -1.5036e-03, -2.1993e-02, -2.0635e-02, -1.7600e-03,\n",
      "        -2.2072e-03, -1.0316e-02, -3.7686e-03,  4.4188e-03,  2.5653e-03,\n",
      "        -3.9194e-03, -1.5284e-03,  1.8405e-02,  2.1616e-03, -5.7974e-03,\n",
      "        -1.5854e-02,  7.9621e-03, -6.4991e-03, -1.3397e-04, -1.0252e-02,\n",
      "        -4.5023e-02,  2.2458e-02, -1.7694e-03,  5.7535e-03, -1.2751e-02,\n",
      "         2.2909e-03, -1.6838e-02, -7.3956e-04, -7.8907e-03, -4.3090e-04,\n",
      "         3.5642e-03,  1.5346e-02,  9.3605e-04, -4.0876e-03,  4.3600e-03,\n",
      "         1.3811e-02, -8.6839e-03, -9.4120e-03,  9.3314e-04, -1.8880e-03,\n",
      "        -3.6295e-03, -1.7009e-02], device='cuda:0', requires_grad=True))\n",
      "('5.0.conv1.weight', Parameter containing:\n",
      "tensor([[[-0.0627],\n",
      "         [-0.1252],\n",
      "         [-0.0288],\n",
      "         ...,\n",
      "         [-0.0066],\n",
      "         [-0.0450],\n",
      "         [-0.0350]],\n",
      "\n",
      "        [[ 0.1661],\n",
      "         [ 0.1327],\n",
      "         [ 0.0591],\n",
      "         ...,\n",
      "         [-0.0439],\n",
      "         [-0.0681],\n",
      "         [-0.0898]],\n",
      "\n",
      "        [[ 0.0414],\n",
      "         [ 0.0155],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [ 0.1350],\n",
      "         [-0.0994],\n",
      "         [-0.0141]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0679],\n",
      "         [-0.1004],\n",
      "         [-0.0816],\n",
      "         ...,\n",
      "         [ 0.1803],\n",
      "         [-0.1665],\n",
      "         [-0.0619]],\n",
      "\n",
      "        [[-0.0050],\n",
      "         [-0.1011],\n",
      "         [ 0.0629],\n",
      "         ...,\n",
      "         [-0.0114],\n",
      "         [-0.2493],\n",
      "         [ 0.0758]],\n",
      "\n",
      "        [[ 0.0625],\n",
      "         [ 0.1069],\n",
      "         [-0.0283],\n",
      "         ...,\n",
      "         [-0.0693],\n",
      "         [ 0.2054],\n",
      "         [ 0.2032]]], device='cuda:0', requires_grad=True))\n",
      "('5.0.conv1.bias', Parameter containing:\n",
      "tensor([ 3.9474e-05, -3.9376e-02,  3.6105e-02,  1.0151e-02,  3.0950e-02,\n",
      "        -2.9116e-02,  3.3746e-02, -1.5522e-02,  3.4416e-02, -3.7487e-02,\n",
      "         2.2748e-02, -1.0544e-02, -2.6843e-02,  3.0301e-02,  2.4376e-02,\n",
      "        -3.8818e-02,  3.8813e-02,  4.3984e-02,  1.4737e-02,  2.8818e-02,\n",
      "         3.4046e-02, -4.8106e-03, -5.5291e-03, -4.2167e-02, -2.6884e-02,\n",
      "         5.5555e-03, -3.0209e-02, -3.9254e-02, -2.7286e-02, -2.8774e-02,\n",
      "        -2.8807e-02, -3.6752e-02,  2.1135e-02,  2.8596e-02,  4.1258e-02,\n",
      "         9.6690e-03, -4.1371e-02,  2.5503e-02, -4.3359e-02, -3.0624e-02,\n",
      "         3.7720e-02, -1.5106e-02,  8.6430e-03,  2.8498e-02,  1.0060e-02,\n",
      "         2.5889e-02,  7.3564e-03, -7.2771e-03, -2.1735e-02,  1.5499e-02,\n",
      "         3.5221e-02, -3.9307e-02, -2.4180e-02, -2.7836e-02,  3.2891e-02,\n",
      "        -3.7589e-02,  3.6967e-02,  3.9687e-02,  2.8160e-02,  3.2388e-02,\n",
      "         2.8709e-03, -2.6202e-02, -1.4809e-02,  2.5993e-02,  8.1211e-03,\n",
      "         1.5997e-02, -2.4961e-02, -3.2897e-02, -3.1847e-02,  2.3146e-02,\n",
      "         3.1125e-02, -4.8593e-03, -2.2860e-02,  2.9465e-02,  1.5822e-02,\n",
      "         4.1386e-02,  2.3500e-02,  3.6595e-03,  1.4046e-02, -1.5102e-02,\n",
      "         9.2612e-03, -1.6633e-02,  5.6053e-03,  3.6518e-02,  4.9242e-03,\n",
      "         3.9259e-02, -1.2941e-02, -2.9818e-02,  2.0490e-03, -4.3792e-02,\n",
      "        -1.4875e-02, -4.2778e-02, -2.7480e-02,  2.9300e-02, -3.9200e-02,\n",
      "         2.0984e-02, -3.4092e-02, -9.0256e-03,  1.8129e-02,  8.6113e-03,\n",
      "         1.5981e-02, -3.6258e-02,  2.7002e-02,  4.4175e-03,  2.3193e-02,\n",
      "         3.0202e-04, -3.1768e-02,  1.4095e-03,  1.4394e-02,  1.8032e-02,\n",
      "        -3.6952e-02, -2.1257e-02, -4.1051e-02,  1.0310e-02,  9.5288e-03,\n",
      "        -3.5809e-03, -2.3275e-02, -3.3810e-02, -2.1024e-02, -1.7521e-02,\n",
      "         3.4860e-03,  4.2228e-02, -4.0414e-02, -1.1480e-02, -1.0821e-02,\n",
      "        -9.7738e-03, -2.8412e-02,  2.6712e-02, -3.7227e-02,  4.2355e-02,\n",
      "         1.9790e-02, -4.2516e-02,  3.8971e-02, -1.5928e-02, -1.5148e-02,\n",
      "        -4.5312e-03,  1.5825e-02, -2.6011e-02,  1.0855e-02,  3.8246e-02,\n",
      "        -7.2895e-03, -1.7643e-02,  3.3912e-02,  1.6436e-02, -3.7068e-02,\n",
      "         4.1521e-02,  4.3518e-02,  2.9520e-02, -4.0605e-03,  1.9593e-02,\n",
      "         4.3451e-02, -3.6992e-02,  1.8490e-02,  2.1828e-02,  2.2987e-02,\n",
      "         2.6935e-02,  2.4185e-02,  9.3901e-03,  4.1046e-02, -2.8145e-02,\n",
      "         2.7511e-02, -1.1589e-02,  2.5642e-02, -3.6568e-02, -4.1766e-02,\n",
      "         6.3812e-03,  7.4985e-03, -1.0325e-02,  2.6088e-02,  6.0366e-03,\n",
      "         4.1161e-02, -3.3585e-02, -1.9087e-02, -1.3039e-03, -4.3928e-02,\n",
      "         4.3022e-02, -1.5634e-02, -1.2831e-02,  4.2815e-02, -2.9728e-02,\n",
      "         3.6511e-02, -2.3685e-02, -1.7455e-02, -4.0890e-02, -3.4578e-02,\n",
      "        -3.4634e-02,  1.5748e-02,  8.9011e-03,  2.1098e-03, -3.6793e-02,\n",
      "        -2.5056e-02,  1.7057e-02, -1.3208e-02, -3.7697e-02, -3.0169e-02,\n",
      "         3.1499e-02, -2.0778e-03, -2.9025e-02,  2.8282e-02, -3.4355e-02,\n",
      "         3.7615e-02, -4.2585e-02,  6.5630e-03, -2.0554e-02,  2.5217e-02,\n",
      "         9.1743e-04,  3.5184e-02, -2.1110e-02, -2.6669e-02,  2.5984e-02,\n",
      "         4.1871e-02, -6.8226e-03, -1.7592e-02, -1.2386e-02, -1.5540e-02,\n",
      "        -2.6238e-02,  1.8313e-02,  9.3075e-03,  3.8009e-02,  2.7362e-02,\n",
      "         8.0812e-03,  3.0519e-02,  1.4693e-02, -1.4915e-02,  4.1530e-02,\n",
      "         4.1045e-02, -4.5219e-03,  3.4141e-02, -6.0799e-03,  8.2423e-03,\n",
      "        -2.7472e-02,  3.3337e-02, -1.4731e-02,  2.1503e-02,  2.9009e-02,\n",
      "         1.8207e-02, -6.6997e-03, -6.6844e-03, -3.0717e-02, -2.6608e-02,\n",
      "         3.1751e-02, -5.5918e-03,  4.1023e-02, -3.6167e-02,  4.2967e-02,\n",
      "        -7.5022e-05,  3.8227e-02, -3.0459e-02, -3.5552e-02, -4.4100e-02,\n",
      "        -2.9670e-02,  3.0994e-03, -1.4067e-02,  3.1665e-02,  1.3276e-02,\n",
      "         7.7725e-03], device='cuda:0', requires_grad=True))\n",
      "('5.0.conv2.weight', Parameter containing:\n",
      "tensor([[[ 0.1068, -0.1148,  0.0484],\n",
      "         [ 0.2677, -0.0803, -0.1966],\n",
      "         [-0.0005, -0.0057, -0.0813],\n",
      "         ...,\n",
      "         [-0.2219,  0.0095, -0.0383],\n",
      "         [ 0.1060, -0.1014,  0.1644],\n",
      "         [ 0.1633,  0.0519,  0.0423]],\n",
      "\n",
      "        [[-0.0229,  0.0060, -0.1328],\n",
      "         [ 0.1631,  0.0953,  0.0055],\n",
      "         [-0.0498, -0.0925, -0.0190],\n",
      "         ...,\n",
      "         [-0.0256,  0.0452,  0.0472],\n",
      "         [-0.0919, -0.0985,  0.0537],\n",
      "         [-0.0082, -0.0269, -0.0850]],\n",
      "\n",
      "        [[-0.0524,  0.0851, -0.0520],\n",
      "         [-0.0476, -0.0059, -0.0071],\n",
      "         [-0.0515,  0.0276,  0.0344],\n",
      "         ...,\n",
      "         [-0.0365,  0.0211,  0.1288],\n",
      "         [ 0.0019,  0.0445,  0.0776],\n",
      "         [ 0.0056, -0.0429,  0.0204]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0570,  0.0304, -0.0084],\n",
      "         [-0.0141, -0.0581, -0.0869],\n",
      "         [ 0.0189,  0.0645,  0.1032],\n",
      "         ...,\n",
      "         [-0.0826,  0.0533,  0.0124],\n",
      "         [ 0.0562,  0.0271,  0.0484],\n",
      "         [-0.0701, -0.0708,  0.0036]],\n",
      "\n",
      "        [[-0.0432, -0.0365,  0.0670],\n",
      "         [ 0.0408,  0.0028, -0.0425],\n",
      "         [-0.0046, -0.0160,  0.0400],\n",
      "         ...,\n",
      "         [ 0.0101,  0.0260,  0.0731],\n",
      "         [-0.0052, -0.0304,  0.0465],\n",
      "         [-0.0458, -0.0076, -0.0355]],\n",
      "\n",
      "        [[ 0.0593, -0.0214, -0.0384],\n",
      "         [-0.0080,  0.0664,  0.0560],\n",
      "         [-0.1118, -0.0616,  0.0746],\n",
      "         ...,\n",
      "         [-0.0168,  0.0405,  0.0043],\n",
      "         [-0.0912,  0.0666,  0.0199],\n",
      "         [-0.0565, -0.0248, -0.0190]]], device='cuda:0', requires_grad=True))\n",
      "('5.0.conv2.bias', Parameter containing:\n",
      "tensor([-1.0316e-03,  1.3510e-02, -2.4425e-02, -1.7022e-02, -2.9628e-02,\n",
      "        -2.2671e-02,  2.4271e-02,  2.5010e-02,  1.5495e-03,  3.5898e-02,\n",
      "        -1.8996e-02, -1.8980e-02, -3.3231e-02, -2.5619e-02,  1.7334e-02,\n",
      "         1.1039e-02, -5.8543e-03, -2.6907e-02, -1.8333e-03,  2.6207e-02,\n",
      "         3.1166e-02,  2.3948e-02, -3.4160e-02,  3.4782e-02,  6.3222e-03,\n",
      "        -1.7023e-02,  3.3385e-02, -1.7931e-04,  2.0040e-02,  2.7726e-02,\n",
      "        -3.7824e-03, -1.6817e-02,  2.0359e-02, -9.1123e-03,  2.1151e-02,\n",
      "         6.0937e-04, -8.4577e-03,  1.6150e-02,  1.9612e-02,  2.8758e-02,\n",
      "         1.4087e-02, -1.3369e-02, -4.0511e-03, -9.2775e-03, -1.0517e-02,\n",
      "        -6.1387e-03,  2.9206e-02, -7.9101e-03,  3.8223e-05, -2.7076e-02,\n",
      "         2.0937e-02, -1.8038e-02,  4.4037e-03, -1.3604e-02, -2.8845e-02,\n",
      "        -3.5041e-02, -9.0760e-03,  5.1491e-03, -3.1760e-02, -2.8586e-02,\n",
      "         2.4552e-02,  1.1394e-02, -3.5871e-02, -7.4440e-03, -3.2460e-02,\n",
      "         1.2985e-03,  2.2044e-02,  1.3432e-02,  1.6023e-02,  3.5915e-03,\n",
      "         1.5510e-02,  3.1451e-02,  2.6655e-02,  2.1542e-02, -1.6009e-02,\n",
      "        -2.7188e-02, -2.4548e-02,  3.1716e-02, -2.5296e-02,  6.8621e-04,\n",
      "        -1.6976e-02, -2.9407e-02,  1.1221e-02,  1.2214e-02,  7.6495e-03,\n",
      "        -1.1616e-02,  6.1084e-03,  7.9096e-03, -2.5974e-02,  1.4992e-03,\n",
      "         2.1113e-02, -1.0307e-02,  6.6240e-03, -1.3960e-02,  3.4013e-03,\n",
      "        -2.0566e-02, -2.1061e-02,  1.5637e-02,  1.9062e-02,  1.6254e-02,\n",
      "         1.9925e-02,  2.0150e-02,  2.2035e-02, -3.3391e-02, -2.7930e-02,\n",
      "         2.0369e-02,  2.5365e-02, -3.6059e-02,  1.4401e-02, -1.9331e-02,\n",
      "        -2.3859e-02,  7.3607e-03,  3.9197e-03,  1.4487e-02,  8.5139e-03,\n",
      "         6.1232e-03, -2.7231e-02, -5.7630e-03,  2.7207e-02,  2.0034e-02,\n",
      "         1.4686e-02,  3.4526e-02, -2.4951e-02,  3.3934e-02, -3.8290e-03,\n",
      "        -1.9028e-03,  2.1716e-02, -1.7298e-03, -2.0517e-03, -7.4039e-03,\n",
      "         2.1863e-02, -3.3406e-02,  1.4355e-02,  1.5798e-02, -3.5261e-02,\n",
      "         2.1838e-02,  2.9032e-02,  4.1980e-03, -3.5455e-02,  5.4922e-03,\n",
      "        -2.9729e-02,  3.1622e-03,  1.5924e-02,  2.8897e-02, -3.0806e-02,\n",
      "         2.3529e-02,  1.8996e-02,  1.3379e-02,  2.1782e-02, -3.0927e-02,\n",
      "        -9.7971e-03,  1.7970e-02,  3.2950e-02,  2.3356e-02, -2.0875e-02,\n",
      "        -3.0500e-02,  2.7841e-02,  6.5148e-03,  1.2244e-02, -2.8324e-02,\n",
      "        -1.5157e-02, -1.6124e-02,  2.2344e-02,  1.1986e-02, -2.5753e-02,\n",
      "        -1.7376e-02,  3.2311e-02,  3.1569e-02,  3.2224e-02,  2.6835e-02,\n",
      "         1.8727e-02, -2.1007e-02,  2.7468e-03, -2.7735e-02,  1.5871e-02,\n",
      "        -2.7247e-02,  3.1221e-02,  2.8194e-02, -1.7504e-02, -3.0109e-02,\n",
      "        -3.0841e-02,  7.1316e-03,  1.3426e-02,  3.0672e-02,  1.5436e-02,\n",
      "        -2.0919e-02,  2.7732e-02,  1.6321e-02,  1.0772e-02, -1.4282e-02,\n",
      "         1.5735e-03,  2.5868e-02,  3.0490e-02, -1.8023e-02,  2.7670e-02,\n",
      "        -1.9837e-02,  3.0295e-02,  1.3546e-04,  1.7137e-02,  2.3718e-02,\n",
      "         1.5619e-02, -8.6697e-03,  2.0271e-02,  2.4469e-02,  3.2540e-02,\n",
      "         2.4936e-02, -2.6832e-02, -1.7305e-02, -2.6133e-02,  3.5585e-02,\n",
      "         9.0158e-03, -1.9863e-03,  2.3131e-02, -1.1664e-03, -1.6566e-02,\n",
      "        -3.0222e-02, -2.8490e-02, -8.0989e-03, -3.1464e-02,  2.1044e-02,\n",
      "        -3.5227e-03,  1.3412e-02,  1.9347e-02, -9.7726e-03,  2.3872e-02,\n",
      "         9.3424e-03,  2.1106e-02,  1.2794e-03, -1.3972e-02,  1.8480e-02,\n",
      "        -1.4150e-02, -2.3881e-02,  1.8967e-02, -3.4463e-02,  4.7513e-03,\n",
      "         1.9728e-02,  2.4642e-02, -2.0103e-02,  2.4301e-02, -6.2023e-03,\n",
      "         2.4401e-02,  1.8946e-02,  1.6954e-02, -1.8140e-02,  3.5267e-02,\n",
      "        -1.6966e-02, -4.9130e-03,  2.6951e-02, -9.3128e-03,  1.8005e-02,\n",
      "         6.4331e-03,  1.3237e-02, -2.1676e-02,  9.2354e-03,  4.2579e-03,\n",
      "        -3.2199e-02], device='cuda:0', requires_grad=True))\n",
      "('5.0.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.0740],\n",
      "         [ 0.0244],\n",
      "         [-0.0510],\n",
      "         ...,\n",
      "         [-0.0340],\n",
      "         [ 0.0155],\n",
      "         [ 0.0656]],\n",
      "\n",
      "        [[ 0.0074],\n",
      "         [-0.0536],\n",
      "         [ 0.0407],\n",
      "         ...,\n",
      "         [ 0.0054],\n",
      "         [ 0.0043],\n",
      "         [ 0.0141]],\n",
      "\n",
      "        [[-0.0535],\n",
      "         [-0.0219],\n",
      "         [-0.0494],\n",
      "         ...,\n",
      "         [-0.0374],\n",
      "         [-0.0045],\n",
      "         [ 0.0017]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0184],\n",
      "         [-0.0253],\n",
      "         [ 0.0576],\n",
      "         ...,\n",
      "         [ 0.0209],\n",
      "         [ 0.0604],\n",
      "         [-0.0392]],\n",
      "\n",
      "        [[-0.0476],\n",
      "         [ 0.0595],\n",
      "         [-0.0676],\n",
      "         ...,\n",
      "         [ 0.0073],\n",
      "         [ 0.0193],\n",
      "         [ 0.0028]],\n",
      "\n",
      "        [[-0.0279],\n",
      "         [ 0.0471],\n",
      "         [-0.0356],\n",
      "         ...,\n",
      "         [ 0.0499],\n",
      "         [ 0.0508],\n",
      "         [ 0.0234]]], device='cuda:0', requires_grad=True))\n",
      "('5.0.conv3.bias', Parameter containing:\n",
      "tensor([-0.0129, -0.0165,  0.0260,  ...,  0.0108,  0.0075,  0.0610],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.0.conv4.weight', Parameter containing:\n",
      "tensor([[[-0.0035],\n",
      "         [-0.0046],\n",
      "         [ 0.0231],\n",
      "         ...,\n",
      "         [ 0.0071],\n",
      "         [-0.0027],\n",
      "         [-0.0243]],\n",
      "\n",
      "        [[ 0.0135],\n",
      "         [ 0.0331],\n",
      "         [ 0.0289],\n",
      "         ...,\n",
      "         [-0.0362],\n",
      "         [-0.0716],\n",
      "         [ 0.0430]],\n",
      "\n",
      "        [[-0.0243],\n",
      "         [ 0.0645],\n",
      "         [-0.0056],\n",
      "         ...,\n",
      "         [ 0.0351],\n",
      "         [-0.0141],\n",
      "         [-0.0314]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0339],\n",
      "         [-0.0180],\n",
      "         [-0.0347],\n",
      "         ...,\n",
      "         [-0.0059],\n",
      "         [ 0.0154],\n",
      "         [-0.0451]],\n",
      "\n",
      "        [[ 0.0175],\n",
      "         [ 0.0403],\n",
      "         [-0.0505],\n",
      "         ...,\n",
      "         [ 0.0415],\n",
      "         [-0.0257],\n",
      "         [-0.0408]],\n",
      "\n",
      "        [[-0.0144],\n",
      "         [-0.0418],\n",
      "         [-0.0027],\n",
      "         ...,\n",
      "         [ 0.0710],\n",
      "         [-0.0353],\n",
      "         [ 0.0438]]], device='cuda:0', requires_grad=True))\n",
      "('5.0.conv4.bias', Parameter containing:\n",
      "tensor([-0.0088,  0.0099, -0.0088,  ...,  0.0184, -0.0266, -0.0305],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.0.bn1.weight', Parameter containing:\n",
      "tensor([1.0016, 1.0127, 0.9833, 1.0627, 1.0031, 1.0052, 0.9068, 1.0070, 1.0324,\n",
      "        1.0451, 1.0101, 1.0231, 1.0405, 0.9293, 1.0724, 1.0400, 1.1159, 0.8443,\n",
      "        1.0389, 1.0026, 0.9538, 0.9880, 1.0231, 1.0095, 0.8445, 0.8780, 0.9925,\n",
      "        0.9770, 1.0425, 1.0324, 1.0232, 1.0680, 0.9962, 1.0271, 1.0300, 1.0253,\n",
      "        1.0891, 0.8343, 1.0103, 0.9436, 1.0354, 0.9902, 1.0125, 0.8315, 1.0318,\n",
      "        0.9716, 0.9957, 1.0207, 1.0139, 1.0122, 0.9832, 0.9956, 0.9909, 1.0232,\n",
      "        1.0554, 0.8947, 0.9949, 0.8288, 1.0041, 0.8904, 0.9263, 0.8808, 1.0145,\n",
      "        0.9649, 1.0246, 0.9833, 0.9519, 1.0218, 0.9483, 0.9803, 0.9948, 0.8959,\n",
      "        0.8687, 0.9465, 0.9404, 1.0332, 1.0158, 1.0812, 0.9905, 0.9103, 0.9438,\n",
      "        1.0859, 1.0275, 1.0135, 1.0114, 1.0578, 0.8840, 0.9586, 0.9676, 0.9130,\n",
      "        1.0929, 1.0568, 1.0418, 1.0566, 0.9398, 0.9476, 0.9501, 1.0161, 1.0381,\n",
      "        0.9950, 0.9529, 0.9449, 0.9552, 1.1011, 1.0407, 0.9226, 1.0436, 0.8887,\n",
      "        1.0633, 0.9328, 0.9780, 1.0450, 0.9624, 1.0232, 0.9540, 0.8417, 0.9584,\n",
      "        1.0435, 0.9599, 1.0011, 1.0024, 1.0220, 1.0568, 0.9849, 0.9378, 0.9147,\n",
      "        0.9868, 0.9779, 1.0180, 1.0022, 1.0173, 1.1909, 1.0119, 1.0082, 0.8974,\n",
      "        1.0003, 0.9979, 0.9276, 1.1001, 0.9048, 0.9786, 0.9157, 1.0687, 1.0568,\n",
      "        0.9646, 0.9938, 0.9818, 0.9615, 1.0052, 0.9635, 0.9698, 1.0534, 0.9661,\n",
      "        0.9243, 1.1224, 1.0525, 0.9985, 1.1430, 0.9025, 0.9211, 0.9102, 0.8763,\n",
      "        0.9668, 0.9891, 0.9931, 1.0247, 1.0742, 0.9480, 1.0508, 0.9862, 1.0293,\n",
      "        0.9079, 1.0012, 1.0332, 0.9945, 1.0203, 1.0229, 0.9474, 0.9683, 1.0498,\n",
      "        1.0339, 0.9876, 1.0775, 1.0085, 1.0329, 0.9987, 1.0659, 1.0498, 0.9435,\n",
      "        0.9296, 0.9278, 1.0082, 1.0135, 1.0025, 1.1184, 0.9165, 1.0035, 0.8900,\n",
      "        0.9844, 0.9409, 0.9807, 0.9272, 0.9502, 1.0181, 1.0391, 1.0375, 1.0291,\n",
      "        0.9341, 0.9887, 0.9990, 0.9148, 1.0305, 0.9710, 1.0031, 0.8354, 1.0741,\n",
      "        0.9578, 0.9959, 0.9379, 0.9403, 1.0200, 1.0517, 0.9846, 0.9567, 1.0438,\n",
      "        1.1418, 1.0001, 0.8641, 0.8768, 0.9229, 0.9891, 0.9388, 1.0326, 0.9017,\n",
      "        1.0688, 0.9248, 1.0100, 0.9503, 0.9803, 1.0782, 0.9773, 1.0696, 0.9834,\n",
      "        0.9411, 1.0243, 1.0410, 1.0107, 0.9907, 0.9746, 1.0261, 0.9707, 0.9394,\n",
      "        1.0052, 1.0847, 0.9962, 1.0760], device='cuda:0', requires_grad=True))\n",
      "('5.0.bn1.bias', Parameter containing:\n",
      "tensor([-0.1981, -0.0687, -0.2110, -0.2126, -0.2761, -0.1655, -0.2552, -0.1986,\n",
      "        -0.1687, -0.1669, -0.1087, -0.1629, -0.1726, -0.1151, -0.1710, -0.1480,\n",
      "        -0.1208, -0.1314, -0.0939, -0.1297, -0.1962, -0.2583, -0.1922, -0.1951,\n",
      "        -0.1156, -0.1807, -0.0773, -0.0760, -0.0581, -0.1673, -0.0676, -0.2172,\n",
      "        -0.2373, -0.1252, -0.2003, -0.1810, -0.2294, -0.2231, -0.1018, -0.1617,\n",
      "        -0.2268, -0.1483, -0.0907, -0.0881, -0.2369, -0.1762, -0.1091, -0.1851,\n",
      "        -0.0957, -0.1708, -0.1476, -0.2114, -0.1757, -0.2297, -0.1362, -0.1437,\n",
      "        -0.2129, -0.1423, -0.1565, -0.1447, -0.1695, -0.1932, -0.1537, -0.1432,\n",
      "        -0.0880, -0.1707, -0.1935, -0.1543, -0.2246, -0.1191, -0.1160, -0.1517,\n",
      "        -0.1373, -0.1796, -0.3212, -0.1861, -0.2251, -0.1218, -0.2370, -0.1592,\n",
      "        -0.1855, -0.1885, -0.1032, -0.1406, -0.2317, -0.0061, -0.1749, -0.1051,\n",
      "        -0.1872, -0.1772, -0.2294, -0.1182, -0.0762, -0.1461, -0.2083, -0.1533,\n",
      "         0.0656, -0.3001, -0.0742, -0.1811, -0.1231, -0.2039, -0.2169, -0.1787,\n",
      "        -0.0780, -0.1679, -0.2606, -0.2117, -0.1994, -0.1197, -0.1422, -0.2496,\n",
      "        -0.1704, -0.1190, -0.1168, -0.1253, -0.1371, -0.0933, -0.1473, -0.1498,\n",
      "        -0.1437, -0.0929, -0.0979, -0.0884, -0.1822, -0.1855, -0.2456, -0.1477,\n",
      "        -0.1168, -0.1688, -0.1372, -0.2585, -0.3138, -0.1230, -0.1709, -0.1555,\n",
      "        -0.2307, -0.2057, -0.0554, -0.1310, -0.1612, -0.1581, -0.1747, -0.0872,\n",
      "        -0.2911, -0.1589, -0.1435, -0.1253, -0.1475, -0.1219, -0.1311, -0.1777,\n",
      "        -0.1835, -0.1270, -0.1547, -0.1779, -0.1439, -0.2757, -0.1602, -0.2294,\n",
      "        -0.2250, -0.1435, -0.1339, -0.1499, -0.2223, -0.1406, -0.1729, -0.1266,\n",
      "        -0.1049, -0.1382, -0.1180, -0.1687, -0.1788, -0.1474, -0.2470, -0.1387,\n",
      "        -0.1243, -0.1671, -0.1421, -0.1348, -0.1341, -0.1359, -0.1792, -0.1582,\n",
      "        -0.1701, -0.2107, -0.1416, -0.1747, -0.1882, -0.1851, -0.1345, -0.2420,\n",
      "        -0.1926, -0.1807, -0.2044, -0.1453, -0.1755, -0.2319, -0.2048, -0.0855,\n",
      "        -0.0914, -0.1540, -0.1754, -0.0784, -0.2015, -0.1355, -0.1419, -0.1236,\n",
      "        -0.1632, -0.1796, -0.1639, -0.1598, -0.1535, -0.1958, -0.0636, -0.2217,\n",
      "        -0.1604, -0.1439, -0.1052, -0.1044, -0.1739, -0.2068, -0.2021, -0.0647,\n",
      "        -0.2175, -0.2596, -0.1171, -0.1618, -0.1278, -0.1350, -0.1826, -0.1099,\n",
      "        -0.2100, -0.2036, -0.2113, -0.1416, -0.2398, -0.0953, -0.1523, -0.1099,\n",
      "        -0.1032, -0.2468, -0.0680, -0.2163, -0.1782, -0.1048, -0.1396, -0.2472,\n",
      "        -0.1314, -0.1514, -0.1744, -0.2252, -0.2403, -0.0715, -0.1921, -0.1974],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.0.bn2.weight', Parameter containing:\n",
      "tensor([1.1463, 0.9915, 0.9709, 0.9907, 0.9736, 0.9548, 1.0021, 0.9509, 1.0103,\n",
      "        0.9451, 0.9160, 1.0300, 0.9165, 0.8977, 0.9644, 0.9446, 1.0010, 0.9327,\n",
      "        0.9839, 1.0365, 0.9559, 1.0211, 0.9224, 0.9480, 0.9310, 0.9643, 0.9745,\n",
      "        0.9384, 0.9394, 0.9507, 0.9686, 0.9877, 1.0066, 0.9836, 0.9519, 0.9566,\n",
      "        0.9479, 1.0570, 1.0043, 0.9964, 1.0028, 1.0254, 0.9735, 1.0007, 1.0860,\n",
      "        1.0577, 0.9466, 0.9804, 1.0149, 0.9853, 0.9774, 1.0097, 0.9821, 0.9871,\n",
      "        0.9410, 0.9071, 0.9564, 0.9709, 1.0439, 0.9786, 0.9589, 1.0070, 0.9802,\n",
      "        0.9925, 0.9352, 0.8790, 1.0226, 1.1217, 1.0035, 1.0725, 0.9580, 0.9792,\n",
      "        1.0777, 0.9708, 1.1163, 1.0590, 0.9468, 1.0148, 1.0137, 0.9543, 1.0175,\n",
      "        0.9732, 1.0678, 0.9428, 0.9697, 0.9328, 0.9264, 0.9596, 0.9680, 0.9328,\n",
      "        0.9652, 0.9703, 0.9480, 0.9602, 0.9489, 1.0190, 0.9031, 1.0617, 0.9824,\n",
      "        0.9390, 0.9353, 0.9205, 0.9104, 0.9396, 0.9825, 0.9830, 1.0219, 1.0811,\n",
      "        0.9503, 1.0848, 0.9642, 0.9547, 1.0097, 0.9893, 0.9331, 1.0621, 0.9815,\n",
      "        0.9910, 0.9150, 1.0182, 0.9753, 0.9352, 1.0643, 1.0096, 0.9051, 0.9869,\n",
      "        0.9082, 0.9796, 0.9327, 0.9370, 0.9969, 0.9578, 0.9647, 0.9571, 1.0517,\n",
      "        0.9476, 0.9754, 1.0404, 1.0789, 0.9957, 1.0324, 0.9669, 1.0797, 0.9466,\n",
      "        0.9170, 0.9903, 1.0561, 1.0950, 0.9784, 0.9384, 0.9904, 0.9465, 0.9985,\n",
      "        0.9994, 0.9876, 1.0054, 0.9550, 1.0247, 0.9706, 1.0047, 0.9945, 0.9662,\n",
      "        0.9636, 0.9519, 1.0349, 0.9763, 0.9976, 0.9414, 1.0202, 0.9605, 0.9565,\n",
      "        0.9521, 0.9163, 0.9991, 0.9730, 0.9134, 1.1023, 1.1224, 1.0114, 0.9931,\n",
      "        0.9387, 0.9581, 0.9863, 0.9327, 1.0052, 0.9467, 1.0012, 1.0310, 0.9813,\n",
      "        0.9705, 0.9348, 0.9025, 1.0216, 0.9372, 0.9570, 0.9412, 0.9959, 1.0141,\n",
      "        0.9449, 1.1513, 0.9108, 1.0421, 0.9830, 1.0236, 0.9890, 0.9031, 1.0524,\n",
      "        0.9449, 0.9854, 0.9662, 0.9923, 0.9352, 0.9113, 0.9451, 0.9577, 0.9515,\n",
      "        1.0173, 0.9492, 0.9759, 1.0105, 1.0409, 0.9529, 0.9792, 1.0707, 1.0050,\n",
      "        0.9292, 0.9556, 1.0111, 1.0028, 1.0527, 0.9899, 0.9162, 0.9437, 1.0094,\n",
      "        1.0766, 0.9016, 0.9663, 0.9611, 0.9703, 0.9828, 1.0070, 0.9758, 1.0426,\n",
      "        0.8791, 0.9454, 0.9443, 1.0120, 1.1120, 0.9692, 0.9295, 1.0208, 0.9558,\n",
      "        0.9666, 0.9418, 0.9357, 0.9715], device='cuda:0', requires_grad=True))\n",
      "('5.0.bn2.bias', Parameter containing:\n",
      "tensor([-0.4361, -0.2809, -0.1989, -0.1337, -0.1961, -0.1259, -0.1885, -0.0990,\n",
      "        -0.1381, -0.1506, -0.1811, -0.2366, -0.1705, -0.1092, -0.1825, -0.1310,\n",
      "        -0.1370, -0.1054, -0.2038, -0.2048, -0.1892, -0.2528, -0.1569, -0.1983,\n",
      "        -0.1762, -0.1786, -0.2177, -0.2118, -0.1465, -0.0987, -0.1676, -0.1238,\n",
      "        -0.1676, -0.1746, -0.2476, -0.1949, -0.1980, -0.2920, -0.2193, -0.2190,\n",
      "        -0.2591, -0.2115, -0.1171, -0.2548, -0.3162, -0.2957, -0.1419, -0.2079,\n",
      "        -0.2561, -0.1327, -0.2028, -0.1828, -0.1272, -0.2611, -0.1419, -0.1048,\n",
      "        -0.1938, -0.1051, -0.2477, -0.1320, -0.1451, -0.2854, -0.1456, -0.1813,\n",
      "        -0.2072, -0.1450, -0.0932, -0.3280, -0.1642, -0.2824, -0.2736, -0.1846,\n",
      "        -0.3615, -0.1172, -0.1879, -0.2815, -0.1264, -0.2047, -0.1713, -0.2386,\n",
      "        -0.2775, -0.1917, -0.1452, -0.2251, -0.1028, -0.1479, -0.1596, -0.1257,\n",
      "        -0.1218, -0.1141, -0.1546, -0.1066, -0.1746, -0.1927, -0.2471, -0.1826,\n",
      "        -0.0530, -0.0740, -0.1234, -0.1841, -0.1969, -0.2220, -0.1662, -0.1501,\n",
      "        -0.2585, -0.2140, -0.4229, -0.2458, -0.1906, -0.2883, -0.2445, -0.2827,\n",
      "        -0.2020, -0.1683, -0.1417, -0.3485, -0.1937, -0.1530, -0.2233, -0.3189,\n",
      "        -0.2238, -0.1997, -0.3255, -0.2172, -0.1607, -0.3140, -0.1938, -0.1257,\n",
      "        -0.1941, -0.2029, -0.2240, -0.1748, -0.1250, -0.1952, -0.1615, -0.1508,\n",
      "        -0.1484, -0.2134, -0.2639, -0.1577, -0.2849, -0.1153, -0.2517, -0.1640,\n",
      "        -0.1674, -0.2099, -0.2730, -0.1522, -0.1423, -0.1319, -0.2065, -0.1241,\n",
      "        -0.2079, -0.3255, -0.2061, -0.2050, -0.1346, -0.1628, -0.2020, -0.1976,\n",
      "        -0.1497, -0.1150, -0.2596, -0.2270, -0.2002, -0.1820, -0.1641, -0.1940,\n",
      "        -0.3190, -0.2686, -0.2664, -0.1641, -0.1229, -0.1239, -0.0891, -0.1882,\n",
      "        -0.2651, -0.1475, -0.2908, -0.2518, -0.1050, -0.1056, -0.2071, -0.1618,\n",
      "        -0.1851, -0.1842, -0.1184, -0.2261, -0.2703, -0.2811, -0.1710, -0.1474,\n",
      "        -0.2148, -0.1305, -0.1885, -0.1178, -0.1551, -0.1084, -0.1172, -0.1225,\n",
      "        -0.1581, -0.2268, -0.2605, -0.2037, -0.1914, -0.1866, -0.3307, -0.1932,\n",
      "        -0.1225, -0.1792, -0.1095, -0.1794, -0.1363, -0.2212, -0.1851, -0.1028,\n",
      "        -0.2274, -0.2410, -0.1899, -0.2574, -0.2217, -0.1165, -0.2549, -0.2837,\n",
      "        -0.2830, -0.1334, -0.2043, -0.2670, -0.2182, -0.2878, -0.2013, -0.0961,\n",
      "        -0.1819, -0.2341, -0.2780, -0.1467, -0.2063, -0.1413, -0.1609, -0.2207,\n",
      "        -0.1646, -0.1929, -0.2839, -0.1018, -0.1670, -0.1502, -0.2767, -0.2106,\n",
      "        -0.1991, -0.1463, -0.1220, -0.2519, -0.1661, -0.1171, -0.0941, -0.2436],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.0.bn3.weight', Parameter containing:\n",
      "tensor([1.0018, 1.0003, 1.0062,  ..., 0.9992, 1.0076, 1.0470], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('5.0.bn3.bias', Parameter containing:\n",
      "tensor([-0.0081,  0.0062,  0.0061,  ..., -0.0007, -0.0038,  0.0093],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.1.conv1.weight', Parameter containing:\n",
      "tensor([[[ 0.0381],\n",
      "         [ 0.0324],\n",
      "         [ 0.0391],\n",
      "         ...,\n",
      "         [ 0.0090],\n",
      "         [-0.0328],\n",
      "         [ 0.1018]],\n",
      "\n",
      "        [[ 0.0306],\n",
      "         [-0.0480],\n",
      "         [-0.0405],\n",
      "         ...,\n",
      "         [-0.0195],\n",
      "         [-0.0038],\n",
      "         [ 0.0897]],\n",
      "\n",
      "        [[-0.0210],\n",
      "         [-0.0108],\n",
      "         [-0.0594],\n",
      "         ...,\n",
      "         [ 0.0253],\n",
      "         [ 0.0736],\n",
      "         [ 0.0366]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0142],\n",
      "         [-0.0075],\n",
      "         [-0.0323],\n",
      "         ...,\n",
      "         [ 0.0107],\n",
      "         [ 0.0071],\n",
      "         [-0.0271]],\n",
      "\n",
      "        [[-0.0407],\n",
      "         [-0.0210],\n",
      "         [-0.0200],\n",
      "         ...,\n",
      "         [ 0.0309],\n",
      "         [ 0.0289],\n",
      "         [ 0.0039]],\n",
      "\n",
      "        [[-0.0135],\n",
      "         [-0.0549],\n",
      "         [ 0.0048],\n",
      "         ...,\n",
      "         [ 0.0248],\n",
      "         [-0.0551],\n",
      "         [ 0.0646]]], device='cuda:0', requires_grad=True))\n",
      "('5.1.conv1.bias', Parameter containing:\n",
      "tensor([ 0.0017, -0.0260,  0.0130, -0.0244,  0.0177, -0.0019,  0.0271, -0.0034,\n",
      "         0.0228,  0.0268, -0.0129, -0.0042, -0.0094, -0.0293,  0.0144, -0.0075,\n",
      "        -0.0124,  0.0026, -0.0214,  0.0106,  0.0134,  0.0176,  0.0308, -0.0090,\n",
      "        -0.0253, -0.0033, -0.0187, -0.0243, -0.0117,  0.0099, -0.0160,  0.0283,\n",
      "         0.0133, -0.0155,  0.0250,  0.0268,  0.0304,  0.0075,  0.0133,  0.0253,\n",
      "        -0.0017,  0.0196, -0.0192,  0.0189, -0.0175, -0.0261, -0.0216,  0.0018,\n",
      "         0.0244,  0.0263,  0.0085, -0.0234, -0.0193,  0.0247,  0.0285, -0.0251,\n",
      "         0.0198, -0.0252, -0.0194, -0.0193, -0.0222, -0.0035,  0.0165, -0.0139,\n",
      "         0.0161,  0.0048, -0.0059, -0.0279,  0.0181, -0.0173,  0.0291, -0.0145,\n",
      "        -0.0044, -0.0105, -0.0260, -0.0100, -0.0079, -0.0291, -0.0154,  0.0296,\n",
      "        -0.0135,  0.0163,  0.0234, -0.0131,  0.0307, -0.0281, -0.0209, -0.0241,\n",
      "        -0.0142, -0.0123, -0.0076, -0.0269, -0.0113,  0.0297,  0.0104,  0.0036,\n",
      "        -0.0172,  0.0253,  0.0063,  0.0035, -0.0285,  0.0004, -0.0294,  0.0122,\n",
      "         0.0243, -0.0194, -0.0230,  0.0287, -0.0160,  0.0192, -0.0017,  0.0182,\n",
      "        -0.0052,  0.0057, -0.0226,  0.0230, -0.0310, -0.0163,  0.0147,  0.0098,\n",
      "        -0.0310, -0.0131, -0.0075, -0.0075, -0.0105, -0.0268,  0.0283,  0.0254,\n",
      "        -0.0030, -0.0160, -0.0160,  0.0306, -0.0302,  0.0207,  0.0311,  0.0217,\n",
      "        -0.0302, -0.0180, -0.0147,  0.0006, -0.0044,  0.0247,  0.0172, -0.0071,\n",
      "        -0.0099,  0.0237,  0.0038, -0.0087,  0.0071,  0.0279,  0.0154, -0.0095,\n",
      "        -0.0282, -0.0092,  0.0070, -0.0119, -0.0136, -0.0068, -0.0104, -0.0028,\n",
      "        -0.0208, -0.0006, -0.0179, -0.0029,  0.0072,  0.0279, -0.0009, -0.0065,\n",
      "        -0.0245,  0.0111,  0.0184, -0.0010,  0.0268,  0.0108,  0.0186, -0.0063,\n",
      "         0.0276, -0.0076, -0.0006, -0.0267,  0.0209,  0.0188,  0.0040, -0.0159,\n",
      "         0.0250,  0.0234, -0.0290,  0.0117,  0.0093,  0.0241,  0.0290,  0.0010,\n",
      "         0.0223,  0.0301, -0.0012,  0.0257,  0.0240,  0.0140, -0.0126, -0.0211,\n",
      "        -0.0004, -0.0274,  0.0136, -0.0233,  0.0277,  0.0302,  0.0138,  0.0188,\n",
      "        -0.0121,  0.0270, -0.0256,  0.0110,  0.0222,  0.0284,  0.0196,  0.0103,\n",
      "         0.0165,  0.0199, -0.0141, -0.0258, -0.0058, -0.0189, -0.0036,  0.0094,\n",
      "        -0.0270,  0.0312,  0.0054,  0.0120, -0.0077,  0.0172, -0.0287,  0.0101,\n",
      "         0.0125, -0.0206,  0.0071, -0.0174, -0.0019, -0.0052,  0.0182, -0.0014,\n",
      "         0.0151, -0.0157,  0.0190,  0.0054,  0.0188, -0.0157, -0.0185, -0.0103,\n",
      "        -0.0209,  0.0217,  0.0308, -0.0251, -0.0186,  0.0152,  0.0167, -0.0240],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.1.conv2.weight', Parameter containing:\n",
      "tensor([[[-6.4286e-02, -9.7324e-02,  9.0938e-02],\n",
      "         [-4.5002e-02, -5.8515e-02, -4.6451e-02],\n",
      "         [-4.4914e-02,  7.5505e-03, -4.1337e-02],\n",
      "         ...,\n",
      "         [ 1.1342e-02, -4.0941e-02, -8.0996e-02],\n",
      "         [-1.5144e-02,  4.6812e-02, -9.2874e-02],\n",
      "         [ 6.7155e-02, -1.8503e-02,  3.8663e-02]],\n",
      "\n",
      "        [[-2.4295e-02,  2.5114e-02,  3.2808e-02],\n",
      "         [ 3.4236e-02,  2.5186e-02,  3.6986e-02],\n",
      "         [-2.7622e-02,  1.5272e-02, -5.5051e-02],\n",
      "         ...,\n",
      "         [ 6.7510e-03,  1.5140e-02,  7.0279e-02],\n",
      "         [-1.7860e-03, -1.4123e-03, -4.6471e-02],\n",
      "         [-3.1608e-02, -9.0959e-02, -2.8080e-02]],\n",
      "\n",
      "        [[-3.0731e-02,  1.8608e-02,  9.2096e-03],\n",
      "         [-3.1009e-03,  8.4530e-03, -4.0898e-02],\n",
      "         [-1.5427e-02,  2.7850e-02,  4.7335e-02],\n",
      "         ...,\n",
      "         [-6.2418e-02,  1.4533e-02, -3.8425e-02],\n",
      "         [ 1.7812e-02, -4.5296e-02,  1.9393e-05],\n",
      "         [ 3.6528e-03, -3.3908e-02,  2.7470e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.2107e-02, -5.7924e-02,  2.4205e-02],\n",
      "         [-2.2318e-02,  1.3015e-02, -9.0355e-02],\n",
      "         [ 2.0859e-02, -9.3190e-03, -9.8172e-04],\n",
      "         ...,\n",
      "         [-4.2280e-02,  3.4726e-02, -1.5149e-02],\n",
      "         [ 7.7943e-03,  7.2792e-02,  2.0078e-02],\n",
      "         [-2.1289e-02,  5.4672e-02, -1.2929e-02]],\n",
      "\n",
      "        [[-4.2588e-03,  8.6004e-03, -3.7468e-02],\n",
      "         [ 3.3886e-02, -2.2092e-02,  2.5427e-02],\n",
      "         [-2.0057e-02,  8.9397e-03,  3.6014e-02],\n",
      "         ...,\n",
      "         [-5.1872e-03,  8.1893e-03,  5.4190e-02],\n",
      "         [ 4.0610e-02,  7.3452e-04,  3.1396e-02],\n",
      "         [-8.2378e-03,  5.5424e-02, -4.1940e-02]],\n",
      "\n",
      "        [[ 8.7650e-02, -3.6644e-02, -3.4594e-02],\n",
      "         [-2.1880e-02,  3.2055e-02,  2.1318e-02],\n",
      "         [ 5.7359e-02,  7.1443e-03,  1.6197e-02],\n",
      "         ...,\n",
      "         [-3.0956e-02, -8.5720e-03,  1.6870e-02],\n",
      "         [-7.2354e-02, -2.7094e-02, -5.6063e-02],\n",
      "         [ 5.4750e-02, -2.2972e-03,  2.1280e-02]]], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('5.1.conv2.bias', Parameter containing:\n",
      "tensor([-2.3696e-02,  1.9929e-02, -1.8680e-02, -3.4239e-02, -1.5059e-02,\n",
      "        -4.6788e-03, -1.1399e-02,  2.6334e-02,  1.2761e-02, -7.8539e-04,\n",
      "        -1.9730e-02, -6.5172e-03,  2.9259e-02,  2.2479e-02, -2.8513e-02,\n",
      "        -2.8996e-03,  2.8955e-02, -1.0516e-02,  1.8550e-02,  2.3228e-02,\n",
      "         3.3987e-03,  1.0565e-02,  2.0985e-02,  2.0048e-02,  1.7108e-02,\n",
      "         1.0974e-02, -1.9802e-02, -3.4367e-02,  2.5774e-02, -2.6974e-02,\n",
      "         1.5866e-02,  2.4272e-02,  8.6704e-03,  3.8921e-03,  6.9658e-03,\n",
      "        -2.2364e-02,  2.9471e-02, -2.5716e-02,  1.3849e-02,  3.4596e-02,\n",
      "        -9.4963e-03,  1.9075e-02, -1.9674e-02,  1.6373e-02, -3.5966e-02,\n",
      "         6.4760e-03,  5.8915e-03,  3.5167e-02,  2.8888e-02,  1.4999e-05,\n",
      "         7.1418e-03,  3.3615e-02,  3.4504e-04, -1.4701e-02,  3.4763e-02,\n",
      "        -2.4427e-02,  2.6122e-02,  3.5945e-02,  3.3594e-02, -2.0867e-02,\n",
      "        -6.1227e-03,  1.6526e-02, -1.1895e-02,  3.5880e-02,  2.2944e-02,\n",
      "         2.5621e-02, -2.2969e-02,  2.4169e-02,  3.3505e-02,  2.2608e-03,\n",
      "        -1.9332e-02,  2.4966e-02,  1.8891e-03, -3.0792e-02,  3.4773e-02,\n",
      "        -1.6353e-03,  1.8235e-02, -2.2435e-02,  2.7628e-02,  2.4130e-02,\n",
      "         1.0311e-03, -1.3350e-02,  1.6604e-02,  3.2719e-02,  6.0422e-03,\n",
      "         9.1159e-03, -3.5402e-02,  3.4946e-02, -1.3564e-02,  9.8608e-04,\n",
      "        -8.5274e-03,  8.6370e-03, -1.2916e-02, -2.4172e-02, -2.4425e-03,\n",
      "        -3.2868e-02, -3.3651e-02,  1.3197e-02, -1.8920e-02, -1.3052e-02,\n",
      "         1.0704e-02, -3.3156e-03,  5.2886e-03, -1.7014e-02,  2.8080e-02,\n",
      "        -8.0516e-03,  3.9656e-03, -1.3489e-02, -3.6153e-04, -1.5995e-02,\n",
      "         1.3744e-02, -1.7882e-02, -1.3887e-02, -1.5396e-02,  7.0092e-03,\n",
      "        -1.3832e-02, -2.7275e-02, -2.9975e-02,  1.5084e-02, -5.2957e-03,\n",
      "         4.8936e-03,  2.5511e-02, -8.7995e-03,  1.9815e-02, -6.7228e-03,\n",
      "        -3.1345e-02,  1.0810e-02, -3.2586e-03,  1.8736e-02, -2.3777e-02,\n",
      "        -1.4699e-02,  2.4681e-02, -3.1725e-02, -2.7295e-02,  3.0030e-02,\n",
      "         2.8009e-03, -3.1066e-02, -2.4239e-02,  3.5027e-02, -2.0482e-02,\n",
      "         1.1111e-02,  2.7416e-02, -1.5232e-02, -4.8054e-03,  4.7155e-03,\n",
      "         2.0034e-02, -2.5474e-02,  1.3442e-02,  1.2883e-02,  7.4133e-03,\n",
      "         2.2298e-02, -2.1632e-02, -3.4888e-02, -3.4879e-03, -9.6634e-03,\n",
      "         1.4693e-04,  2.8961e-02, -8.3766e-03,  3.2248e-02,  3.4163e-02,\n",
      "        -1.1022e-02, -1.3700e-03, -9.3942e-03, -6.1299e-03,  1.1057e-02,\n",
      "        -7.3920e-03,  5.0370e-04,  2.2845e-02, -1.7962e-02,  6.7628e-03,\n",
      "        -8.9482e-03,  2.4075e-02,  1.1932e-02, -2.8280e-02,  2.2282e-03,\n",
      "        -3.4689e-02,  2.0689e-02, -3.5158e-02,  6.1620e-03,  2.8337e-02,\n",
      "         3.3558e-02,  1.1100e-02,  4.1466e-03,  2.0940e-02,  1.5383e-02,\n",
      "        -5.8270e-03, -1.9993e-02, -2.2816e-03,  1.9684e-02, -3.3738e-02,\n",
      "        -2.7843e-02,  1.9610e-02,  5.7793e-03,  2.7642e-02,  3.2011e-02,\n",
      "        -1.4763e-02, -5.6602e-03,  2.7111e-02,  1.2263e-02, -2.9884e-02,\n",
      "        -3.4805e-04,  3.1015e-02, -1.8880e-02,  1.7997e-02, -3.0147e-02,\n",
      "         1.2582e-02,  3.0160e-02,  1.3839e-02,  4.2398e-03,  1.3904e-02,\n",
      "        -3.0103e-02,  2.7761e-02, -3.3697e-02,  2.3643e-02, -2.4401e-02,\n",
      "         6.2901e-03,  3.3908e-03,  1.2832e-02, -2.0249e-02,  3.1094e-02,\n",
      "         1.6949e-02,  5.9640e-05, -2.2341e-02,  5.8481e-03, -8.0235e-03,\n",
      "        -2.5277e-02, -2.8415e-02, -1.6692e-02, -1.4373e-02,  1.5692e-02,\n",
      "         1.0961e-02, -3.4929e-02,  2.8485e-02,  5.8471e-03,  5.5618e-03,\n",
      "        -8.3076e-03, -1.7737e-02, -2.1192e-02, -1.9900e-02, -2.2581e-02,\n",
      "        -1.2650e-02, -2.5334e-02, -5.5766e-03,  9.0347e-03,  2.9952e-02,\n",
      "         3.5313e-02, -4.7097e-03,  3.3481e-02,  1.0793e-02, -1.0438e-03,\n",
      "         5.6467e-03,  1.6517e-02,  2.6335e-02, -2.6243e-02,  2.1424e-02,\n",
      "         8.8916e-03], device='cuda:0', requires_grad=True))\n",
      "('5.1.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.0778],\n",
      "         [ 0.0164],\n",
      "         [ 0.0013],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [ 0.0493],\n",
      "         [ 0.0339]],\n",
      "\n",
      "        [[-0.0168],\n",
      "         [ 0.0226],\n",
      "         [-0.0146],\n",
      "         ...,\n",
      "         [-0.0551],\n",
      "         [-0.0112],\n",
      "         [ 0.0080]],\n",
      "\n",
      "        [[-0.0491],\n",
      "         [-0.0222],\n",
      "         [-0.0365],\n",
      "         ...,\n",
      "         [ 0.0023],\n",
      "         [-0.0271],\n",
      "         [-0.0070]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0648],\n",
      "         [ 0.0631],\n",
      "         [ 0.0246],\n",
      "         ...,\n",
      "         [-0.0503],\n",
      "         [ 0.0148],\n",
      "         [ 0.0024]],\n",
      "\n",
      "        [[-0.0136],\n",
      "         [-0.0693],\n",
      "         [-0.0282],\n",
      "         ...,\n",
      "         [-0.0600],\n",
      "         [-0.0152],\n",
      "         [ 0.0551]],\n",
      "\n",
      "        [[ 0.0383],\n",
      "         [-0.0137],\n",
      "         [-0.0538],\n",
      "         ...,\n",
      "         [ 0.0170],\n",
      "         [-0.0843],\n",
      "         [ 0.0087]]], device='cuda:0', requires_grad=True))\n",
      "('5.1.conv3.bias', Parameter containing:\n",
      "tensor([ 0.0240,  0.0594, -0.0623,  ...,  0.0067,  0.0349,  0.0494],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.1.bn1.weight', Parameter containing:\n",
      "tensor([1.0538, 1.0089, 0.9800, 0.9714, 1.0379, 1.0176, 1.0372, 1.0167, 1.0535,\n",
      "        0.9727, 1.0334, 1.0723, 1.0358, 0.9648, 0.9658, 1.0463, 1.0114, 0.9991,\n",
      "        0.9941, 1.0045, 1.0018, 1.0412, 0.9837, 0.9997, 0.9533, 0.9659, 0.9361,\n",
      "        0.9375, 0.9739, 0.9557, 0.9892, 0.9732, 0.9831, 0.9912, 1.0107, 1.0440,\n",
      "        0.9542, 1.0553, 1.0413, 1.0573, 0.9852, 1.0124, 1.0086, 0.9883, 1.0307,\n",
      "        0.9579, 1.0258, 0.9954, 1.0028, 0.9334, 0.9551, 1.0106, 1.0102, 0.9729,\n",
      "        1.0018, 0.9794, 0.9721, 0.9839, 1.0902, 1.0027, 1.0170, 1.0887, 0.9987,\n",
      "        0.9862, 1.0264, 1.0334, 0.9407, 0.9839, 0.9623, 0.9653, 1.0657, 1.0934,\n",
      "        1.0151, 0.9177, 0.9539, 1.0587, 1.0413, 1.0281, 1.0242, 0.9385, 0.9934,\n",
      "        0.9683, 1.0219, 1.0290, 1.0379, 1.0079, 0.9585, 0.9921, 1.0059, 0.9555,\n",
      "        1.0219, 0.9220, 0.9564, 0.9683, 1.0033, 0.9592, 1.1132, 1.0050, 0.9563,\n",
      "        1.0463, 1.0719, 0.9425, 1.0020, 1.0486, 1.0348, 1.0003, 1.0157, 1.0420,\n",
      "        0.9843, 0.9647, 1.0219, 1.0074, 0.9598, 1.0582, 0.9623, 0.9803, 0.9785,\n",
      "        0.9985, 0.9353, 1.0731, 0.9809, 0.9678, 1.0422, 0.9526, 1.0662, 0.9968,\n",
      "        0.9428, 0.9689, 1.0187, 0.9604, 0.9559, 0.9875, 0.9665, 0.9606, 0.9779,\n",
      "        1.0205, 1.0438, 0.9622, 1.0220, 0.9685, 1.0170, 1.0049, 0.9739, 0.9770,\n",
      "        0.9799, 0.9681, 0.9850, 1.0110, 1.0011, 0.9696, 0.9385, 1.0302, 0.9827,\n",
      "        0.9754, 0.9555, 1.0595, 0.9546, 1.0323, 0.9551, 0.9983, 1.0367, 1.0210,\n",
      "        0.9665, 1.0602, 0.9983, 0.9806, 1.0312, 0.9584, 0.9572, 0.9888, 1.0599,\n",
      "        0.9831, 1.0052, 0.9687, 1.0423, 1.0173, 1.0617, 0.9643, 0.9966, 0.9682,\n",
      "        0.9879, 0.9826, 1.0347, 1.0065, 1.0035, 0.9776, 0.9800, 0.9947, 1.0390,\n",
      "        0.9883, 0.9750, 1.0650, 1.0634, 1.0773, 0.9429, 0.9279, 0.9648, 1.0018,\n",
      "        1.0249, 1.0287, 1.0450, 0.9756, 0.9381, 0.9688, 0.9823, 0.9730, 0.9936,\n",
      "        1.0203, 0.9904, 0.9692, 0.9740, 0.9914, 1.0544, 1.0089, 0.9862, 1.0343,\n",
      "        1.0218, 1.0675, 0.9740, 1.0552, 1.0163, 0.9659, 0.9715, 0.9828, 0.9474,\n",
      "        0.9996, 0.9840, 1.0205, 0.9518, 0.9233, 0.9738, 1.0643, 1.0282, 1.0132,\n",
      "        0.9951, 1.0357, 1.0282, 1.0283, 0.9667, 1.0147, 1.0062, 0.9520, 0.9600,\n",
      "        0.9957, 1.0425, 1.0384, 0.9158, 1.0069, 0.9778, 1.0665, 0.9573, 0.9647,\n",
      "        0.9494, 0.9970, 0.9844, 0.9543], device='cuda:0', requires_grad=True))\n",
      "('5.1.bn1.bias', Parameter containing:\n",
      "tensor([-0.0462, -0.0172, -0.0528, -0.0675, -0.0508,  0.0204, -0.0508, -0.0279,\n",
      "        -0.0157, -0.0930, -0.0531,  0.0094, -0.0012, -0.1350, -0.0673,  0.0189,\n",
      "         0.0128, -0.0680, -0.1121,  0.0030, -0.0929, -0.0220, -0.0482, -0.0840,\n",
      "        -0.1257,  0.0011, -0.0636, -0.1087, -0.0399, -0.0898, -0.0089, -0.0876,\n",
      "        -0.0956, -0.0198, -0.0777, -0.0317, -0.0402,  0.0084, -0.0563, -0.0630,\n",
      "        -0.0684, -0.0257, -0.0401, -0.0255, -0.0459, -0.0666, -0.0293, -0.0745,\n",
      "        -0.0496, -0.0632, -0.0417, -0.0124, -0.0392, -0.0960, -0.0684, -0.0741,\n",
      "        -0.0622, -0.0374, -0.1052, -0.0711, -0.0775, -0.0540, -0.1132, -0.0751,\n",
      "         0.0032, -0.0951, -0.0576, -0.0892, -0.0433, -0.0895, -0.0437, -0.0957,\n",
      "         0.0028, -0.0670, -0.0924, -0.0369, -0.0381, -0.0725, -0.0150, -0.0835,\n",
      "        -0.0374, -0.0373, -0.0235, -0.0573, -0.0792, -0.0906, -0.0811, -0.0212,\n",
      "        -0.0932, -0.0572, -0.0699, -0.1309, -0.0618, -0.0891, -0.0464, -0.0232,\n",
      "        -0.0020, -0.0668, -0.0463,  0.0034, -0.0140, -0.0455, -0.0272, -0.0456,\n",
      "        -0.0708, -0.0423, -0.0508, -0.0711, -0.0775, -0.1085, -0.0540, -0.0467,\n",
      "        -0.0830, -0.0306, -0.0953, -0.0998, -0.0998, -0.0231, -0.0928, -0.0036,\n",
      "        -0.1096, -0.0604, -0.0540, -0.0743, -0.0905, -0.0775, -0.0597, -0.0498,\n",
      "        -0.0126, -0.0126, -0.0954, -0.0808, -0.1060, -0.0756, -0.0775, -0.0540,\n",
      "        -0.1038, -0.1350, -0.0595, -0.1097, -0.0299, -0.0159, -0.0770, -0.0030,\n",
      "        -0.0861, -0.0886, -0.1073, -0.0398, -0.0951, -0.0823, -0.0703, -0.1068,\n",
      "        -0.0543, -0.0719, -0.0448, -0.0386, -0.0600, -0.0428, -0.0711, -0.0601,\n",
      "        -0.0449, -0.0517, -0.0723, -0.0591, -0.1178, -0.1110, -0.0311, -0.1166,\n",
      "        -0.0886, -0.1171, -0.0823, -0.0155, -0.0874, -0.0750, -0.0892, -0.0256,\n",
      "        -0.1202, -0.0525, -0.0656, -0.1063, -0.0365, -0.0849, -0.0104, -0.0756,\n",
      "        -0.0667, -0.0487, -0.1225, -0.0435,  0.0099, -0.0554, -0.0426, -0.0912,\n",
      "        -0.0449, -0.0979, -0.0932, -0.0664, -0.0870, -0.0544, -0.0718, -0.0193,\n",
      "        -0.0446, -0.1135, -0.0797, -0.0977, -0.0487, -0.0362, -0.0553, -0.0388,\n",
      "        -0.0552, -0.0924, -0.0229, -0.1065, -0.1127, -0.0311, -0.1248, -0.0559,\n",
      "        -0.0744, -0.0529, -0.0466, -0.0086, -0.0510, -0.0442, -0.0587, -0.0696,\n",
      "        -0.0277, -0.0382, -0.0321, -0.0207, -0.0565, -0.1326, -0.0988, -0.0591,\n",
      "        -0.0904, -0.0172, -0.0453, -0.1079, -0.0384, -0.1096, -0.0851, -0.0857,\n",
      "        -0.0060, -0.0863, -0.0932, -0.0793, -0.0078, -0.0764, -0.0960, -0.0317,\n",
      "        -0.0763, -0.0769, -0.0635, -0.0793, -0.0441, -0.1224, -0.0380, -0.1111],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.1.bn2.weight', Parameter containing:\n",
      "tensor([0.9889, 0.9788, 0.9647, 0.9843, 0.9946, 1.0375, 1.0302, 0.9664, 0.9992,\n",
      "        0.9596, 0.9988, 0.9719, 1.0111, 1.0089, 1.0203, 0.9912, 1.0063, 0.9716,\n",
      "        1.0061, 0.9978, 1.0378, 0.9898, 0.9511, 0.9792, 0.9776, 0.9968, 0.9866,\n",
      "        1.0238, 0.9694, 0.9743, 1.0013, 1.0287, 0.9950, 0.9972, 1.0285, 0.9672,\n",
      "        0.9995, 1.0001, 1.0193, 0.9610, 0.9647, 1.0317, 1.0950, 0.9994, 1.0354,\n",
      "        0.9850, 0.9764, 1.0385, 1.0035, 0.9992, 1.0311, 0.9449, 0.9808, 1.0055,\n",
      "        0.9886, 0.9948, 0.9738, 0.9773, 0.9124, 0.9786, 0.9842, 0.9633, 1.0077,\n",
      "        1.0060, 1.0127, 0.9970, 1.0297, 1.0170, 0.9679, 1.0547, 1.0212, 1.0470,\n",
      "        1.0204, 0.9758, 0.9850, 1.0000, 0.9883, 0.9776, 0.9671, 0.9707, 1.0408,\n",
      "        0.9481, 0.9102, 0.9773, 0.9926, 0.9606, 1.0445, 0.9870, 1.0044, 0.9884,\n",
      "        1.0196, 1.0185, 0.9786, 0.9817, 0.9632, 1.0321, 0.9599, 0.9650, 1.0061,\n",
      "        1.0101, 0.9419, 1.0320, 1.0150, 1.0272, 0.9844, 0.9510, 1.0552, 1.0444,\n",
      "        1.0034, 0.9491, 0.9775, 1.0348, 0.9866, 0.9540, 1.0247, 1.0220, 0.9836,\n",
      "        1.0343, 0.9926, 0.9917, 0.9684, 1.0227, 0.9534, 0.9792, 1.0305, 0.9761,\n",
      "        1.0012, 1.0153, 0.9903, 0.9978, 0.9746, 1.0531, 0.9560, 1.0742, 1.0827,\n",
      "        0.9943, 1.0067, 0.9578, 0.9937, 0.9968, 0.9738, 0.9756, 0.9283, 1.0097,\n",
      "        0.9935, 1.0119, 0.9703, 1.0407, 0.9504, 1.0023, 1.0230, 0.9780, 1.0247,\n",
      "        0.9587, 0.9893, 0.9735, 0.9656, 0.9751, 0.9985, 0.9762, 1.0165, 0.9929,\n",
      "        1.0460, 1.0230, 1.0329, 0.9869, 1.0490, 0.9757, 0.9747, 1.0927, 1.0348,\n",
      "        1.0693, 0.9502, 1.0162, 1.0358, 1.0504, 0.9835, 1.0133, 0.9199, 0.9737,\n",
      "        1.0310, 1.0166, 0.9371, 1.0577, 1.0188, 0.9809, 1.0332, 1.0223, 0.9893,\n",
      "        0.9846, 0.9831, 0.9638, 0.9915, 0.9771, 1.1065, 0.9799, 1.0252, 0.9930,\n",
      "        1.0112, 1.0235, 0.9583, 0.9654, 0.9865, 1.0000, 0.9946, 0.9336, 0.9721,\n",
      "        1.0129, 0.9981, 1.0191, 1.0202, 1.0439, 0.9948, 1.0054, 1.0164, 1.0058,\n",
      "        0.9924, 1.0103, 0.9913, 1.0060, 1.0183, 1.0326, 1.0595, 1.0225, 0.9835,\n",
      "        1.0086, 0.9441, 0.9781, 0.9810, 1.0124, 0.9892, 1.0325, 1.0146, 1.0520,\n",
      "        0.9736, 0.9725, 0.9505, 1.0330, 0.9606, 0.9758, 1.0245, 0.9823, 0.9244,\n",
      "        0.9557, 1.0102, 1.0170, 1.0090, 1.0150, 0.9899, 0.9595, 1.0304, 0.9726,\n",
      "        0.9521, 1.0254, 1.0152, 0.9791], device='cuda:0', requires_grad=True))\n",
      "('5.1.bn2.bias', Parameter containing:\n",
      "tensor([-0.1651, -0.1086, -0.0187, -0.0943, -0.0606, -0.0828, -0.0656, -0.0760,\n",
      "        -0.0272, -0.0543, -0.0290, -0.0576, -0.0796, -0.0960, -0.1156, -0.0913,\n",
      "        -0.0942, -0.0667, -0.0758, -0.0689, -0.1223, -0.0788, -0.0643, -0.1093,\n",
      "        -0.0582, -0.0741, -0.0795,  0.0119, -0.0746, -0.0570, -0.0778, -0.0409,\n",
      "        -0.0118, -0.0949, -0.1108, -0.0950, -0.0172, -0.0633, -0.0188, -0.0646,\n",
      "        -0.0787, -0.0356, -0.1781, -0.0576, -0.0713, -0.1219, -0.0706, -0.0539,\n",
      "        -0.0696, -0.0750, -0.0067, -0.0755, -0.0688, -0.0121, -0.1075, -0.0164,\n",
      "        -0.0764, -0.0850, -0.1097, -0.0758, -0.1102, -0.0596, -0.0421, -0.0703,\n",
      "        -0.1300, -0.0984, -0.0612, -0.0744, -0.0781, -0.0647, -0.1026, -0.0985,\n",
      "        -0.0793, -0.0999, -0.0780, -0.1023, -0.0528, -0.0630, -0.1198, -0.0466,\n",
      "        -0.0770, -0.0650, -0.1239, -0.1212, -0.0840, -0.1118,  0.0080, -0.0289,\n",
      "        -0.0590, -0.0999, -0.1325, -0.0696, -0.1163, -0.0796, -0.0651, -0.1330,\n",
      "        -0.1139, -0.0788, -0.0574, -0.1181, -0.1063, -0.1144, -0.0771, -0.0633,\n",
      "        -0.1083, -0.0451, -0.0231, -0.1234, -0.0577, -0.0136, -0.0843, -0.1052,\n",
      "        -0.0845, -0.0670, -0.0798, -0.0346, -0.1094, -0.0886, -0.1024, -0.0501,\n",
      "        -0.0679, -0.1109, -0.1011, -0.0519, -0.0604, -0.1031, -0.0684, -0.0876,\n",
      "        -0.0782, -0.0954, -0.0573, -0.1181, -0.0927, -0.1162, -0.1193, -0.0624,\n",
      "        -0.1316, -0.0804, -0.1132, -0.0783, -0.1250, -0.0926, -0.0695, -0.0788,\n",
      "        -0.0420, -0.1214, -0.0507, -0.0325, -0.0719, -0.0715, -0.1205, -0.1574,\n",
      "        -0.0697, -0.0606, -0.0713, -0.1063, -0.1319, -0.0955, -0.1072, -0.1514,\n",
      "        -0.0104, -0.0687, -0.0493, -0.0403, -0.0868, -0.0650, -0.0482, -0.1044,\n",
      "        -0.0533, -0.0154, -0.0715, -0.0439, -0.1392, -0.0943, -0.0606, -0.1412,\n",
      "        -0.0952, -0.0973, -0.0634, -0.0876, -0.0928, -0.0715, -0.1221, -0.0465,\n",
      "        -0.0739, -0.0720, -0.0561, -0.1022, -0.0625, -0.0816, -0.0955, -0.1063,\n",
      "        -0.0820, -0.0781, -0.0452, -0.0742, -0.0471, -0.0675, -0.0699, -0.1235,\n",
      "        -0.1291, -0.1072, -0.0299, -0.0997, -0.0814, -0.1212, -0.1233, -0.0600,\n",
      "        -0.1846, -0.0778, -0.0849, -0.1434, -0.0941, -0.0377, -0.0154, -0.0617,\n",
      "        -0.0981, -0.0500, -0.0503, -0.1259, -0.0585, -0.0217, -0.0343, -0.0816,\n",
      "        -0.0909, -0.0239, -0.0967, -0.0572, -0.0329, -0.0627, -0.0716, -0.0887,\n",
      "        -0.0564, -0.0267, -0.1300, -0.0663, -0.1148, -0.0736, -0.0341, -0.0914,\n",
      "        -0.0347, -0.0573, -0.0894, -0.1555, -0.0404, -0.0303, -0.0686, -0.0442,\n",
      "        -0.0813, -0.0352, -0.0292, -0.0886, -0.0942, -0.0425, -0.0815, -0.0881],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.1.bn3.weight', Parameter containing:\n",
      "tensor([1.0150, 1.0382, 1.0357,  ..., 1.0158, 1.0037, 0.8951], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('5.1.bn3.bias', Parameter containing:\n",
      "tensor([-0.0017,  0.0189,  0.0087,  ...,  0.0060, -0.0049, -0.0238],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.2.conv1.weight', Parameter containing:\n",
      "tensor([[[ 0.0351],\n",
      "         [ 0.0423],\n",
      "         [ 0.0530],\n",
      "         ...,\n",
      "         [-0.0068],\n",
      "         [ 0.0153],\n",
      "         [ 0.0295]],\n",
      "\n",
      "        [[ 0.0426],\n",
      "         [ 0.0346],\n",
      "         [ 0.0696],\n",
      "         ...,\n",
      "         [ 0.0322],\n",
      "         [ 0.0324],\n",
      "         [ 0.0450]],\n",
      "\n",
      "        [[ 0.0192],\n",
      "         [ 0.0154],\n",
      "         [-0.0025],\n",
      "         ...,\n",
      "         [ 0.0206],\n",
      "         [-0.0160],\n",
      "         [ 0.0010]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0075],\n",
      "         [-0.0208],\n",
      "         [-0.0185],\n",
      "         ...,\n",
      "         [-0.0144],\n",
      "         [ 0.0027],\n",
      "         [-0.0518]],\n",
      "\n",
      "        [[ 0.0004],\n",
      "         [-0.0693],\n",
      "         [-0.0137],\n",
      "         ...,\n",
      "         [-0.0285],\n",
      "         [ 0.0222],\n",
      "         [ 0.0210]],\n",
      "\n",
      "        [[-0.0103],\n",
      "         [ 0.0030],\n",
      "         [-0.0045],\n",
      "         ...,\n",
      "         [-0.0162],\n",
      "         [ 0.0198],\n",
      "         [-0.0829]]], device='cuda:0', requires_grad=True))\n",
      "('5.2.conv1.bias', Parameter containing:\n",
      "tensor([ 3.1201e-05,  2.9590e-02, -2.9506e-02,  2.8173e-02, -1.2769e-02,\n",
      "         2.4556e-04,  1.3458e-03, -2.1106e-02,  5.0803e-03,  1.4294e-02,\n",
      "        -2.8767e-02, -6.7073e-03,  2.7795e-02,  1.4245e-02, -9.4521e-04,\n",
      "         2.0732e-02, -2.9789e-02, -2.6274e-02, -2.0547e-03,  2.0222e-02,\n",
      "        -1.1922e-02, -2.2105e-02, -1.7083e-02, -3.0043e-02, -1.0888e-02,\n",
      "         2.9578e-02, -2.5591e-02,  2.8849e-02,  1.2467e-02, -2.0756e-02,\n",
      "         8.0109e-03, -9.1781e-03, -8.3475e-03, -1.5806e-02,  1.5670e-02,\n",
      "        -9.1180e-03,  2.6394e-03, -5.7910e-03,  1.9390e-02, -3.1223e-02,\n",
      "        -1.2927e-04, -1.4640e-02,  1.4653e-02,  6.4052e-03,  1.5564e-02,\n",
      "         2.8794e-02, -2.9608e-02, -2.2251e-02, -2.2475e-02, -1.9033e-03,\n",
      "         2.8506e-02, -2.9682e-02, -2.9364e-02,  1.3165e-02, -2.2651e-02,\n",
      "         1.6857e-02, -2.3449e-02,  1.7457e-02,  2.7170e-02, -7.6837e-03,\n",
      "        -2.1283e-02, -1.9285e-02,  1.2335e-02, -2.1183e-02,  2.2505e-03,\n",
      "        -2.9780e-02,  1.0959e-02,  2.8292e-02,  3.1136e-02, -1.7606e-02,\n",
      "         1.8572e-02,  3.0208e-03,  1.2299e-02,  1.8339e-02,  2.3266e-02,\n",
      "        -1.7334e-02, -1.6560e-04,  2.3622e-02,  6.7960e-03, -7.8748e-03,\n",
      "        -1.4805e-02,  2.8286e-02, -1.5648e-02,  1.8858e-02,  9.1424e-03,\n",
      "        -2.2252e-03, -5.2246e-04,  1.6122e-02,  1.7863e-02, -1.7531e-02,\n",
      "         2.2524e-04, -2.8963e-02, -3.6692e-03,  1.7187e-02, -2.9429e-02,\n",
      "        -6.3728e-03, -1.6595e-02, -3.1805e-03,  1.1944e-02, -1.1953e-02,\n",
      "         1.6472e-03, -4.1369e-03,  2.8626e-02, -1.0185e-02, -2.0216e-02,\n",
      "        -1.3624e-02, -2.4096e-02, -2.8862e-02,  1.8859e-02,  6.6611e-03,\n",
      "         1.7938e-02, -1.5562e-02,  1.7246e-02,  2.6440e-02,  2.1656e-02,\n",
      "        -2.9929e-02, -1.3204e-02,  2.8168e-02, -2.5721e-03, -4.2347e-03,\n",
      "         1.3298e-02,  2.5346e-02,  2.8362e-02,  2.2939e-02, -2.6940e-03,\n",
      "         1.3731e-02,  1.7828e-02,  2.7682e-02,  2.4305e-02,  9.9465e-03,\n",
      "         2.2878e-02,  8.3322e-03, -5.1703e-04,  1.3221e-02,  2.6210e-02,\n",
      "         2.3103e-02,  2.9378e-02, -2.1227e-02, -2.4416e-02, -2.8823e-03,\n",
      "        -5.8085e-03, -5.2321e-03, -6.4572e-03, -3.8916e-03, -9.4721e-03,\n",
      "         2.1380e-02,  1.5908e-02,  2.1659e-02,  6.1881e-03,  1.3685e-02,\n",
      "         3.0811e-02, -1.5163e-02, -4.7098e-03, -2.1220e-02,  2.5553e-02,\n",
      "         1.2408e-03, -6.0373e-03,  2.2113e-02, -2.8719e-02,  3.3933e-03,\n",
      "         8.8383e-03,  5.6944e-03,  1.1379e-02, -2.7577e-02,  3.4737e-03,\n",
      "        -2.8814e-02,  2.1296e-02,  2.3154e-02,  9.4979e-03, -2.7458e-02,\n",
      "         4.5710e-04, -1.3565e-02, -1.0961e-02,  1.5377e-02, -2.9263e-02,\n",
      "        -2.6657e-02, -2.8637e-02,  2.8564e-02, -1.9327e-03, -8.1811e-04,\n",
      "        -9.5114e-03,  1.6201e-02, -5.6765e-03,  4.9133e-04,  3.7900e-03,\n",
      "        -5.7262e-03, -1.6481e-02, -2.9690e-02,  1.6462e-02, -2.6407e-02,\n",
      "        -2.1112e-02, -2.4079e-02, -2.9934e-02, -1.0828e-02, -1.9527e-02,\n",
      "         1.4688e-02,  1.9787e-02,  2.9304e-02, -5.5925e-03, -2.7722e-02,\n",
      "        -2.2661e-02,  2.7706e-02, -2.7889e-02,  6.0649e-03,  2.4417e-02,\n",
      "        -1.9655e-02, -2.0629e-02,  1.8105e-02,  4.6592e-03, -1.0186e-02,\n",
      "         2.1104e-02, -1.4459e-02,  3.5575e-03,  2.0201e-02,  1.8072e-03,\n",
      "        -6.5246e-03, -1.8810e-02, -2.6532e-02, -3.6491e-03,  9.0863e-03,\n",
      "         2.4303e-02,  3.1272e-03,  2.7071e-03,  2.0507e-02,  2.8755e-02,\n",
      "        -2.9126e-02, -1.8561e-02, -2.7798e-03, -1.4844e-02, -6.6617e-03,\n",
      "         9.5215e-03, -2.0314e-02,  8.4948e-03, -2.5277e-02, -1.0554e-02,\n",
      "         1.8444e-02,  2.8640e-02, -4.6214e-03, -1.1124e-02,  2.0540e-02,\n",
      "         7.5124e-03,  8.1997e-03, -6.6528e-03, -2.0695e-02,  1.5770e-02,\n",
      "         2.1331e-02, -7.8332e-03,  5.6977e-03, -8.4721e-03, -1.7568e-02,\n",
      "         2.3057e-02, -1.5833e-02, -2.7518e-02, -1.2335e-02,  3.0760e-02,\n",
      "        -1.0816e-02], device='cuda:0', requires_grad=True))\n",
      "('5.2.conv2.weight', Parameter containing:\n",
      "tensor([[[-6.1512e-02, -1.6630e-02,  2.5779e-02],\n",
      "         [ 3.3602e-02, -6.5848e-03,  5.0457e-02],\n",
      "         [-1.4044e-02, -5.4665e-03,  9.1320e-02],\n",
      "         ...,\n",
      "         [-2.3031e-02, -6.4818e-02,  4.3809e-02],\n",
      "         [-2.8959e-02,  6.0209e-02, -3.3145e-04],\n",
      "         [ 5.0287e-02,  2.0732e-02, -4.9059e-02]],\n",
      "\n",
      "        [[ 4.1939e-02,  3.2041e-03,  5.7375e-03],\n",
      "         [-7.9810e-02, -5.5225e-03,  1.7556e-02],\n",
      "         [-1.0149e-02, -1.9804e-02, -8.8342e-03],\n",
      "         ...,\n",
      "         [-1.2330e-02, -1.4900e-02,  2.6414e-02],\n",
      "         [ 4.0526e-02,  4.0834e-02, -4.2358e-03],\n",
      "         [-3.4912e-02, -2.3922e-02,  4.7112e-02]],\n",
      "\n",
      "        [[ 1.8675e-02, -1.1589e-02,  5.7932e-03],\n",
      "         [-9.4271e-03,  9.2468e-03, -5.0698e-02],\n",
      "         [ 5.1806e-02, -1.0180e-02, -1.6618e-02],\n",
      "         ...,\n",
      "         [ 5.6867e-02,  8.5574e-03, -5.3217e-02],\n",
      "         [-2.3916e-02,  5.2417e-02, -9.6338e-02],\n",
      "         [ 3.8837e-02,  4.1267e-02, -8.3491e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.3011e-02, -6.7371e-07,  1.5141e-02],\n",
      "         [ 1.2710e-02,  7.6983e-02,  5.2154e-02],\n",
      "         [ 2.2731e-02,  8.1618e-05,  1.0574e-02],\n",
      "         ...,\n",
      "         [ 2.8523e-02, -4.0725e-02, -1.8931e-02],\n",
      "         [ 5.7925e-02, -8.7925e-02,  2.5146e-02],\n",
      "         [-5.1341e-02,  3.1809e-02, -4.0275e-02]],\n",
      "\n",
      "        [[ 1.9191e-02,  1.4702e-02,  4.3841e-02],\n",
      "         [-2.3563e-02,  2.5833e-02,  1.1831e-03],\n",
      "         [-8.0027e-02,  6.4935e-03, -5.5909e-02],\n",
      "         ...,\n",
      "         [ 2.4061e-02,  2.3579e-02,  3.6058e-02],\n",
      "         [ 4.2215e-02, -2.2072e-02,  7.0702e-02],\n",
      "         [-3.5838e-02, -5.6364e-02, -4.4717e-02]],\n",
      "\n",
      "        [[ 8.2299e-02,  2.4873e-02, -7.1634e-02],\n",
      "         [ 1.5905e-02, -3.8667e-03, -1.7787e-02],\n",
      "         [-2.8026e-02, -2.2757e-02, -8.7737e-03],\n",
      "         ...,\n",
      "         [ 3.2606e-02, -3.4549e-02,  1.2017e-02],\n",
      "         [ 2.6230e-03, -7.4254e-03,  8.8201e-03],\n",
      "         [-4.0045e-03,  3.8739e-04,  4.8412e-03]]], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('5.2.conv2.bias', Parameter containing:\n",
      "tensor([ 0.0160, -0.0095, -0.0303,  0.0060,  0.0359, -0.0081,  0.0049, -0.0298,\n",
      "        -0.0039,  0.0296, -0.0157,  0.0024,  0.0041, -0.0255,  0.0234, -0.0119,\n",
      "        -0.0090,  0.0010, -0.0077,  0.0288,  0.0054, -0.0239,  0.0242,  0.0177,\n",
      "        -0.0124, -0.0211,  0.0283, -0.0162, -0.0108,  0.0241, -0.0256, -0.0054,\n",
      "         0.0326, -0.0327,  0.0227,  0.0292, -0.0349,  0.0142, -0.0023,  0.0157,\n",
      "        -0.0033,  0.0034,  0.0212,  0.0250, -0.0174,  0.0318, -0.0248, -0.0290,\n",
      "        -0.0283,  0.0162,  0.0059,  0.0264,  0.0111, -0.0026,  0.0182, -0.0274,\n",
      "        -0.0062,  0.0220, -0.0041, -0.0217,  0.0260,  0.0139, -0.0079, -0.0005,\n",
      "        -0.0227,  0.0012,  0.0008,  0.0086, -0.0289, -0.0250,  0.0092, -0.0132,\n",
      "        -0.0171,  0.0267,  0.0151, -0.0030, -0.0252,  0.0037, -0.0161, -0.0118,\n",
      "        -0.0015,  0.0098,  0.0115, -0.0335,  0.0297,  0.0029,  0.0147,  0.0218,\n",
      "         0.0216, -0.0180, -0.0151, -0.0042,  0.0044,  0.0129, -0.0033,  0.0188,\n",
      "        -0.0012,  0.0082, -0.0131, -0.0225,  0.0346,  0.0280,  0.0309, -0.0027,\n",
      "         0.0197, -0.0050,  0.0224, -0.0169,  0.0255, -0.0160,  0.0170,  0.0326,\n",
      "        -0.0210,  0.0113,  0.0265, -0.0233,  0.0038,  0.0296,  0.0281, -0.0019,\n",
      "        -0.0301,  0.0324, -0.0238,  0.0300, -0.0358,  0.0228, -0.0010, -0.0007,\n",
      "        -0.0286, -0.0235, -0.0072,  0.0312,  0.0170,  0.0276, -0.0211,  0.0302,\n",
      "        -0.0144, -0.0348,  0.0075,  0.0308, -0.0024, -0.0077, -0.0298, -0.0325,\n",
      "         0.0292,  0.0068,  0.0056,  0.0359, -0.0160,  0.0161,  0.0069,  0.0138,\n",
      "         0.0204, -0.0302,  0.0124, -0.0112,  0.0261,  0.0119, -0.0286, -0.0066,\n",
      "         0.0130,  0.0174, -0.0071,  0.0076,  0.0204,  0.0326,  0.0073, -0.0227,\n",
      "        -0.0138,  0.0058, -0.0251, -0.0170, -0.0121,  0.0049, -0.0267,  0.0140,\n",
      "         0.0224, -0.0236, -0.0230,  0.0002,  0.0122,  0.0081,  0.0276,  0.0192,\n",
      "         0.0058,  0.0296, -0.0244, -0.0335,  0.0053, -0.0132,  0.0205, -0.0299,\n",
      "        -0.0172,  0.0252,  0.0041, -0.0064, -0.0045, -0.0194, -0.0220,  0.0080,\n",
      "        -0.0057,  0.0287,  0.0136, -0.0122, -0.0031, -0.0334, -0.0037,  0.0023,\n",
      "         0.0199,  0.0188,  0.0185,  0.0229, -0.0326,  0.0340, -0.0123,  0.0077,\n",
      "        -0.0360, -0.0127,  0.0065, -0.0190, -0.0088, -0.0165, -0.0051, -0.0249,\n",
      "        -0.0351,  0.0079,  0.0358, -0.0236, -0.0129, -0.0059,  0.0349,  0.0064,\n",
      "         0.0057, -0.0176, -0.0058,  0.0072, -0.0043, -0.0078,  0.0271, -0.0094,\n",
      "         0.0254,  0.0215,  0.0060,  0.0003, -0.0204, -0.0016, -0.0344, -0.0206,\n",
      "        -0.0106, -0.0085, -0.0214, -0.0133,  0.0293, -0.0269,  0.0012, -0.0041],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.2.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.0072],\n",
      "         [ 0.0379],\n",
      "         [-0.0499],\n",
      "         ...,\n",
      "         [-0.0329],\n",
      "         [ 0.0155],\n",
      "         [-0.0334]],\n",
      "\n",
      "        [[-0.0075],\n",
      "         [-0.0611],\n",
      "         [-0.0681],\n",
      "         ...,\n",
      "         [ 0.0086],\n",
      "         [ 0.0530],\n",
      "         [ 0.0360]],\n",
      "\n",
      "        [[ 0.0381],\n",
      "         [ 0.0144],\n",
      "         [-0.0405],\n",
      "         ...,\n",
      "         [-0.0358],\n",
      "         [ 0.0294],\n",
      "         [ 0.0686]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0513],\n",
      "         [ 0.0433],\n",
      "         [ 0.0500],\n",
      "         ...,\n",
      "         [ 0.0488],\n",
      "         [ 0.0624],\n",
      "         [ 0.0189]],\n",
      "\n",
      "        [[-0.0478],\n",
      "         [-0.0326],\n",
      "         [ 0.0102],\n",
      "         ...,\n",
      "         [ 0.0213],\n",
      "         [-0.0373],\n",
      "         [-0.0016]],\n",
      "\n",
      "        [[-0.0157],\n",
      "         [-0.0131],\n",
      "         [-0.0493],\n",
      "         ...,\n",
      "         [-0.0750],\n",
      "         [-0.0254],\n",
      "         [-0.0037]]], device='cuda:0', requires_grad=True))\n",
      "('5.2.conv3.bias', Parameter containing:\n",
      "tensor([-0.0186,  0.0052, -0.0527,  ...,  0.0189,  0.0436, -0.0043],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.2.bn1.weight', Parameter containing:\n",
      "tensor([1.0074, 0.9711, 0.9627, 0.9701, 0.9228, 0.9510, 1.0186, 1.0248, 0.9977,\n",
      "        0.9681, 0.9662, 1.0306, 1.0076, 1.0654, 1.0423, 1.0130, 0.9875, 1.0945,\n",
      "        0.9579, 0.9854, 0.9909, 1.0153, 1.0323, 0.9874, 0.9563, 1.0064, 1.0295,\n",
      "        0.9676, 1.0246, 0.9875, 0.9698, 1.0229, 1.0155, 1.0153, 0.9590, 0.9948,\n",
      "        0.9993, 0.9441, 1.0104, 0.9841, 1.0031, 0.9776, 1.0133, 1.0310, 1.0067,\n",
      "        0.9837, 0.9583, 1.0683, 1.0293, 0.9893, 1.0379, 1.0619, 0.9809, 0.9427,\n",
      "        0.9960, 1.0092, 0.9815, 1.0160, 0.9998, 1.0583, 0.9610, 0.9996, 1.0275,\n",
      "        0.9930, 1.0557, 0.9981, 1.0250, 1.0215, 0.9943, 0.9911, 1.0155, 1.0652,\n",
      "        1.0164, 0.9393, 1.0065, 0.9983, 1.0029, 1.0039, 1.0246, 1.0310, 0.9570,\n",
      "        1.0271, 1.0031, 1.0222, 1.0215, 1.0756, 0.9895, 1.0105, 1.0034, 1.0116,\n",
      "        1.0278, 0.9645, 1.0103, 0.9820, 1.0047, 0.9699, 1.0153, 0.9146, 0.9841,\n",
      "        0.9975, 1.0170, 1.0124, 1.0424, 0.9695, 1.0218, 1.0232, 0.9540, 0.9709,\n",
      "        1.0126, 1.0329, 1.0199, 1.0173, 0.9919, 1.0160, 0.9799, 1.0157, 0.9579,\n",
      "        1.0296, 1.0074, 0.9898, 0.9793, 0.9950, 0.9462, 0.9772, 0.9593, 0.9009,\n",
      "        0.9412, 0.9671, 0.9893, 0.9757, 1.0097, 1.0015, 1.0032, 1.0093, 0.9992,\n",
      "        0.9880, 1.0485, 0.9988, 1.0287, 1.0128, 0.9695, 1.0008, 0.9947, 0.9461,\n",
      "        1.0761, 0.9146, 0.9846, 0.9992, 0.9441, 1.0442, 0.9859, 0.9557, 0.9842,\n",
      "        0.9825, 0.9958, 1.0082, 1.0166, 1.0403, 1.0807, 1.0065, 1.0029, 0.9540,\n",
      "        0.9408, 0.9795, 1.0264, 1.0662, 1.0634, 0.9585, 0.9623, 0.9645, 0.9685,\n",
      "        0.9753, 0.9716, 1.0019, 0.9483, 0.9778, 1.0376, 0.9703, 1.0212, 0.9703,\n",
      "        1.0310, 1.0386, 1.0208, 0.9806, 0.9873, 0.9928, 0.9831, 0.9795, 0.9935,\n",
      "        0.9717, 0.9672, 1.0631, 0.9551, 0.8985, 1.0406, 0.9572, 1.0006, 0.9681,\n",
      "        0.9688, 1.0947, 0.9653, 1.0550, 0.9745, 0.9804, 0.9879, 1.0279, 0.9595,\n",
      "        0.9836, 1.0334, 0.9564, 0.9732, 0.9954, 1.0409, 1.0346, 1.0006, 0.9861,\n",
      "        0.9721, 1.0227, 1.0748, 0.9907, 0.9643, 0.9976, 0.9668, 0.9630, 0.9891,\n",
      "        0.9968, 1.0002, 1.0321, 1.0460, 1.0025, 0.9570, 0.9521, 1.0202, 0.9747,\n",
      "        0.9624, 0.9995, 1.0313, 0.9928, 1.0115, 1.0129, 1.0174, 0.9976, 0.9602,\n",
      "        0.9717, 1.0156, 1.0247, 1.0173, 0.9621, 0.9869, 0.9512, 1.0285, 0.9596,\n",
      "        0.9741, 1.0420, 0.9913, 0.9799], device='cuda:0', requires_grad=True))\n",
      "('5.2.bn1.bias', Parameter containing:\n",
      "tensor([-0.1087, -0.0733, -0.1048, -0.1255, -0.1040, -0.1343, -0.0918, -0.0688,\n",
      "        -0.0756, -0.0523, -0.1066, -0.0452, -0.1022, -0.0964, -0.0786, -0.0498,\n",
      "        -0.0289, -0.0447, -0.0930, -0.0741, -0.1122, -0.0391, -0.0671, -0.1250,\n",
      "        -0.1452, -0.0818, -0.0725, -0.1147, -0.1257, -0.0907, -0.1077, -0.0930,\n",
      "        -0.0739, -0.0204, -0.1448, -0.0782, -0.0417, -0.1074, -0.0843, -0.0962,\n",
      "        -0.0608, -0.0615, -0.0974, -0.0793, -0.0628, -0.0778, -0.0730, -0.0726,\n",
      "        -0.0529, -0.0867, -0.0507, -0.0636, -0.0786, -0.0610, -0.1098, -0.0558,\n",
      "        -0.1135, -0.0965, -0.0499, -0.0867, -0.0964, -0.0948, -0.0708, -0.0638,\n",
      "        -0.1103, -0.0845, -0.0690, -0.0822, -0.1051, -0.0842, -0.0183, -0.0441,\n",
      "        -0.0484, -0.0674, -0.0632, -0.0400, -0.0943, -0.0973, -0.0441, -0.0293,\n",
      "        -0.0659, -0.0697, -0.0834, -0.0462, -0.0540, -0.0464, -0.0349, -0.0687,\n",
      "        -0.0403, -0.0026, -0.0512, -0.0828, -0.0811, -0.0634, -0.0976, -0.0766,\n",
      "        -0.0595, -0.1301, -0.0257, -0.0538, -0.0668, -0.0786, -0.0333, -0.0885,\n",
      "        -0.0253, -0.1123, -0.1348, -0.0658, -0.0686, -0.0562, -0.1042, -0.0382,\n",
      "        -0.0375, -0.1528, -0.0359, -0.0608, -0.0887, -0.0627, -0.0750, -0.0704,\n",
      "        -0.0894, -0.0831, -0.0967, -0.0760, -0.0759, -0.1044, -0.1504, -0.0945,\n",
      "        -0.0971, -0.0706, -0.0454, -0.0562, -0.0685, -0.0445, -0.0731, -0.0259,\n",
      "        -0.0811, -0.0624, -0.0015, -0.0528, -0.0908, -0.0681, -0.0692, -0.1049,\n",
      "        -0.0925, -0.1225, -0.0993, -0.0887, -0.0542, -0.0597, -0.0555, -0.0594,\n",
      "        -0.1336, -0.0956, -0.0576, -0.0775, -0.0825, -0.0465, -0.0346, -0.0487,\n",
      "        -0.0356, -0.0756, -0.0848, -0.0588, -0.0635, -0.0420, -0.1331, -0.0977,\n",
      "        -0.0841, -0.1261, -0.0906, -0.0568, -0.0871, -0.0995, -0.0994, -0.0703,\n",
      "        -0.0628, -0.1096, -0.0053, -0.0578, -0.0704, -0.0642, -0.0158, -0.0879,\n",
      "        -0.0825, -0.0853, -0.0098, -0.1129, -0.0548, -0.1050, -0.0719, -0.0281,\n",
      "        -0.1095, -0.1406, -0.0992, -0.0881, -0.1438, -0.0877, -0.0726, -0.0310,\n",
      "        -0.0816, -0.1217, -0.0309, -0.0699, -0.0996, -0.0769, -0.0906, -0.0656,\n",
      "        -0.0427, -0.0759, -0.0481, -0.0908, -0.0361, -0.1010, -0.0538, -0.0357,\n",
      "        -0.0685, -0.0790, -0.0398, -0.0656, -0.1088, -0.1004, -0.0181, -0.0649,\n",
      "        -0.1267, -0.0930, -0.0835, -0.1099, -0.1223, -0.1468, -0.1276, -0.0899,\n",
      "        -0.0633, -0.1003, -0.0676, -0.1024, -0.0728, -0.0701, -0.0607, -0.0762,\n",
      "        -0.1039, -0.0892, -0.0632, -0.1083, -0.0318, -0.1075, -0.0575, -0.1035,\n",
      "        -0.1344, -0.1033, -0.1184, -0.1127, -0.0676, -0.0900, -0.0764, -0.1108],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.2.bn2.weight', Parameter containing:\n",
      "tensor([1.0151, 0.9374, 1.0070, 0.9552, 0.9759, 0.9837, 1.0330, 0.9684, 0.9948,\n",
      "        1.0152, 1.0234, 0.9607, 0.9764, 0.9715, 0.9907, 0.9635, 0.9842, 1.0003,\n",
      "        1.0287, 0.9904, 0.9619, 1.0211, 1.0022, 0.9903, 1.0184, 0.9964, 1.0220,\n",
      "        0.9916, 0.9565, 0.9911, 0.9834, 1.0066, 0.9673, 1.0073, 0.9657, 1.0209,\n",
      "        0.9710, 0.9724, 0.9483, 1.0084, 1.0170, 1.0016, 1.0117, 0.9981, 1.0530,\n",
      "        0.9831, 0.9894, 0.9768, 1.0317, 1.0252, 0.9776, 0.9732, 0.9931, 0.9942,\n",
      "        0.9603, 1.0427, 0.9636, 0.9930, 0.9672, 0.9977, 0.9834, 1.0010, 0.9877,\n",
      "        0.9478, 0.9686, 1.0068, 1.0042, 1.0265, 0.9853, 0.9844, 0.9830, 1.0032,\n",
      "        0.9496, 0.9382, 1.0080, 0.9775, 0.9849, 0.9478, 0.9650, 1.0208, 0.9957,\n",
      "        0.9884, 0.9854, 1.0235, 0.9606, 1.0316, 1.0049, 1.0026, 1.0149, 1.0213,\n",
      "        0.9898, 0.9789, 1.0091, 0.9898, 0.9822, 1.0109, 0.9595, 0.9988, 0.9433,\n",
      "        0.9920, 0.9328, 1.0160, 1.0315, 0.9988, 0.9708, 0.9708, 0.9965, 0.9185,\n",
      "        0.9922, 0.9882, 0.9856, 0.9938, 1.0223, 0.9599, 1.0087, 1.0000, 0.9991,\n",
      "        0.9775, 0.9668, 1.0167, 0.9983, 1.0136, 0.9426, 1.0072, 1.0145, 1.0590,\n",
      "        1.0289, 0.9966, 0.9805, 1.0294, 1.0716, 0.9642, 1.0186, 0.9528, 1.0170,\n",
      "        1.0084, 0.9837, 0.9890, 1.0029, 1.0128, 0.9961, 1.0085, 1.0267, 1.1064,\n",
      "        1.0777, 1.0454, 1.0276, 1.0105, 1.0209, 1.0316, 1.0046, 1.0320, 0.9704,\n",
      "        1.0830, 0.9740, 1.0061, 0.9854, 0.9908, 1.0668, 1.0350, 0.9676, 1.0211,\n",
      "        0.9961, 0.9643, 0.9621, 0.9557, 0.9949, 0.9757, 1.0193, 1.0238, 1.0041,\n",
      "        0.9766, 1.0248, 1.0135, 0.9657, 1.0126, 0.9820, 1.0529, 0.9866, 0.9972,\n",
      "        1.0084, 1.0029, 1.0300, 1.0528, 0.9897, 1.0297, 1.0218, 1.0056, 1.0243,\n",
      "        1.0151, 1.0091, 0.9823, 0.9574, 0.9946, 1.0026, 0.9960, 0.9752, 1.0020,\n",
      "        0.9532, 0.9662, 0.9582, 1.0021, 0.9960, 0.9852, 0.9878, 0.9709, 1.0072,\n",
      "        1.0616, 0.9504, 1.0343, 1.0467, 1.0036, 0.9653, 0.9683, 1.0080, 1.0439,\n",
      "        0.9600, 1.0310, 1.0222, 1.0368, 0.9662, 1.0025, 0.9634, 0.9843, 1.0128,\n",
      "        0.9908, 0.9598, 0.9893, 0.9951, 1.0016, 1.0101, 1.0237, 1.0188, 1.0054,\n",
      "        1.0019, 0.9963, 1.0438, 0.9852, 1.0260, 1.0196, 1.0067, 1.0253, 1.0238,\n",
      "        0.9638, 0.9851, 0.9512, 0.9815, 1.0135, 1.0098, 1.0444, 0.9741, 1.0098,\n",
      "        1.0106, 0.9664, 1.0119, 0.9566], device='cuda:0', requires_grad=True))\n",
      "('5.2.bn2.bias', Parameter containing:\n",
      "tensor([-0.0833, -0.0556, -0.0743, -0.0973, -0.1013, -0.1268, -0.1013, -0.1225,\n",
      "        -0.0742, -0.0484, -0.0806, -0.1202, -0.1133, -0.0840, -0.0760, -0.0665,\n",
      "        -0.0917, -0.0753, -0.0993, -0.1087, -0.1022, -0.0616, -0.1354, -0.1177,\n",
      "        -0.0362, -0.0437, -0.0993, -0.0743, -0.0639, -0.0807, -0.0617, -0.1334,\n",
      "        -0.1230, -0.0805, -0.0962, -0.1141, -0.0766, -0.1236, -0.1055, -0.0876,\n",
      "        -0.1027, -0.0758, -0.0838, -0.0690, -0.0975, -0.1131, -0.0788, -0.1006,\n",
      "        -0.0651, -0.1231, -0.1028, -0.1282, -0.0720, -0.0629, -0.0405, -0.0671,\n",
      "        -0.0915, -0.1107, -0.0593, -0.0574, -0.0581, -0.0746, -0.0833, -0.1316,\n",
      "        -0.0928, -0.0955, -0.0499, -0.1018, -0.0917, -0.0706, -0.0676, -0.1459,\n",
      "        -0.0549, -0.0875, -0.1388, -0.1036, -0.0284, -0.0353, -0.0667, -0.1132,\n",
      "        -0.0692, -0.0896, -0.1200, -0.0743, -0.0862, -0.0635, -0.0368, -0.0701,\n",
      "        -0.0656, -0.0212, -0.0628, -0.0434, -0.0633, -0.0568, -0.0862, -0.0428,\n",
      "        -0.0763, -0.0931, -0.0943, -0.0534, -0.1052, -0.0885, -0.0802, -0.1235,\n",
      "        -0.0668, -0.0611, -0.0441, -0.1774, -0.0816, -0.0398, -0.0414, -0.1356,\n",
      "        -0.0833, -0.0630, -0.0755, -0.0767, -0.0931, -0.0894, -0.0598, -0.0602,\n",
      "        -0.1081, -0.0789, -0.1272, -0.1525, -0.0622, -0.1005, -0.0696, -0.0482,\n",
      "        -0.0941, -0.0589, -0.0833, -0.1141, -0.1177, -0.1020, -0.1200, -0.1476,\n",
      "        -0.1322, -0.0973, -0.0605, -0.0737, -0.0738, -0.0848, -0.0486, -0.0716,\n",
      "        -0.1232, -0.0648, -0.0584, -0.0792, -0.0809, -0.0922, -0.0811, -0.1141,\n",
      "        -0.0610, -0.0353, -0.1200, -0.1142, -0.1378, -0.0910, -0.0410, -0.0707,\n",
      "        -0.0756, -0.1428, -0.0929, -0.1085, -0.1172, -0.0942, -0.0294, -0.0689,\n",
      "        -0.0595, -0.0687, -0.0941, -0.0368, -0.0523, -0.0143, -0.0879, -0.0317,\n",
      "        -0.1180, -0.1068, -0.1189, -0.0888, -0.0771, -0.1288, -0.1039, -0.0238,\n",
      "        -0.1362, -0.0525, -0.1086, -0.0960, -0.0704, -0.0573, -0.1059, -0.0760,\n",
      "        -0.0836, -0.0523, -0.0755, -0.0758, -0.0923, -0.0344, -0.0943, -0.0464,\n",
      "        -0.0880, -0.0858, -0.0798, -0.0516, -0.0457, -0.0510, -0.0908, -0.0364,\n",
      "        -0.1347, -0.0736, -0.0777, -0.0940, -0.0573, -0.0497, -0.0872, -0.0121,\n",
      "        -0.0618, -0.0972, -0.0679, -0.0292, -0.0565, -0.0961, -0.1143, -0.1201,\n",
      "        -0.1279, -0.1101, -0.0728, -0.0961, -0.0643, -0.0836, -0.0902, -0.0873,\n",
      "        -0.0560, -0.0599, -0.0423, -0.0995, -0.0939, -0.1518, -0.0479, -0.0975,\n",
      "        -0.0468, -0.1116, -0.0638, -0.0751, -0.0479, -0.0636, -0.1324, -0.0275,\n",
      "        -0.1065, -0.0405, -0.1017, -0.0753, -0.1082, -0.0438, -0.0578, -0.0498],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.2.bn3.weight', Parameter containing:\n",
      "tensor([1.0037, 0.9963, 1.0139,  ..., 1.0112, 1.0070, 0.9171], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('5.2.bn3.bias', Parameter containing:\n",
      "tensor([-0.0130,  0.0067,  0.0059,  ..., -0.0098, -0.0074,  0.0060],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.3.conv1.weight', Parameter containing:\n",
      "tensor([[[-0.0401],\n",
      "         [ 0.0404],\n",
      "         [-0.0241],\n",
      "         ...,\n",
      "         [-0.0034],\n",
      "         [-0.0573],\n",
      "         [ 0.0431]],\n",
      "\n",
      "        [[-0.0416],\n",
      "         [-0.0579],\n",
      "         [-0.0031],\n",
      "         ...,\n",
      "         [ 0.0234],\n",
      "         [ 0.0165],\n",
      "         [-0.0502]],\n",
      "\n",
      "        [[-0.0199],\n",
      "         [ 0.0178],\n",
      "         [ 0.0340],\n",
      "         ...,\n",
      "         [ 0.0222],\n",
      "         [ 0.0271],\n",
      "         [-0.0107]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0093],\n",
      "         [-0.0039],\n",
      "         [ 0.0621],\n",
      "         ...,\n",
      "         [ 0.0059],\n",
      "         [-0.0043],\n",
      "         [-0.0189]],\n",
      "\n",
      "        [[-0.0167],\n",
      "         [-0.0146],\n",
      "         [ 0.0193],\n",
      "         ...,\n",
      "         [ 0.0220],\n",
      "         [ 0.0095],\n",
      "         [-0.0047]],\n",
      "\n",
      "        [[-0.0154],\n",
      "         [-0.0083],\n",
      "         [ 0.0420],\n",
      "         ...,\n",
      "         [-0.0117],\n",
      "         [ 0.0085],\n",
      "         [ 0.0236]]], device='cuda:0', requires_grad=True))\n",
      "('5.3.conv1.bias', Parameter containing:\n",
      "tensor([-1.9737e-02,  1.5861e-02, -2.7438e-02,  1.2712e-02,  9.7989e-04,\n",
      "        -1.2370e-03,  7.0260e-03, -1.3428e-02, -2.9243e-03, -2.5971e-02,\n",
      "         8.8883e-03, -2.0994e-02, -2.1272e-02,  4.6916e-03, -6.9724e-03,\n",
      "         2.5591e-02, -4.5177e-03,  1.1374e-02,  1.7722e-02, -2.1226e-02,\n",
      "         2.8695e-03, -2.9062e-02, -2.4367e-02,  1.1904e-02, -1.9621e-02,\n",
      "         2.8157e-02, -2.3802e-02, -2.6772e-02,  2.1466e-02, -4.1108e-03,\n",
      "         8.6459e-03, -2.1308e-02,  7.4183e-03, -5.5671e-03,  1.5971e-02,\n",
      "        -2.4382e-02, -2.9333e-02,  1.6229e-02,  1.1951e-02, -8.2079e-03,\n",
      "         9.0835e-03,  1.5363e-02, -2.0284e-02, -7.3654e-04, -1.6341e-02,\n",
      "        -1.8797e-02, -9.3152e-03,  1.9446e-02,  1.2876e-02, -9.3660e-03,\n",
      "        -2.2166e-02, -9.1524e-03,  5.5961e-03, -1.9170e-02, -5.8767e-03,\n",
      "         2.3653e-03,  2.4110e-03,  3.0807e-02,  1.6270e-02, -2.5149e-02,\n",
      "        -1.8309e-02,  2.3169e-03, -1.4307e-02, -6.6492e-03, -1.0733e-02,\n",
      "         1.4496e-02, -3.2659e-03, -2.1389e-02, -2.8604e-02, -2.7312e-03,\n",
      "        -3.1048e-02, -3.0994e-02,  2.2066e-02,  9.6257e-03,  1.3177e-02,\n",
      "        -7.7762e-03,  1.7770e-02, -8.4714e-03,  1.6580e-02,  3.1102e-02,\n",
      "        -2.7826e-02, -1.0438e-02, -2.0498e-02, -2.1607e-02,  2.9984e-02,\n",
      "        -2.2662e-05,  3.9092e-03,  2.6932e-02, -1.5902e-02,  6.0653e-03,\n",
      "         1.3054e-02, -1.3471e-02, -2.6406e-02,  1.2822e-02,  2.2299e-02,\n",
      "        -5.8839e-03,  6.0378e-03, -3.2154e-03, -8.2197e-03, -1.5386e-03,\n",
      "        -2.7442e-02, -2.6894e-02,  1.1210e-02,  2.2771e-02,  5.7820e-03,\n",
      "        -1.7500e-02,  3.0789e-03, -2.3703e-02,  2.8359e-02, -6.6559e-03,\n",
      "         1.9222e-02,  2.3080e-02, -2.3551e-02,  2.0534e-02,  1.6681e-02,\n",
      "         4.1165e-03, -3.8590e-03,  1.4814e-02, -1.0751e-02,  2.8170e-02,\n",
      "         1.8480e-02, -1.1647e-02,  7.0076e-03,  2.1130e-02,  2.9327e-02,\n",
      "         2.7308e-03, -2.8736e-02,  2.4067e-02, -1.1198e-02, -1.8084e-02,\n",
      "        -2.8065e-02, -2.6141e-02, -1.9470e-02, -1.5011e-02, -7.0569e-03,\n",
      "        -1.4845e-02,  2.5936e-02, -3.3359e-03, -2.2859e-02, -2.4441e-02,\n",
      "         2.3989e-02, -3.0781e-02,  9.2215e-03,  2.4930e-02,  2.5386e-02,\n",
      "         3.5322e-03,  7.8843e-04,  1.1688e-02,  3.0926e-02, -2.2096e-02,\n",
      "        -2.3504e-02, -2.3436e-02, -1.4978e-02,  2.4572e-02, -4.0391e-03,\n",
      "         4.0202e-04, -1.9406e-02, -2.7203e-02,  2.3119e-02,  9.2049e-03,\n",
      "         1.4550e-02, -2.4729e-02,  1.0329e-03,  1.5457e-02,  6.1357e-03,\n",
      "        -2.9203e-02,  2.4696e-02, -3.1207e-02,  8.7495e-03,  2.7124e-02,\n",
      "        -7.2365e-05, -2.0754e-02, -2.4701e-03, -1.8434e-02,  2.4522e-02,\n",
      "        -1.0640e-02,  2.5077e-02, -7.0451e-03, -8.3573e-03, -2.5779e-02,\n",
      "         7.9028e-03,  2.6724e-02,  1.3198e-02,  9.2592e-03, -2.4277e-02,\n",
      "         2.0030e-02, -3.5102e-03,  2.1107e-02,  2.8040e-02,  2.0812e-02,\n",
      "        -2.0223e-02,  9.3715e-04,  7.1516e-03,  2.9188e-02, -6.0648e-03,\n",
      "        -1.5038e-02,  7.8669e-03, -1.2522e-02, -2.5133e-02,  8.4723e-03,\n",
      "        -2.1438e-02,  1.8364e-02, -1.4178e-02,  2.5599e-02,  1.6589e-02,\n",
      "         2.8380e-02, -2.0945e-02,  1.2777e-03,  2.1489e-02,  5.5441e-04,\n",
      "         2.4211e-02,  2.0600e-02, -1.5841e-02,  1.1141e-03,  7.0636e-03,\n",
      "        -2.1542e-02, -2.9575e-03,  4.1874e-03,  2.6713e-02, -2.2900e-04,\n",
      "        -2.2287e-02, -3.9466e-03, -1.1817e-03,  1.2094e-02, -1.7372e-02,\n",
      "         2.6832e-02, -1.0189e-02,  2.5526e-02, -1.1289e-02, -1.6093e-02,\n",
      "        -2.1589e-02,  1.6736e-02, -2.0998e-02,  4.4668e-03, -1.2070e-02,\n",
      "         1.3912e-02, -2.1020e-02, -2.6148e-02,  1.6648e-02, -1.5194e-02,\n",
      "         1.2922e-02, -1.0622e-02,  1.2314e-02,  2.4358e-02, -1.7899e-02,\n",
      "        -2.9625e-02,  2.0967e-02,  2.3681e-02,  3.0410e-02,  3.2262e-03,\n",
      "        -2.4063e-02,  1.2880e-02,  1.1724e-02,  1.6051e-02,  3.8950e-03,\n",
      "        -3.7258e-03], device='cuda:0', requires_grad=True))\n",
      "('5.3.conv2.weight', Parameter containing:\n",
      "tensor([[[ 6.5413e-03, -1.8625e-02, -4.9491e-02],\n",
      "         [-6.3171e-03,  4.2666e-02, -6.1595e-02],\n",
      "         [ 4.5329e-02,  2.5043e-02, -4.0416e-02],\n",
      "         ...,\n",
      "         [-5.8088e-02,  4.1698e-03, -3.1902e-02],\n",
      "         [ 4.8782e-02, -1.0077e-02, -4.7942e-02],\n",
      "         [ 4.2764e-02,  7.2036e-02,  5.4941e-02]],\n",
      "\n",
      "        [[-4.3511e-02,  4.4351e-02, -1.4713e-02],\n",
      "         [-6.8375e-02, -1.8383e-02, -2.7463e-02],\n",
      "         [ 8.4709e-02,  3.6001e-03, -4.0073e-02],\n",
      "         ...,\n",
      "         [-2.6222e-02,  3.2368e-02,  1.8584e-03],\n",
      "         [-4.2890e-02, -4.1115e-02,  1.0352e-02],\n",
      "         [-6.0048e-04, -3.9563e-02,  6.7170e-02]],\n",
      "\n",
      "        [[-3.4915e-03,  7.8920e-03,  6.0961e-02],\n",
      "         [ 4.6044e-03,  4.3233e-02, -9.2212e-04],\n",
      "         [-1.2338e-02,  2.3190e-02,  3.5893e-03],\n",
      "         ...,\n",
      "         [ 2.4931e-02,  3.1527e-02, -5.1285e-02],\n",
      "         [ 1.7513e-02, -4.2482e-02,  5.5858e-02],\n",
      "         [ 1.0061e-03,  2.7783e-02,  6.6232e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1002e-02, -2.2406e-02, -4.3699e-02],\n",
      "         [-3.3056e-03,  1.3430e-02, -2.3257e-02],\n",
      "         [-1.1270e-02,  6.0488e-02,  7.7418e-05],\n",
      "         ...,\n",
      "         [ 5.5892e-02, -1.6456e-02,  3.8541e-02],\n",
      "         [ 2.1239e-02,  8.3112e-03, -6.6574e-02],\n",
      "         [-3.1175e-02,  5.5459e-02,  2.9389e-02]],\n",
      "\n",
      "        [[-4.4069e-02,  3.3499e-02,  4.2528e-02],\n",
      "         [-3.9123e-02,  4.9566e-02, -3.0213e-02],\n",
      "         [-1.4852e-02, -7.9500e-03, -8.9324e-03],\n",
      "         ...,\n",
      "         [ 7.0200e-02,  4.5401e-02,  1.4233e-03],\n",
      "         [ 8.5332e-03, -1.7136e-02, -8.5108e-02],\n",
      "         [-2.0966e-02,  1.2134e-02, -5.0854e-03]],\n",
      "\n",
      "        [[ 1.1107e-02,  4.6812e-02, -4.7323e-02],\n",
      "         [ 2.9775e-02,  2.7596e-02,  4.5573e-02],\n",
      "         [-6.6004e-02,  3.0310e-02,  2.8794e-02],\n",
      "         ...,\n",
      "         [ 1.4092e-02,  1.8642e-02, -1.4275e-02],\n",
      "         [ 1.0873e-01,  1.0299e-01, -3.3962e-02],\n",
      "         [-1.9911e-02, -9.0132e-03, -4.2213e-02]]], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('5.3.conv2.bias', Parameter containing:\n",
      "tensor([ 0.0038,  0.0038, -0.0260,  0.0333, -0.0053,  0.0184, -0.0134,  0.0331,\n",
      "        -0.0017,  0.0023, -0.0032,  0.0260,  0.0203, -0.0238,  0.0100, -0.0243,\n",
      "        -0.0185, -0.0335,  0.0306,  0.0338,  0.0271,  0.0267, -0.0181, -0.0262,\n",
      "         0.0132, -0.0170, -0.0175,  0.0262,  0.0117, -0.0319,  0.0324, -0.0296,\n",
      "        -0.0156, -0.0022, -0.0145,  0.0339,  0.0216,  0.0300,  0.0202,  0.0033,\n",
      "         0.0261,  0.0013,  0.0078,  0.0310, -0.0345,  0.0101,  0.0052, -0.0209,\n",
      "         0.0351,  0.0302,  0.0325,  0.0322,  0.0328,  0.0328, -0.0268,  0.0218,\n",
      "         0.0045, -0.0127,  0.0229,  0.0021,  0.0044, -0.0109,  0.0246,  0.0306,\n",
      "        -0.0175, -0.0151, -0.0261,  0.0186, -0.0152,  0.0253,  0.0048, -0.0272,\n",
      "         0.0137, -0.0068,  0.0046,  0.0040,  0.0354,  0.0167, -0.0297, -0.0338,\n",
      "         0.0118,  0.0248,  0.0108, -0.0256, -0.0193,  0.0135, -0.0165,  0.0179,\n",
      "        -0.0214, -0.0083, -0.0086,  0.0133,  0.0128, -0.0056, -0.0198, -0.0317,\n",
      "         0.0230, -0.0239, -0.0175,  0.0031, -0.0062, -0.0257,  0.0343,  0.0240,\n",
      "        -0.0323, -0.0233, -0.0241,  0.0027,  0.0169,  0.0179, -0.0122,  0.0053,\n",
      "        -0.0331,  0.0021, -0.0275, -0.0304,  0.0302,  0.0316, -0.0263,  0.0001,\n",
      "        -0.0002, -0.0133, -0.0052,  0.0193, -0.0139, -0.0189, -0.0078,  0.0030,\n",
      "        -0.0200, -0.0214,  0.0115,  0.0303, -0.0281,  0.0133,  0.0314,  0.0129,\n",
      "         0.0125, -0.0079, -0.0213,  0.0360,  0.0050, -0.0040,  0.0022,  0.0095,\n",
      "        -0.0346,  0.0033,  0.0213, -0.0163, -0.0142,  0.0301,  0.0147, -0.0195,\n",
      "        -0.0253, -0.0089, -0.0119,  0.0338, -0.0064, -0.0324, -0.0205, -0.0232,\n",
      "        -0.0211, -0.0139, -0.0033, -0.0175,  0.0275, -0.0202,  0.0343, -0.0249,\n",
      "        -0.0226, -0.0025,  0.0024,  0.0237, -0.0304, -0.0109, -0.0271,  0.0143,\n",
      "         0.0144, -0.0356,  0.0025,  0.0315, -0.0276,  0.0060, -0.0158, -0.0318,\n",
      "         0.0285,  0.0230,  0.0084, -0.0043,  0.0313, -0.0209,  0.0058, -0.0099,\n",
      "         0.0180, -0.0021,  0.0339,  0.0205, -0.0101, -0.0291,  0.0141,  0.0205,\n",
      "         0.0068, -0.0061,  0.0353,  0.0207, -0.0162,  0.0292,  0.0120,  0.0154,\n",
      "        -0.0193,  0.0292,  0.0193,  0.0252,  0.0070,  0.0096,  0.0190,  0.0014,\n",
      "        -0.0327,  0.0121, -0.0164, -0.0267,  0.0027,  0.0332,  0.0347,  0.0069,\n",
      "        -0.0342, -0.0029,  0.0357,  0.0059,  0.0147, -0.0162, -0.0242,  0.0199,\n",
      "        -0.0070,  0.0098, -0.0079, -0.0330,  0.0244,  0.0065, -0.0241, -0.0338,\n",
      "        -0.0281, -0.0213, -0.0314, -0.0033, -0.0051,  0.0221, -0.0183, -0.0357,\n",
      "         0.0187,  0.0111,  0.0208,  0.0322, -0.0266, -0.0242,  0.0231, -0.0125],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.3.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.0523],\n",
      "         [ 0.0135],\n",
      "         [-0.0677],\n",
      "         ...,\n",
      "         [-0.0583],\n",
      "         [-0.0284],\n",
      "         [ 0.0379]],\n",
      "\n",
      "        [[ 0.0401],\n",
      "         [-0.0034],\n",
      "         [ 0.0203],\n",
      "         ...,\n",
      "         [ 0.0406],\n",
      "         [-0.0104],\n",
      "         [-0.0063]],\n",
      "\n",
      "        [[-0.0249],\n",
      "         [ 0.0609],\n",
      "         [ 0.0604],\n",
      "         ...,\n",
      "         [-0.0409],\n",
      "         [ 0.0042],\n",
      "         [-0.0421]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0453],\n",
      "         [ 0.0981],\n",
      "         [-0.0244],\n",
      "         ...,\n",
      "         [ 0.0217],\n",
      "         [ 0.0878],\n",
      "         [ 0.0108]],\n",
      "\n",
      "        [[ 0.0050],\n",
      "         [-0.0460],\n",
      "         [ 0.0356],\n",
      "         ...,\n",
      "         [-0.0317],\n",
      "         [ 0.0369],\n",
      "         [ 0.0449]],\n",
      "\n",
      "        [[-0.0349],\n",
      "         [ 0.0223],\n",
      "         [-0.0638],\n",
      "         ...,\n",
      "         [-0.0384],\n",
      "         [ 0.0588],\n",
      "         [ 0.0728]]], device='cuda:0', requires_grad=True))\n",
      "('5.3.conv3.bias', Parameter containing:\n",
      "tensor([-0.0225,  0.0042,  0.0251,  ..., -0.0504,  0.0618,  0.0015],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.3.bn1.weight', Parameter containing:\n",
      "tensor([0.9748, 0.9940, 1.0427, 0.9596, 1.0335, 0.9271, 0.9864, 1.0102, 0.9998,\n",
      "        1.0358, 1.0255, 1.0156, 0.9678, 0.9759, 0.9644, 1.0152, 1.0319, 1.0689,\n",
      "        1.0281, 1.0724, 0.9493, 1.0001, 1.0114, 0.9685, 0.9971, 1.0376, 0.9612,\n",
      "        1.0450, 0.9969, 0.9883, 0.9285, 0.9711, 0.9420, 0.9378, 0.9752, 1.0151,\n",
      "        0.9831, 1.0048, 0.9599, 0.9744, 1.0084, 1.0244, 1.0140, 0.9722, 0.9763,\n",
      "        1.0364, 0.9769, 1.0091, 1.0025, 0.9957, 0.9852, 1.0071, 1.0010, 0.9884,\n",
      "        0.9593, 0.9675, 0.9603, 1.0047, 0.9685, 1.0347, 0.9609, 1.0622, 0.9526,\n",
      "        1.0374, 1.0238, 1.0270, 0.9888, 1.0135, 0.9558, 0.9908, 1.0227, 1.0499,\n",
      "        0.9867, 1.0312, 1.0081, 0.9766, 1.0453, 0.9672, 0.9720, 1.0067, 1.0375,\n",
      "        0.9896, 0.9896, 1.0007, 0.9733, 1.0085, 0.9851, 0.9874, 0.9751, 0.9592,\n",
      "        1.0172, 0.9350, 1.0013, 1.0629, 0.9993, 1.0425, 0.9633, 1.0470, 0.9617,\n",
      "        1.0040, 0.9453, 0.9840, 1.0331, 0.9789, 0.9887, 1.0529, 1.0063, 0.9783,\n",
      "        0.9597, 1.0088, 0.9973, 0.9747, 1.0266, 0.9966, 0.9468, 1.0006, 1.0353,\n",
      "        1.0302, 1.0108, 1.0101, 0.9875, 1.0315, 0.9972, 1.0189, 0.9871, 0.9647,\n",
      "        0.9742, 1.0114, 0.9882, 0.9735, 1.0490, 0.9798, 1.0481, 1.0141, 0.9716,\n",
      "        0.9706, 0.9745, 0.9921, 0.9234, 0.9747, 1.0167, 0.9736, 0.9979, 0.9457,\n",
      "        1.0167, 0.9929, 0.9667, 1.0255, 1.0587, 0.9651, 0.9696, 1.0098, 0.9816,\n",
      "        1.0041, 1.0196, 0.9951, 0.9744, 0.9937, 1.0396, 1.0212, 0.9767, 1.0163,\n",
      "        0.9783, 0.9426, 0.9765, 1.0173, 0.9918, 0.9799, 1.0142, 0.9436, 0.9663,\n",
      "        1.0133, 0.9875, 0.9657, 1.0168, 0.9800, 1.0052, 1.0037, 0.9871, 1.0428,\n",
      "        0.9995, 0.9802, 1.0519, 1.0240, 1.0291, 0.9923, 1.0218, 1.0063, 1.0200,\n",
      "        0.9926, 0.9836, 0.9993, 1.0205, 0.9625, 1.0611, 1.0147, 1.0598, 1.0008,\n",
      "        0.9561, 0.9915, 0.9706, 1.0003, 1.0111, 0.9526, 0.9852, 0.9925, 0.9705,\n",
      "        0.9724, 0.9899, 0.9775, 0.9591, 1.0056, 0.9854, 0.9746, 0.9328, 1.0180,\n",
      "        1.0167, 1.0432, 0.9994, 0.9760, 0.9670, 1.0074, 1.0655, 0.9996, 1.0155,\n",
      "        0.9284, 0.9642, 0.9513, 0.9655, 1.0374, 0.9699, 0.9360, 1.0180, 1.0700,\n",
      "        1.0245, 0.9946, 1.0352, 0.9709, 1.0233, 1.0561, 1.0569, 0.9941, 1.0251,\n",
      "        1.0428, 1.0168, 1.0169, 0.9725, 1.0229, 1.0523, 1.0633, 1.0007, 1.0046,\n",
      "        0.9738, 1.0062, 0.9942, 1.0147], device='cuda:0', requires_grad=True))\n",
      "('5.3.bn1.bias', Parameter containing:\n",
      "tensor([-0.0638, -0.0208, -0.0981, -0.0691, -0.0311, -0.1069, -0.0301, -0.0827,\n",
      "        -0.0935, -0.1131, -0.0589, -0.0702, -0.1145, -0.0971, -0.0527, -0.0951,\n",
      "        -0.0860, -0.1031, -0.1315, -0.0840, -0.0642, -0.0517, -0.0650, -0.0962,\n",
      "        -0.0806, -0.0498, -0.0835, -0.0882, -0.0659, -0.0692, -0.1010, -0.0622,\n",
      "        -0.0948, -0.0995, -0.0583, -0.1015, -0.0555, -0.0472, -0.1184, -0.0850,\n",
      "        -0.0807, -0.0772, -0.0459, -0.0920, -0.0728, -0.0601, -0.0927, -0.0558,\n",
      "        -0.0700, -0.0816, -0.0914, -0.0840, -0.0568, -0.0434, -0.0634, -0.0648,\n",
      "        -0.0570, -0.0531, -0.0905, -0.0881, -0.0338, -0.0414, -0.0978, -0.0284,\n",
      "        -0.0926, -0.0321, -0.0959, -0.0998, -0.0491, -0.0345, -0.0578, -0.0569,\n",
      "        -0.0946, -0.0777, -0.0660, -0.0661, -0.1110, -0.0726, -0.1073, -0.0754,\n",
      "        -0.0700, -0.0732, -0.0622, -0.0434, -0.0642, -0.0836, -0.0754, -0.0587,\n",
      "        -0.0839, -0.0882, -0.0842, -0.1031, -0.0454, -0.0744, -0.0480, -0.0599,\n",
      "        -0.0473, -0.0336, -0.0783, -0.0880, -0.0696, -0.1174, -0.0567, -0.0301,\n",
      "        -0.0353, -0.0431, -0.0811, -0.1130, -0.1054, -0.1067, -0.1148, -0.0700,\n",
      "        -0.0544, -0.0478, -0.0994, -0.0834, -0.0873, -0.0931, -0.0911, -0.0541,\n",
      "        -0.0963, -0.0618, -0.0479, -0.1305, -0.1034, -0.0822, -0.0882, -0.0985,\n",
      "        -0.0761, -0.1145, -0.0424, -0.1145, -0.0825, -0.0609, -0.1041, -0.1062,\n",
      "        -0.0664, -0.0780, -0.0808, -0.0022, -0.0494, -0.1204, -0.1067, -0.0906,\n",
      "        -0.0471, -0.0346, -0.1033, -0.0810, -0.0993, -0.0748, -0.1160, -0.1004,\n",
      "        -0.1193, -0.0563, -0.0625, -0.0843, -0.0724, -0.0728, -0.1129, -0.0596,\n",
      "        -0.0549, -0.0795, -0.0598, -0.0790, -0.0823, -0.0493, -0.0644, -0.1289,\n",
      "        -0.0815, -0.0713, -0.0843, -0.0483, -0.0347, -0.0806, -0.0716, -0.0483,\n",
      "        -0.0278, -0.0606, -0.0737, -0.0593, -0.0040, -0.0569, -0.0429, -0.0366,\n",
      "        -0.0782, -0.0808, -0.0485, -0.1026, -0.1016, -0.0540, -0.0585, -0.0277,\n",
      "        -0.0958, -0.0742, -0.0357, -0.0563, -0.0616, -0.0973, -0.1060, -0.0619,\n",
      "        -0.0522, -0.0748, -0.0712, -0.1020, -0.0927, -0.0852, -0.0892, -0.0858,\n",
      "        -0.0200, -0.0556, -0.0319, -0.0698, -0.0868, -0.0691, -0.1158, -0.0759,\n",
      "        -0.0319, -0.0383, -0.0771, -0.0473, -0.0579, -0.0815, -0.0854, -0.0593,\n",
      "        -0.0654, -0.0811, -0.1071, -0.0942, -0.0989, -0.0316, -0.1014, -0.1215,\n",
      "        -0.0668, -0.0915, -0.0194, -0.0873, -0.0727, -0.0929, -0.0816, -0.0957,\n",
      "        -0.0416, -0.0817, -0.0466, -0.0404, -0.0555, -0.0879, -0.0408, -0.0537,\n",
      "        -0.0286, -0.0104, -0.0050, -0.0154, -0.0996, -0.0502, -0.1008, -0.0937],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.3.bn2.weight', Parameter containing:\n",
      "tensor([1.0047, 0.9952, 0.9896, 0.9909, 0.9855, 0.9720, 1.0317, 0.9815, 1.0316,\n",
      "        1.0096, 0.9747, 0.9711, 0.9876, 1.0020, 1.0234, 0.9845, 1.0327, 0.9710,\n",
      "        0.9951, 1.0055, 0.9791, 1.0077, 0.9935, 0.9980, 0.9581, 0.9751, 0.9755,\n",
      "        1.0118, 0.9657, 1.0134, 0.9965, 1.0283, 1.0049, 1.0273, 1.0223, 0.9630,\n",
      "        0.9963, 0.9537, 1.0015, 0.9847, 0.9827, 1.0119, 1.0194, 0.9746, 0.9857,\n",
      "        1.0377, 1.0060, 1.0293, 0.9906, 1.0240, 0.9831, 1.0376, 1.0284, 0.9763,\n",
      "        1.0263, 1.0099, 0.9904, 1.0297, 1.0339, 0.9807, 0.9838, 1.0155, 1.0209,\n",
      "        0.9815, 0.9937, 1.0168, 0.9524, 0.9824, 0.9608, 1.0374, 0.9849, 0.9665,\n",
      "        0.9718, 0.9652, 1.0247, 1.0131, 0.9918, 0.9907, 0.9771, 1.0340, 0.9882,\n",
      "        1.0134, 0.9740, 1.0019, 0.9873, 1.0036, 1.0166, 0.9906, 1.0354, 0.9597,\n",
      "        0.9787, 1.0157, 0.9912, 0.9899, 1.0219, 0.9682, 1.0123, 0.9935, 0.9770,\n",
      "        0.9627, 0.9979, 0.9812, 0.9634, 1.0128, 1.0058, 0.9876, 0.9990, 1.0111,\n",
      "        0.9563, 0.9836, 1.0355, 1.0108, 1.0045, 0.9780, 1.0022, 1.0289, 0.9745,\n",
      "        1.0116, 0.9752, 1.0644, 0.9971, 0.9837, 0.9973, 1.0194, 1.0241, 0.9978,\n",
      "        0.9784, 0.9947, 1.0232, 0.9664, 1.0191, 1.0365, 0.9942, 0.9743, 0.9811,\n",
      "        0.9889, 0.9677, 0.9575, 0.9819, 0.9768, 1.0535, 0.9984, 1.0225, 1.0044,\n",
      "        0.9946, 0.9641, 1.0074, 0.9474, 0.9981, 1.0116, 1.0155, 1.0236, 0.9779,\n",
      "        1.0026, 0.9905, 1.0016, 0.9676, 1.0043, 0.9913, 0.9560, 1.0255, 0.9911,\n",
      "        0.9796, 0.9559, 0.9976, 0.9865, 0.9703, 0.9801, 1.0182, 0.9926, 0.9964,\n",
      "        0.9980, 1.0459, 0.9603, 0.9645, 1.0202, 1.0029, 1.0333, 0.9981, 0.9643,\n",
      "        0.9697, 0.9874, 0.9911, 1.0527, 1.0119, 0.9894, 1.0306, 0.9829, 1.0343,\n",
      "        1.0361, 1.0017, 1.0011, 1.0218, 1.0319, 1.0274, 1.0503, 0.9795, 0.9586,\n",
      "        1.0257, 1.0138, 1.0136, 1.0819, 1.0307, 1.0028, 0.9919, 0.9766, 1.0222,\n",
      "        1.0180, 1.0087, 0.9721, 0.9749, 0.9772, 1.0210, 0.9755, 1.0080, 1.0007,\n",
      "        1.0273, 0.9874, 0.9996, 0.9885, 0.9866, 0.9997, 1.0074, 0.9941, 1.0691,\n",
      "        0.9736, 0.9816, 0.9844, 0.9783, 0.9901, 1.0103, 0.9761, 0.9670, 0.9820,\n",
      "        0.9955, 0.9998, 0.9925, 0.9780, 0.9813, 1.0388, 0.9767, 0.9976, 0.9805,\n",
      "        1.0238, 1.0198, 0.9556, 0.9929, 1.0002, 0.9617, 1.0117, 0.9933, 0.9738,\n",
      "        0.9929, 1.0063, 1.0264, 1.0243], device='cuda:0', requires_grad=True))\n",
      "('5.3.bn2.bias', Parameter containing:\n",
      "tensor([-0.0557, -0.1123, -0.0961, -0.0724, -0.0947, -0.0921, -0.1175, -0.0923,\n",
      "        -0.0859, -0.1089, -0.0809, -0.0683, -0.0861, -0.0582, -0.0531, -0.0621,\n",
      "        -0.0653, -0.0665, -0.0916, -0.0510, -0.0865, -0.0542, -0.0629, -0.1215,\n",
      "        -0.0699, -0.0454, -0.0760, -0.1043, -0.0954, -0.0619, -0.0967, -0.0832,\n",
      "        -0.0704, -0.0942, -0.0259, -0.0842, -0.0819, -0.0904, -0.0593, -0.0345,\n",
      "        -0.0367, -0.0446, -0.1188, -0.0527, -0.1002, -0.0543, -0.0638, -0.0252,\n",
      "        -0.0652, -0.0860, -0.0659, -0.0324, -0.0474, -0.0794, -0.0704, -0.0437,\n",
      "        -0.0632, -0.0416, -0.0828, -0.0382, -0.0589, -0.0622, -0.1040, -0.0656,\n",
      "        -0.0896, -0.0843, -0.0699, -0.0488, -0.0996, -0.0879, -0.1130, -0.1009,\n",
      "        -0.0931, -0.0544, -0.0041, -0.1067, -0.0644, -0.0512, -0.0990, -0.0901,\n",
      "        -0.0385, -0.0591, -0.1049, -0.0643, -0.0469, -0.0835, -0.0873, -0.0464,\n",
      "        -0.0815, -0.0587, -0.0356, -0.1137, -0.0722, -0.1110, -0.0537, -0.1022,\n",
      "        -0.0802, -0.0728, -0.0960, -0.0875, -0.0923, -0.0697, -0.0684, -0.0833,\n",
      "        -0.0486, -0.0492, -0.1126, -0.0737, -0.0562, -0.0797, -0.0323, -0.0449,\n",
      "        -0.0793, -0.0967, -0.0773, -0.0912, -0.0570, -0.0629, -0.0485, -0.0465,\n",
      "        -0.0889, -0.0464, -0.1027, -0.0679, -0.1104, -0.0682, -0.1037, -0.1005,\n",
      "        -0.0738, -0.0591, -0.0292, -0.0975, -0.0928, -0.0691, -0.0585, -0.0936,\n",
      "        -0.0663, -0.1251, -0.0481, -0.0759, -0.0370, -0.0524, -0.0228, -0.0627,\n",
      "        -0.0645, -0.0732, -0.0660, -0.0789, -0.0503, -0.1126, -0.0504, -0.0892,\n",
      "        -0.0982, -0.0522, -0.1075, -0.0819, -0.1282, -0.0586, -0.0711, -0.0536,\n",
      "        -0.0961, -0.0690, -0.0498, -0.0777, -0.0955, -0.0583, -0.0288, -0.0464,\n",
      "        -0.0685, -0.0564, -0.1136, -0.0906, -0.0723, -0.1056, -0.0441, -0.0326,\n",
      "        -0.1179, -0.0848, -0.0985, -0.0575, -0.1224, -0.1208, -0.0714, -0.0701,\n",
      "        -0.0792, -0.0996, -0.1201, -0.0791, -0.0864, -0.1298, -0.0845, -0.0907,\n",
      "        -0.1034, -0.0275, -0.0869, -0.0548, -0.0934, -0.0757, -0.0980, -0.1030,\n",
      "        -0.0691, -0.0615, -0.0564, -0.0663, -0.0526, -0.0658, -0.0597, -0.1251,\n",
      "        -0.0568, -0.0640, -0.1292, -0.0976, -0.0139, -0.1158, -0.0790, -0.0706,\n",
      "        -0.1255, -0.0798, -0.0469, -0.0474, -0.0987, -0.0631, -0.0469, -0.0922,\n",
      "        -0.0762, -0.0681, -0.0797, -0.1556, -0.1255, -0.0485, -0.0855, -0.1041,\n",
      "        -0.0860, -0.0523, -0.1175, -0.0489, -0.0703, -0.0465, -0.0676, -0.0408,\n",
      "        -0.0935, -0.0730, -0.0331, -0.0690, -0.0581, -0.1050, -0.0362, -0.0884,\n",
      "        -0.0576, -0.0999, -0.0541, -0.0555, -0.0308, -0.1228, -0.0774, -0.0667],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.3.bn3.weight', Parameter containing:\n",
      "tensor([1.0177, 0.9966, 1.0146,  ..., 1.0039, 1.0072, 0.8957], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('5.3.bn3.bias', Parameter containing:\n",
      "tensor([ 0.0075, -0.0043, -0.0049,  ..., -0.0055, -0.0127, -0.0008],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.4.conv1.weight', Parameter containing:\n",
      "tensor([[[ 0.0247],\n",
      "         [ 0.0025],\n",
      "         [ 0.0023],\n",
      "         ...,\n",
      "         [-0.0406],\n",
      "         [-0.0254],\n",
      "         [ 0.0426]],\n",
      "\n",
      "        [[ 0.0095],\n",
      "         [ 0.0427],\n",
      "         [ 0.0158],\n",
      "         ...,\n",
      "         [-0.0357],\n",
      "         [ 0.0249],\n",
      "         [-0.0163]],\n",
      "\n",
      "        [[-0.0110],\n",
      "         [ 0.0543],\n",
      "         [ 0.0293],\n",
      "         ...,\n",
      "         [-0.0188],\n",
      "         [-0.0109],\n",
      "         [-0.0047]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0129],\n",
      "         [ 0.0184],\n",
      "         [-0.0129],\n",
      "         ...,\n",
      "         [ 0.0182],\n",
      "         [-0.0142],\n",
      "         [-0.0388]],\n",
      "\n",
      "        [[ 0.0158],\n",
      "         [ 0.0147],\n",
      "         [ 0.0111],\n",
      "         ...,\n",
      "         [-0.0179],\n",
      "         [-0.0243],\n",
      "         [-0.0130]],\n",
      "\n",
      "        [[-0.0250],\n",
      "         [-0.0102],\n",
      "         [ 0.0109],\n",
      "         ...,\n",
      "         [ 0.0021],\n",
      "         [-0.0195],\n",
      "         [-0.0366]]], device='cuda:0', requires_grad=True))\n",
      "('5.4.conv1.bias', Parameter containing:\n",
      "tensor([-0.0305, -0.0225, -0.0024, -0.0123,  0.0301,  0.0025,  0.0144,  0.0196,\n",
      "        -0.0139,  0.0180,  0.0288, -0.0231, -0.0123,  0.0066, -0.0088, -0.0177,\n",
      "        -0.0185,  0.0096, -0.0207, -0.0268, -0.0117,  0.0099, -0.0282,  0.0155,\n",
      "         0.0019,  0.0281,  0.0061,  0.0089, -0.0008, -0.0001,  0.0292,  0.0085,\n",
      "         0.0301,  0.0165, -0.0092, -0.0085,  0.0007,  0.0080,  0.0293, -0.0074,\n",
      "         0.0138, -0.0300,  0.0245,  0.0306,  0.0121, -0.0106,  0.0057, -0.0163,\n",
      "         0.0126, -0.0162,  0.0087,  0.0280, -0.0057, -0.0044,  0.0082,  0.0073,\n",
      "        -0.0193, -0.0187, -0.0052, -0.0160, -0.0008, -0.0157,  0.0061, -0.0104,\n",
      "         0.0038,  0.0211,  0.0036,  0.0128,  0.0308, -0.0208, -0.0214, -0.0156,\n",
      "        -0.0148,  0.0006, -0.0060, -0.0160,  0.0269, -0.0310, -0.0255, -0.0178,\n",
      "        -0.0167,  0.0066, -0.0087,  0.0169,  0.0218,  0.0278,  0.0302,  0.0037,\n",
      "         0.0056,  0.0302,  0.0018,  0.0274, -0.0073, -0.0281,  0.0115, -0.0094,\n",
      "         0.0248,  0.0227,  0.0163,  0.0271, -0.0190,  0.0213, -0.0007, -0.0225,\n",
      "         0.0073,  0.0129, -0.0236,  0.0281,  0.0040,  0.0218, -0.0045, -0.0192,\n",
      "        -0.0298, -0.0079,  0.0046, -0.0019, -0.0260,  0.0230, -0.0246,  0.0308,\n",
      "        -0.0305,  0.0160,  0.0204,  0.0278, -0.0008, -0.0026,  0.0311, -0.0089,\n",
      "        -0.0253, -0.0115, -0.0175, -0.0242,  0.0026,  0.0202,  0.0143, -0.0253,\n",
      "        -0.0277,  0.0006,  0.0304,  0.0298,  0.0027,  0.0247,  0.0144, -0.0200,\n",
      "         0.0114, -0.0156, -0.0224,  0.0040, -0.0149, -0.0078,  0.0236, -0.0041,\n",
      "         0.0156,  0.0304,  0.0300,  0.0117,  0.0170, -0.0095,  0.0211,  0.0261,\n",
      "        -0.0204, -0.0093,  0.0036, -0.0226,  0.0143,  0.0007,  0.0093, -0.0126,\n",
      "        -0.0108,  0.0082, -0.0218, -0.0038, -0.0077, -0.0266,  0.0251,  0.0103,\n",
      "        -0.0304, -0.0122,  0.0230,  0.0141,  0.0192,  0.0297,  0.0230,  0.0154,\n",
      "        -0.0052,  0.0159,  0.0102,  0.0305,  0.0261,  0.0233,  0.0173,  0.0128,\n",
      "         0.0070,  0.0276,  0.0073,  0.0201,  0.0181,  0.0142, -0.0186,  0.0044,\n",
      "        -0.0065,  0.0084,  0.0189,  0.0299, -0.0171,  0.0011,  0.0112, -0.0235,\n",
      "        -0.0061, -0.0092, -0.0207,  0.0058, -0.0246,  0.0177,  0.0232, -0.0107,\n",
      "         0.0206,  0.0061,  0.0218,  0.0171,  0.0048, -0.0235, -0.0143,  0.0230,\n",
      "         0.0189,  0.0209,  0.0271, -0.0045,  0.0046,  0.0293,  0.0109,  0.0177,\n",
      "         0.0154, -0.0068, -0.0278, -0.0172,  0.0015,  0.0080, -0.0076, -0.0219,\n",
      "        -0.0208, -0.0029,  0.0132, -0.0174, -0.0131, -0.0218, -0.0298,  0.0193,\n",
      "         0.0297, -0.0271,  0.0110, -0.0014,  0.0296,  0.0229,  0.0083,  0.0268],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.4.conv2.weight', Parameter containing:\n",
      "tensor([[[ 0.0243, -0.0131, -0.0010],\n",
      "         [-0.0030,  0.0417, -0.0423],\n",
      "         [-0.0429,  0.0239,  0.0064],\n",
      "         ...,\n",
      "         [ 0.0183, -0.0326,  0.0098],\n",
      "         [-0.0374, -0.0307,  0.0106],\n",
      "         [ 0.0256, -0.0108,  0.0058]],\n",
      "\n",
      "        [[-0.0083, -0.0507,  0.0096],\n",
      "         [ 0.0326,  0.0264,  0.0242],\n",
      "         [-0.0208, -0.0298,  0.0416],\n",
      "         ...,\n",
      "         [-0.0408,  0.0178,  0.0079],\n",
      "         [-0.0163,  0.0069, -0.0006],\n",
      "         [ 0.0563,  0.0144,  0.0756]],\n",
      "\n",
      "        [[ 0.0492, -0.1000,  0.0220],\n",
      "         [-0.0289,  0.0605,  0.0754],\n",
      "         [ 0.0154,  0.0168, -0.0965],\n",
      "         ...,\n",
      "         [ 0.0006,  0.0682, -0.0314],\n",
      "         [ 0.0130,  0.0081, -0.0048],\n",
      "         [ 0.0700,  0.0070, -0.0534]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0112,  0.0319,  0.0166],\n",
      "         [-0.0033,  0.0301, -0.0048],\n",
      "         [ 0.0128, -0.0416, -0.0138],\n",
      "         ...,\n",
      "         [-0.0308, -0.0184, -0.0415],\n",
      "         [ 0.0092,  0.0162,  0.0139],\n",
      "         [-0.0138,  0.0098, -0.0137]],\n",
      "\n",
      "        [[-0.0108, -0.0341,  0.0006],\n",
      "         [ 0.0189, -0.0010, -0.0547],\n",
      "         [-0.0460, -0.0312,  0.0572],\n",
      "         ...,\n",
      "         [ 0.0368, -0.0304, -0.0271],\n",
      "         [-0.0113, -0.0146, -0.0368],\n",
      "         [-0.0136,  0.0101,  0.0576]],\n",
      "\n",
      "        [[ 0.0038,  0.0508,  0.0395],\n",
      "         [ 0.0382, -0.0059,  0.0403],\n",
      "         [ 0.0590,  0.0360,  0.0701],\n",
      "         ...,\n",
      "         [ 0.0352, -0.0527,  0.0301],\n",
      "         [-0.0325, -0.0302,  0.0118],\n",
      "         [ 0.0141,  0.0366,  0.0067]]], device='cuda:0', requires_grad=True))\n",
      "('5.4.conv2.bias', Parameter containing:\n",
      "tensor([-1.6066e-02, -2.7384e-02, -3.5771e-02, -2.7750e-02,  2.9618e-02,\n",
      "         2.8552e-02, -6.2632e-03, -1.0035e-02, -2.7941e-02,  7.7074e-03,\n",
      "         1.0032e-02, -1.5202e-02, -3.1782e-02,  3.4938e-02,  1.4060e-02,\n",
      "         4.7528e-03, -3.4698e-02, -2.0801e-02,  7.4263e-03, -1.7163e-02,\n",
      "        -1.2157e-02, -5.8046e-05,  1.6298e-02,  2.1137e-02,  1.4860e-02,\n",
      "        -7.2466e-03, -7.1769e-03,  6.0529e-03, -1.5895e-03,  1.3066e-02,\n",
      "        -2.4002e-02,  1.9174e-02,  3.2915e-02, -6.8003e-03, -6.9692e-03,\n",
      "         6.1261e-03,  5.9966e-03,  6.6321e-03, -1.9235e-02,  3.1410e-02,\n",
      "         1.6260e-02, -1.6328e-02,  1.6142e-02, -1.3850e-02,  5.7795e-03,\n",
      "         2.0073e-03,  3.1370e-02,  4.2546e-03,  3.4743e-02,  3.4594e-02,\n",
      "         3.5112e-03,  4.1497e-03, -2.7328e-02, -2.6879e-03,  2.2521e-02,\n",
      "        -1.6955e-02,  1.2177e-02,  2.3083e-02, -9.5990e-04,  1.4150e-02,\n",
      "        -2.9526e-02,  3.0982e-02, -1.6388e-02,  1.6650e-02,  2.3909e-02,\n",
      "         2.6243e-02, -3.5235e-03,  1.0389e-02,  2.8806e-03, -3.2732e-03,\n",
      "        -2.9699e-02, -2.9570e-02,  1.1233e-02, -1.4049e-02,  3.3071e-02,\n",
      "         1.8201e-02,  1.1142e-02, -2.9422e-02,  1.4906e-02, -2.1384e-02,\n",
      "         1.1592e-02,  3.0464e-02,  2.4665e-02, -1.0073e-02,  6.4802e-03,\n",
      "        -1.3034e-02, -1.6536e-02,  2.2133e-02,  8.8603e-03, -1.3692e-02,\n",
      "         7.0680e-03,  1.8797e-02, -1.2253e-02,  2.4176e-02,  2.0504e-02,\n",
      "        -3.1751e-02, -7.0550e-03,  8.8200e-03, -2.3307e-02, -1.5745e-02,\n",
      "         1.8917e-02,  7.0536e-03, -1.3162e-02, -1.0849e-02, -2.0159e-02,\n",
      "         3.3447e-02,  2.1134e-02,  7.8983e-03,  3.0866e-03,  2.9882e-03,\n",
      "         2.1725e-02, -9.7333e-03, -1.8951e-03, -1.0257e-02,  7.4404e-03,\n",
      "         2.1223e-03, -7.6146e-03,  2.8239e-04, -2.5396e-02,  3.3769e-02,\n",
      "         2.0184e-02, -1.5405e-02,  3.4974e-02,  8.9883e-03,  1.2861e-02,\n",
      "         2.9399e-02,  3.2111e-02, -3.3509e-02,  2.3627e-03,  3.1528e-02,\n",
      "         2.4731e-02, -2.7342e-02, -2.6992e-02, -1.9158e-02,  2.5654e-02,\n",
      "         1.3661e-02,  9.6233e-04, -1.9629e-02, -1.6368e-02, -1.2376e-02,\n",
      "        -3.3022e-02,  3.9395e-03,  2.2961e-02,  3.0653e-02,  1.7128e-02,\n",
      "        -2.2579e-02, -1.4545e-02,  2.8130e-02,  9.9986e-03, -3.1919e-02,\n",
      "        -9.1171e-03, -2.4730e-02,  2.8770e-02, -2.2535e-02, -1.1837e-02,\n",
      "         1.9484e-02, -3.2721e-02,  1.6284e-03, -8.2267e-03,  1.8749e-02,\n",
      "        -1.6393e-02,  2.8791e-02, -5.7460e-03,  7.1452e-03, -1.3479e-02,\n",
      "        -4.7964e-03, -2.2372e-02, -2.3855e-02,  2.1455e-02,  2.7379e-02,\n",
      "         2.7956e-02, -4.0474e-04,  2.8577e-02,  9.8041e-03, -1.5852e-02,\n",
      "        -3.4853e-03,  1.4465e-02,  6.9082e-03,  3.0025e-02, -2.2935e-02,\n",
      "         1.4290e-02,  2.8400e-02, -2.9577e-02, -3.5162e-02,  1.9393e-02,\n",
      "        -3.1843e-02, -2.4941e-02,  3.1264e-02, -2.5128e-02, -2.6434e-03,\n",
      "         3.2414e-02, -1.5426e-02, -2.0648e-02, -9.6480e-03,  2.8010e-02,\n",
      "         5.8345e-03,  1.6604e-02, -3.4578e-02,  2.3658e-02, -2.4561e-02,\n",
      "         2.7670e-02, -4.9276e-03,  9.0121e-03,  3.2518e-02,  1.6925e-02,\n",
      "        -4.4173e-03, -1.2023e-02, -1.2336e-02, -3.1286e-02, -2.5270e-02,\n",
      "         9.8914e-03, -2.1766e-02,  9.5352e-03,  1.9441e-02, -1.3063e-02,\n",
      "         2.7840e-02, -3.2736e-02, -1.8453e-02, -3.5672e-02, -1.4458e-02,\n",
      "         9.6403e-03, -1.7272e-04, -3.4367e-02,  3.4107e-02,  2.2816e-02,\n",
      "        -1.2748e-02, -1.6336e-02,  1.1247e-03, -3.2299e-02,  2.9336e-02,\n",
      "        -4.5572e-04, -3.4460e-02,  1.7283e-02, -1.9283e-02,  1.3578e-03,\n",
      "        -2.0657e-02, -2.3363e-02,  3.3193e-02, -5.5139e-03, -2.0427e-02,\n",
      "         6.8267e-03,  3.3563e-02, -3.3403e-03, -3.2316e-02, -1.9990e-02,\n",
      "        -3.5350e-02, -1.5073e-02,  4.4820e-03,  3.4511e-02, -1.1215e-02,\n",
      "         2.3122e-02,  1.6858e-02,  8.8070e-03, -1.2864e-02, -2.9615e-02,\n",
      "        -2.7591e-02], device='cuda:0', requires_grad=True))\n",
      "('5.4.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.0595],\n",
      "         [-0.0035],\n",
      "         [-0.0352],\n",
      "         ...,\n",
      "         [ 0.0420],\n",
      "         [-0.0257],\n",
      "         [ 0.0646]],\n",
      "\n",
      "        [[-0.0419],\n",
      "         [ 0.0030],\n",
      "         [ 0.0233],\n",
      "         ...,\n",
      "         [ 0.0574],\n",
      "         [-0.0191],\n",
      "         [-0.0209]],\n",
      "\n",
      "        [[-0.0108],\n",
      "         [ 0.0575],\n",
      "         [-0.0404],\n",
      "         ...,\n",
      "         [-0.0576],\n",
      "         [ 0.0207],\n",
      "         [ 0.0343]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0386],\n",
      "         [ 0.0068],\n",
      "         [ 0.0699],\n",
      "         ...,\n",
      "         [ 0.0633],\n",
      "         [ 0.0097],\n",
      "         [ 0.0371]],\n",
      "\n",
      "        [[ 0.0241],\n",
      "         [-0.0382],\n",
      "         [ 0.0235],\n",
      "         ...,\n",
      "         [ 0.0190],\n",
      "         [ 0.0426],\n",
      "         [ 0.0264]],\n",
      "\n",
      "        [[-0.0266],\n",
      "         [-0.0460],\n",
      "         [ 0.0235],\n",
      "         ...,\n",
      "         [ 0.0254],\n",
      "         [ 0.0432],\n",
      "         [-0.0262]]], device='cuda:0', requires_grad=True))\n",
      "('5.4.conv3.bias', Parameter containing:\n",
      "tensor([-0.0141, -0.0153,  0.0310,  ..., -0.0128,  0.0485,  0.0362],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.4.bn1.weight', Parameter containing:\n",
      "tensor([1.0241, 1.0152, 0.9791, 1.0142, 1.0161, 0.9891, 0.9905, 1.0669, 0.9911,\n",
      "        0.9289, 0.9855, 1.0093, 1.0102, 1.0366, 0.9699, 1.0053, 1.0021, 1.0091,\n",
      "        0.9654, 0.9905, 0.9840, 1.0022, 1.0291, 0.9818, 1.0065, 1.0319, 1.0123,\n",
      "        1.0029, 0.9920, 0.9893, 1.0272, 0.9822, 1.0364, 0.9516, 0.9637, 1.0299,\n",
      "        0.9851, 1.0188, 1.0402, 0.9845, 0.9867, 1.0141, 0.9965, 1.0193, 0.9939,\n",
      "        1.0562, 1.0272, 1.0095, 0.9941, 0.9864, 1.0000, 0.9755, 1.0078, 0.9832,\n",
      "        1.0001, 0.9558, 1.0199, 1.0273, 0.9954, 0.9615, 0.9722, 0.9802, 1.0014,\n",
      "        1.0127, 1.0182, 1.0200, 0.9695, 0.9703, 1.0369, 1.0078, 1.0078, 0.9820,\n",
      "        1.0061, 1.0253, 1.0283, 1.0655, 1.0179, 0.9695, 1.0305, 0.9584, 0.9455,\n",
      "        1.0664, 1.0216, 1.0158, 1.0084, 1.0362, 1.0021, 1.0239, 1.0963, 1.0428,\n",
      "        1.0075, 1.0113, 1.0116, 1.0078, 0.9903, 1.0149, 1.0221, 1.0086, 0.9848,\n",
      "        0.9517, 1.0108, 1.0047, 0.9581, 0.9956, 0.9888, 0.9893, 1.0223, 0.9663,\n",
      "        0.9612, 1.0118, 0.9542, 0.9346, 0.9508, 0.9734, 1.0715, 0.9950, 0.9809,\n",
      "        0.9761, 0.9884, 0.9907, 0.9936, 0.9941, 0.9604, 0.9860, 0.9600, 1.0426,\n",
      "        0.9662, 1.0317, 1.0044, 0.9696, 0.9750, 0.9908, 0.9483, 0.9411, 0.9813,\n",
      "        0.9887, 0.9908, 0.9797, 0.9897, 0.9924, 1.0454, 0.9861, 1.0163, 0.9923,\n",
      "        1.0127, 0.9736, 0.9735, 1.0077, 0.9949, 0.9691, 0.9623, 1.0262, 1.0241,\n",
      "        1.0330, 0.9900, 1.0151, 1.0105, 1.0371, 0.9519, 1.0282, 1.0006, 1.0207,\n",
      "        0.9901, 1.0116, 1.0167, 0.9540, 0.9602, 1.0709, 0.9661, 0.9870, 0.9965,\n",
      "        0.9842, 1.0232, 1.0346, 1.0187, 0.9887, 0.9549, 0.9918, 0.9668, 1.0332,\n",
      "        1.0131, 1.0284, 1.0841, 0.9738, 0.9842, 0.9808, 0.9946, 0.9855, 0.9911,\n",
      "        0.9619, 1.0016, 0.9488, 1.0229, 0.9742, 0.9807, 1.0018, 0.9985, 0.9729,\n",
      "        1.0040, 1.0086, 0.9537, 0.9640, 1.0231, 0.9728, 1.0211, 1.0035, 1.0209,\n",
      "        0.9776, 0.9401, 1.0404, 1.0192, 1.0231, 1.0112, 1.0251, 0.9794, 1.0004,\n",
      "        0.9978, 0.9924, 1.0321, 1.0061, 1.0105, 1.0105, 0.9651, 1.1049, 1.0210,\n",
      "        1.0012, 0.9886, 0.9749, 0.9466, 0.9837, 0.9647, 0.9543, 0.9737, 0.9639,\n",
      "        1.0047, 0.9988, 0.9593, 1.0112, 1.0039, 1.0641, 1.0086, 0.9941, 0.9682,\n",
      "        1.0133, 0.9679, 1.0048, 0.9711, 0.9889, 0.9924, 0.9868, 0.9638, 1.0069,\n",
      "        1.0236, 0.9825, 0.9683, 1.0201], device='cuda:0', requires_grad=True))\n",
      "('5.4.bn1.bias', Parameter containing:\n",
      "tensor([-0.0492, -0.0546, -0.0827, -0.0769, -0.0121, -0.0828, -0.0764, -0.0386,\n",
      "        -0.0886, -0.1125, -0.0702, -0.0645, -0.0495, -0.0561, -0.0685, -0.0748,\n",
      "        -0.0783, -0.0497, -0.0830, -0.0733, -0.1047, -0.0599, -0.0690, -0.0516,\n",
      "        -0.0649, -0.0797, -0.0388, -0.0852, -0.0980, -0.0717, -0.0440, -0.0547,\n",
      "        -0.0755, -0.0563, -0.0702, -0.0516, -0.0969, -0.0257, -0.0312, -0.0440,\n",
      "        -0.0327, -0.0780, -0.0773, -0.0429, -0.0482, -0.0710, -0.0404, -0.0730,\n",
      "        -0.1032, -0.0766, -0.0783, -0.0711, -0.0892, -0.0692, -0.0735, -0.0471,\n",
      "        -0.1021, -0.0245, -0.0750, -0.0546, -0.0984, -0.0862, -0.0671, -0.0362,\n",
      "        -0.0952, -0.0312, -0.0828, -0.0686, -0.0661, -0.0423, -0.1171, -0.1221,\n",
      "        -0.0843, -0.0567, -0.0689, -0.0256, -0.0771, -0.0721, -0.0258, -0.0914,\n",
      "        -0.0455, -0.0311, -0.0795, -0.0930, -0.0916, -0.0334, -0.0937, -0.0706,\n",
      "        -0.0647, -0.0622, -0.0637, -0.0654, -0.0226, -0.0781, -0.0858, -0.0525,\n",
      "        -0.0757, -0.0701, -0.0211, -0.0707, -0.0663, -0.0448, -0.0712, -0.0662,\n",
      "        -0.0632, -0.0711, -0.0537, -0.1140, -0.0703, -0.0168, -0.0370, -0.0708,\n",
      "        -0.0604, -0.0721, -0.0800, -0.0935, -0.1015, -0.0816, -0.0569, -0.0395,\n",
      "        -0.0395, -0.0555, -0.0514, -0.0405, -0.0814, -0.0814, -0.0559, -0.0724,\n",
      "        -0.0668, -0.0708, -0.0599, -0.0448, -0.0494, -0.1035, -0.0515, -0.0715,\n",
      "        -0.0799, -0.0053, -0.0668, -0.0417, -0.0626, -0.0573, -0.0756, -0.0216,\n",
      "        -0.0471, -0.0591, -0.0504, -0.0911, -0.0554, -0.0566, -0.0711, -0.0557,\n",
      "        -0.0481, -0.0889, -0.0858, -0.0283, -0.0635, -0.0592, -0.0833, -0.0533,\n",
      "        -0.1200, -0.0692, -0.0593, -0.0733, -0.0485, -0.0446, -0.0634, -0.0461,\n",
      "        -0.0717,  0.0096, -0.0939, -0.0716, -0.0595, -0.0498, -0.0246, -0.0667,\n",
      "        -0.0423, -0.0471, -0.0577, -0.0675, -0.0880, -0.0635, -0.0299, -0.0799,\n",
      "        -0.0476, -0.0752, -0.0315, -0.0798, -0.0810, -0.0836, -0.0427, -0.0614,\n",
      "        -0.0278, -0.0780, -0.0691, -0.0726, -0.0670, -0.0828, -0.0976, -0.0444,\n",
      "        -0.0779, -0.1089, -0.0032, -0.0923, -0.0394, -0.0441, -0.0695, -0.0345,\n",
      "        -0.0517, -0.0827, -0.0394, -0.0444, -0.0735, -0.0417, -0.0924, -0.0994,\n",
      "        -0.0600, -0.0951, -0.0374, -0.0006, -0.0970, -0.0688, -0.0705, -0.1097,\n",
      "        -0.0574, -0.0604, -0.0577, -0.1168, -0.0632, -0.0772, -0.1119, -0.1014,\n",
      "        -0.0468, -0.0713, -0.0915, -0.0417, -0.0808, -0.0984, -0.0707, -0.0736,\n",
      "        -0.0545, -0.0817, -0.0768, -0.0938, -0.0683, -0.0434, -0.0975, -0.0972,\n",
      "        -0.0700, -0.0458, -0.0602, -0.1025, -0.0591, -0.0618, -0.0800, -0.0383],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.4.bn2.weight', Parameter containing:\n",
      "tensor([1.0368, 1.0439, 1.0023, 0.9804, 1.0197, 0.9577, 0.9814, 1.0208, 1.0308,\n",
      "        0.9740, 0.9786, 1.0635, 1.0040, 1.0059, 1.0471, 0.9897, 1.0206, 0.9709,\n",
      "        1.0013, 1.0147, 1.0091, 1.0004, 0.9996, 1.0374, 0.9954, 0.9968, 0.9520,\n",
      "        1.0457, 1.0025, 0.9660, 0.9922, 0.9803, 1.0008, 1.0038, 0.9630, 1.0069,\n",
      "        1.0051, 0.9773, 0.9598, 1.0200, 0.9660, 0.9909, 1.0228, 0.9925, 1.0175,\n",
      "        0.9874, 1.0059, 0.9813, 0.9470, 0.9808, 1.0208, 0.9932, 0.9814, 0.9996,\n",
      "        0.9886, 1.0232, 1.0115, 0.9733, 0.9881, 1.0105, 1.0281, 0.9710, 0.9576,\n",
      "        1.0179, 0.9693, 1.0448, 1.0221, 0.9671, 0.9750, 1.0192, 1.0106, 1.0066,\n",
      "        0.9907, 0.9867, 0.9942, 1.0029, 0.9869, 0.9991, 0.9913, 0.9913, 0.9979,\n",
      "        1.0442, 0.9997, 0.9720, 1.0366, 1.0036, 0.9677, 0.9848, 0.9650, 1.0318,\n",
      "        1.0065, 1.0277, 0.9917, 1.0092, 0.9936, 1.0262, 0.9984, 0.9810, 1.0226,\n",
      "        1.0114, 1.0140, 1.0202, 1.0251, 1.0140, 0.9884, 0.9715, 0.9844, 1.0241,\n",
      "        0.9963, 1.0372, 0.9923, 1.0357, 0.9909, 0.9909, 0.9979, 0.9969, 0.9899,\n",
      "        1.0419, 1.0052, 1.0129, 1.0141, 1.0066, 0.9808, 0.9764, 1.0253, 0.9546,\n",
      "        0.9465, 0.9589, 0.9810, 1.0203, 0.9876, 1.0209, 0.9481, 1.0102, 1.0062,\n",
      "        0.9926, 1.0039, 0.9821, 1.0041, 1.0344, 1.0058, 0.9659, 1.0579, 1.0019,\n",
      "        0.9675, 0.9993, 1.0295, 1.0167, 0.9834, 1.0033, 0.9815, 1.0276, 0.9781,\n",
      "        1.0032, 1.0122, 0.9883, 1.0200, 1.0091, 0.9867, 0.9935, 1.0241, 0.9944,\n",
      "        1.0213, 1.0047, 0.9982, 1.0005, 1.0457, 1.0024, 0.9733, 0.9893, 1.0314,\n",
      "        0.9707, 1.0047, 1.0109, 0.9913, 1.0124, 1.0051, 1.0202, 1.0285, 1.0015,\n",
      "        0.9946, 1.0081, 0.9863, 1.0234, 0.9720, 0.9886, 0.9900, 0.9916, 0.9421,\n",
      "        0.9911, 1.0177, 1.0021, 1.0021, 1.0142, 0.9898, 1.0407, 0.9628, 1.0114,\n",
      "        0.9818, 1.0067, 1.0265, 0.9866, 0.9983, 1.0013, 0.9875, 1.0256, 0.9929,\n",
      "        0.9808, 1.0556, 0.9875, 0.9826, 0.9518, 0.9707, 1.0240, 1.0043, 0.9983,\n",
      "        0.9861, 0.9648, 0.9781, 1.0016, 0.9955, 1.0002, 0.9896, 1.0009, 0.9936,\n",
      "        0.9587, 0.9928, 0.9904, 0.9822, 0.9831, 1.0056, 1.0104, 0.9998, 0.9791,\n",
      "        0.9294, 0.9949, 0.9959, 1.0103, 1.0052, 1.0019, 1.0019, 0.9675, 0.9934,\n",
      "        1.0178, 1.0049, 0.9703, 0.9697, 0.9868, 1.0124, 1.0079, 0.9997, 0.9872,\n",
      "        1.0085, 0.9944, 1.0058, 0.9719], device='cuda:0', requires_grad=True))\n",
      "('5.4.bn2.bias', Parameter containing:\n",
      "tensor([-0.0809, -0.0745, -0.0651, -0.0729, -0.0575, -0.0676, -0.0352, -0.0679,\n",
      "        -0.0620, -0.0238, -0.0335, -0.0313, -0.0150, -0.0286, -0.0931, -0.0706,\n",
      "        -0.0691, -0.0573, -0.0810, -0.0283, -0.0735, -0.0625, -0.0673, -0.0611,\n",
      "        -0.0579, -0.0573, -0.0536, -0.0526, -0.0265, -0.0319, -0.0400, -0.0612,\n",
      "        -0.1171, -0.0335, -0.0375, -0.0744, -0.0136, -0.0638, -0.0905, -0.0740,\n",
      "        -0.0527, -0.0632, -0.0644, -0.0427, -0.0322, -0.0138, -0.0455, -0.0584,\n",
      "        -0.0866, -0.0321, -0.0446, -0.0355, -0.0462, -0.0651, -0.0688, -0.0499,\n",
      "        -0.0915, -0.0839, -0.0600, -0.0395, -0.0420, -0.0685, -0.0652, -0.1198,\n",
      "        -0.0336, -0.0126, -0.0731, -0.0531, -0.0867, -0.0632, -0.0619, -0.0580,\n",
      "        -0.0641, -0.0564, -0.0401, -0.1035, -0.0355, -0.0326, -0.0395, -0.1004,\n",
      "        -0.0858, -0.0227, -0.0470, -0.0877, -0.0670, -0.0460, -0.0323, -0.0680,\n",
      "        -0.0774, -0.0570, -0.0856, -0.0303, -0.0891, -0.0199, -0.1276, -0.0558,\n",
      "        -0.0305, -0.0477, -0.0970, -0.0204, -0.0149, -0.0220, -0.0251, -0.0594,\n",
      "        -0.0478, -0.0873, -0.0752, -0.0436, -0.0402, -0.1089, -0.0172, -0.0707,\n",
      "        -0.0693, -0.0764, -0.0539, -0.0064, -0.0441, -0.1025, -0.0221, -0.0451,\n",
      "        -0.0459, -0.0465, -0.0533, -0.0532, -0.0759, -0.0882, -0.0837, -0.0989,\n",
      "        -0.0410, -0.0473, -0.0493, -0.0590, -0.0737, -0.0862, -0.0848, -0.1057,\n",
      "        -0.1168, -0.0858, -0.0644, -0.1441, -0.0408, -0.0510, -0.0770, -0.0226,\n",
      "        -0.0650, -0.0587, -0.0205, -0.0531, -0.0401, -0.0737, -0.0368, -0.0577,\n",
      "        -0.0962, -0.0641, -0.0419, -0.0718, -0.0484, -0.0163, -0.0629, -0.0537,\n",
      "        -0.0184, -0.1294, -0.0404, -0.0274, -0.1232, -0.0607, -0.0441, -0.0404,\n",
      "        -0.1194, -0.1009, -0.0957, -0.0488, -0.0612, -0.0583, -0.0947, -0.0535,\n",
      "        -0.0811, -0.0897, -0.0515, -0.0387, -0.0501, -0.0639, -0.0531, -0.0631,\n",
      "        -0.0570, -0.0702, -0.1140, -0.0550, -0.0615, -0.0099, -0.0635, -0.0603,\n",
      "        -0.0618, -0.0330, -0.0664, -0.0348, -0.0970, -0.0183, -0.0245, -0.0250,\n",
      "        -0.0340, -0.0685, -0.0872, -0.0350, -0.0670, -0.0956, -0.0557, -0.0953,\n",
      "        -0.0623,  0.0040, -0.0567, -0.1046, -0.0444, -0.0526, -0.0666, -0.1026,\n",
      "        -0.0554, -0.0520, -0.0480, -0.0958, -0.0829, -0.0706, -0.0419, -0.0694,\n",
      "        -0.0991, -0.0424, -0.0142, -0.0665, -0.1237, -0.0472, -0.0574, -0.0634,\n",
      "        -0.1248, -0.0887, -0.0673, -0.1217, -0.1621, -0.0880, -0.0680, -0.0388,\n",
      "        -0.0445, -0.0873, -0.0824, -0.0665, -0.0764, -0.0405, -0.0824, -0.1008,\n",
      "        -0.0379, -0.0273, -0.0973, -0.0573, -0.0118, -0.0717, -0.0851, -0.0996],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.4.bn3.weight', Parameter containing:\n",
      "tensor([0.9975, 1.0022, 1.0036,  ..., 1.0012, 0.9937, 0.9360], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('5.4.bn3.bias', Parameter containing:\n",
      "tensor([-0.0035, -0.0055, -0.0027,  ..., -0.0022, -0.0043,  0.0051],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.5.conv1.weight', Parameter containing:\n",
      "tensor([[[-0.0183],\n",
      "         [ 0.0072],\n",
      "         [ 0.0153],\n",
      "         ...,\n",
      "         [-0.0545],\n",
      "         [ 0.0386],\n",
      "         [-0.0163]],\n",
      "\n",
      "        [[ 0.0244],\n",
      "         [-0.0106],\n",
      "         [-0.0221],\n",
      "         ...,\n",
      "         [ 0.0256],\n",
      "         [ 0.0194],\n",
      "         [-0.0485]],\n",
      "\n",
      "        [[ 0.0455],\n",
      "         [ 0.0520],\n",
      "         [-0.0177],\n",
      "         ...,\n",
      "         [ 0.0442],\n",
      "         [-0.0334],\n",
      "         [-0.0548]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0068],\n",
      "         [ 0.0189],\n",
      "         [-0.0056],\n",
      "         ...,\n",
      "         [-0.0398],\n",
      "         [ 0.0320],\n",
      "         [ 0.0491]],\n",
      "\n",
      "        [[-0.0245],\n",
      "         [ 0.0289],\n",
      "         [ 0.0022],\n",
      "         ...,\n",
      "         [ 0.0038],\n",
      "         [ 0.0346],\n",
      "         [ 0.0132]],\n",
      "\n",
      "        [[-0.0203],\n",
      "         [-0.0463],\n",
      "         [-0.0414],\n",
      "         ...,\n",
      "         [ 0.0461],\n",
      "         [ 0.0254],\n",
      "         [ 0.0211]]], device='cuda:0', requires_grad=True))\n",
      "('5.5.conv1.bias', Parameter containing:\n",
      "tensor([ 0.0280, -0.0309, -0.0073, -0.0020,  0.0192, -0.0032,  0.0279, -0.0077,\n",
      "        -0.0148, -0.0136,  0.0204,  0.0186, -0.0099,  0.0246, -0.0246,  0.0100,\n",
      "         0.0108,  0.0161, -0.0009,  0.0311,  0.0114, -0.0177, -0.0258, -0.0139,\n",
      "         0.0112, -0.0065, -0.0283, -0.0117, -0.0294,  0.0088,  0.0088, -0.0305,\n",
      "         0.0110, -0.0224, -0.0294, -0.0058,  0.0295,  0.0112,  0.0312,  0.0290,\n",
      "        -0.0222, -0.0004, -0.0066,  0.0200,  0.0303,  0.0112, -0.0275,  0.0101,\n",
      "        -0.0198,  0.0234,  0.0100,  0.0127, -0.0158,  0.0118,  0.0248, -0.0295,\n",
      "        -0.0283,  0.0269, -0.0232,  0.0277, -0.0040, -0.0211,  0.0198, -0.0195,\n",
      "        -0.0183,  0.0259, -0.0176,  0.0129, -0.0225, -0.0022, -0.0022,  0.0035,\n",
      "        -0.0040,  0.0002, -0.0158, -0.0195, -0.0291, -0.0136,  0.0075, -0.0031,\n",
      "         0.0298,  0.0154,  0.0110,  0.0041, -0.0017,  0.0132, -0.0180, -0.0195,\n",
      "        -0.0300,  0.0005,  0.0230, -0.0006,  0.0081,  0.0214, -0.0275, -0.0242,\n",
      "         0.0173, -0.0258,  0.0088, -0.0159, -0.0073, -0.0042, -0.0035, -0.0310,\n",
      "         0.0202,  0.0086,  0.0267, -0.0043,  0.0120,  0.0204, -0.0120, -0.0049,\n",
      "        -0.0282, -0.0226,  0.0059,  0.0259,  0.0215,  0.0142,  0.0212, -0.0286,\n",
      "         0.0294,  0.0089, -0.0173,  0.0031,  0.0297,  0.0163,  0.0305,  0.0150,\n",
      "         0.0089, -0.0246, -0.0015,  0.0306, -0.0086,  0.0132,  0.0240,  0.0195,\n",
      "        -0.0154, -0.0020, -0.0201,  0.0029, -0.0228, -0.0175, -0.0154, -0.0165,\n",
      "         0.0226,  0.0156,  0.0205,  0.0183,  0.0153, -0.0088,  0.0132, -0.0152,\n",
      "        -0.0020,  0.0214, -0.0125, -0.0150, -0.0217, -0.0260,  0.0291, -0.0185,\n",
      "         0.0051, -0.0132,  0.0109, -0.0008,  0.0009,  0.0028, -0.0100, -0.0087,\n",
      "        -0.0287,  0.0255, -0.0292, -0.0134,  0.0271, -0.0110, -0.0291, -0.0176,\n",
      "        -0.0144, -0.0280, -0.0234, -0.0027, -0.0009, -0.0243,  0.0215,  0.0002,\n",
      "         0.0310,  0.0229, -0.0042, -0.0267,  0.0013,  0.0180,  0.0134,  0.0241,\n",
      "        -0.0093,  0.0091, -0.0049, -0.0197,  0.0305, -0.0197,  0.0303,  0.0065,\n",
      "         0.0246, -0.0185, -0.0237,  0.0269,  0.0227,  0.0031,  0.0219,  0.0132,\n",
      "         0.0142, -0.0101, -0.0211, -0.0105,  0.0164,  0.0020,  0.0094,  0.0298,\n",
      "        -0.0048, -0.0298, -0.0266, -0.0247, -0.0152,  0.0119, -0.0227,  0.0140,\n",
      "         0.0102,  0.0300, -0.0105,  0.0218,  0.0059, -0.0112,  0.0124, -0.0203,\n",
      "        -0.0135, -0.0172,  0.0111, -0.0053,  0.0170, -0.0152, -0.0236,  0.0214,\n",
      "        -0.0155,  0.0208,  0.0162, -0.0151,  0.0041,  0.0015,  0.0077, -0.0006,\n",
      "        -0.0068, -0.0082,  0.0116,  0.0294, -0.0109,  0.0114, -0.0222,  0.0130],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.5.conv2.weight', Parameter containing:\n",
      "tensor([[[ 0.0145,  0.0212,  0.0121],\n",
      "         [-0.0634, -0.0123,  0.0404],\n",
      "         [-0.0539,  0.0409,  0.0271],\n",
      "         ...,\n",
      "         [ 0.0097, -0.0162,  0.0136],\n",
      "         [-0.0254, -0.0095, -0.0003],\n",
      "         [ 0.0410, -0.0160, -0.0507]],\n",
      "\n",
      "        [[ 0.0192, -0.0172,  0.0154],\n",
      "         [ 0.0064,  0.0115, -0.0038],\n",
      "         [-0.0098,  0.0355,  0.0468],\n",
      "         ...,\n",
      "         [-0.0371, -0.0033,  0.0407],\n",
      "         [ 0.0039,  0.0364, -0.0156],\n",
      "         [ 0.0392,  0.0267,  0.0089]],\n",
      "\n",
      "        [[ 0.0110, -0.0179,  0.0290],\n",
      "         [-0.0212,  0.0077, -0.0434],\n",
      "         [ 0.0286, -0.0211,  0.0041],\n",
      "         ...,\n",
      "         [ 0.0080, -0.0080, -0.0361],\n",
      "         [-0.0366, -0.0428,  0.0182],\n",
      "         [-0.0136, -0.0259, -0.0020]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0267,  0.0106, -0.0662],\n",
      "         [ 0.0762, -0.0377,  0.0160],\n",
      "         [ 0.0353, -0.0305,  0.0409],\n",
      "         ...,\n",
      "         [ 0.0108,  0.0133, -0.0349],\n",
      "         [ 0.0006,  0.0060, -0.0180],\n",
      "         [ 0.0234,  0.0211, -0.0399]],\n",
      "\n",
      "        [[-0.0471,  0.0057,  0.0473],\n",
      "         [ 0.0289,  0.0365, -0.0930],\n",
      "         [ 0.0506,  0.0140, -0.0287],\n",
      "         ...,\n",
      "         [ 0.0326, -0.0096,  0.0383],\n",
      "         [-0.0452,  0.0244,  0.0029],\n",
      "         [-0.0405, -0.0034, -0.0609]],\n",
      "\n",
      "        [[-0.0428, -0.0506,  0.0449],\n",
      "         [-0.0011,  0.0108, -0.0019],\n",
      "         [-0.0592, -0.0061,  0.0159],\n",
      "         ...,\n",
      "         [-0.0513,  0.0040, -0.0905],\n",
      "         [-0.0459,  0.0357, -0.0113],\n",
      "         [ 0.0056, -0.0552,  0.0098]]], device='cuda:0', requires_grad=True))\n",
      "('5.5.conv2.bias', Parameter containing:\n",
      "tensor([ 0.0301, -0.0145, -0.0068, -0.0142,  0.0213, -0.0325,  0.0210, -0.0216,\n",
      "         0.0277,  0.0173,  0.0129,  0.0009, -0.0333,  0.0095, -0.0177, -0.0304,\n",
      "        -0.0257, -0.0096,  0.0223,  0.0337,  0.0209,  0.0083, -0.0089, -0.0324,\n",
      "         0.0266, -0.0217, -0.0205,  0.0097,  0.0282, -0.0349, -0.0152, -0.0338,\n",
      "        -0.0172, -0.0171, -0.0286,  0.0254, -0.0304,  0.0273, -0.0248,  0.0096,\n",
      "         0.0182, -0.0275,  0.0011, -0.0276,  0.0147,  0.0322,  0.0252,  0.0117,\n",
      "         0.0178, -0.0001, -0.0170,  0.0191, -0.0071, -0.0287, -0.0231, -0.0332,\n",
      "        -0.0166, -0.0210, -0.0271,  0.0180,  0.0268, -0.0272, -0.0065,  0.0318,\n",
      "         0.0050, -0.0063,  0.0181, -0.0092, -0.0021,  0.0289, -0.0316, -0.0048,\n",
      "         0.0001, -0.0294, -0.0199,  0.0212,  0.0185, -0.0121, -0.0294, -0.0038,\n",
      "         0.0334,  0.0238,  0.0066,  0.0174, -0.0259, -0.0267, -0.0189,  0.0106,\n",
      "        -0.0126, -0.0287, -0.0165,  0.0352,  0.0136, -0.0075,  0.0285,  0.0278,\n",
      "        -0.0152, -0.0035, -0.0304,  0.0076,  0.0330, -0.0064, -0.0295, -0.0061,\n",
      "        -0.0063,  0.0048,  0.0245,  0.0233,  0.0253, -0.0002,  0.0218, -0.0307,\n",
      "        -0.0346, -0.0247,  0.0243,  0.0182, -0.0149, -0.0009,  0.0043, -0.0199,\n",
      "        -0.0252, -0.0087,  0.0171, -0.0268, -0.0152,  0.0050,  0.0250, -0.0261,\n",
      "        -0.0051, -0.0082,  0.0189,  0.0232, -0.0022,  0.0146, -0.0220, -0.0085,\n",
      "        -0.0196, -0.0284, -0.0350,  0.0113,  0.0233,  0.0263, -0.0171,  0.0262,\n",
      "         0.0115, -0.0074, -0.0293,  0.0080,  0.0148, -0.0327,  0.0315,  0.0319,\n",
      "         0.0116, -0.0258,  0.0013,  0.0125,  0.0183,  0.0133, -0.0210, -0.0157,\n",
      "        -0.0267,  0.0338,  0.0251,  0.0044,  0.0357,  0.0159, -0.0202,  0.0230,\n",
      "        -0.0155, -0.0303,  0.0168, -0.0060, -0.0123,  0.0333,  0.0247,  0.0170,\n",
      "         0.0328,  0.0153,  0.0152,  0.0233,  0.0327, -0.0048, -0.0222, -0.0156,\n",
      "         0.0085, -0.0195, -0.0305, -0.0155,  0.0351,  0.0138,  0.0131, -0.0093,\n",
      "        -0.0302, -0.0197,  0.0090, -0.0139,  0.0016, -0.0025, -0.0252, -0.0005,\n",
      "         0.0136, -0.0359,  0.0337, -0.0075, -0.0168,  0.0151, -0.0211,  0.0007,\n",
      "         0.0360,  0.0103,  0.0114,  0.0301,  0.0111, -0.0303, -0.0105,  0.0248,\n",
      "         0.0319, -0.0101,  0.0232,  0.0174, -0.0281, -0.0184,  0.0098,  0.0207,\n",
      "        -0.0250,  0.0074, -0.0208,  0.0299, -0.0191, -0.0059,  0.0301,  0.0207,\n",
      "        -0.0003,  0.0033,  0.0242, -0.0250, -0.0337, -0.0058, -0.0213,  0.0290,\n",
      "        -0.0010, -0.0220,  0.0052, -0.0200, -0.0338, -0.0217,  0.0030,  0.0321,\n",
      "         0.0343, -0.0009, -0.0358,  0.0063,  0.0343,  0.0084,  0.0081, -0.0347],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.5.conv3.weight', Parameter containing:\n",
      "tensor([[[-0.0048],\n",
      "         [-0.0380],\n",
      "         [ 0.0262],\n",
      "         ...,\n",
      "         [ 0.0043],\n",
      "         [-0.0281],\n",
      "         [ 0.0277]],\n",
      "\n",
      "        [[ 0.0070],\n",
      "         [-0.0339],\n",
      "         [ 0.0004],\n",
      "         ...,\n",
      "         [ 0.0277],\n",
      "         [ 0.0124],\n",
      "         [-0.0204]],\n",
      "\n",
      "        [[-0.0629],\n",
      "         [-0.0553],\n",
      "         [ 0.0250],\n",
      "         ...,\n",
      "         [ 0.0260],\n",
      "         [ 0.0101],\n",
      "         [-0.0391]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0184],\n",
      "         [-0.0321],\n",
      "         [ 0.0317],\n",
      "         ...,\n",
      "         [ 0.0545],\n",
      "         [ 0.0048],\n",
      "         [-0.0414]],\n",
      "\n",
      "        [[ 0.0190],\n",
      "         [-0.0059],\n",
      "         [ 0.0543],\n",
      "         ...,\n",
      "         [ 0.0128],\n",
      "         [ 0.0265],\n",
      "         [-0.0633]],\n",
      "\n",
      "        [[ 0.0424],\n",
      "         [ 0.0229],\n",
      "         [ 0.0470],\n",
      "         ...,\n",
      "         [-0.0200],\n",
      "         [ 0.0449],\n",
      "         [-0.0352]]], device='cuda:0', requires_grad=True))\n",
      "('5.5.conv3.bias', Parameter containing:\n",
      "tensor([-0.0097,  0.0505,  0.0159,  ...,  0.0128,  0.0549,  0.0138],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.5.bn1.weight', Parameter containing:\n",
      "tensor([1.0286, 1.0178, 1.0256, 1.0592, 1.0539, 1.0125, 1.0522, 1.0154, 1.0024,\n",
      "        0.9999, 0.9924, 1.0094, 1.0080, 1.0197, 1.0498, 0.9594, 1.0480, 0.9966,\n",
      "        0.9586, 0.9858, 1.0369, 0.9752, 0.9530, 1.0215, 0.9738, 1.0296, 0.9897,\n",
      "        1.0217, 1.0002, 1.0572, 0.9834, 0.9947, 0.9769, 1.0063, 0.9988, 0.9943,\n",
      "        0.9610, 0.9962, 0.9853, 1.0363, 1.0191, 0.9859, 0.9618, 0.9862, 0.9887,\n",
      "        0.9746, 0.9855, 0.9822, 0.9858, 0.9498, 0.9564, 0.9817, 0.9742, 1.0038,\n",
      "        0.9785, 1.0112, 0.9861, 0.9556, 0.9791, 0.9971, 1.0263, 1.0057, 1.0346,\n",
      "        1.0164, 1.0063, 1.0205, 0.9988, 0.9934, 1.0169, 0.9940, 1.0035, 0.9622,\n",
      "        0.9553, 0.9807, 0.9511, 0.9836, 1.0399, 0.9826, 0.9840, 1.0735, 0.9500,\n",
      "        1.0218, 0.9875, 1.0029, 0.9726, 1.0177, 1.0071, 1.0103, 0.9826, 1.0215,\n",
      "        0.9943, 1.0260, 0.9966, 0.9787, 0.9811, 0.9710, 1.0231, 1.0597, 1.0018,\n",
      "        1.0210, 1.0171, 0.9946, 1.0341, 0.9686, 1.0003, 0.9993, 1.0641, 1.0328,\n",
      "        0.9749, 1.0405, 1.0321, 0.9782, 1.0024, 1.0322, 0.9913, 1.0150, 1.0073,\n",
      "        1.0301, 0.9982, 0.9586, 1.0295, 1.0001, 0.9851, 0.9739, 0.9974, 0.9907,\n",
      "        0.9926, 1.0091, 1.0244, 0.9828, 0.9592, 0.9838, 1.0186, 0.9798, 1.0098,\n",
      "        0.9683, 0.9683, 1.0245, 0.9511, 1.0002, 0.9695, 0.9727, 0.9604, 0.9699,\n",
      "        1.0342, 0.9874, 1.0161, 1.0023, 0.9814, 1.0093, 0.9683, 0.9739, 1.0365,\n",
      "        0.9981, 0.9680, 1.0130, 0.9841, 1.0323, 0.9951, 1.0108, 0.9903, 0.9893,\n",
      "        0.9524, 1.0369, 1.0318, 0.9737, 0.9826, 0.9472, 1.0276, 0.9866, 0.9538,\n",
      "        0.9855, 0.9963, 0.9706, 1.0159, 1.0123, 0.9767, 0.9844, 1.0448, 0.9513,\n",
      "        1.0008, 1.0015, 1.0382, 1.0044, 0.9799, 1.0015, 0.9518, 0.9763, 0.9995,\n",
      "        1.0059, 1.0223, 0.9986, 0.9647, 0.9878, 0.9955, 1.0096, 1.0116, 0.9617,\n",
      "        0.9973, 1.0026, 1.0484, 1.0127, 1.0408, 0.9907, 0.9740, 0.9433, 1.0128,\n",
      "        1.0027, 1.0191, 0.9764, 0.9831, 1.0565, 0.9687, 1.0182, 0.9732, 1.0252,\n",
      "        1.0042, 0.9690, 0.9969, 1.0444, 1.0153, 0.9988, 1.0219, 1.0059, 1.0136,\n",
      "        1.0072, 0.9710, 1.0492, 1.0376, 0.9980, 0.9870, 0.9930, 1.0051, 1.0232,\n",
      "        0.9997, 0.9714, 0.9818, 1.0169, 1.0288, 0.9929, 1.0409, 0.9833, 0.9926,\n",
      "        0.9801, 0.9856, 0.9928, 0.9957, 0.9547, 1.0114, 1.0030, 1.0319, 1.0117,\n",
      "        1.0262, 0.9934, 0.9876, 1.0452], device='cuda:0', requires_grad=True))\n",
      "('5.5.bn1.bias', Parameter containing:\n",
      "tensor([-0.0224, -0.0549, -0.0172, -0.0503, -0.0442, -0.0120, -0.0348, -0.0558,\n",
      "        -0.0660, -0.0296, -0.0449, -0.0363, -0.0244, -0.0699, -0.0561, -0.0117,\n",
      "        -0.0483, -0.0743, -0.0559, -0.0382, -0.0462, -0.0126, -0.0626, -0.0320,\n",
      "        -0.0495, -0.0591, -0.0467, -0.0490, -0.0251, -0.0184, -0.0743, -0.0400,\n",
      "        -0.0151, -0.0218, -0.0708, -0.0660, -0.0753, -0.0202, -0.0200, -0.0332,\n",
      "        -0.0726, -0.0159, -0.0601, -0.0361, -0.0436, -0.0336, -0.0758, -0.0382,\n",
      "        -0.0215, -0.0545, -0.0381, -0.0269, -0.0466, -0.0427, -0.0468, -0.0275,\n",
      "        -0.0187, -0.0642, -0.0485, -0.0712, -0.0266, -0.0467, -0.0229, -0.0312,\n",
      "        -0.0348, -0.0452, -0.0118, -0.0509, -0.0319, -0.0640, -0.0545, -0.0384,\n",
      "        -0.0264, -0.0366, -0.0431, -0.0301, -0.0318, -0.0095, -0.0172, -0.0106,\n",
      "        -0.0660, -0.0350, -0.0636, -0.0413, -0.0582, -0.0180, -0.0503, -0.0552,\n",
      "        -0.0199, -0.0149,  0.0160, -0.0364, -0.0221, -0.0311, -0.0537, -0.0397,\n",
      "        -0.0380,  0.0090, -0.0295, -0.0565, -0.0826, -0.0577, -0.0355, -0.0694,\n",
      "        -0.0407, -0.0368, -0.0459, -0.0204, -0.0877, -0.0085, -0.0636, -0.0480,\n",
      "        -0.0098, -0.0587, -0.0402, -0.0112, -0.0438, -0.0436, -0.0418, -0.0522,\n",
      "        -0.0119, -0.0345, -0.0531,  0.0253, -0.0488, -0.0438, -0.0162, -0.0066,\n",
      "        -0.0118, -0.0590, -0.0276, -0.0141, -0.0452, -0.0443, -0.0337, -0.0426,\n",
      "        -0.0133, -0.0648, -0.0228, -0.0431, -0.0452, -0.0513, -0.0403, -0.0633,\n",
      "        -0.0289, -0.0291,  0.0018, -0.0140, -0.0669, -0.0149, -0.0566, -0.0505,\n",
      "        -0.0715, -0.0265, -0.0159, -0.0219, -0.0616, -0.0493, -0.0370, -0.0403,\n",
      "        -0.0590, -0.0550, -0.0375, -0.0614, -0.0609, -0.0528, -0.0192, -0.0790,\n",
      "        -0.0315, -0.0370, -0.0655, -0.0094, -0.0329, -0.0230, -0.0415, -0.0657,\n",
      "        -0.0259, -0.0430, -0.0236, -0.0637, -0.0315, -0.0467, -0.0327, -0.0448,\n",
      "        -0.0356, -0.0296, -0.0934, -0.0540, -0.0855,  0.0090, -0.0424,  0.0066,\n",
      "        -0.0628, -0.0435, -0.0524, -0.0236, -0.0414, -0.0646, -0.0313, -0.0419,\n",
      "        -0.0148, -0.0292, -0.0342, -0.0254, -0.0384, -0.0706, -0.0402, -0.0473,\n",
      "        -0.0600, -0.0721, -0.0444, -0.0548, -0.0545, -0.0438, -0.0869, -0.0487,\n",
      "        -0.0473, -0.0455, -0.0270, -0.0003, -0.0204, -0.0306, -0.0330,  0.0045,\n",
      "        -0.0142, -0.0331,  0.0136, -0.0019, -0.0709, -0.0384, -0.0063, -0.0122,\n",
      "        -0.0775, -0.0373, -0.0260, -0.0518, -0.0169, -0.0617, -0.0227, -0.0640,\n",
      "        -0.0500, -0.0493, -0.0350, -0.0641, -0.0123, -0.0367, -0.0431, -0.0647,\n",
      "        -0.0431, -0.0398, -0.0268, -0.0648, -0.0660, -0.0312, -0.0126, -0.0378],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('5.5.bn2.weight', Parameter containing:\n",
      "tensor([1.0095, 0.9900, 1.0033, 0.9804, 0.9817, 1.0437, 0.9701, 1.0161, 0.9928,\n",
      "        0.9820, 1.0064, 1.0234, 0.9918, 0.9760, 0.9956, 0.9994, 1.0355, 0.9813,\n",
      "        0.9936, 0.9921, 0.9968, 1.0454, 0.9992, 1.0117, 0.9995, 1.0332, 1.0182,\n",
      "        0.9679, 1.0037, 1.0335, 0.9768, 0.9992, 0.9746, 0.9636, 1.0293, 0.9951,\n",
      "        0.9821, 0.9909, 1.0418, 0.9730, 0.9916, 0.9751, 1.0056, 1.0200, 0.9695,\n",
      "        1.0010, 1.0023, 0.9939, 0.9922, 0.9739, 1.0104, 0.9947, 0.9791, 0.9680,\n",
      "        1.0297, 0.9990, 1.0077, 0.9923, 0.9748, 1.0131, 0.9932, 0.9490, 1.0024,\n",
      "        0.9886, 1.0103, 1.0024, 0.9791, 0.9963, 0.9833, 0.9620, 1.0338, 1.0003,\n",
      "        1.0085, 0.9965, 1.0126, 1.0366, 0.9713, 0.9711, 0.9926, 1.0003, 1.0234,\n",
      "        0.9937, 0.9717, 0.9976, 0.9837, 0.9937, 0.9764, 0.9884, 0.9494, 0.9880,\n",
      "        1.0231, 0.9959, 0.9897, 1.0091, 0.9990, 1.0158, 1.0216, 0.9941, 0.9945,\n",
      "        1.0008, 0.9794, 0.9623, 0.9842, 0.9838, 0.9753, 0.9896, 0.9835, 0.9793,\n",
      "        0.9763, 0.9985, 1.0242, 0.9937, 1.0055, 0.9980, 1.0089, 1.0056, 1.0268,\n",
      "        0.9890, 1.0624, 0.9731, 0.9725, 1.0473, 1.0378, 0.9536, 0.9745, 0.9784,\n",
      "        0.9957, 1.0122, 0.9826, 0.9911, 0.9994, 0.9992, 1.0355, 0.9944, 0.9875,\n",
      "        0.9549, 1.0116, 0.9617, 1.0237, 0.9543, 0.9875, 1.0069, 1.0310, 1.0337,\n",
      "        0.9928, 1.0452, 1.0041, 0.9792, 0.9864, 0.9980, 1.0059, 1.0193, 1.0071,\n",
      "        1.0108, 0.9879, 0.9892, 1.0174, 0.9750, 0.9742, 1.0125, 1.0512, 1.0364,\n",
      "        1.0194, 0.9720, 0.9838, 1.0093, 1.0053, 1.0070, 0.9510, 0.9891, 1.0256,\n",
      "        1.0138, 1.0052, 0.9968, 0.9772, 1.0323, 0.9776, 1.0197, 1.0339, 1.0062,\n",
      "        0.9981, 1.0030, 0.9839, 1.0419, 1.0226, 1.0424, 0.9666, 1.0194, 1.0120,\n",
      "        0.9963, 1.0146, 0.9841, 1.0179, 0.9976, 1.0202, 0.9850, 0.9722, 0.9596,\n",
      "        1.0287, 1.0281, 1.0172, 1.0129, 1.0147, 1.0046, 1.0179, 0.9948, 0.9805,\n",
      "        1.0272, 0.9896, 1.0288, 0.9759, 1.0219, 1.0081, 1.0186, 0.9787, 1.0231,\n",
      "        1.0061, 1.0105, 0.9895, 0.9957, 1.0422, 0.9814, 1.0149, 1.0002, 1.0081,\n",
      "        1.0316, 0.9850, 1.0107, 1.0194, 0.9844, 0.9624, 0.9805, 0.9796, 1.0026,\n",
      "        1.0081, 0.9701, 0.9981, 0.9936, 1.0447, 0.9933, 0.9672, 0.9929, 0.9918,\n",
      "        1.0147, 1.0159, 0.9873, 0.9870, 0.9906, 0.9829, 0.9990, 1.0045, 1.0194,\n",
      "        1.0086, 1.0128, 1.0008, 1.0235], device='cuda:0', requires_grad=True))\n",
      "('5.5.bn2.bias', Parameter containing:\n",
      "tensor([-6.2555e-02, -7.8678e-02, -5.5421e-02, -5.3656e-02, -4.4775e-02,\n",
      "        -6.5724e-02, -4.6992e-02, -9.6082e-03, -4.0946e-02, -6.1409e-02,\n",
      "        -2.8162e-02, -1.7893e-03, -5.4592e-02, -5.2202e-02, -8.0270e-02,\n",
      "        -4.8002e-02, -4.9000e-02, -5.7988e-02, -2.7999e-02, -3.0578e-02,\n",
      "        -1.4545e-02, -3.0939e-02, -2.9757e-02, -5.5251e-02, -2.3493e-02,\n",
      "        -5.8094e-02, -2.8778e-02, -8.5139e-02, -1.5046e-02, -6.9352e-02,\n",
      "        -3.1065e-02, -4.0292e-03, -4.0070e-02, -4.4529e-02, -4.7471e-02,\n",
      "        -1.4237e-02, -5.4273e-02, -4.5744e-02, -2.2058e-02, -2.3020e-02,\n",
      "        -9.7016e-03, -4.2660e-02, -3.6939e-02, -1.7455e-02, -4.1327e-02,\n",
      "        -7.2792e-02, -4.6125e-02, -4.6831e-02, -7.2672e-02, -2.5189e-02,\n",
      "        -3.1705e-02, -5.0813e-02, -4.6036e-02, -2.9898e-02, -5.4374e-02,\n",
      "        -4.9709e-02, -3.4379e-02, -2.1548e-02, -5.2236e-02, -6.2859e-02,\n",
      "        -2.9896e-02, -8.5593e-02, -5.1184e-02, -2.6208e-02, -5.6106e-02,\n",
      "        -6.1525e-02, -5.1575e-02, -5.0485e-02, -4.1626e-02, -4.9666e-02,\n",
      "        -3.1603e-02, -5.7663e-02, -2.9490e-02, -6.4306e-02, -3.9104e-02,\n",
      "        -5.4346e-02, -8.7830e-02, -1.8207e-02, -1.2287e-02, -1.4689e-02,\n",
      "         7.9512e-03, -2.3602e-02, -4.1251e-02, -2.7031e-02, -2.8380e-02,\n",
      "        -6.1031e-02, -4.7576e-02, -2.3804e-02, -6.9320e-02, -5.9615e-02,\n",
      "        -4.1325e-02, -4.5737e-02, -1.6740e-02, -1.6595e-02, -1.2813e-02,\n",
      "        -4.8084e-02, -4.8419e-02, -3.9651e-03, -5.3374e-02, -3.7515e-02,\n",
      "        -2.8380e-02, -6.0186e-02, -5.1665e-02, -5.5579e-02, -3.3681e-02,\n",
      "        -3.5377e-02, -1.5013e-02, -6.7797e-02, -5.4820e-02, -5.5424e-02,\n",
      "        -8.3184e-02, -3.0289e-02, -4.7746e-02, -8.2269e-03, -3.2796e-02,\n",
      "        -2.0105e-03, -4.2477e-02, -3.0158e-02, -3.1468e-02, -6.6613e-02,\n",
      "        -6.1836e-02,  1.7006e-02, -5.3606e-02, -4.7181e-02, -4.2356e-02,\n",
      "        -4.4155e-02, -2.3979e-02, -4.2669e-02, -5.1121e-02, -4.5531e-02,\n",
      "        -4.3253e-02, -7.4489e-02, -4.8760e-02, -4.9319e-02, -5.1453e-02,\n",
      "        -4.8584e-02, -1.6787e-02, -5.1108e-02, -8.0895e-02, -7.5359e-02,\n",
      "        -3.8759e-02, -1.1864e-02, -1.3398e-02,  2.2962e-03, -4.2866e-02,\n",
      "        -3.4476e-02, -2.5175e-03, -3.6567e-02, -2.6821e-02, -3.9567e-02,\n",
      "        -4.9178e-02, -7.8650e-02, -3.9732e-02, -4.8351e-02, -2.6543e-02,\n",
      "        -6.1710e-02, -6.5352e-02,  1.6305e-03, -9.3530e-03, -1.3879e-02,\n",
      "        -2.0700e-02, -1.1601e-03, -3.0123e-02, -5.9010e-02, -1.5687e-02,\n",
      "        -7.0655e-02, -4.0945e-02, -3.3597e-02, -4.5019e-02, -3.1929e-02,\n",
      "        -1.5176e-02, -5.2675e-02, -2.4910e-02, -5.1400e-02, -3.8309e-02,\n",
      "        -1.5047e-02,  7.3006e-05, -5.2049e-02, -3.9090e-02, -1.1891e-02,\n",
      "        -8.8996e-02, -4.6262e-02, -7.4747e-02, -4.3806e-02, -5.0102e-02,\n",
      "        -1.7970e-02, -4.9722e-02, -4.8588e-02, -3.1520e-02, -5.1666e-02,\n",
      "        -7.9068e-02, -3.2793e-02, -2.8842e-02, -3.0920e-02,  8.7543e-03,\n",
      "         4.6935e-03, -4.1019e-02, -3.3386e-02,  1.8709e-02, -4.3864e-02,\n",
      "        -2.5543e-02, -6.4594e-02, -5.3438e-02, -6.5411e-02, -1.2252e-03,\n",
      "        -5.7438e-02, -1.5289e-02, -7.2255e-02, -5.8983e-03, -7.8905e-02,\n",
      "        -3.4248e-02, -2.0660e-02, -5.5242e-02, -6.1263e-03, -8.0465e-02,\n",
      "        -6.2246e-02, -1.0019e-01, -4.8968e-02, -7.4539e-02, -5.5261e-02,\n",
      "        -2.8802e-02, -6.4385e-02, -2.6447e-02, -6.0035e-02, -6.2861e-02,\n",
      "        -2.4919e-02, -5.5131e-02,  2.2722e-03, -6.4618e-02, -7.4535e-02,\n",
      "        -5.2385e-02, -6.2749e-02, -2.7605e-02, -5.7384e-02,  1.1078e-03,\n",
      "        -7.1239e-02, -4.6789e-02, -3.8450e-02, -7.4797e-02,  1.0389e-02,\n",
      "        -4.4851e-02, -5.7893e-02, -1.7398e-02, -5.0652e-02, -3.2580e-02,\n",
      "        -3.2337e-02, -2.3713e-02,  1.0146e-02, -4.1240e-02, -3.8848e-02,\n",
      "        -1.8324e-02, -4.7737e-02, -4.0644e-02, -5.8727e-02, -6.2985e-02,\n",
      "        -4.1580e-02], device='cuda:0', requires_grad=True))\n",
      "('5.5.bn3.weight', Parameter containing:\n",
      "tensor([1.0087, 1.0017, 0.9890,  ..., 0.9981, 1.0009, 0.9580], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('5.5.bn3.bias', Parameter containing:\n",
      "tensor([-0.0047, -0.0019,  0.0019,  ..., -0.0024, -0.0036, -0.0002],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.0.conv1.weight', Parameter containing:\n",
      "tensor([[[ 0.0147],\n",
      "         [ 0.0240],\n",
      "         [-0.0321],\n",
      "         ...,\n",
      "         [-0.0196],\n",
      "         [-0.0206],\n",
      "         [-0.0138]],\n",
      "\n",
      "        [[-0.0442],\n",
      "         [ 0.0186],\n",
      "         [-0.0111],\n",
      "         ...,\n",
      "         [ 0.0065],\n",
      "         [-0.0004],\n",
      "         [-0.0003]],\n",
      "\n",
      "        [[ 0.0069],\n",
      "         [-0.0272],\n",
      "         [-0.0046],\n",
      "         ...,\n",
      "         [ 0.0132],\n",
      "         [ 0.0062],\n",
      "         [ 0.0074]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0081],\n",
      "         [ 0.0237],\n",
      "         [ 0.0168],\n",
      "         ...,\n",
      "         [-0.0060],\n",
      "         [ 0.0201],\n",
      "         [-0.0064]],\n",
      "\n",
      "        [[ 0.0121],\n",
      "         [-0.0129],\n",
      "         [-0.0226],\n",
      "         ...,\n",
      "         [ 0.0149],\n",
      "         [-0.0189],\n",
      "         [ 0.0378]],\n",
      "\n",
      "        [[ 0.0381],\n",
      "         [-0.0138],\n",
      "         [-0.0120],\n",
      "         ...,\n",
      "         [ 0.0345],\n",
      "         [ 0.0583],\n",
      "         [ 0.0483]]], device='cuda:0', requires_grad=True))\n",
      "('7.0.conv1.bias', Parameter containing:\n",
      "tensor([-1.9911e-02,  1.1090e-02,  6.1379e-03,  1.3937e-02, -1.3186e-02,\n",
      "        -3.0879e-02, -2.9678e-03,  3.5898e-03,  2.1658e-02,  2.1317e-02,\n",
      "        -2.0192e-02, -4.5341e-03,  1.8435e-03, -1.2811e-02,  1.9105e-03,\n",
      "         1.7287e-02,  6.1371e-03, -2.8774e-02,  2.4633e-02, -9.0111e-03,\n",
      "        -1.7923e-02, -2.3468e-02, -2.2576e-02, -1.6520e-02, -4.6061e-04,\n",
      "         1.3217e-02, -1.7740e-02, -9.2141e-03,  2.4973e-02,  1.1896e-02,\n",
      "         2.0601e-02,  2.4199e-02,  2.0772e-02, -1.2894e-02, -1.7592e-02,\n",
      "        -6.9171e-03,  2.8625e-02,  1.6495e-02,  4.7986e-03, -1.6049e-02,\n",
      "         1.0436e-02, -1.8430e-03, -2.1160e-02, -2.3585e-02,  2.9345e-02,\n",
      "        -3.0357e-02, -1.5242e-02,  1.3459e-02,  2.3335e-02, -1.0429e-02,\n",
      "         2.9412e-02,  5.6134e-03, -2.9772e-02,  1.7194e-02,  7.0089e-03,\n",
      "         1.6315e-02,  2.9002e-02, -3.1630e-03,  2.9467e-02, -2.1067e-02,\n",
      "         1.7935e-02,  1.1643e-02,  1.6974e-02,  2.1938e-02,  1.6479e-02,\n",
      "         7.3069e-03,  2.2759e-02,  4.1675e-03, -1.2763e-02, -2.2650e-02,\n",
      "         1.9259e-02, -2.6180e-02, -2.6857e-03, -1.0035e-02,  2.2815e-02,\n",
      "        -2.5577e-02,  1.9453e-02,  6.2225e-03,  3.0757e-02,  1.3433e-02,\n",
      "        -8.0172e-03,  6.1230e-04,  1.9686e-03, -7.2881e-03,  2.3219e-02,\n",
      "        -7.7397e-03,  1.3139e-02, -2.3881e-02, -2.8819e-02, -1.0579e-02,\n",
      "        -2.9306e-02,  2.5457e-02,  1.5637e-02,  2.4380e-02,  6.0233e-03,\n",
      "        -2.1164e-02,  5.9869e-03,  1.4969e-05,  1.5163e-02,  1.1564e-02,\n",
      "         1.0696e-02, -9.3526e-03,  3.1201e-02, -6.2873e-04, -2.9790e-02,\n",
      "         2.3577e-02, -8.5702e-03, -2.8777e-02, -1.8312e-02, -1.7054e-02,\n",
      "        -2.4250e-02,  6.9538e-03,  2.3216e-02,  1.6299e-02,  2.5923e-02,\n",
      "        -1.0290e-02, -1.8270e-02, -1.1142e-02, -1.3284e-02, -7.7770e-04,\n",
      "        -2.6788e-02,  1.9467e-03,  7.3126e-03,  2.8666e-02,  2.3115e-02,\n",
      "        -7.7999e-03,  2.9964e-02,  2.6691e-02,  1.5356e-02, -1.6560e-02,\n",
      "        -4.6598e-03, -1.9307e-02, -1.6399e-02, -6.9545e-03,  1.5270e-03,\n",
      "         2.2987e-02,  2.4436e-02, -2.2141e-02, -9.0079e-03,  1.0878e-02,\n",
      "        -1.2826e-02, -1.1262e-02,  1.3686e-02,  2.0798e-03, -8.8957e-03,\n",
      "        -2.7835e-02,  1.7890e-02, -2.8367e-02,  1.9086e-02,  2.7194e-02,\n",
      "         2.4750e-02,  1.3044e-02, -1.5347e-02,  1.2472e-02, -1.3846e-02,\n",
      "         1.0794e-03,  2.7564e-03,  6.6227e-03, -1.6360e-02, -1.3324e-02,\n",
      "         2.6144e-02,  9.7147e-03,  2.2468e-03,  5.2867e-04, -2.4123e-02,\n",
      "         9.9973e-03,  3.0652e-02,  1.1795e-02, -5.5022e-03, -1.3095e-02,\n",
      "         2.0006e-02, -1.6382e-02,  2.7535e-02, -1.1456e-02,  1.7685e-02,\n",
      "         9.4621e-04,  1.8833e-02,  2.3391e-02, -9.4758e-03,  3.0474e-02,\n",
      "        -2.0574e-02,  2.4371e-02, -2.4827e-02,  1.0734e-02,  2.7567e-02,\n",
      "         8.4811e-03, -2.4702e-02,  4.3044e-03, -5.2771e-03,  3.0837e-02,\n",
      "        -5.6655e-03, -1.1455e-02, -1.5872e-02, -2.7105e-02,  8.3457e-03,\n",
      "         1.9309e-03,  2.8033e-02, -7.0430e-03,  1.0831e-02,  1.2892e-02,\n",
      "        -2.4345e-02,  1.7550e-02, -2.1439e-02, -7.3018e-03,  4.0798e-03,\n",
      "        -4.5881e-03, -1.1777e-02,  8.5706e-03, -8.4701e-04, -2.2743e-02,\n",
      "         1.0454e-02,  1.6670e-02,  8.3202e-03, -1.0390e-02, -2.4639e-02,\n",
      "         3.0675e-02, -8.7500e-03, -2.5215e-02,  2.9223e-02,  4.2897e-03,\n",
      "        -2.6199e-02, -2.7070e-02, -1.1744e-03, -7.8806e-04,  2.3815e-03,\n",
      "        -1.7066e-04, -1.4267e-02, -2.8839e-02,  1.2411e-02, -6.6033e-03,\n",
      "        -2.1945e-02, -2.7633e-02,  2.6394e-02, -2.8428e-02, -2.4652e-02,\n",
      "         6.6286e-03,  2.8120e-02,  8.4829e-03,  2.2480e-02,  2.7255e-02,\n",
      "         4.5076e-03, -2.7586e-02,  2.0716e-02, -1.3656e-02,  2.3301e-02,\n",
      "         1.8291e-02,  2.8964e-02,  2.6872e-02, -4.9870e-03, -1.0778e-02,\n",
      "        -2.5184e-02,  2.8953e-02, -2.4259e-02, -9.7728e-03,  1.1235e-02,\n",
      "        -7.4321e-03, -5.6165e-03, -2.6871e-02, -2.1506e-02, -1.7421e-02,\n",
      "         2.7754e-02, -1.7874e-02, -2.4126e-02, -1.5108e-02, -2.6709e-02,\n",
      "        -2.2042e-02, -2.6899e-02, -2.7553e-02, -1.6681e-02,  2.7163e-02,\n",
      "        -2.1406e-02,  1.1076e-02, -2.2437e-03, -1.1862e-02, -2.3164e-02,\n",
      "         1.6993e-02,  1.6404e-02,  1.5877e-02,  1.1028e-02, -1.7564e-02,\n",
      "        -1.4864e-02,  3.0935e-02, -2.2447e-02,  2.4404e-02, -2.3574e-02,\n",
      "         4.5228e-03, -1.4094e-02, -2.5708e-02, -1.6253e-02,  1.2773e-02,\n",
      "         3.0356e-02,  6.3494e-03, -2.0055e-02,  1.9535e-02,  1.8284e-02,\n",
      "         6.1207e-03, -1.6975e-02,  3.0768e-03,  2.0283e-03,  6.9553e-03,\n",
      "        -2.8265e-02,  1.3216e-02, -2.3470e-02, -1.5266e-02,  1.9254e-02,\n",
      "        -2.4838e-02, -4.6847e-03,  1.1164e-02, -1.8516e-02,  1.2031e-02,\n",
      "         2.0958e-03,  5.9707e-03,  2.7250e-02, -1.6557e-02,  2.7989e-02,\n",
      "         2.0211e-02,  1.5076e-03,  2.8058e-02,  2.7076e-02,  8.4177e-03,\n",
      "         1.8029e-03, -1.8269e-02,  2.1808e-02,  1.7687e-02,  3.0112e-02,\n",
      "        -1.3084e-02, -1.2712e-02,  2.4784e-02, -8.2438e-03,  1.8693e-02,\n",
      "        -1.0654e-02, -2.7975e-02,  1.6835e-02,  2.9930e-02, -2.4818e-03,\n",
      "         2.4148e-02,  1.9117e-02,  3.1047e-02,  2.4397e-02, -2.6140e-02,\n",
      "         1.9085e-03, -8.6216e-03, -1.8792e-02,  6.9069e-03, -8.3067e-03,\n",
      "         1.3838e-02, -2.9898e-02, -2.6557e-02,  3.8924e-03, -2.2247e-02,\n",
      "         1.9217e-02, -4.1910e-03, -2.7089e-02, -8.3986e-03, -2.8109e-02,\n",
      "        -2.0219e-02,  1.4007e-02, -2.3627e-02, -2.8425e-02, -2.4942e-02,\n",
      "        -1.7535e-02, -1.5158e-03, -1.6544e-02,  1.4450e-02,  2.4124e-02,\n",
      "         8.3420e-03,  1.4781e-02,  2.6209e-02,  2.1162e-02,  1.8868e-02,\n",
      "        -1.8292e-02, -3.0452e-02, -1.9434e-02,  2.9592e-02, -7.3202e-03,\n",
      "        -2.1795e-02,  1.7533e-02, -2.6246e-02, -3.1178e-03, -1.2636e-02,\n",
      "        -2.2360e-02, -6.0298e-03,  9.8933e-03,  1.1442e-02, -2.4473e-02,\n",
      "        -2.8380e-02,  3.3148e-03,  1.6591e-02,  2.0507e-02,  9.1765e-04,\n",
      "         2.0941e-02,  2.8498e-02,  2.9786e-02, -1.9410e-02,  1.4597e-02,\n",
      "         2.5977e-02, -2.5814e-02, -3.0913e-02,  1.1936e-02, -2.1769e-02,\n",
      "        -1.8128e-02, -1.3444e-02,  1.5504e-02,  1.0851e-02, -2.1540e-02,\n",
      "        -1.5872e-02,  2.2240e-02,  2.0729e-04,  7.4802e-04, -1.6565e-02,\n",
      "        -2.3009e-02, -4.6085e-03, -4.9230e-03,  9.1058e-03, -6.7844e-03,\n",
      "        -3.1410e-03,  3.0588e-02,  7.6483e-03,  1.5883e-02,  1.7281e-02,\n",
      "        -1.3294e-02,  1.2998e-03,  1.9152e-02, -1.4139e-02,  5.8047e-03,\n",
      "         2.9399e-02, -1.0426e-03, -1.6352e-02, -2.3255e-02, -2.2170e-02,\n",
      "         2.3777e-03,  1.2784e-02, -2.3809e-02,  1.8592e-02,  1.4920e-02,\n",
      "         9.7416e-03, -2.4688e-02,  1.2471e-02,  2.2452e-02, -3.8081e-03,\n",
      "        -2.7723e-02,  6.9464e-03,  2.2171e-02, -4.0262e-03,  2.1747e-02,\n",
      "         4.4594e-03,  1.5286e-02, -4.5491e-03,  2.0950e-02,  8.8879e-03,\n",
      "         2.2556e-03, -1.7766e-03,  2.0480e-02,  4.5806e-03, -1.5924e-02,\n",
      "        -4.5317e-03,  1.7787e-02, -1.1093e-02, -1.9869e-02,  1.1454e-02,\n",
      "        -1.9772e-02,  2.7677e-02, -2.6627e-02, -2.7328e-02, -1.4525e-02,\n",
      "        -2.7537e-02,  2.3070e-03, -1.6345e-02, -1.8009e-02, -6.4829e-03,\n",
      "         4.0787e-03, -9.5184e-03,  2.6651e-02, -1.9865e-02,  2.9178e-02,\n",
      "         1.0483e-02, -1.3506e-03,  2.1571e-02,  2.5905e-03,  5.6338e-05,\n",
      "        -2.1903e-02, -2.2099e-02, -1.9147e-02, -1.7092e-02, -7.3195e-03,\n",
      "        -3.0283e-04,  2.0126e-02,  2.0452e-02, -3.0884e-02, -2.5726e-02,\n",
      "        -9.9290e-03,  1.1406e-02,  2.6150e-02,  6.8646e-03, -1.6603e-02,\n",
      "         2.0555e-02, -2.0002e-02, -1.6142e-02, -1.6455e-02, -2.1082e-02,\n",
      "        -4.2552e-03, -1.8885e-02, -1.7535e-02,  1.9123e-02,  1.9323e-02,\n",
      "         2.4538e-02, -1.0096e-02, -6.9298e-03,  9.3763e-03, -3.9852e-03,\n",
      "        -1.9404e-02,  1.7183e-02], device='cuda:0', requires_grad=True))\n",
      "('7.0.conv2.weight', Parameter containing:\n",
      "tensor([[[-2.0669e-02, -5.2356e-03,  1.2685e-03],\n",
      "         [-6.8684e-03,  2.1686e-03, -1.9280e-02],\n",
      "         [ 1.5778e-02, -9.2979e-03,  4.5578e-03],\n",
      "         ...,\n",
      "         [ 1.4243e-02, -2.4120e-03, -5.4350e-04],\n",
      "         [-1.1098e-03,  1.0415e-02,  4.6432e-03],\n",
      "         [-2.0377e-02,  1.6476e-02, -1.2351e-02]],\n",
      "\n",
      "        [[-1.2523e-02, -9.2808e-03, -1.3391e-02],\n",
      "         [ 1.6634e-03, -9.0224e-03,  1.6599e-05],\n",
      "         [ 2.3988e-02, -6.5766e-03,  1.4841e-02],\n",
      "         ...,\n",
      "         [ 1.4443e-02, -7.9348e-03, -2.3604e-02],\n",
      "         [ 3.2904e-02, -1.3197e-02,  9.5795e-03],\n",
      "         [ 2.3301e-02, -1.0244e-02, -2.7111e-02]],\n",
      "\n",
      "        [[ 1.5630e-02, -2.9196e-02, -1.8790e-02],\n",
      "         [ 1.7069e-02,  1.3540e-02,  2.1647e-02],\n",
      "         [ 1.2255e-02,  1.4687e-02, -1.8639e-02],\n",
      "         ...,\n",
      "         [-9.4643e-03, -2.1697e-02, -1.9347e-03],\n",
      "         [-1.3473e-02, -1.2281e-02, -2.3990e-02],\n",
      "         [ 1.8388e-02, -2.0641e-02,  2.3937e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.7543e-03,  2.2054e-02, -3.9009e-03],\n",
      "         [ 4.4153e-03, -1.4616e-02,  6.2025e-03],\n",
      "         [ 5.7948e-03,  2.4830e-02,  6.6048e-03],\n",
      "         ...,\n",
      "         [ 3.9473e-03,  2.2727e-02,  1.8235e-02],\n",
      "         [-5.3036e-03, -7.9870e-03,  2.1246e-02],\n",
      "         [-1.1892e-02, -1.9281e-02,  5.2169e-03]],\n",
      "\n",
      "        [[-1.6733e-02,  2.0945e-02, -9.1428e-03],\n",
      "         [-1.4438e-03, -7.3914e-04,  2.4815e-02],\n",
      "         [ 2.1733e-02,  3.9433e-03,  1.7894e-02],\n",
      "         ...,\n",
      "         [-3.7968e-03,  1.9763e-02, -2.0957e-02],\n",
      "         [ 1.0219e-02, -1.7986e-03, -1.2342e-02],\n",
      "         [-1.5888e-02, -5.9415e-03, -1.9292e-02]],\n",
      "\n",
      "        [[-5.4407e-03,  1.8738e-02, -3.0656e-02],\n",
      "         [-9.9467e-03, -2.5269e-02, -1.5694e-02],\n",
      "         [-2.5365e-02, -7.7035e-03, -1.0704e-02],\n",
      "         ...,\n",
      "         [ 1.3531e-03, -1.2340e-03, -2.3618e-02],\n",
      "         [-2.4880e-02,  1.0457e-02,  1.0095e-02],\n",
      "         [-3.0064e-02, -1.3382e-04,  2.1186e-02]]], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('7.0.conv2.bias', Parameter containing:\n",
      "tensor([-2.2190e-02,  6.7099e-03,  3.3015e-05,  1.5430e-02,  2.3653e-02,\n",
      "         1.6491e-02,  1.4765e-02,  1.1614e-02,  1.8330e-02, -1.7348e-03,\n",
      "         2.3218e-02,  1.8497e-03,  2.5130e-03, -2.1620e-03, -2.2966e-02,\n",
      "         4.4453e-03,  1.0788e-02, -1.8521e-02,  1.0258e-02,  5.8034e-03,\n",
      "         2.2296e-04,  1.6538e-02,  1.1824e-02, -2.5413e-02, -6.7898e-03,\n",
      "        -1.6008e-02,  2.1822e-02, -1.0051e-02,  3.8132e-03,  1.8787e-02,\n",
      "        -8.4806e-03,  1.7123e-02, -2.5446e-02, -1.1023e-02, -2.0643e-02,\n",
      "         2.1149e-02,  2.2948e-02, -1.7954e-02,  1.2702e-02,  5.8415e-03,\n",
      "         2.1150e-02,  5.8507e-03, -9.0398e-03, -2.4662e-02,  5.7152e-03,\n",
      "        -9.9342e-03,  9.6155e-04,  1.6286e-02, -4.1377e-03, -5.2300e-03,\n",
      "         7.3429e-03, -1.2939e-02, -9.7783e-03, -1.7937e-02, -2.0435e-02,\n",
      "         1.6266e-02, -1.0719e-02, -2.3910e-02, -2.3187e-02,  1.2119e-02,\n",
      "        -1.0278e-02,  1.9101e-02,  1.7538e-02,  5.1199e-03,  7.1962e-03,\n",
      "         5.6036e-03,  3.5694e-03,  6.1190e-03,  1.6959e-02,  1.5585e-02,\n",
      "         5.1242e-03,  1.0409e-02,  2.3605e-02,  6.7566e-04, -2.0523e-02,\n",
      "         3.8285e-03,  9.0665e-03, -2.8304e-03,  1.6867e-02,  6.0550e-03,\n",
      "        -1.7184e-02,  1.3078e-02, -1.1896e-02,  1.3467e-02,  1.1686e-02,\n",
      "         2.2316e-02,  2.2616e-02,  1.6444e-03,  1.9782e-02,  1.5714e-02,\n",
      "         8.7836e-04,  2.0420e-02, -2.2282e-02, -1.4406e-02,  1.5094e-04,\n",
      "        -2.4518e-02,  1.3951e-03, -1.8912e-02,  5.3671e-03, -3.3909e-03,\n",
      "         2.6281e-03, -2.1800e-02,  1.6401e-02,  1.3534e-02,  1.6139e-02,\n",
      "         1.5712e-03,  5.0812e-03, -1.7627e-02,  2.0022e-03, -6.4085e-03,\n",
      "        -1.4291e-02,  2.3702e-03,  2.4666e-02,  1.8223e-02,  2.1757e-02,\n",
      "        -1.8872e-03,  1.0244e-02,  1.5144e-02, -1.7059e-03, -1.3698e-02,\n",
      "        -1.6162e-02,  6.8028e-04, -2.2559e-02,  4.3563e-03, -1.2197e-02,\n",
      "         1.1484e-02,  2.2624e-02, -3.7160e-03, -1.4715e-02,  1.1050e-02,\n",
      "        -6.5864e-03, -8.6335e-03, -1.0274e-02, -1.4215e-02,  2.1357e-02,\n",
      "         6.0730e-03,  5.9537e-03, -1.1303e-02, -1.0700e-02,  2.4185e-02,\n",
      "         4.2260e-03, -1.6675e-02, -7.4694e-03,  1.9358e-02,  1.3627e-02,\n",
      "        -1.9820e-02,  4.7595e-03,  2.3918e-02, -1.1692e-03,  1.0157e-02,\n",
      "        -2.5096e-02,  1.1320e-02, -2.5349e-02, -1.8710e-02,  2.1111e-02,\n",
      "        -1.6223e-02, -2.0422e-02, -1.6824e-02,  1.6485e-02, -1.3312e-02,\n",
      "        -1.8292e-02, -1.0160e-02, -1.2018e-02, -3.7554e-03,  1.4351e-02,\n",
      "         2.5507e-02, -1.9907e-02,  2.1481e-02,  9.3483e-03,  2.5180e-02,\n",
      "         1.4686e-04,  7.3526e-03, -1.8385e-02, -1.4650e-02, -5.3360e-03,\n",
      "         7.5064e-04, -9.8033e-03, -1.0997e-02,  2.1352e-03,  3.2005e-03,\n",
      "        -2.2739e-02,  3.8242e-03,  1.4851e-02,  1.9219e-02,  1.7445e-02,\n",
      "         1.4028e-02,  2.3826e-02,  2.3969e-02,  2.4520e-03,  1.1701e-02,\n",
      "         1.8184e-02,  1.3482e-02, -4.1135e-03, -2.5569e-03,  2.4864e-03,\n",
      "        -1.7272e-02,  1.6824e-02, -1.7082e-02, -4.3337e-03,  2.5006e-02,\n",
      "         1.4640e-02,  1.0454e-02,  1.2614e-02, -1.5757e-02,  6.3076e-03,\n",
      "         2.0214e-02,  1.4865e-02,  1.5832e-02,  2.3356e-02, -1.4824e-02,\n",
      "         1.0515e-02,  1.0785e-02, -2.3666e-02, -2.3118e-02,  1.8639e-02,\n",
      "        -9.8723e-03,  1.0091e-03, -1.0875e-02, -1.7401e-02, -5.7992e-03,\n",
      "        -2.1516e-02, -1.6794e-02,  1.2681e-02, -1.1902e-02, -2.8205e-03,\n",
      "        -2.3575e-02, -1.0212e-02,  1.5761e-03, -1.9730e-02,  8.8618e-03,\n",
      "        -9.0176e-03, -1.0217e-02, -1.7965e-02,  1.7283e-02, -2.2859e-02,\n",
      "         9.8213e-03,  4.0125e-03,  2.1692e-03, -2.5292e-04, -5.7226e-03,\n",
      "        -7.1553e-03,  7.6350e-03, -1.2001e-04, -1.2520e-02,  1.1922e-02,\n",
      "         2.3366e-02, -2.4955e-02, -9.5731e-04, -1.9165e-03,  1.3277e-02,\n",
      "         5.5737e-05, -1.5929e-02, -2.4149e-02,  1.8543e-02, -1.9606e-02,\n",
      "         1.4454e-02,  1.2838e-02, -1.2475e-02, -1.9319e-02, -1.9401e-02,\n",
      "        -1.5608e-03, -8.8111e-03, -4.6460e-03,  2.9382e-03, -7.0411e-04,\n",
      "        -1.3472e-03, -2.1016e-02, -7.1295e-03, -1.9186e-02, -3.1151e-03,\n",
      "        -2.2840e-02,  2.0374e-02, -9.4921e-03, -1.7846e-02,  1.4915e-02,\n",
      "         7.2846e-03,  3.5112e-03, -1.7837e-02, -1.7728e-03,  1.7223e-02,\n",
      "         6.1624e-03,  2.3580e-02,  1.0791e-02,  2.2095e-02, -8.1980e-03,\n",
      "        -1.6069e-02, -1.6992e-02, -2.5215e-02,  5.2924e-03, -7.6711e-03,\n",
      "        -2.3221e-02, -1.5184e-03,  6.9865e-03,  1.5299e-02,  1.2832e-02,\n",
      "        -7.9853e-03, -8.1959e-04,  6.4224e-03, -6.9739e-03, -1.6283e-02,\n",
      "         1.3938e-02, -1.1691e-02, -1.6899e-03, -6.7348e-03, -6.6173e-03,\n",
      "        -1.4801e-02, -6.4680e-03,  1.8050e-02,  1.3979e-02, -6.3216e-03,\n",
      "        -1.3075e-02, -1.7025e-02,  7.7957e-03,  1.7953e-02, -1.9765e-02,\n",
      "         1.2619e-02,  8.8554e-03, -2.2994e-02,  6.9316e-03,  2.1776e-02,\n",
      "        -1.1723e-03, -1.5373e-02, -2.8396e-03,  2.1734e-02,  9.4105e-03,\n",
      "        -2.4169e-02,  8.6305e-03, -1.7506e-02,  1.3644e-02,  2.4875e-02,\n",
      "        -1.0785e-02, -1.1351e-03,  5.9640e-04,  1.1718e-02,  2.4061e-02,\n",
      "         2.2457e-02,  1.0119e-02, -3.3130e-03,  7.8247e-03,  1.7641e-02,\n",
      "         1.4225e-02,  1.0347e-03, -2.0618e-02,  2.4488e-02, -2.1470e-02,\n",
      "        -1.3677e-03,  1.1676e-02,  1.4122e-02,  2.4787e-02, -2.1396e-02,\n",
      "         8.8971e-03,  5.3414e-03, -1.6780e-02,  1.0136e-02,  1.6821e-02,\n",
      "        -1.4412e-02,  7.1048e-04,  5.6157e-03, -2.3555e-02, -2.5487e-02,\n",
      "         2.0482e-02,  2.0542e-02, -1.9494e-02, -9.9861e-03,  1.4338e-02,\n",
      "        -1.4549e-02,  8.5492e-03, -5.2107e-03, -1.3619e-02, -5.3897e-03,\n",
      "         4.7848e-03, -1.2308e-02, -2.3653e-03, -2.2179e-02, -1.5036e-02,\n",
      "        -1.6635e-03, -1.6171e-04,  1.0856e-02, -4.6161e-03,  2.3653e-02,\n",
      "         2.3113e-02,  7.0194e-03, -7.1594e-03, -2.0610e-02,  9.0072e-03,\n",
      "        -1.0078e-02,  7.6076e-03, -1.1289e-02,  1.6316e-02, -8.9292e-03,\n",
      "        -1.9518e-02, -1.4518e-02, -2.4630e-02, -3.8401e-03,  1.2617e-02,\n",
      "        -2.1704e-02,  1.5600e-02, -1.9009e-02, -1.3881e-02, -9.5934e-03,\n",
      "        -2.2035e-02, -1.6709e-02,  7.5677e-03,  1.4552e-02,  9.3547e-03,\n",
      "         6.0139e-04,  3.0789e-03,  5.8119e-03,  6.8334e-03, -1.7403e-02,\n",
      "        -3.9571e-03, -1.4088e-02,  5.6181e-04, -7.7475e-03, -7.4610e-03,\n",
      "        -2.3821e-02,  2.3471e-02,  1.7030e-02,  4.1291e-03,  2.0303e-02,\n",
      "        -2.4704e-02,  1.0258e-02,  1.7096e-02, -1.4320e-02, -1.0264e-02,\n",
      "        -2.3114e-02,  5.2698e-03, -2.3637e-02, -2.2977e-02, -1.5361e-02,\n",
      "        -9.0503e-03, -5.0938e-03, -1.7616e-02, -2.2426e-02,  1.1328e-02,\n",
      "        -1.8207e-02,  5.9665e-03, -5.4454e-03, -1.8940e-02, -9.8993e-04,\n",
      "         2.1582e-02,  1.8660e-02, -2.0293e-02,  1.7197e-02,  4.2030e-03,\n",
      "        -7.4983e-03,  1.4447e-02,  1.5399e-02, -2.4404e-02, -1.5019e-02,\n",
      "        -1.9170e-03, -6.0745e-03,  2.2279e-02,  5.7739e-03, -1.6580e-02,\n",
      "         2.4092e-02, -1.5593e-02,  1.9515e-02, -1.1274e-02,  7.1570e-03,\n",
      "        -7.4506e-03,  3.3541e-03,  1.6231e-02,  1.8207e-02, -1.5300e-02,\n",
      "        -3.2613e-03, -2.5079e-02,  1.5710e-03,  1.7384e-02,  2.5344e-02,\n",
      "         2.1636e-03, -1.6002e-02, -1.6992e-02,  2.6338e-04,  4.4327e-03,\n",
      "         1.1314e-02,  3.2288e-03, -8.1984e-04,  2.4307e-02, -1.2347e-02,\n",
      "        -2.2869e-02,  3.5222e-03,  2.3466e-02,  1.4593e-02,  9.2965e-03,\n",
      "         6.7992e-03, -1.7009e-02, -4.4317e-03,  2.4372e-02, -1.0022e-02,\n",
      "         1.3803e-02, -2.4208e-02,  2.2257e-02, -2.7830e-03,  1.5856e-02,\n",
      "         2.3362e-02,  2.1137e-02, -1.5513e-03, -2.2994e-02,  1.3838e-03,\n",
      "        -5.7419e-03,  1.0016e-02, -3.8457e-03, -3.2185e-03,  2.5427e-02,\n",
      "        -2.0158e-02,  7.6017e-03, -6.3025e-03, -2.3012e-03, -2.2215e-02,\n",
      "         8.0556e-03, -2.5098e-02], device='cuda:0', requires_grad=True))\n",
      "('7.0.conv3.weight', Parameter containing:\n",
      "tensor([[[-0.0115],\n",
      "         [ 0.0462],\n",
      "         [-0.0317],\n",
      "         ...,\n",
      "         [ 0.0351],\n",
      "         [ 0.0412],\n",
      "         [ 0.0032]],\n",
      "\n",
      "        [[ 0.0213],\n",
      "         [ 0.0358],\n",
      "         [-0.0289],\n",
      "         ...,\n",
      "         [ 0.0208],\n",
      "         [-0.0069],\n",
      "         [-0.0387]],\n",
      "\n",
      "        [[ 0.0135],\n",
      "         [ 0.0219],\n",
      "         [-0.0291],\n",
      "         ...,\n",
      "         [-0.0101],\n",
      "         [-0.0370],\n",
      "         [-0.0068]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0426],\n",
      "         [ 0.0431],\n",
      "         [ 0.0307],\n",
      "         ...,\n",
      "         [ 0.0186],\n",
      "         [ 0.0221],\n",
      "         [-0.0184]],\n",
      "\n",
      "        [[-0.0081],\n",
      "         [ 0.0036],\n",
      "         [-0.0370],\n",
      "         ...,\n",
      "         [ 0.0134],\n",
      "         [ 0.0340],\n",
      "         [ 0.0348]],\n",
      "\n",
      "        [[-0.0120],\n",
      "         [-0.0283],\n",
      "         [-0.0047],\n",
      "         ...,\n",
      "         [ 0.0373],\n",
      "         [-0.0510],\n",
      "         [-0.0266]]], device='cuda:0', requires_grad=True))\n",
      "('7.0.conv3.bias', Parameter containing:\n",
      "tensor([ 0.0030, -0.0137, -0.0392,  ...,  0.0243,  0.0135,  0.0053],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.0.conv4.weight', Parameter containing:\n",
      "tensor([[[ 0.0200],\n",
      "         [ 0.0513],\n",
      "         [ 0.0253],\n",
      "         ...,\n",
      "         [-0.0006],\n",
      "         [-0.0062],\n",
      "         [ 0.0371]],\n",
      "\n",
      "        [[ 0.0276],\n",
      "         [ 0.0170],\n",
      "         [-0.0202],\n",
      "         ...,\n",
      "         [-0.0026],\n",
      "         [-0.0071],\n",
      "         [-0.0181]],\n",
      "\n",
      "        [[ 0.0170],\n",
      "         [-0.0087],\n",
      "         [-0.0088],\n",
      "         ...,\n",
      "         [ 0.0200],\n",
      "         [ 0.0113],\n",
      "         [ 0.0250]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0242],\n",
      "         [-0.0259],\n",
      "         [-0.0018],\n",
      "         ...,\n",
      "         [ 0.0052],\n",
      "         [-0.0192],\n",
      "         [-0.0460]],\n",
      "\n",
      "        [[-0.0290],\n",
      "         [-0.0104],\n",
      "         [ 0.0001],\n",
      "         ...,\n",
      "         [ 0.0239],\n",
      "         [-0.0124],\n",
      "         [ 0.0085]],\n",
      "\n",
      "        [[ 0.0292],\n",
      "         [ 0.0204],\n",
      "         [-0.0025],\n",
      "         ...,\n",
      "         [ 0.0218],\n",
      "         [ 0.0148],\n",
      "         [ 0.0080]]], device='cuda:0', requires_grad=True))\n",
      "('7.0.conv4.bias', Parameter containing:\n",
      "tensor([ 0.0297,  0.0135,  0.0048,  ...,  0.0122, -0.0178, -0.0007],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.0.bn1.weight', Parameter containing:\n",
      "tensor([0.9766, 0.9897, 1.0038, 0.9772, 0.9933, 0.9765, 1.0461, 1.0183, 1.0057,\n",
      "        0.9799, 0.9976, 0.9848, 0.9854, 1.0458, 1.0008, 1.0104, 1.0333, 0.9784,\n",
      "        1.0189, 0.9869, 1.0014, 1.0142, 0.9781, 1.0078, 1.0215, 0.9955, 0.9962,\n",
      "        1.0069, 0.9910, 1.0268, 0.9786, 0.9906, 0.9841, 1.0090, 0.9844, 1.0018,\n",
      "        0.9899, 0.9810, 0.9852, 0.9876, 1.0050, 0.9799, 0.9887, 1.0030, 0.9844,\n",
      "        0.9931, 0.9855, 0.9952, 1.0004, 0.9780, 1.0070, 1.0058, 1.0206, 0.9809,\n",
      "        0.9844, 1.0253, 1.0022, 1.0027, 0.9856, 0.9961, 0.9828, 1.0093, 0.9843,\n",
      "        0.9836, 1.0012, 0.9803, 0.9876, 0.9995, 0.9899, 1.0409, 1.0100, 1.0010,\n",
      "        0.9935, 0.9920, 1.0083, 1.0184, 1.0037, 0.9880, 1.0105, 0.9922, 0.9862,\n",
      "        1.0219, 0.9920, 1.0079, 0.9976, 0.9903, 0.9878, 0.9866, 0.9999, 0.9918,\n",
      "        0.9807, 0.9864, 1.0018, 0.9765, 0.9908, 1.0076, 1.0289, 1.0022, 1.0045,\n",
      "        1.0074, 1.0104, 1.0007, 0.9846, 0.9890, 1.0070, 1.0105, 0.9953, 0.9934,\n",
      "        1.0066, 1.0340, 1.0023, 0.9900, 1.0004, 1.0276, 1.0057, 0.9847, 1.0354,\n",
      "        1.0022, 0.9906, 0.9919, 0.9998, 0.9978, 1.0095, 0.9967, 1.0039, 0.9839,\n",
      "        1.0031, 0.9925, 0.9787, 0.9865, 1.0161, 1.0027, 0.9764, 1.0059, 0.9957,\n",
      "        0.9941, 1.0081, 0.9986, 1.0126, 1.0055, 0.9776, 0.9834, 1.0071, 1.0029,\n",
      "        0.9885, 0.9981, 0.9943, 1.0020, 1.0308, 1.0013, 1.0009, 1.0043, 0.9932,\n",
      "        1.0637, 0.9916, 1.0052, 1.0026, 1.0103, 0.9987, 0.9842, 0.9951, 1.0090,\n",
      "        0.9902, 1.0001, 0.9945, 0.9955, 0.9847, 1.0491, 0.9918, 1.0009, 0.9857,\n",
      "        1.0079, 1.0018, 0.9858, 0.9889, 0.9922, 1.0096, 1.0122, 0.9921, 1.0138,\n",
      "        1.0246, 0.9867, 0.9911, 0.9924, 1.0064, 0.9833, 0.9923, 1.0300, 1.0023,\n",
      "        0.9927, 0.9836, 0.9948, 1.0002, 1.0098, 0.9826, 0.9857, 0.9970, 1.0190,\n",
      "        0.9944, 0.9898, 0.9892, 1.0049, 0.9905, 0.9921, 0.9920, 1.0043, 0.9992,\n",
      "        0.9848, 0.9855, 0.9801, 0.9885, 0.9866, 0.9812, 0.9918, 0.9817, 0.9773,\n",
      "        0.9869, 0.9838, 0.9899, 0.9876, 0.9835, 0.9832, 0.9926, 1.0193, 1.0001,\n",
      "        0.9913, 0.9974, 1.0098, 0.9836, 0.9944, 0.9801, 1.0230, 0.9933, 0.9903,\n",
      "        0.9899, 1.0229, 0.9909, 0.9824, 1.0134, 1.0156, 1.0044, 0.9944, 0.9976,\n",
      "        1.0128, 0.9962, 0.9983, 0.9876, 1.0062, 0.9985, 1.0112, 0.9967, 1.0000,\n",
      "        1.0029, 0.9964, 0.9925, 1.0206, 0.9902, 0.9994, 0.9820, 1.0002, 0.9898,\n",
      "        1.0087, 0.9908, 0.9937, 0.9917, 1.0188, 0.9769, 1.0007, 1.0091, 1.0003,\n",
      "        1.0366, 0.9808, 1.0150, 0.9893, 0.9955, 0.9842, 1.0598, 1.0041, 0.9963,\n",
      "        1.0273, 0.9917, 1.0004, 1.0167, 0.9951, 0.9870, 1.0035, 0.9897, 1.0081,\n",
      "        0.9778, 0.9898, 0.9977, 1.0048, 0.9902, 1.0135, 0.9965, 0.9914, 0.9910,\n",
      "        0.9944, 0.9959, 1.0159, 0.9920, 1.0020, 0.9952, 0.9887, 0.9877, 0.9878,\n",
      "        0.9878, 0.9908, 1.0229, 1.0054, 1.0113, 0.9904, 0.9887, 0.9957, 0.9748,\n",
      "        1.0009, 0.9851, 1.0333, 1.0048, 1.0134, 0.9927, 0.9973, 0.9945, 0.9884,\n",
      "        1.0062, 1.0139, 0.9833, 0.9905, 0.9966, 1.0102, 1.0046, 0.9940, 0.9879,\n",
      "        0.9939, 0.9975, 0.9914, 0.9926, 0.9942, 0.9979, 1.0468, 1.0561, 0.9845,\n",
      "        0.9959, 1.0068, 0.9875, 0.9986, 1.0218, 1.0154, 0.9954, 0.9958, 1.0232,\n",
      "        0.9938, 1.0207, 1.0671, 1.0001, 0.9871, 1.0350, 0.9830, 0.9960, 1.0208,\n",
      "        0.9978, 1.0093, 1.0060, 0.9875, 0.9817, 0.9897, 1.0051, 1.0201, 0.9983,\n",
      "        0.9904, 1.0061, 1.0047, 1.0022, 0.9944, 0.9906, 1.0106, 0.9960, 0.9984,\n",
      "        1.0039, 1.0010, 0.9982, 0.9940, 1.0324, 0.9933, 1.0118, 0.9902, 0.9894,\n",
      "        1.0080, 1.0357, 0.9990, 0.9850, 0.9908, 0.9852, 1.0036, 1.0070, 0.9854,\n",
      "        0.9815, 0.9874, 0.9933, 1.0015, 1.0179, 1.0359, 0.9928, 0.9947, 1.0064,\n",
      "        0.9989, 0.9958, 0.9923, 0.9966, 0.9858, 1.0009, 1.0315, 1.0076, 0.9971,\n",
      "        0.9976, 1.0034, 1.0132, 0.9927, 1.0144, 0.9925, 0.9967, 0.9979, 0.9915,\n",
      "        0.9956, 0.9869, 0.9992, 0.9923, 0.9884, 1.0101, 0.9838, 0.9983, 0.9823,\n",
      "        0.9946, 0.9971, 1.0078, 0.9839, 1.0059, 0.9863, 1.0139, 1.0107, 0.9987,\n",
      "        1.0147, 0.9949, 0.9933, 1.0036, 0.9984, 0.9825, 1.0019, 0.9994, 1.0048,\n",
      "        0.9929, 0.9991, 1.0142, 0.9920, 1.0063, 1.0146, 0.9895, 1.0082, 0.9909,\n",
      "        0.9926, 0.9847, 1.0036, 0.9820, 0.9901, 1.0188, 0.9889, 0.9747, 0.9911,\n",
      "        0.9983, 0.9812, 0.9895, 1.0038, 1.0067, 0.9881, 0.9884, 1.0144, 0.9859,\n",
      "        0.9866, 0.9812, 0.9965, 1.0066, 1.0041, 1.0078, 0.9910, 0.9980, 0.9957,\n",
      "        1.0300, 0.9901, 1.0268, 0.9913, 0.9895, 1.0124, 0.9983, 1.0407, 0.9930,\n",
      "        0.9804, 1.0052, 1.0190, 1.0069, 0.9994, 0.9933, 1.0053, 0.9992, 1.0036,\n",
      "        1.0302, 0.9991, 0.9936, 0.9986, 0.9985, 0.9915, 0.9995, 1.0207],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.0.bn1.bias', Parameter containing:\n",
      "tensor([-0.0413, -0.0337, -0.0223, -0.0499, -0.0309, -0.0277, -0.0851, -0.0004,\n",
      "         0.0061, -0.0849, -0.0086, -0.0265, -0.0234, -0.0852, -0.0340, -0.0032,\n",
      "        -0.0269, -0.0561, -0.0308, -0.0112, -0.0148, -0.0288, -0.0369, -0.0257,\n",
      "        -0.0298, -0.0410, -0.0162, -0.0498, -0.0673, -0.0036, -0.0468, -0.0559,\n",
      "        -0.0091, -0.0369, -0.0238, -0.0242, -0.0184, -0.1026, -0.0177, -0.0155,\n",
      "        -0.0111, -0.0296, -0.0377, -0.0467, -0.0269, -0.0520, -0.0215, -0.0420,\n",
      "        -0.0366, -0.0395, -0.0168, -0.0676, -0.0317, -0.0288, -0.0181, -0.0620,\n",
      "        -0.0136, -0.0466, -0.0395, -0.0111, -0.0182, -0.0440, -0.0340, -0.0251,\n",
      "        -0.0041, -0.0222, -0.0277, -0.0651, -0.1251, -0.0078, -0.0303, -0.0044,\n",
      "        -0.0594, -0.0223, -0.0234, -0.0267, -0.0574, -0.0166, -0.0169, -0.0278,\n",
      "        -0.0302, -0.0795, -0.0903, -0.0137, -0.0163, -0.0358, -0.0282, -0.0196,\n",
      "        -0.0399, -0.0210, -0.0304, -0.0462, -0.0332, -0.0484, -0.0723, -0.1192,\n",
      "        -0.0940, -0.0271, -0.0225, -0.0172, -0.0195, -0.0790, -0.0353, -0.0243,\n",
      "        -0.0208, -0.0208, -0.0085, -0.0207, -0.0497, -0.0652, -0.0638, -0.0162,\n",
      "        -0.0458, -0.0640, -0.0276, -0.0502, -0.0438, -0.0177, -0.0071, -0.0368,\n",
      "        -0.0133, -0.0349, -0.0076, -0.0252, -0.0146, -0.0233, -0.0365, -0.0639,\n",
      "        -0.0563, -0.0190, -0.0053, -0.0161, -0.0256, -0.0200, -0.0465, -0.0692,\n",
      "        -0.1355, -0.0110, -0.0173, -0.0165, -0.0343, -0.0094, -0.0177, -0.1080,\n",
      "        -0.0345, -0.0200, -0.0193, -0.0293, -0.0551, -0.0365, -0.0539, -0.0061,\n",
      "        -0.0243, -0.0060, -0.0145, -0.0087, -0.0416, -0.0325, -0.0417, -0.0220,\n",
      "        -0.0217, -0.2179, -0.0405, -0.0023, -0.0400, -0.0353, -0.0507, -0.0147,\n",
      "        -0.0264, -0.0183, -0.0225, -0.0212, -0.0354, -0.0454, -0.0156, -0.0331,\n",
      "        -0.0103, -0.0219, -0.0178, -0.0207, -0.1497, -0.0149, -0.0207, -0.0944,\n",
      "        -0.0326, -0.0286, -0.0068, -0.0474, -0.0165, -0.0317, -0.0453, -0.0199,\n",
      "        -0.0857, -0.0237, -0.0234, -0.0394, -0.0298, -0.0056, -0.0433, -0.0168,\n",
      "        -0.1514, -0.0485, -0.0321, -0.0181, -0.0174, -0.0309, -0.0487, -0.0201,\n",
      "        -0.0249, -0.0198, -0.0170, -0.0164, -0.0181, -0.0247, -0.0398, -0.0253,\n",
      "        -0.0277, -0.0180, -0.0144, -0.0154, -0.0185, -0.0424, -0.0173, -0.0491,\n",
      "        -0.0122, -0.0309, -0.0137, -0.0434, -0.0246, -0.0495, -0.0232, -0.0438,\n",
      "        -0.0846, -0.0197, -0.0236, -0.0163, -0.0363, -0.0134, -0.0271, -0.0690,\n",
      "        -0.0187, -0.0136, -0.0168, -0.0493, -0.0234, -0.0178, -0.0303, -0.0411,\n",
      "        -0.0184, -0.0631, -0.0281, -0.0125, -0.0981, -0.0189, -0.0085, -0.0274,\n",
      "        -0.0198, -0.0234, -0.0460, -0.0047, -0.0153, -0.0036, -0.0456, -0.0309,\n",
      "        -0.0273, -0.0291, -0.0635, -0.0149, -0.0116, -0.0090, -0.0797, -0.0204,\n",
      "        -0.0618, -0.0362, -0.0360, -0.0175, -0.1938, -0.0052, -0.0279,  0.0174,\n",
      "        -0.0208, -0.0230, -0.0371, -0.0304, -0.0419, -0.0085, -0.0294, -0.0323,\n",
      "        -0.0148, -0.0366, -0.0576, -0.0111, -0.0210, -0.0398, -0.0089, -0.0204,\n",
      "        -0.0372, -0.0235, -0.0870,  0.0101, -0.0225, -0.0152, -0.0386, -0.0264,\n",
      "        -0.0298, -0.0048, -0.0235, -0.0916, -0.0948, -0.0091, -0.0379, -0.0608,\n",
      "        -0.0319, -0.0464, -0.0185, -0.0283, -0.0212, -0.1113, -0.0492, -0.0356,\n",
      "        -0.0092, -0.0166, -0.0161, -0.0349, -0.0887, -0.0497, -0.0217, -0.1014,\n",
      "        -0.0159, -0.0664, -0.0084, -0.0522, -0.0240, -0.0045, -0.0120, -0.0315,\n",
      "        -0.0122, -0.0349, -0.0338, -0.1356, -0.0772, -0.0253, -0.0350, -0.0272,\n",
      "        -0.0139, -0.0665, -0.1060, -0.0266, -0.0214, -0.0162, -0.0337, -0.0046,\n",
      "        -0.0093, -0.0757, -0.0069, -0.0400, -0.0766, -0.0246, -0.0081, -0.0074,\n",
      "        -0.0377, -0.0213, -0.0435, -0.0113, -0.0161, -0.0351, -0.0440, -0.0174,\n",
      "        -0.0203, -0.0274, -0.0086, -0.0263, -0.0203, -0.0370, -0.0205, -0.0685,\n",
      "        -0.0664, -0.0213, -0.0113, -0.0152, -0.0451, -0.0330, -0.0286, -0.0124,\n",
      "        -0.1210, -0.0477, -0.0163, -0.0328, -0.0951, -0.0441, -0.0121, -0.0093,\n",
      "        -0.0282, -0.0157, -0.0226, -0.0282, -0.0150, -0.0260, -0.1459, -0.0113,\n",
      "        -0.0219, -0.0624, -0.0222, -0.0245, -0.0264, -0.0357, -0.0228, -0.0253,\n",
      "        -0.0210, -0.0196, -0.0130, -0.0814, -0.0048, -0.0225, -0.0324, -0.0294,\n",
      "        -0.0497, -0.0099, -0.0413, -0.0154, -0.0327, -0.0283, -0.0151, -0.0240,\n",
      "        -0.0242, -0.0283, -0.0286, -0.0244, -0.0503, -0.0227, -0.0285, -0.0120,\n",
      "        -0.0139, -0.0293, -0.0207, -0.0184, -0.0136, -0.0252, -0.0482, -0.0019,\n",
      "        -0.0270, -0.0325, -0.0196, -0.0078, -0.0124, -0.1152, -0.0272, -0.0156,\n",
      "        -0.0039, -0.0116, -0.0059, -0.0306, -0.0321, -0.0067, -0.0384, -0.0332,\n",
      "        -0.0405, -0.0677, -0.0166, -0.0422, -0.0447, -0.0372, -0.0375, -0.0235,\n",
      "        -0.0464, -0.0126, -0.0272, -0.0143, -0.0043, -0.0183, -0.0169, -0.0105,\n",
      "        -0.0135, -0.0319, -0.0293, -0.0272, -0.0383, -0.0240, -0.0512, -0.0353,\n",
      "        -0.0167, -0.0175, -0.0364, -0.0441, -0.0624, -0.0209, -0.0437, -0.0059,\n",
      "        -0.0256, -0.0195, -0.0505, -0.1609, -0.1002, -0.0287, -0.0224, -0.0371,\n",
      "        -0.0477, -0.0366, -0.0205, -0.0453, -0.0504, -0.0528, -0.0894, -0.0451,\n",
      "        -0.0334,  0.0040, -0.0285, -0.0346, -0.0269, -0.0453, -0.0282, -0.0364],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.0.bn2.weight', Parameter containing:\n",
      "tensor([1.0005, 1.0180, 0.9938, 0.9915, 1.0055, 1.0003, 1.0002, 0.9919, 1.0093,\n",
      "        0.9951, 0.9914, 0.9893, 0.9948, 1.0078, 0.9882, 0.9908, 0.9924, 0.9957,\n",
      "        1.0410, 0.9953, 1.0006, 1.0216, 0.9951, 1.0243, 0.9956, 0.9970, 0.9887,\n",
      "        1.0288, 0.9936, 0.9953, 0.9908, 0.9933, 1.0025, 0.9952, 0.9978, 0.9920,\n",
      "        0.9944, 0.9983, 0.9956, 0.9911, 1.0014, 1.0047, 0.9949, 0.9956, 1.0055,\n",
      "        0.9866, 0.9977, 1.0143, 0.9921, 0.9979, 1.0293, 0.9925, 0.9891, 0.9940,\n",
      "        1.0105, 1.0007, 0.9907, 0.9876, 0.9942, 0.9884, 1.0065, 0.9929, 0.9944,\n",
      "        0.9913, 0.9945, 1.0128, 0.9991, 0.9889, 0.9917, 0.9948, 0.9955, 0.9944,\n",
      "        0.9889, 0.9919, 0.9965, 0.9978, 1.0313, 1.0056, 1.0008, 0.9962, 0.9982,\n",
      "        0.9966, 0.9969, 0.9967, 0.9945, 0.9938, 0.9893, 1.0005, 1.0025, 0.9879,\n",
      "        1.0077, 1.0074, 0.9881, 0.9849, 0.9918, 0.9956, 1.0073, 0.9906, 1.0227,\n",
      "        0.9969, 1.0058, 1.0177, 0.9949, 0.9914, 1.0058, 1.0196, 1.0176, 0.9935,\n",
      "        0.9847, 1.0103, 0.9893, 0.9907, 0.9968, 0.9849, 0.9937, 1.0021, 1.0260,\n",
      "        0.9930, 0.9965, 1.0314, 0.9923, 0.9928, 1.0066, 0.9931, 1.0100, 0.9913,\n",
      "        1.0161, 1.0015, 1.0436, 1.0102, 0.9922, 1.0312, 0.9937, 0.9930, 0.9954,\n",
      "        0.9881, 0.9897, 1.0082, 1.0012, 0.9918, 0.9991, 0.9882, 0.9895, 0.9935,\n",
      "        1.0033, 0.9913, 1.0210, 0.9938, 1.0035, 0.9862, 0.9968, 0.9955, 0.9951,\n",
      "        0.9896, 0.9915, 1.0422, 0.9947, 0.9952, 1.0302, 0.9932, 0.9959, 0.9865,\n",
      "        0.9935, 0.9924, 0.9877, 0.9999, 1.0043, 1.0523, 1.0121, 0.9920, 0.9956,\n",
      "        0.9957, 1.0315, 1.0128, 1.0239, 0.9946, 0.9932, 0.9949, 1.0194, 1.0105,\n",
      "        1.0113, 1.0016, 0.9969, 1.0005, 1.0015, 0.9888, 0.9943, 0.9917, 1.0122,\n",
      "        0.9949, 0.9961, 0.9876, 0.9969, 0.9870, 0.9971, 1.0004, 0.9919, 0.9981,\n",
      "        0.9924, 1.0129, 1.0012, 0.9907, 0.9877, 1.0013, 0.9915, 0.9910, 1.0035,\n",
      "        1.0074, 0.9938, 0.9964, 0.9936, 0.9943, 1.0067, 0.9899, 0.9930, 1.0017,\n",
      "        0.9829, 0.9900, 0.9999, 0.9940, 1.0260, 0.9946, 0.9963, 0.9989, 0.9944,\n",
      "        0.9887, 1.0029, 1.0068, 0.9931, 0.9901, 0.9953, 0.9804, 1.0403, 0.9959,\n",
      "        1.0004, 0.9956, 0.9956, 1.0189, 0.9895, 1.0021, 0.9952, 0.9917, 0.9917,\n",
      "        1.0023, 0.9966, 0.9859, 1.0073, 0.9941, 0.9991, 1.0073, 0.9886, 0.9983,\n",
      "        0.9870, 0.9876, 1.0320, 0.9975, 0.9955, 1.0128, 0.9905, 1.0058, 0.9979,\n",
      "        1.0051, 0.9938, 1.0043, 1.0240, 0.9982, 0.9946, 0.9957, 1.0580, 0.9928,\n",
      "        1.0057, 0.9904, 0.9985, 1.0216, 1.0050, 0.9997, 0.9975, 0.9970, 0.9871,\n",
      "        0.9927, 0.9978, 0.9856, 0.9900, 0.9934, 1.0038, 1.0015, 0.9975, 0.9889,\n",
      "        0.9946, 0.9944, 0.9897, 1.0200, 1.0403, 1.0029, 0.9987, 0.9934, 1.0276,\n",
      "        0.9900, 0.9859, 0.9949, 0.9934, 0.9864, 0.9931, 1.0051, 1.0029, 1.0271,\n",
      "        0.9891, 0.9931, 1.0050, 1.0100, 1.0357, 0.9936, 0.9945, 0.9961, 0.9967,\n",
      "        0.9924, 0.9926, 1.0081, 0.9920, 0.9985, 0.9907, 1.0029, 0.9914, 1.0052,\n",
      "        1.0057, 0.9946, 0.9893, 0.9994, 0.9946, 0.9885, 1.0153, 1.0304, 1.0029,\n",
      "        1.0190, 0.9946, 0.9879, 1.0041, 0.9996, 1.0044, 0.9847, 0.9920, 0.9973,\n",
      "        0.9901, 0.9946, 0.9870, 0.9928, 0.9885, 1.0034, 0.9963, 0.9906, 0.9945,\n",
      "        0.9896, 1.0112, 1.0009, 1.0090, 0.9901, 1.0134, 0.9992, 1.0002, 1.0142,\n",
      "        0.9944, 1.0346, 0.9951, 0.9976, 0.9909, 1.0034, 0.9988, 1.0063, 0.9897,\n",
      "        0.9936, 0.9971, 1.0046, 0.9891, 0.9929, 0.9999, 0.9944, 0.9972, 1.0015,\n",
      "        1.0012, 0.9929, 1.0267, 1.0058, 0.9965, 1.0017, 0.9910, 0.9906, 1.0132,\n",
      "        0.9948, 1.0186, 0.9923, 0.9892, 0.9941, 0.9948, 0.9905, 0.9896, 0.9878,\n",
      "        1.0018, 1.0016, 1.0156, 0.9997, 0.9891, 1.0031, 1.0162, 0.9956, 0.9890,\n",
      "        0.9902, 0.9931, 0.9933, 0.9907, 0.9945, 1.0193, 0.9899, 1.0426, 0.9891,\n",
      "        0.9950, 0.9977, 1.0168, 1.0375, 0.9980, 1.0092, 0.9972, 0.9959, 1.0030,\n",
      "        0.9919, 1.0045, 0.9938, 0.9900, 1.0246, 0.9840, 1.0118, 1.0146, 0.9961,\n",
      "        1.0247, 1.0098, 0.9918, 1.0023, 0.9934, 0.9925, 0.9977, 0.9945, 1.0045,\n",
      "        0.9993, 0.9918, 0.9973, 0.9937, 0.9885, 0.9942, 0.9963, 0.9915, 0.9901,\n",
      "        0.9964, 1.0242, 0.9960, 0.9876, 1.0174, 1.0277, 0.9923, 1.0127, 1.0110,\n",
      "        1.0098, 1.0016, 1.0139, 1.0033, 0.9952, 0.9904, 0.9966, 0.9915, 1.0084,\n",
      "        0.9941, 0.9927, 0.9985, 1.0072, 1.0117, 0.9989, 0.9912, 1.0101, 0.9933,\n",
      "        0.9905, 0.9930, 0.9914, 0.9938, 0.9991, 0.9934, 0.9993, 0.9963, 1.0112,\n",
      "        1.0002, 0.9955, 0.9945, 0.9998, 0.9929, 0.9900, 0.9959, 0.9914, 0.9950,\n",
      "        0.9933, 0.9916, 1.0125, 0.9872, 0.9913, 0.9959, 0.9944, 1.0017, 1.0341,\n",
      "        0.9941, 0.9905, 0.9957, 0.9904, 1.0373, 1.0134, 0.9864, 0.9944],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.0.bn2.bias', Parameter containing:\n",
      "tensor([-3.2714e-03, -2.4553e-02, -5.6945e-03, -1.0833e-02, -1.5929e-02,\n",
      "        -4.6466e-03, -1.4887e-02, -4.2990e-03, -9.2429e-03, -5.5933e-03,\n",
      "        -8.3464e-03, -6.9525e-03, -9.6536e-03, -2.6980e-02, -1.2141e-02,\n",
      "        -5.8332e-03, -3.2893e-03, -1.0208e-02, -8.9366e-02, -3.4349e-03,\n",
      "        -1.9130e-02, -1.6505e-02, -5.6151e-03, -8.0926e-02, -7.0364e-03,\n",
      "         4.7402e-03, -7.1227e-03, -1.2694e-02, -1.0104e-02, -6.8316e-03,\n",
      "        -6.3241e-03, -5.2865e-03, -6.8770e-03, -8.7773e-03, -6.0070e-03,\n",
      "        -5.8182e-03, -1.5738e-02, -1.2991e-02, -2.4118e-02, -1.9181e-02,\n",
      "        -3.6293e-02, -4.3656e-02, -1.3629e-02, -1.8213e-02, -5.9494e-02,\n",
      "        -5.0767e-03, -5.6950e-03, -1.3958e-02, -9.0125e-03, -3.3562e-03,\n",
      "        -5.3198e-02, -9.1779e-03, -5.9546e-03, -5.6796e-03, -2.8213e-02,\n",
      "        -1.6486e-02, -9.8159e-03, -8.4602e-03, -1.9282e-02, -9.6957e-03,\n",
      "        -2.4493e-02, -1.8024e-02, -4.2927e-03, -2.6098e-02, -8.8449e-03,\n",
      "        -1.8594e-02, -1.2453e-02, -7.9465e-03, -1.2173e-02, -7.4182e-03,\n",
      "        -8.0980e-03, -1.7674e-02, -2.1054e-03, -1.1176e-02, -1.8148e-02,\n",
      "        -4.8007e-02, -2.2731e-02, -5.0952e-02, -5.3029e-02,  2.1101e-04,\n",
      "        -2.5879e-03, -1.8722e-02, -5.3859e-02, -3.9443e-03, -7.7450e-03,\n",
      "        -1.1166e-02, -4.4731e-03, -1.8515e-02, -1.7222e-02, -9.0625e-03,\n",
      "        -2.7507e-02, -1.3243e-02, -6.4302e-03, -1.1247e-02, -1.7801e-03,\n",
      "        -1.4710e-02, -4.3275e-02, -1.2492e-02, -3.0127e-02, -1.2166e-02,\n",
      "        -2.1638e-02, -5.7825e-02, -1.0094e-02, -2.9107e-03, -4.9690e-02,\n",
      "        -6.3104e-02, -5.7925e-02, -7.9372e-03, -8.2357e-03, -4.3761e-02,\n",
      "        -7.4133e-03, -2.2638e-02, -1.2472e-02, -7.2635e-03, -5.4908e-03,\n",
      "        -2.8099e-02, -1.4306e-02, -1.3592e-02, -5.3860e-03, -1.8484e-02,\n",
      "        -1.8859e-03, -3.8990e-02, -7.6467e-03, -1.5790e-03, -5.0568e-02,\n",
      "        -1.2271e-02,  1.8489e-03, -4.9252e-02, -2.2922e-02, -5.8094e-02,\n",
      "        -2.3457e-02, -3.2484e-02, -1.1564e-02, -1.3387e-02, -4.7377e-03,\n",
      "        -7.6108e-03, -1.9524e-02, -2.7021e-02, -8.0594e-03, -1.3223e-02,\n",
      "        -1.5801e-02, -1.2056e-02, -1.8951e-02, -2.0413e-02, -1.1941e-03,\n",
      "        -1.5814e-02, -8.4783e-03, -2.1266e-02, -2.3613e-02, -7.3905e-03,\n",
      "        -4.7677e-03, -4.9349e-03, -2.6305e-03, -1.7248e-02, -4.3341e-03,\n",
      "        -6.8791e-02, -1.4722e-02, -7.0643e-03, -1.5967e-02, -3.6799e-03,\n",
      "        -2.9373e-02, -5.7195e-03, -1.1596e-02, -1.7959e-02, -6.1078e-03,\n",
      "        -7.4845e-03, -1.2863e-02, -7.9888e-02, -2.1301e-02, -7.6669e-03,\n",
      "        -4.3007e-03, -6.3166e-03, -1.7941e-02, -1.6366e-02, -2.9237e-02,\n",
      "        -2.3617e-02, -2.6163e-02, -2.2774e-03, -1.3141e-02, -3.6490e-02,\n",
      "        -1.9922e-02, -2.1300e-02, -2.2298e-02, -4.5280e-02, -5.0125e-03,\n",
      "        -2.4740e-02, -1.5262e-02, -1.1991e-02, -4.1442e-02, -1.2982e-02,\n",
      "        -3.4178e-03, -1.2080e-02, -2.1542e-03, -1.1586e-02, -3.3321e-04,\n",
      "        -1.0496e-03, -4.4226e-03, -4.1117e-03, -1.8202e-02, -7.5780e-03,\n",
      "        -4.2450e-02, -5.1457e-03, -1.1467e-04, -8.6478e-03, -1.9124e-02,\n",
      "        -2.4957e-02, -2.7417e-02, -1.9495e-02, -2.3244e-02, -5.0476e-03,\n",
      "        -8.5466e-03, -7.1965e-03, -2.0393e-02, -7.5406e-03, -7.5866e-03,\n",
      "        -2.3006e-02, -1.1224e-02, -1.1145e-02, -3.0356e-02, -1.3709e-02,\n",
      "         1.0152e-02, -2.4208e-02, -8.1667e-03, -2.7617e-03, -1.1934e-02,\n",
      "        -1.9698e-02, -2.1646e-03, -2.8652e-02, -9.8412e-03, -1.3940e-02,\n",
      "        -2.8338e-03, -1.4112e-02, -7.0952e-02, -7.3380e-03, -1.2621e-02,\n",
      "        -4.0248e-02, -7.8389e-03, -2.2218e-02, -9.0410e-03, -1.1668e-02,\n",
      "        -1.0834e-02, -7.4035e-03, -6.4603e-03, -1.0524e-03, -2.3731e-02,\n",
      "        -1.2303e-02, -1.8021e-02, -7.3008e-03, -2.2558e-02, -2.1251e-02,\n",
      "        -6.3660e-03, -8.5976e-03, -1.7845e-02, -1.5621e-02, -8.1532e-02,\n",
      "        -4.9236e-02, -1.8015e-03, -2.3790e-02, -8.6521e-03, -2.0791e-02,\n",
      "        -2.9513e-02, -2.2057e-02, -1.3824e-02, -2.7337e-02, -6.0501e-02,\n",
      "        -5.9318e-02, -7.2325e-03, -2.0132e-02, -8.9080e-02, -3.0533e-02,\n",
      "        -3.4359e-02, -8.7841e-03, -1.7899e-02, -3.1812e-02,  3.7166e-03,\n",
      "        -9.7635e-03, -1.7700e-03, -1.3318e-02, -1.1539e-02, -1.8611e-02,\n",
      "        -3.9581e-02, -2.6611e-02, -1.5248e-02, -1.3188e-02, -8.6929e-04,\n",
      "        -2.7783e-03, -1.8942e-02, -1.0337e-02, -4.0690e-03, -8.9017e-03,\n",
      "        -6.7642e-03, -3.0806e-02, -1.9771e-02, -3.9593e-02, -5.2632e-04,\n",
      "        -5.9414e-03, -6.6055e-02, -7.4757e-03, -1.5158e-02, -2.0615e-02,\n",
      "        -5.5154e-03, -1.5065e-02, -7.8123e-03, -3.1467e-02, -1.3685e-03,\n",
      "        -2.2330e-02, -1.6111e-02, -4.6643e-03, -1.6473e-02, -2.8219e-02,\n",
      "        -6.0640e-03, -3.9420e-03, -7.6145e-03,  4.4219e-03, -2.7098e-02,\n",
      "        -7.7470e-03, -1.3851e-02, -2.0166e-02, -6.0924e-03, -5.7541e-05,\n",
      "        -6.0808e-03, -1.8194e-02, -1.6943e-02, -6.3610e-03, -1.7200e-02,\n",
      "         3.2871e-04, -1.6766e-02, -9.2967e-03, -2.3319e-02, -1.6098e-02,\n",
      "        -7.2700e-02, -6.9798e-02, -3.1705e-02, -1.7125e-02, -4.4397e-03,\n",
      "        -1.1541e-02, -2.4211e-02, -7.9352e-03, -2.2594e-02, -1.3868e-02,\n",
      "        -2.1067e-02, -6.3581e-03, -8.2102e-03, -9.7280e-03, -7.6657e-03,\n",
      "        -1.2285e-02, -1.0016e-02, -3.2010e-02, -7.8815e-03, -1.4578e-02,\n",
      "        -3.8316e-02, -5.8057e-03,  6.8208e-03, -1.4041e-02, -1.7379e-02,\n",
      "        -1.3173e-02, -2.4688e-03,  4.3523e-04, -2.9735e-02, -3.2322e-02,\n",
      "        -3.5203e-02, -5.5567e-02, -8.8765e-03, -2.4322e-02, -1.0394e-02,\n",
      "        -6.7814e-03, -1.1015e-02, -1.5099e-02, -1.0393e-02, -4.9122e-03,\n",
      "        -2.7007e-03, -2.7400e-02, -8.1004e-03, -3.1157e-02, -3.9107e-02,\n",
      "        -1.0909e-02, -4.4189e-03, -3.7666e-03, -4.0127e-03, -1.1715e-02,\n",
      "        -1.5522e-02, -2.9244e-02, -2.6644e-03, -4.6453e-02, -1.1363e-02,\n",
      "        -1.5968e-02, -2.8379e-02, -1.6243e-02, -4.0350e-02, -1.9293e-02,\n",
      "        -6.2655e-03, -6.2378e-03, -1.7944e-02, -1.0809e-02, -8.8261e-03,\n",
      "        -7.4400e-03, -6.3850e-03, -8.4444e-03, -7.3546e-02, -1.6515e-02,\n",
      "        -1.0044e-02, -1.0719e-02, -1.0177e-02, -3.5728e-03, -1.2483e-02,\n",
      "        -2.5173e-02, -6.5369e-03, -8.0794e-03, -8.0857e-03, -5.6250e-03,\n",
      "        -1.1792e-02, -7.8839e-03, -3.7395e-02, -1.6306e-02, -2.4041e-02,\n",
      "        -4.0371e-02, -2.0188e-02, -7.9655e-02, -1.8311e-02, -4.4922e-02,\n",
      "        -2.9364e-02, -7.1892e-03, -8.3331e-03, -7.3890e-03, -2.1831e-02,\n",
      "        -5.4138e-03, -9.7371e-03, -3.7978e-02, -7.4929e-03, -2.0935e-02,\n",
      "        -6.9848e-02, -9.7284e-03, -4.3688e-02, -1.5748e-02, -1.2682e-02,\n",
      "        -2.1231e-02, -1.5780e-02, -3.1446e-03, -3.4923e-02, -4.6148e-03,\n",
      "         4.6317e-03, -7.8991e-03, -2.2755e-02, -2.1037e-02, -1.8664e-03,\n",
      "        -8.8997e-03, -9.4897e-03, -3.1154e-02, -1.4986e-02, -2.5782e-02,\n",
      "        -3.3663e-03, -5.9030e-02, -5.7554e-03, -1.2866e-02, -1.7210e-02,\n",
      "        -2.0639e-02, -2.4304e-02, -6.6733e-02, -3.8767e-02, -3.5459e-02,\n",
      "        -1.5445e-02, -1.4441e-02, -7.7219e-03,  4.0951e-05, -1.1546e-02,\n",
      "        -1.5490e-02, -3.9880e-03, -3.7572e-02, -5.7019e-03, -4.9528e-03,\n",
      "        -2.4571e-03, -5.0367e-02, -3.6874e-02, -9.5840e-03, -1.1568e-02,\n",
      "        -2.2299e-02, -1.7978e-02, -8.6253e-03, -6.3617e-03, -1.4502e-02,\n",
      "        -2.0461e-02, -3.1350e-02, -1.1651e-02, -7.8768e-03, -2.3199e-02,\n",
      "        -1.1236e-02, -1.4316e-02, -2.3085e-03, -2.6287e-02, -3.3392e-02,\n",
      "        -6.7894e-03, -7.6235e-03, -1.0106e-02, -1.6325e-02, -1.2978e-02,\n",
      "        -3.0724e-02, -9.4963e-03, -8.7797e-03, -1.1376e-02, -1.0292e-02,\n",
      "        -2.2364e-03, -1.5747e-03, -1.3856e-02, -2.6110e-02, -2.9322e-03,\n",
      "        -1.8303e-02, -1.1812e-02, -7.2635e-03, -3.5486e-03, -2.8004e-02,\n",
      "        -6.9388e-03, -4.7752e-03], device='cuda:0', requires_grad=True))\n",
      "('7.0.bn3.weight', Parameter containing:\n",
      "tensor([1.0252, 1.0011, 0.9996,  ..., 0.9995, 1.0009, 1.0186], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('7.0.bn3.bias', Parameter containing:\n",
      "tensor([ 7.3869e-04, -1.2993e-05, -1.3511e-04,  ..., -1.3730e-04,\n",
      "        -1.3900e-03,  1.2495e-03], device='cuda:0', requires_grad=True))\n",
      "('7.1.conv1.weight', Parameter containing:\n",
      "tensor([[[-4.4255e-03],\n",
      "         [-1.7878e-02],\n",
      "         [ 1.9711e-02],\n",
      "         ...,\n",
      "         [-2.1918e-02],\n",
      "         [ 8.3864e-03],\n",
      "         [ 1.4565e-02]],\n",
      "\n",
      "        [[ 3.5001e-03],\n",
      "         [-1.1898e-02],\n",
      "         [ 1.7124e-02],\n",
      "         ...,\n",
      "         [-1.0332e-02],\n",
      "         [-4.9031e-03],\n",
      "         [ 1.1339e-02]],\n",
      "\n",
      "        [[-1.9527e-02],\n",
      "         [-3.4095e-03],\n",
      "         [-1.6776e-02],\n",
      "         ...,\n",
      "         [ 1.2224e-02],\n",
      "         [ 2.0237e-02],\n",
      "         [-1.1645e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.1780e-02],\n",
      "         [ 1.8766e-02],\n",
      "         [ 1.0446e-02],\n",
      "         ...,\n",
      "         [ 6.7987e-06],\n",
      "         [-2.6579e-03],\n",
      "         [ 1.6422e-02]],\n",
      "\n",
      "        [[-7.9760e-03],\n",
      "         [ 8.4725e-03],\n",
      "         [ 1.8592e-02],\n",
      "         ...,\n",
      "         [-1.1376e-03],\n",
      "         [ 1.1395e-02],\n",
      "         [-1.2505e-02]],\n",
      "\n",
      "        [[ 2.9431e-02],\n",
      "         [ 1.3720e-02],\n",
      "         [ 1.4811e-02],\n",
      "         ...,\n",
      "         [-1.0069e-02],\n",
      "         [ 1.9128e-02],\n",
      "         [ 1.6104e-02]]], device='cuda:0', requires_grad=True))\n",
      "('7.1.conv1.bias', Parameter containing:\n",
      "tensor([-1.9293e-02, -1.1706e-02,  1.6298e-02, -1.4145e-02,  1.7962e-02,\n",
      "         2.0646e-03,  1.1961e-02,  2.0660e-03, -1.9395e-02, -4.7516e-03,\n",
      "        -1.6741e-02,  1.7677e-02, -3.6296e-03, -3.9858e-03, -1.5590e-02,\n",
      "         1.7374e-02, -1.4407e-02,  7.3534e-03,  2.3475e-03, -2.0964e-02,\n",
      "         1.6802e-02, -2.2095e-03, -1.7380e-02, -5.5725e-03,  5.9808e-04,\n",
      "        -1.2547e-02,  6.3498e-03, -5.1645e-03,  1.8692e-02, -1.4717e-02,\n",
      "         1.9867e-02, -7.7735e-04, -5.1433e-03,  2.0055e-02,  1.6713e-02,\n",
      "        -1.5656e-02,  7.3930e-03,  1.5008e-02,  1.9025e-03,  4.3135e-03,\n",
      "        -3.2228e-03,  1.8805e-02, -2.1526e-02,  9.8201e-03, -2.1155e-02,\n",
      "         1.3117e-02,  1.2154e-02, -9.9731e-03,  2.8915e-05, -2.6232e-03,\n",
      "        -7.9844e-03,  2.2095e-02,  3.3150e-03, -5.7685e-03, -8.5779e-03,\n",
      "        -1.8609e-03,  8.5902e-03,  1.0626e-02, -1.4291e-02,  1.3860e-02,\n",
      "        -5.1989e-03, -3.0275e-03, -1.0708e-02, -1.8253e-02, -2.0022e-02,\n",
      "        -1.3144e-02,  1.5196e-02,  1.4569e-03, -1.5190e-02, -1.8035e-02,\n",
      "         4.3153e-03,  1.5088e-02,  1.9579e-02, -7.7314e-03,  7.8288e-04,\n",
      "         9.5108e-03,  2.1938e-02, -1.6491e-02, -1.0139e-02, -3.1531e-03,\n",
      "        -1.8624e-02,  9.6617e-03, -1.3538e-02, -1.6585e-02,  1.0440e-02,\n",
      "        -1.8002e-02, -1.7935e-02, -9.2038e-03, -5.8429e-03, -5.3464e-03,\n",
      "        -4.1202e-03,  1.1155e-02, -7.1863e-03,  1.7002e-02,  1.7580e-02,\n",
      "        -1.2971e-02, -1.5998e-02, -2.1829e-02,  3.3230e-03, -1.1959e-04,\n",
      "         4.3502e-03,  1.9053e-02, -7.6087e-03,  1.6869e-02, -1.1608e-02,\n",
      "         1.7784e-02, -3.5863e-03, -2.0951e-02, -2.0423e-03, -2.1381e-02,\n",
      "         2.0645e-02,  4.0822e-04, -1.3040e-02,  1.2905e-02,  1.9546e-02,\n",
      "         6.7591e-03, -1.0896e-02, -1.5488e-03, -2.0279e-02, -1.2515e-02,\n",
      "        -1.8267e-02,  1.0931e-02, -2.1428e-02, -2.1458e-02, -5.6030e-03,\n",
      "        -1.7028e-02, -5.1182e-04,  1.5873e-02, -1.0584e-02,  1.3261e-02,\n",
      "        -1.7238e-02, -3.6484e-03,  8.8944e-04, -1.4603e-02, -1.9984e-02,\n",
      "         5.4353e-03, -1.1306e-02,  1.8904e-02, -2.7320e-03,  1.8048e-03,\n",
      "         1.4052e-02, -6.3241e-03,  1.7933e-03, -3.9148e-03,  1.6115e-02,\n",
      "        -1.1215e-02, -1.7053e-03,  4.6699e-03,  1.3422e-02, -1.6380e-02,\n",
      "        -5.8562e-03,  7.3277e-03, -9.9047e-04, -6.2316e-03, -1.2168e-02,\n",
      "        -3.0943e-03, -1.8505e-02, -2.0853e-02,  2.0019e-02,  1.1544e-02,\n",
      "        -1.7786e-02, -1.0974e-02,  4.5546e-03,  2.0197e-03, -3.5672e-03,\n",
      "         5.1434e-03,  3.6556e-03, -2.4023e-03, -1.0585e-02, -2.2083e-02,\n",
      "        -1.0761e-02,  1.0138e-02, -6.8032e-03, -1.9103e-02,  1.6812e-02,\n",
      "         3.5562e-03,  7.1346e-03,  1.0881e-02, -1.5856e-02,  1.8181e-02,\n",
      "        -6.0809e-03,  7.4481e-03, -5.7626e-03,  1.3869e-02,  1.5047e-02,\n",
      "         1.2029e-02,  2.3418e-03, -2.1922e-02,  2.1014e-02, -7.0034e-03,\n",
      "        -1.6039e-02, -1.1272e-02,  1.7058e-02, -1.8858e-02, -1.3616e-02,\n",
      "        -1.1554e-02, -6.1458e-03,  1.7449e-02,  1.5066e-02, -2.2066e-03,\n",
      "         2.0067e-02,  1.5293e-02,  1.5298e-02, -1.4203e-02, -4.2861e-03,\n",
      "        -2.9707e-03,  2.1070e-02, -1.7922e-02, -1.6576e-02, -1.6861e-02,\n",
      "         1.8578e-02, -1.3023e-02, -8.8588e-03,  1.6244e-02,  6.9936e-04,\n",
      "         9.2370e-03, -1.8919e-02,  1.2101e-02,  8.5249e-03, -2.1844e-03,\n",
      "         9.0848e-03, -1.1725e-02,  1.7063e-02,  2.4313e-03, -7.6791e-03,\n",
      "         1.7590e-02,  1.7529e-02, -1.0037e-04, -1.4609e-02, -2.0344e-02,\n",
      "        -2.1553e-02,  2.0335e-02,  4.5771e-03,  1.1179e-02,  7.7665e-03,\n",
      "         2.1969e-02, -1.1870e-02,  2.0840e-02, -1.2054e-02, -6.5917e-03,\n",
      "        -2.1305e-02, -7.1448e-03,  1.9604e-02, -3.6954e-03, -1.6896e-03,\n",
      "         2.1162e-02,  1.3230e-02, -9.5733e-04,  5.6677e-03,  1.7228e-02,\n",
      "         1.6895e-02, -2.5400e-03, -4.0013e-04,  1.5997e-03,  5.0384e-03,\n",
      "         8.7095e-03, -1.4203e-02,  8.1696e-05,  1.3815e-02,  1.9038e-02,\n",
      "        -1.3894e-02, -1.4678e-02, -1.3526e-02, -1.2986e-02, -1.0131e-02,\n",
      "         1.4635e-02, -1.2113e-02,  8.6327e-03, -2.1552e-02,  2.0098e-02,\n",
      "         1.3738e-02, -2.0767e-03, -5.8074e-04,  1.0402e-02,  1.9067e-02,\n",
      "         2.0856e-02, -1.6237e-02,  1.6424e-02, -2.2351e-03, -1.9671e-02,\n",
      "         8.2447e-03, -2.1872e-02, -1.2304e-02,  1.1001e-02,  2.9273e-04,\n",
      "        -1.2348e-02,  6.9885e-03, -1.7309e-02, -1.8170e-02,  1.1549e-04,\n",
      "        -1.9746e-02, -1.1961e-02,  1.4313e-02,  1.1420e-02,  1.1780e-02,\n",
      "        -9.2675e-03,  1.8828e-02, -8.5369e-03,  1.2922e-02,  1.8545e-02,\n",
      "         1.6246e-02,  1.8164e-02, -1.7864e-02,  7.3669e-04, -5.3996e-03,\n",
      "         1.7140e-02, -4.9035e-03,  2.7656e-03,  2.0877e-02,  1.5643e-02,\n",
      "         1.3311e-02,  1.6071e-02, -5.6973e-03,  4.5588e-03,  3.4350e-03,\n",
      "         5.3595e-03,  1.6402e-03, -2.8314e-03, -1.8563e-02,  6.3669e-03,\n",
      "         2.1809e-02, -3.0012e-03,  1.2092e-02, -4.9821e-03, -1.9817e-02,\n",
      "         9.7769e-03, -6.4926e-03,  1.3727e-02, -1.0603e-02, -1.8420e-02,\n",
      "        -8.7802e-03,  8.6073e-03, -1.3238e-03,  1.6159e-02, -7.2219e-03,\n",
      "         1.4736e-02, -4.1489e-03, -1.9439e-02,  3.1773e-03,  1.3733e-03,\n",
      "        -2.2836e-03, -6.7718e-03,  1.1583e-03,  1.0412e-02, -8.7175e-03,\n",
      "         6.3891e-03,  2.1739e-02,  2.1884e-04,  1.9786e-02, -1.5145e-02,\n",
      "        -3.0926e-03, -2.0901e-02,  1.9711e-02, -2.9350e-03,  1.4343e-02,\n",
      "         8.9579e-03,  1.7897e-02, -1.6613e-02, -2.2180e-03,  3.0199e-04,\n",
      "         1.8362e-02, -1.0541e-02,  8.1141e-03, -1.9053e-02, -5.0564e-03,\n",
      "        -5.2833e-03,  5.4539e-03,  1.5811e-02, -1.3619e-02,  6.9309e-03,\n",
      "         1.3069e-02, -7.1423e-03,  1.7385e-03, -7.5451e-04, -2.0944e-02,\n",
      "        -4.0858e-03,  7.6503e-03, -1.7512e-02, -5.8383e-04, -3.4653e-03,\n",
      "        -1.3315e-02, -5.3035e-03, -1.0641e-02, -2.1976e-02, -1.3548e-02,\n",
      "         4.6725e-03,  4.4516e-03, -5.2846e-03,  1.0637e-02,  2.4441e-03,\n",
      "        -4.6454e-03, -2.0947e-03, -2.4784e-03, -1.2289e-02,  1.7587e-02,\n",
      "        -1.9545e-02,  2.1412e-02, -9.9393e-03, -1.1990e-02, -2.1218e-02,\n",
      "        -2.0830e-02, -7.3111e-03,  8.9947e-03,  7.0269e-03, -3.1803e-03,\n",
      "        -1.7777e-02, -1.8970e-02,  1.9733e-02, -3.7965e-03,  8.5158e-03,\n",
      "         2.7966e-03, -6.3666e-03, -1.1643e-02,  1.8591e-02,  9.0723e-04,\n",
      "        -1.3668e-02, -2.9650e-03,  1.9895e-02, -6.1636e-03,  2.2514e-03,\n",
      "        -1.1088e-03,  2.3354e-03,  4.7438e-03, -3.7959e-03,  3.7188e-03,\n",
      "        -7.8174e-03, -1.6567e-02, -5.9704e-04, -6.2236e-04, -1.3056e-02,\n",
      "        -1.8075e-02, -6.5650e-03,  8.0725e-04,  9.9212e-03,  6.2187e-03,\n",
      "         1.7129e-02,  4.8029e-03,  2.0569e-02, -1.1323e-02,  1.2041e-02,\n",
      "        -5.2460e-03, -8.4182e-03,  2.0168e-02,  1.7700e-02, -9.2952e-03,\n",
      "         5.8530e-03, -1.2089e-02, -5.9670e-03, -1.5026e-02, -4.4583e-05,\n",
      "         5.6638e-03, -1.5149e-02,  1.1337e-02,  9.0964e-03, -1.3429e-02,\n",
      "        -5.2877e-03, -2.0540e-02,  7.9235e-03, -2.0308e-02, -2.1658e-02,\n",
      "        -9.2281e-03,  1.9566e-03,  1.8365e-02,  9.8815e-03,  2.0941e-02,\n",
      "        -8.5607e-03,  9.4306e-03,  1.7243e-02,  1.5185e-02,  1.8218e-02,\n",
      "         1.5621e-03, -1.3090e-02, -1.5798e-02, -2.1888e-02, -3.0664e-03,\n",
      "         2.8242e-03,  1.6401e-03, -5.0628e-03, -1.0078e-02, -9.2302e-03,\n",
      "         1.6862e-02, -2.3136e-03, -1.8092e-02, -8.8334e-03, -1.4209e-02,\n",
      "         2.0217e-02, -1.5398e-02,  1.9182e-03,  1.4868e-02,  1.6915e-03,\n",
      "        -1.2438e-02, -1.4789e-02,  6.9445e-03, -1.4068e-03, -1.3713e-02,\n",
      "        -4.5594e-03, -2.0971e-02, -6.8837e-03, -1.2123e-02,  8.4920e-04,\n",
      "        -4.0407e-03,  2.2392e-03,  2.3477e-03, -2.0342e-02, -1.6435e-02,\n",
      "        -2.1631e-02, -4.2679e-03, -1.3118e-02, -2.1757e-02, -3.2304e-03,\n",
      "         1.2372e-02,  1.7279e-02], device='cuda:0', requires_grad=True))\n",
      "('7.1.conv2.weight', Parameter containing:\n",
      "tensor([[[-0.0238, -0.0038, -0.0172],\n",
      "         [-0.0125,  0.0290,  0.0040],\n",
      "         [-0.0127, -0.0011, -0.0229],\n",
      "         ...,\n",
      "         [ 0.0244, -0.0107,  0.0222],\n",
      "         [-0.0072,  0.0255,  0.0051],\n",
      "         [-0.0270,  0.0124,  0.0120]],\n",
      "\n",
      "        [[-0.0172,  0.0108, -0.0153],\n",
      "         [-0.0221,  0.0192,  0.0040],\n",
      "         [ 0.0248, -0.0069, -0.0100],\n",
      "         ...,\n",
      "         [-0.0113, -0.0177, -0.0109],\n",
      "         [-0.0226,  0.0227,  0.0101],\n",
      "         [ 0.0138, -0.0168, -0.0159]],\n",
      "\n",
      "        [[ 0.0008,  0.0134,  0.0197],\n",
      "         [ 0.0154,  0.0194, -0.0134],\n",
      "         [ 0.0088,  0.0052, -0.0075],\n",
      "         ...,\n",
      "         [ 0.0030, -0.0241,  0.0007],\n",
      "         [ 0.0184, -0.0114, -0.0030],\n",
      "         [ 0.0203, -0.0166,  0.0235]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0172, -0.0249,  0.0055],\n",
      "         [-0.0228,  0.0177,  0.0009],\n",
      "         [ 0.0178, -0.0115,  0.0123],\n",
      "         ...,\n",
      "         [-0.0119,  0.0018,  0.0235],\n",
      "         [ 0.0067, -0.0068,  0.0227],\n",
      "         [ 0.0142, -0.0207,  0.0268]],\n",
      "\n",
      "        [[ 0.0048,  0.0219, -0.0058],\n",
      "         [-0.0272,  0.0113,  0.0078],\n",
      "         [-0.0183,  0.0108, -0.0110],\n",
      "         ...,\n",
      "         [ 0.0167,  0.0154, -0.0205],\n",
      "         [ 0.0047, -0.0064,  0.0167],\n",
      "         [ 0.0165, -0.0062,  0.0062]],\n",
      "\n",
      "        [[-0.0181,  0.0085, -0.0274],\n",
      "         [ 0.0238,  0.0022, -0.0158],\n",
      "         [-0.0076,  0.0153,  0.0129],\n",
      "         ...,\n",
      "         [-0.0012, -0.0087,  0.0006],\n",
      "         [ 0.0018,  0.0176,  0.0453],\n",
      "         [ 0.0073, -0.0152, -0.0067]]], device='cuda:0', requires_grad=True))\n",
      "('7.1.conv2.bias', Parameter containing:\n",
      "tensor([-2.2480e-02,  2.1265e-02, -8.2151e-03, -6.5457e-03,  2.3215e-02,\n",
      "        -1.6242e-02, -6.3461e-03,  2.9669e-04, -5.5870e-03, -1.9042e-02,\n",
      "        -2.0251e-02,  5.5628e-03, -2.1513e-02,  2.4047e-02,  7.7780e-03,\n",
      "         1.2635e-02,  6.2591e-03,  4.8460e-03,  1.5277e-02, -1.0756e-02,\n",
      "        -2.7622e-03, -1.1051e-02,  6.8605e-04, -1.5241e-02,  6.5761e-03,\n",
      "         2.1850e-02,  1.6756e-02, -1.0790e-02,  3.4415e-03,  1.8136e-02,\n",
      "         1.9233e-02,  1.4729e-02,  2.5030e-02, -2.3023e-02,  2.2910e-02,\n",
      "        -1.2274e-03,  4.1217e-04, -1.6733e-02,  5.4813e-03, -1.3250e-02,\n",
      "         2.0633e-02,  1.7696e-02,  7.0881e-03,  7.7521e-03,  5.1469e-03,\n",
      "         1.7840e-04, -5.4600e-03,  1.4661e-02,  1.5532e-02, -1.4039e-02,\n",
      "         3.6073e-03,  1.5116e-02, -1.6669e-02, -1.9894e-02, -1.8862e-02,\n",
      "        -4.6960e-03,  1.1437e-02,  1.8640e-02,  1.5497e-02, -4.8896e-03,\n",
      "        -1.4699e-02, -2.4763e-02, -7.3442e-03, -2.5067e-02,  4.9277e-03,\n",
      "         2.4689e-02, -1.3407e-02,  2.4767e-02,  1.8705e-02,  2.4137e-03,\n",
      "         8.7668e-03, -2.2823e-02, -2.1051e-02, -1.8868e-02, -1.5228e-02,\n",
      "         1.8766e-02, -8.7865e-03,  1.4461e-02, -1.3509e-02,  1.5614e-02,\n",
      "         6.2047e-03, -8.2290e-03,  1.4027e-02, -1.5606e-02,  1.6492e-02,\n",
      "         2.2833e-02, -2.2628e-02,  1.4408e-02, -8.2122e-03, -2.0579e-02,\n",
      "        -1.8826e-02, -2.4456e-02, -2.2817e-02, -8.3123e-03, -4.8149e-03,\n",
      "         1.6249e-02,  5.1334e-03, -1.0573e-02,  1.4539e-02,  8.6579e-03,\n",
      "         7.1271e-03, -1.4928e-02, -5.1932e-03, -2.4741e-02, -1.8188e-02,\n",
      "        -1.9284e-02, -1.3253e-02,  7.7494e-04,  1.3090e-03, -7.6294e-03,\n",
      "        -2.2947e-02, -1.2767e-02,  1.0626e-02,  1.0986e-02, -1.4361e-02,\n",
      "         2.1525e-02,  1.2575e-02, -2.4373e-02, -1.2312e-02, -2.1110e-03,\n",
      "        -2.1773e-02, -8.9740e-03,  1.7495e-02, -4.5069e-03,  2.2113e-02,\n",
      "         2.6556e-03, -2.0890e-02,  1.7707e-03,  1.4158e-02,  5.1978e-03,\n",
      "        -1.4156e-02, -2.1686e-02, -6.0269e-03,  1.1934e-02, -2.3921e-02,\n",
      "         1.5572e-02, -8.7260e-04,  1.5352e-02, -7.0814e-03, -9.5865e-03,\n",
      "         1.8107e-02,  1.9140e-03, -7.6300e-03, -1.9848e-03, -6.7861e-03,\n",
      "        -6.9305e-03, -8.3747e-03,  4.3250e-03, -2.1424e-02, -2.0195e-02,\n",
      "         5.3900e-03,  1.5378e-02, -1.2567e-02,  2.2157e-02, -1.0750e-02,\n",
      "         8.2567e-03, -1.4147e-02,  1.7004e-02, -2.1050e-02, -1.2469e-02,\n",
      "        -1.1836e-02,  1.9225e-02,  1.3632e-02,  1.9301e-02, -1.3496e-02,\n",
      "        -1.5078e-02,  1.6644e-02,  1.0374e-02, -6.0771e-03,  1.8417e-02,\n",
      "         2.0411e-02, -8.7067e-04,  9.2880e-03, -2.1378e-02, -7.5137e-03,\n",
      "        -7.1298e-04,  2.4080e-02, -2.4259e-02, -2.0223e-02,  3.8021e-03,\n",
      "         1.8993e-02,  5.5348e-03, -2.1511e-02,  1.5728e-02, -2.0109e-02,\n",
      "         1.2924e-02,  3.6874e-04, -1.0053e-04,  1.9751e-02, -9.7461e-03,\n",
      "         5.8127e-03, -1.2368e-03,  2.7430e-03, -2.9703e-03, -6.0811e-03,\n",
      "         8.4714e-03,  6.8445e-03,  1.4517e-02, -1.5573e-02,  1.1286e-02,\n",
      "         2.0060e-02,  9.7010e-04, -2.0175e-02, -2.2582e-02,  3.6842e-03,\n",
      "         6.2954e-03,  1.9372e-02, -2.3907e-02, -9.6140e-03,  1.4009e-02,\n",
      "         1.7999e-02, -2.9089e-03, -4.1690e-04, -1.8599e-02,  4.9873e-03,\n",
      "        -1.1700e-02, -4.9096e-03,  3.0330e-03,  2.1764e-02,  1.5887e-02,\n",
      "        -1.9863e-02,  2.3049e-02, -2.1391e-02,  1.2768e-02,  2.2752e-02,\n",
      "        -1.6107e-02,  2.0029e-02, -2.3462e-02,  1.2255e-02, -1.6346e-02,\n",
      "         1.5356e-02,  1.7547e-02, -6.7784e-03,  6.2810e-03, -2.3198e-02,\n",
      "        -1.9911e-02, -1.7933e-02, -2.3950e-02,  8.1367e-03, -9.6778e-03,\n",
      "         5.5539e-03, -4.1911e-03,  5.3117e-04,  4.7941e-03,  2.0007e-03,\n",
      "        -1.5350e-02, -1.7181e-02, -2.4267e-02,  6.2166e-03,  2.5003e-02,\n",
      "         1.1603e-02, -1.6713e-02, -1.8906e-02,  3.5538e-03,  5.3523e-03,\n",
      "        -1.0103e-02, -2.4069e-02,  1.6110e-02, -1.6024e-02, -6.5485e-03,\n",
      "         1.8817e-02, -1.1757e-02,  1.7166e-02,  1.6612e-02, -5.4367e-03,\n",
      "         1.5399e-02, -1.6125e-02,  4.9829e-03, -1.3199e-02,  2.5971e-03,\n",
      "        -1.2220e-02,  2.4395e-03,  5.9231e-03, -8.9722e-03, -5.2410e-03,\n",
      "         1.2549e-03,  7.2697e-03,  4.5599e-03,  2.4367e-02, -2.4969e-02,\n",
      "        -7.6979e-03, -1.6009e-02,  1.7651e-02,  3.6446e-03,  1.5136e-02,\n",
      "         1.3062e-02,  1.0117e-02,  2.3290e-03,  3.8769e-03,  2.0968e-02,\n",
      "        -6.8423e-03,  7.2200e-03,  1.7754e-02, -2.2132e-02, -7.6965e-03,\n",
      "         1.8903e-02, -5.7159e-04,  9.0599e-03,  2.4200e-02, -6.9195e-03,\n",
      "        -1.4461e-03,  1.2114e-02, -9.0948e-03,  1.5896e-02, -6.6554e-03,\n",
      "         1.3058e-02, -2.0891e-02,  2.5265e-02,  4.7861e-04, -2.5172e-02,\n",
      "         8.8597e-03,  1.4676e-02, -1.5812e-02,  6.2273e-03,  1.8043e-02,\n",
      "        -1.8548e-02, -9.8492e-03, -1.4092e-03, -1.4725e-02,  4.9211e-05,\n",
      "         2.2589e-02, -2.0083e-02,  5.0809e-03, -1.0144e-02,  2.3312e-03,\n",
      "        -1.6702e-02,  1.8430e-02, -1.1371e-02, -7.9721e-03,  1.8832e-02,\n",
      "        -1.9631e-02, -1.3810e-02,  2.0880e-02,  1.2944e-02, -1.1686e-02,\n",
      "        -2.3938e-02, -2.1202e-02, -1.5719e-02,  2.0884e-02, -2.0622e-02,\n",
      "        -2.1548e-02, -1.4623e-02,  2.2318e-02, -1.7121e-02,  1.1531e-02,\n",
      "         1.7636e-02, -2.1366e-02, -1.2996e-02,  6.2213e-03, -1.3637e-02,\n",
      "        -1.5312e-02, -6.3604e-03,  1.7578e-02, -7.2816e-03,  2.3338e-02,\n",
      "         9.5309e-03, -1.3461e-02, -1.1667e-02,  1.4016e-02, -1.3888e-02,\n",
      "        -3.2326e-03,  2.2638e-02,  1.7930e-02,  5.5751e-03, -1.4846e-02,\n",
      "        -2.3252e-02, -1.2949e-02,  1.8687e-02,  7.2627e-03,  1.9346e-03,\n",
      "         7.5303e-03, -4.4750e-03, -2.1207e-02,  1.4307e-02, -1.2090e-02,\n",
      "         1.0822e-02, -2.2225e-02,  2.8814e-03, -1.4155e-03, -2.1777e-02,\n",
      "        -4.2703e-03,  6.5112e-03, -2.4338e-02,  2.3165e-02, -1.5709e-02,\n",
      "         1.0016e-02,  2.4394e-03,  7.0089e-03, -1.2609e-02, -1.1812e-02,\n",
      "        -1.1564e-02,  1.6558e-02, -8.7054e-03, -3.4986e-04, -1.8374e-03,\n",
      "        -7.7936e-03, -2.1163e-02, -1.5639e-02,  1.7848e-02, -2.2908e-02,\n",
      "         3.9552e-03,  1.5880e-02,  2.4683e-02, -1.9706e-02,  6.0296e-03,\n",
      "        -2.0747e-02,  1.5141e-02,  2.1223e-03,  6.3338e-03,  9.7032e-03,\n",
      "         1.6166e-02,  1.0702e-02, -6.6211e-03,  1.6401e-02,  1.7667e-02,\n",
      "        -2.0846e-02,  2.4901e-02, -9.2060e-03, -1.7792e-02, -1.9869e-03,\n",
      "         2.3782e-02,  2.0830e-02,  1.3963e-02,  1.6088e-02,  7.2300e-03,\n",
      "        -3.9183e-03, -2.0854e-03,  4.8014e-03,  2.1586e-03, -2.2733e-02,\n",
      "        -1.0002e-02,  1.4437e-02, -7.0733e-03, -1.6911e-02,  3.4221e-03,\n",
      "        -7.3494e-03,  1.7209e-02, -3.8606e-03,  7.2880e-03, -1.4199e-02,\n",
      "        -1.6219e-02,  2.4064e-02,  1.5205e-02,  5.0527e-03, -9.1395e-03,\n",
      "        -1.1789e-02,  6.0435e-03, -1.6292e-02,  1.3748e-02, -1.3311e-03,\n",
      "         2.0121e-02,  7.1165e-03,  6.6967e-04,  1.0403e-02,  3.5175e-03,\n",
      "         9.5326e-03, -7.9246e-03,  1.6749e-02, -1.3843e-02,  8.4486e-03,\n",
      "        -1.8603e-02,  1.0879e-02, -1.4680e-02,  2.1844e-03,  2.3231e-03,\n",
      "        -5.2336e-04, -2.0861e-02,  2.9059e-03, -2.4903e-02,  1.8523e-02,\n",
      "        -2.0886e-02, -1.9196e-02,  1.6699e-02, -1.7133e-02, -1.6405e-02,\n",
      "         7.7671e-03, -1.2094e-02, -1.1961e-02, -7.5146e-03, -1.6689e-02,\n",
      "        -1.2448e-03, -3.7806e-03,  4.1532e-03, -1.2635e-02,  4.8536e-03,\n",
      "        -5.7754e-03, -3.2357e-03,  2.4658e-02, -4.9920e-04, -3.3141e-03,\n",
      "        -1.5231e-02,  1.3728e-02,  1.4619e-02,  1.3338e-02,  1.5820e-02,\n",
      "        -4.4908e-04,  2.0116e-03, -9.3059e-03, -4.7894e-03,  6.3072e-03,\n",
      "        -2.2617e-02,  1.6943e-02,  1.3722e-02, -6.1496e-04, -2.4048e-02,\n",
      "        -1.6825e-02, -1.3576e-02,  5.3375e-03, -2.2152e-02,  1.6691e-02,\n",
      "        -1.6705e-02,  7.0301e-03], device='cuda:0', requires_grad=True))\n",
      "('7.1.conv3.weight', Parameter containing:\n",
      "tensor([[[ 0.0141],\n",
      "         [ 0.0233],\n",
      "         [-0.0198],\n",
      "         ...,\n",
      "         [-0.0085],\n",
      "         [-0.0189],\n",
      "         [ 0.0147]],\n",
      "\n",
      "        [[ 0.0392],\n",
      "         [-0.0389],\n",
      "         [-0.0284],\n",
      "         ...,\n",
      "         [ 0.0056],\n",
      "         [ 0.0083],\n",
      "         [-0.0117]],\n",
      "\n",
      "        [[-0.0353],\n",
      "         [-0.0391],\n",
      "         [ 0.0151],\n",
      "         ...,\n",
      "         [ 0.0283],\n",
      "         [-0.0092],\n",
      "         [-0.0408]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0185],\n",
      "         [ 0.0005],\n",
      "         [-0.0252],\n",
      "         ...,\n",
      "         [ 0.0096],\n",
      "         [-0.0126],\n",
      "         [-0.0064]],\n",
      "\n",
      "        [[ 0.0053],\n",
      "         [-0.0463],\n",
      "         [ 0.0386],\n",
      "         ...,\n",
      "         [-0.0402],\n",
      "         [ 0.0313],\n",
      "         [-0.0314]],\n",
      "\n",
      "        [[-0.0007],\n",
      "         [ 0.0134],\n",
      "         [ 0.0262],\n",
      "         ...,\n",
      "         [ 0.0289],\n",
      "         [ 0.0120],\n",
      "         [ 0.0367]]], device='cuda:0', requires_grad=True))\n",
      "('7.1.conv3.bias', Parameter containing:\n",
      "tensor([ 0.0338, -0.0176, -0.0166,  ..., -0.0223,  0.0401, -0.0116],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.1.bn1.weight', Parameter containing:\n",
      "tensor([1.0014, 1.0023, 1.0038, 0.9952, 1.0059, 1.0011, 0.9956, 0.9990, 1.0131,\n",
      "        0.9995, 1.0008, 1.0008, 0.9973, 0.9973, 0.9958, 0.9989, 0.9989, 1.0014,\n",
      "        1.0003, 1.0006, 0.9961, 0.9997, 0.9971, 1.0054, 0.9970, 0.9965, 0.9994,\n",
      "        0.9977, 0.9974, 0.9972, 0.9994, 0.9962, 1.0066, 0.9980, 1.0063, 1.0026,\n",
      "        0.9999, 1.0021, 1.0043, 1.0039, 1.0022, 0.9960, 0.9970, 1.0067, 1.0057,\n",
      "        1.0030, 0.9996, 0.9980, 1.0002, 1.0010, 0.9978, 0.9972, 1.0006, 0.9981,\n",
      "        0.9978, 1.0045, 1.0003, 1.0008, 1.0019, 1.0002, 0.9981, 0.9962, 1.0023,\n",
      "        0.9982, 1.0000, 1.0034, 0.9997, 0.9977, 1.0053, 1.0001, 0.9939, 0.9993,\n",
      "        1.0013, 0.9937, 1.0043, 0.9990, 1.0003, 0.9959, 1.0047, 1.0026, 0.9953,\n",
      "        1.0081, 0.9967, 1.0018, 1.0107, 0.9992, 1.0067, 1.0048, 0.9960, 0.9984,\n",
      "        1.0062, 0.9960, 1.0020, 1.0029, 0.9980, 1.0002, 0.9980, 0.9963, 0.9964,\n",
      "        0.9977, 1.0006, 0.9960, 1.0017, 0.9992, 0.9945, 0.9970, 0.9947, 0.9966,\n",
      "        1.0005, 0.9989, 0.9953, 1.0004, 1.0064, 1.0070, 0.9929, 0.9999, 0.9935,\n",
      "        0.9999, 1.0034, 1.0066, 1.0061, 1.0034, 0.9959, 1.0015, 0.9970, 0.9961,\n",
      "        0.9944, 1.0098, 0.9960, 0.9998, 1.0026, 1.0028, 0.9980, 0.9950, 1.0077,\n",
      "        1.0017, 1.0034, 0.9942, 1.0011, 1.0096, 0.9986, 0.9993, 0.9950, 0.9997,\n",
      "        0.9995, 1.0054, 0.9975, 0.9993, 0.9999, 1.0037, 1.0021, 1.0042, 0.9994,\n",
      "        0.9969, 0.9952, 1.0025, 0.9978, 0.9981, 1.0062, 0.9976, 0.9995, 1.0017,\n",
      "        1.0039, 1.0009, 0.9977, 0.9962, 0.9985, 0.9986, 1.0020, 1.0020, 0.9990,\n",
      "        1.0109, 0.9939, 0.9974, 0.9995, 1.0016, 1.0033, 0.9969, 1.0107, 0.9996,\n",
      "        1.0008, 1.0078, 1.0043, 1.0043, 0.9992, 1.0022, 0.9974, 0.9995, 0.9990,\n",
      "        0.9963, 1.0063, 1.0001, 1.0010, 0.9946, 0.9935, 1.0040, 0.9997, 0.9997,\n",
      "        1.0058, 0.9993, 1.0009, 0.9984, 0.9993, 1.0021, 1.0061, 0.9998, 1.0048,\n",
      "        0.9975, 0.9975, 1.0052, 1.0031, 0.9992, 0.9973, 1.0000, 0.9982, 0.9942,\n",
      "        0.9926, 0.9968, 1.0006, 1.0003, 0.9969, 0.9992, 1.0000, 1.0052, 0.9997,\n",
      "        1.0034, 0.9979, 1.0032, 1.0053, 0.9945, 1.0016, 0.9958, 1.0010, 0.9965,\n",
      "        0.9978, 0.9970, 1.0017, 1.0037, 1.0058, 1.0009, 1.0015, 1.0058, 1.0014,\n",
      "        0.9995, 0.9994, 1.0006, 1.0080, 0.9952, 0.9960, 0.9978, 0.9948, 1.0000,\n",
      "        0.9959, 1.0009, 0.9971, 0.9973, 0.9981, 0.9993, 1.0012, 1.0078, 1.0060,\n",
      "        1.0017, 0.9993, 0.9928, 0.9982, 0.9972, 1.0003, 0.9991, 0.9960, 1.0018,\n",
      "        1.0008, 0.9972, 0.9984, 1.0017, 0.9973, 0.9966, 0.9956, 0.9986, 0.9949,\n",
      "        0.9993, 0.9972, 1.0004, 0.9956, 1.0020, 1.0005, 1.0006, 0.9958, 1.0021,\n",
      "        0.9975, 0.9992, 1.0019, 0.9989, 0.9983, 0.9990, 1.0023, 0.9983, 1.0052,\n",
      "        0.9984, 0.9986, 0.9995, 1.0067, 1.0002, 0.9962, 1.0023, 1.0024, 1.0060,\n",
      "        1.0021, 0.9942, 1.0024, 0.9988, 0.9988, 0.9977, 0.9930, 0.9983, 1.0055,\n",
      "        1.0013, 1.0020, 0.9956, 0.9957, 1.0009, 0.9979, 1.0049, 1.0009, 1.0044,\n",
      "        0.9968, 1.0017, 0.9976, 0.9966, 0.9984, 1.0001, 0.9978, 0.9975, 0.9953,\n",
      "        0.9946, 0.9970, 1.0030, 1.0002, 0.9928, 0.9982, 0.9994, 1.0034, 1.0003,\n",
      "        1.0080, 1.0039, 1.0009, 0.9961, 0.9949, 1.0081, 0.9968, 0.9984, 1.0045,\n",
      "        1.0136, 1.0143, 1.0010, 0.9992, 0.9983, 1.0004, 1.0013, 1.0004, 0.9990,\n",
      "        0.9969, 0.9989, 0.9986, 0.9975, 0.9993, 0.9927, 1.0040, 0.9983, 0.9993,\n",
      "        1.0077, 0.9988, 0.9976, 0.9991, 0.9944, 0.9978, 0.9952, 0.9992, 0.9953,\n",
      "        1.0010, 0.9949, 1.0000, 0.9974, 0.9982, 0.9974, 1.0022, 0.9989, 0.9997,\n",
      "        1.0007, 0.9992, 0.9954, 0.9996, 1.0079, 0.9960, 0.9967, 1.0082, 0.9987,\n",
      "        0.9984, 1.0005, 0.9976, 1.0006, 1.0000, 1.0037, 0.9993, 1.0071, 1.0039,\n",
      "        0.9980, 0.9997, 0.9974, 0.9997, 1.0094, 1.0016, 1.0072, 0.9998, 0.9951,\n",
      "        0.9993, 0.9977, 1.0034, 1.0024, 0.9975, 0.9993, 1.0022, 0.9943, 0.9981,\n",
      "        1.0035, 0.9973, 0.9945, 0.9965, 0.9974, 1.0041, 0.9979, 0.9946, 1.0006,\n",
      "        1.0028, 0.9975, 0.9964, 1.0064, 1.0020, 0.9969, 0.9999, 0.9987, 0.9988,\n",
      "        0.9976, 1.0031, 0.9982, 0.9969, 1.0047, 0.9966, 1.0003, 0.9939, 0.9981,\n",
      "        0.9993, 0.9969, 0.9975, 1.0002, 1.0040, 0.9961, 1.0022, 1.0030, 0.9987,\n",
      "        1.0020, 1.0021, 1.0071, 1.0020, 0.9972, 0.9980, 0.9990, 1.0038, 0.9982,\n",
      "        0.9967, 1.0025, 0.9974, 1.0016, 0.9983, 1.0003, 0.9998, 0.9990, 1.0054,\n",
      "        0.9979, 1.0012, 0.9983, 1.0003, 0.9981, 0.9996, 0.9931, 0.9972, 1.0017,\n",
      "        1.0004, 1.0013, 0.9993, 1.0011, 0.9996, 1.0002, 0.9991, 1.0032, 0.9993,\n",
      "        1.0022, 0.9980, 1.0116, 1.0002, 1.0043, 0.9948, 1.0006, 1.0041, 0.9971,\n",
      "        1.0033, 0.9932, 0.9957, 1.0012, 0.9992, 0.9988, 1.0060, 1.0029],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.1.bn1.bias', Parameter containing:\n",
      "tensor([-5.8431e-04,  5.7252e-04,  3.7439e-03,  1.3719e-04,  5.4757e-03,\n",
      "        -3.3931e-03, -3.1450e-03,  4.3138e-03,  4.2896e-03,  2.0095e-03,\n",
      "        -4.9186e-04, -3.4415e-04, -5.7582e-03, -4.2052e-03, -4.1991e-03,\n",
      "         9.4962e-04, -2.9491e-03, -3.7921e-03, -1.8799e-03, -2.1910e-03,\n",
      "        -3.1092e-03, -5.1114e-03, -4.1369e-03,  5.4266e-03, -2.6558e-03,\n",
      "        -4.0892e-03,  9.2014e-05,  1.8692e-03,  1.2589e-03, -6.5636e-03,\n",
      "         1.3985e-03, -2.7235e-03,  8.8873e-03,  1.1035e-03, -1.1042e-03,\n",
      "        -3.2362e-03, -1.4961e-03, -4.3961e-03, -8.6690e-04, -3.5006e-03,\n",
      "         8.1719e-04, -4.1377e-03, -4.1521e-03,  7.2577e-03,  7.2023e-03,\n",
      "        -8.0923e-03,  8.3345e-04, -2.0501e-03,  3.6685e-04,  1.2252e-03,\n",
      "        -1.8325e-06, -2.4079e-03, -3.8865e-03, -4.4495e-03, -8.6152e-04,\n",
      "         2.3352e-03,  2.2797e-03, -1.9729e-03,  5.8652e-04,  1.9262e-03,\n",
      "        -5.7619e-03, -6.6614e-03,  1.5192e-03, -3.2840e-03, -1.2607e-03,\n",
      "        -1.8803e-03, -4.7212e-03, -5.0233e-03, -1.0020e-03,  4.3405e-03,\n",
      "        -6.0795e-03,  1.1805e-03, -5.3990e-03, -7.4268e-03, -5.2991e-03,\n",
      "        -6.4484e-04, -4.6313e-03, -4.5162e-03,  1.3603e-03, -5.0154e-04,\n",
      "        -4.4160e-03,  1.2422e-03, -2.1811e-03, -5.2297e-04, -3.7098e-04,\n",
      "        -2.5572e-03, -8.3596e-04,  8.6758e-03, -6.3715e-03, -8.0753e-05,\n",
      "        -6.3330e-03, -7.2459e-03,  9.2684e-05, -3.2690e-03, -4.2757e-03,\n",
      "        -2.7316e-03, -1.3216e-03, -7.7234e-03, -3.6472e-03, -6.9381e-04,\n",
      "        -5.5394e-03, -2.9038e-03, -3.8913e-03, -1.1711e-03, -3.0494e-03,\n",
      "        -4.3098e-04, -3.2208e-03, -4.4536e-03, -2.8846e-03, -3.3437e-03,\n",
      "        -3.1203e-03,  2.1499e-03,  8.6358e-03, -9.4295e-04, -8.6199e-03,\n",
      "        -4.7306e-03, -5.8413e-03, -3.5551e-03,  3.6134e-03, -4.3358e-03,\n",
      "         2.7674e-03, -8.1544e-03,  3.7750e-04,  6.2681e-04, -5.9712e-03,\n",
      "        -1.8315e-03, -2.1002e-03,  1.7102e-02, -4.0046e-03,  8.1310e-04,\n",
      "        -3.2970e-03, -1.5802e-04, -3.1003e-03, -4.5829e-03, -4.0492e-05,\n",
      "         2.1859e-03,  1.7154e-03, -5.4661e-03, -4.8625e-03,  1.2956e-02,\n",
      "        -4.5343e-03, -7.0011e-04, -5.8998e-03, -2.0178e-04, -1.4642e-04,\n",
      "        -3.5420e-03, -2.0694e-03, -5.4867e-03, -4.2828e-03,  3.3338e-03,\n",
      "        -1.0479e-04, -4.1303e-03, -2.2637e-03,  5.0643e-04, -3.2751e-03,\n",
      "        -3.1788e-03, -2.2781e-03, -1.5513e-03, -1.4459e-03, -9.6676e-04,\n",
      "         8.2069e-04,  2.7595e-03,  2.7740e-03, -4.0816e-03,  7.8290e-03,\n",
      "        -3.3432e-03, -9.5219e-04, -2.0322e-03, -2.5131e-03, -3.9031e-03,\n",
      "        -4.5715e-04,  4.3990e-04, -5.2416e-03, -1.9835e-03, -2.0128e-03,\n",
      "        -1.8468e-03, -2.4551e-03, -1.8689e-03,  4.3837e-03, -4.2741e-03,\n",
      "        -6.5482e-04,  8.1772e-03,  6.4607e-03,  2.9522e-03, -2.7441e-03,\n",
      "         2.9234e-03,  4.8933e-04, -4.7507e-04, -2.9007e-03,  6.6393e-04,\n",
      "        -2.0635e-03, -3.6267e-03, -5.0944e-03, -5.7086e-03, -6.5104e-03,\n",
      "         3.3373e-03,  5.7641e-03, -9.2535e-06,  3.4987e-03, -3.6363e-04,\n",
      "        -6.5964e-03, -4.8248e-03,  9.4789e-04,  3.8818e-03,  2.1348e-03,\n",
      "        -3.5487e-03,  4.8407e-03,  1.0204e-03,  1.2722e-03, -4.2893e-03,\n",
      "        -8.5034e-04, -9.6289e-04, -9.6918e-03,  3.6572e-04, -4.0970e-03,\n",
      "        -2.1089e-03, -8.2170e-04, -8.6198e-04, -2.8164e-04,  3.3238e-03,\n",
      "        -2.2415e-03, -3.3017e-03, -1.2921e-03, -3.2374e-03,  4.5277e-04,\n",
      "        -1.6540e-03,  3.6936e-04,  1.4324e-03,  9.4404e-03, -2.4578e-03,\n",
      "        -5.8842e-04, -3.6909e-03, -2.0873e-03, -5.6446e-03, -2.5193e-03,\n",
      "        -1.6364e-04,  6.6565e-03, -8.9012e-04,  2.1998e-03, -6.1817e-04,\n",
      "         3.7152e-03, -2.3633e-03,  8.7310e-04,  2.6087e-03,  2.9086e-04,\n",
      "        -4.0766e-04,  1.7495e-03, -1.8409e-03, -3.4095e-03, -3.4008e-03,\n",
      "        -1.7058e-03, -1.8024e-03, -1.3432e-03,  6.9366e-04, -2.5236e-03,\n",
      "        -4.3181e-03, -4.8519e-03,  5.5813e-04,  1.2418e-03,  5.6979e-03,\n",
      "         2.4375e-03, -2.0437e-03, -1.6324e-03, -5.1890e-03, -4.1652e-03,\n",
      "        -3.4623e-03, -2.1465e-03, -4.8534e-03, -3.2801e-03,  3.8075e-03,\n",
      "         2.4987e-03, -4.3712e-03, -4.2019e-03, -4.1652e-04,  2.0712e-03,\n",
      "        -2.2015e-03, -4.6930e-03, -1.2749e-03, -4.5617e-03, -2.1829e-03,\n",
      "        -2.9681e-03, -9.3586e-04, -6.4183e-03, -5.7303e-03,  1.8214e-03,\n",
      "        -4.1707e-03,  6.2314e-05,  5.5884e-06, -2.0089e-03, -3.6956e-03,\n",
      "        -3.0581e-03, -2.0865e-03, -4.3642e-04,  4.1615e-03,  1.5909e-03,\n",
      "        -1.3284e-04,  1.7802e-03, -3.4478e-03, -6.0598e-04, -4.0863e-03,\n",
      "        -7.8189e-04, -4.1461e-03,  4.7656e-03, -3.2490e-03,  1.4254e-03,\n",
      "         2.7088e-03, -2.2052e-03, -5.7837e-03,  1.6947e-03, -7.4973e-04,\n",
      "        -2.6334e-03, -4.1341e-03, -5.3838e-03,  2.9061e-03, -7.3871e-03,\n",
      "        -1.3614e-03,  1.1233e-03, -7.4432e-03, -7.8332e-04, -1.7944e-03,\n",
      "         5.9760e-04,  2.9869e-03, -1.4323e-03, -3.0140e-03, -4.4166e-03,\n",
      "        -7.6069e-03, -9.6830e-03, -2.5815e-03, -3.5760e-03, -2.0647e-03,\n",
      "        -4.1917e-03,  8.8281e-05, -3.5651e-03, -6.5663e-03, -3.2188e-03,\n",
      "        -2.1157e-03,  4.6888e-04, -3.2473e-03, -1.4941e-04, -2.3351e-03,\n",
      "        -3.5507e-03,  4.7057e-05,  7.2102e-03,  6.7635e-04, -1.4967e-03,\n",
      "        -6.1639e-03, -6.9679e-03,  7.7417e-03, -2.7753e-03, -3.8948e-03,\n",
      "         5.7691e-03, -3.5687e-03,  1.3376e-03,  5.0872e-04,  2.8357e-04,\n",
      "        -4.7719e-03,  5.8906e-04, -1.0427e-03,  5.5942e-04, -3.0005e-03,\n",
      "        -4.1420e-05, -5.4572e-04, -1.7949e-03, -1.4476e-03,  4.5727e-04,\n",
      "        -3.9679e-03,  7.7698e-03, -4.7148e-03,  2.7152e-03, -4.0846e-03,\n",
      "        -1.3846e-03,  3.6709e-04, -1.6238e-03, -3.3301e-03, -1.1786e-03,\n",
      "        -4.0873e-03, -8.6792e-04,  1.9065e-03, -1.7457e-03, -5.1569e-03,\n",
      "         4.6089e-04, -3.4169e-03, -4.1725e-03, -4.2983e-03, -2.1298e-03,\n",
      "        -5.8546e-04, -4.2120e-03, -3.8056e-03, -4.8767e-03, -1.8024e-03,\n",
      "         6.0724e-05,  9.0036e-03, -4.9561e-03, -4.3680e-03, -1.6086e-03,\n",
      "         9.6788e-05, -4.2799e-03, -1.6498e-04,  1.4662e-03,  5.0385e-04,\n",
      "         3.2203e-03, -5.9830e-03, -1.5586e-03, -8.7147e-04,  1.0847e-03,\n",
      "         3.4521e-05, -3.5248e-03, -7.0499e-03,  2.2549e-03,  4.0799e-04,\n",
      "         2.8410e-03, -1.1247e-02, -2.5643e-03, -6.3718e-03,  1.4346e-03,\n",
      "        -2.3639e-03, -1.5545e-03,  1.0444e-03, -4.3929e-03, -6.1446e-04,\n",
      "         1.4418e-03, -1.8419e-03, -9.0878e-03,  3.4106e-03, -2.1739e-03,\n",
      "        -1.6651e-03,  3.4133e-03, -5.9154e-03,  1.7871e-03, -1.8580e-03,\n",
      "        -4.6658e-03,  3.4638e-03, -4.0559e-03, -5.1528e-03, -7.4392e-03,\n",
      "         9.6659e-04,  3.9485e-03, -1.9735e-03, -5.9848e-03, -1.7953e-03,\n",
      "        -1.9389e-03, -3.3972e-03, -3.2440e-03, -1.6511e-03, -5.1058e-03,\n",
      "         4.5372e-03,  4.1111e-03, -2.4005e-03, -6.4253e-03, -2.0433e-03,\n",
      "         1.5932e-03, -1.2984e-03,  3.8423e-04, -5.0404e-04, -5.8893e-03,\n",
      "        -4.1350e-03,  1.6288e-03,  1.2036e-03, -5.2362e-03,  1.9004e-04,\n",
      "         5.9428e-05, -3.2127e-03,  7.9126e-03, -2.1058e-03,  1.2969e-03,\n",
      "        -3.2070e-04,  2.3030e-04,  1.1031e-03, -2.2013e-03, -3.1079e-03,\n",
      "        -4.7025e-03,  6.4822e-03, -1.4900e-03, -1.6751e-03,  1.7653e-03,\n",
      "        -4.9238e-04,  8.1991e-04, -4.1028e-03,  3.9386e-03, -1.4629e-03,\n",
      "         5.6689e-04, -5.7494e-03, -3.3962e-03, -4.5227e-03, -1.1749e-03,\n",
      "        -6.8763e-03, -2.1351e-03, -6.8144e-05, -3.6499e-03, -3.8174e-03,\n",
      "        -5.9744e-04, -3.9279e-04,  3.3572e-04, -2.6850e-03,  1.1425e-03,\n",
      "         2.2424e-03, -2.2674e-03, -5.7338e-04, -3.6779e-03,  2.6379e-03,\n",
      "        -4.7923e-04,  3.0852e-03, -2.0045e-03,  6.7740e-04,  2.4428e-03,\n",
      "        -4.0008e-03, -3.4395e-03, -5.6369e-03, -2.4870e-04, -4.6354e-03,\n",
      "        -1.8860e-03, -1.1523e-03], device='cuda:0', requires_grad=True))\n",
      "('7.1.bn2.weight', Parameter containing:\n",
      "tensor([0.9995, 0.9987, 0.9997, 0.9990, 0.9990, 0.9996, 1.0016, 0.9942, 0.9992,\n",
      "        1.0003, 0.9958, 1.0013, 0.9960, 0.9999, 1.0029, 0.9981, 0.9961, 1.0006,\n",
      "        1.0008, 1.0039, 1.0005, 0.9952, 0.9973, 0.9983, 1.0008, 0.9990, 0.9959,\n",
      "        0.9990, 1.0049, 1.0002, 0.9969, 1.0038, 1.0010, 0.9969, 1.0048, 1.0033,\n",
      "        0.9978, 1.0001, 0.9982, 0.9984, 0.9984, 1.0004, 0.9999, 1.0035, 0.9968,\n",
      "        0.9980, 1.0056, 0.9989, 1.0015, 0.9978, 0.9982, 1.0031, 1.0022, 0.9992,\n",
      "        0.9993, 0.9994, 1.0004, 0.9999, 1.0036, 1.0008, 0.9974, 0.9985, 0.9979,\n",
      "        0.9953, 0.9996, 1.0000, 0.9931, 1.0007, 1.0005, 0.9989, 0.9999, 0.9998,\n",
      "        1.0017, 0.9984, 0.9988, 0.9964, 1.0000, 0.9959, 0.9987, 1.0001, 0.9983,\n",
      "        1.0041, 0.9995, 0.9995, 1.0093, 1.0030, 0.9983, 1.0003, 1.0019, 0.9974,\n",
      "        0.9999, 1.0014, 0.9950, 1.0037, 0.9970, 0.9978, 1.0014, 0.9985, 1.0027,\n",
      "        0.9993, 0.9966, 0.9983, 0.9997, 1.0020, 1.0025, 0.9968, 1.0007, 0.9971,\n",
      "        0.9994, 0.9986, 0.9987, 0.9985, 0.9987, 0.9967, 0.9985, 0.9959, 1.0040,\n",
      "        0.9956, 1.0023, 0.9980, 0.9963, 1.0025, 1.0024, 1.0021, 0.9985, 0.9965,\n",
      "        0.9940, 0.9981, 1.0002, 1.0021, 0.9999, 0.9962, 0.9996, 1.0010, 0.9998,\n",
      "        1.0045, 1.0036, 1.0059, 1.0083, 0.9956, 0.9994, 0.9954, 0.9986, 1.0017,\n",
      "        1.0017, 1.0043, 1.0003, 1.0011, 1.0006, 1.0098, 1.0006, 1.0016, 0.9981,\n",
      "        0.9984, 1.0023, 1.0022, 1.0015, 0.9982, 1.0060, 0.9999, 1.0004, 0.9950,\n",
      "        0.9973, 1.0023, 0.9955, 1.0007, 1.0007, 0.9981, 0.9985, 1.0010, 0.9968,\n",
      "        1.0011, 0.9974, 0.9947, 1.0057, 1.0038, 0.9976, 1.0056, 0.9999, 1.0008,\n",
      "        1.0005, 1.0049, 0.9997, 1.0026, 0.9957, 0.9986, 0.9991, 0.9954, 1.0000,\n",
      "        1.0026, 1.0019, 1.0008, 0.9968, 0.9978, 0.9947, 0.9992, 1.0005, 1.0020,\n",
      "        1.0039, 0.9994, 1.0065, 1.0035, 0.9987, 0.9987, 0.9996, 1.0079, 1.0004,\n",
      "        0.9987, 0.9960, 1.0070, 1.0010, 0.9977, 1.0005, 0.9965, 0.9967, 1.0063,\n",
      "        1.0016, 1.0004, 0.9994, 1.0020, 0.9968, 0.9986, 1.0013, 0.9990, 1.0027,\n",
      "        1.0008, 0.9976, 0.9970, 1.0006, 1.0005, 0.9993, 1.0008, 0.9989, 1.0023,\n",
      "        1.0023, 1.0020, 0.9992, 0.9998, 1.0075, 1.0076, 0.9982, 0.9959, 0.9973,\n",
      "        1.0024, 0.9994, 0.9997, 0.9962, 1.0017, 1.0002, 1.0035, 0.9970, 1.0003,\n",
      "        1.0086, 1.0025, 0.9981, 0.9962, 0.9990, 0.9998, 1.0003, 1.0001, 0.9964,\n",
      "        0.9988, 0.9977, 0.9998, 1.0039, 1.0002, 1.0060, 0.9984, 0.9991, 1.0007,\n",
      "        0.9994, 0.9943, 1.0004, 0.9992, 0.9997, 0.9952, 0.9987, 0.9987, 0.9967,\n",
      "        0.9982, 1.0005, 0.9988, 0.9976, 0.9995, 1.0005, 0.9979, 1.0003, 1.0093,\n",
      "        1.0007, 1.0027, 0.9997, 1.0064, 1.0018, 0.9971, 1.0008, 1.0002, 1.0063,\n",
      "        1.0032, 1.0002, 0.9996, 0.9988, 0.9981, 0.9989, 1.0081, 1.0018, 1.0014,\n",
      "        0.9989, 0.9997, 0.9987, 0.9966, 0.9993, 1.0014, 0.9977, 1.0041, 1.0037,\n",
      "        1.0002, 1.0113, 0.9970, 1.0006, 0.9998, 0.9977, 1.0010, 1.0069, 0.9988,\n",
      "        0.9972, 1.0034, 0.9975, 1.0020, 0.9983, 0.9997, 1.0229, 0.9972, 1.0008,\n",
      "        0.9966, 1.0143, 0.9977, 0.9956, 1.0061, 0.9997, 0.9949, 0.9960, 0.9984,\n",
      "        0.9981, 1.0002, 0.9992, 0.9978, 0.9980, 0.9980, 0.9975, 1.0000, 0.9969,\n",
      "        0.9984, 1.0045, 0.9979, 0.9991, 0.9955, 0.9987, 0.9987, 0.9993, 1.0015,\n",
      "        0.9975, 1.0010, 0.9997, 0.9991, 0.9960, 1.0006, 1.0014, 1.0015, 0.9978,\n",
      "        0.9982, 1.0020, 0.9950, 1.0018, 0.9994, 0.9996, 1.0008, 0.9953, 0.9984,\n",
      "        0.9976, 0.9999, 0.9973, 0.9997, 0.9969, 1.0010, 1.0037, 1.0014, 0.9973,\n",
      "        0.9952, 0.9989, 1.0017, 1.0008, 1.0019, 1.0041, 0.9945, 0.9999, 0.9991,\n",
      "        0.9998, 0.9992, 1.0035, 1.0009, 1.0016, 0.9955, 0.9980, 0.9973, 1.0018,\n",
      "        0.9974, 0.9984, 1.0031, 0.9961, 1.0043, 0.9977, 0.9966, 0.9971, 1.0007,\n",
      "        0.9980, 1.0019, 0.9946, 0.9987, 1.0005, 0.9995, 1.0000, 0.9965, 1.0110,\n",
      "        1.0079, 1.0009, 1.0091, 1.0017, 0.9985, 0.9967, 0.9985, 0.9978, 1.0046,\n",
      "        0.9986, 0.9981, 0.9982, 0.9981, 0.9975, 1.0013, 0.9998, 0.9993, 0.9998,\n",
      "        0.9995, 0.9970, 1.0003, 0.9965, 1.0001, 0.9989, 0.9993, 0.9981, 0.9992,\n",
      "        1.0028, 0.9970, 1.0013, 1.0032, 0.9986, 0.9951, 0.9985, 1.0012, 1.0017,\n",
      "        0.9996, 0.9955, 0.9954, 0.9992, 0.9987, 1.0003, 0.9984, 0.9967, 0.9983,\n",
      "        1.0017, 0.9992, 1.0058, 0.9950, 0.9973, 0.9965, 1.0033, 0.9997, 0.9981,\n",
      "        0.9976, 1.0025, 1.0006, 1.0030, 1.0035, 1.0022, 1.0002, 1.0041, 1.0022,\n",
      "        1.0024, 0.9966, 1.0037, 1.0005, 1.0010, 0.9999, 1.0018, 1.0008, 0.9998,\n",
      "        0.9998, 1.0016, 1.0013, 1.0013, 1.0020, 1.0001, 1.0081, 1.0021, 1.0003,\n",
      "        0.9986, 0.9952, 0.9976, 1.0108, 1.0007, 0.9986, 0.9962, 1.0085],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.1.bn2.bias', Parameter containing:\n",
      "tensor([ 1.6313e-03, -3.0810e-04,  2.7443e-03, -4.3623e-04, -5.7567e-03,\n",
      "         1.4261e-03, -5.0844e-03, -2.2385e-03,  4.5441e-03,  9.1587e-05,\n",
      "        -3.5106e-03,  2.9590e-03, -1.8853e-03,  9.8168e-05, -4.6056e-03,\n",
      "         1.6693e-03, -1.8281e-03, -6.5750e-04, -2.5796e-03,  2.3934e-03,\n",
      "        -1.5532e-03, -1.4980e-03, -1.6277e-03, -2.2327e-03,  1.9852e-04,\n",
      "        -6.6375e-04, -2.5126e-03,  1.3889e-04,  1.1040e-02, -1.2028e-03,\n",
      "        -3.5270e-03,  1.3287e-02,  6.2388e-04, -2.1093e-03,  3.2515e-03,\n",
      "         3.6324e-03, -6.1607e-04, -7.5998e-04,  9.0448e-04, -3.1153e-03,\n",
      "         2.2962e-03,  5.9712e-03, -1.8702e-05,  4.3538e-03, -3.4648e-04,\n",
      "        -2.9879e-03, -1.3751e-03,  3.3860e-04, -9.3519e-05,  6.8410e-04,\n",
      "        -1.4111e-03,  2.3411e-03,  3.0421e-03,  1.9669e-03,  5.8933e-04,\n",
      "         3.9152e-03,  6.4358e-05, -2.6172e-04,  7.1246e-03,  5.7175e-05,\n",
      "        -4.2737e-03, -2.8293e-03,  1.8323e-03, -4.1217e-03, -6.5005e-04,\n",
      "        -5.7172e-04, -4.7670e-03,  2.0751e-04,  1.9791e-03, -4.7589e-04,\n",
      "        -1.1490e-03, -2.6888e-04,  2.0921e-03,  2.7638e-03, -6.0942e-04,\n",
      "        -7.7440e-04, -1.2943e-03,  2.4081e-04, -5.2271e-03,  1.7202e-03,\n",
      "        -2.0124e-03,  3.7641e-03, -1.9985e-03, -6.1883e-04, -1.9608e-02,\n",
      "         1.1792e-03, -1.1447e-03,  2.1724e-03,  9.1826e-03, -1.0720e-03,\n",
      "         1.8714e-04, -4.9733e-04, -4.5181e-04,  9.5124e-03, -2.0120e-03,\n",
      "        -9.9243e-04,  5.1099e-04,  7.3018e-04, -1.5446e-03,  1.6363e-04,\n",
      "        -6.8482e-04,  9.3160e-04, -3.4228e-03,  7.2416e-04,  1.5094e-03,\n",
      "        -1.8126e-03,  5.0104e-04, -1.9256e-03, -1.3692e-03,  1.3323e-04,\n",
      "        -2.9497e-04, -4.0312e-03, -1.3435e-03, -2.9124e-03, -6.5150e-03,\n",
      "        -5.2165e-04, -1.8687e-03, -3.2650e-03, -2.8998e-03, -6.1506e-04,\n",
      "        -1.2837e-03,  2.1923e-03, -3.1832e-04,  1.0310e-02, -1.3802e-03,\n",
      "         1.3581e-03, -2.0023e-03, -2.9087e-03, -1.5348e-03,  1.3292e-02,\n",
      "         1.3740e-03, -4.9177e-03,  4.5102e-03, -2.4769e-03, -2.7675e-03,\n",
      "         1.4171e-03, -7.9648e-04, -1.2872e-02,  1.7782e-02, -1.6596e-03,\n",
      "         9.3054e-04, -3.3643e-03,  1.3258e-03,  9.0307e-03,  3.1162e-03,\n",
      "         3.4600e-03,  1.5465e-03,  6.7755e-04,  9.9485e-04, -8.7921e-03,\n",
      "        -1.2553e-03, -1.6172e-03, -9.4040e-04, -5.6994e-04,  2.6134e-03,\n",
      "         2.3868e-03, -1.4163e-03, -1.7515e-04, -2.0629e-02, -2.4736e-03,\n",
      "         1.0669e-03, -2.9622e-03, -2.1309e-03,  1.8038e-03, -4.4939e-03,\n",
      "         2.7478e-03, -5.1803e-03, -2.5272e-03,  1.0432e-03, -1.8763e-03,\n",
      "        -6.6597e-04, -2.7487e-03, -2.7063e-03, -1.6775e-04,  3.0988e-03,\n",
      "         3.9856e-03,  3.0859e-03, -4.7519e-03,  4.2885e-03, -1.9374e-03,\n",
      "         8.1224e-04,  1.1395e-02,  4.8551e-03, -4.5476e-03, -2.9196e-03,\n",
      "        -8.0493e-04, -4.9648e-03, -3.4986e-03,  1.3889e-04, -1.1819e-03,\n",
      "         2.4361e-03, -1.0447e-03, -1.5646e-03, -2.0935e-03, -3.8255e-03,\n",
      "         5.4266e-05,  6.3879e-04,  1.5140e-03,  3.7002e-03, -1.8286e-03,\n",
      "         7.1357e-03,  1.8373e-03, -3.6079e-03, -1.2456e-03, -3.1571e-03,\n",
      "         2.0822e-03,  3.2470e-03,  1.8369e-03, -1.3057e-03,  4.2263e-03,\n",
      "        -1.3608e-03,  5.7192e-04,  2.4706e-04, -2.8564e-04, -2.6212e-03,\n",
      "         7.5437e-03,  1.2415e-03,  4.8033e-04,  7.3600e-04,  1.5191e-03,\n",
      "        -2.1923e-03,  6.3008e-05,  2.0190e-04, -1.0629e-04,  2.4183e-03,\n",
      "        -8.4439e-04,  1.0016e-03, -7.4016e-04, -8.4092e-03,  1.3476e-03,\n",
      "         1.1937e-03, -3.2559e-03,  1.2919e-04,  1.8280e-03,  5.9041e-03,\n",
      "         5.2685e-04, -2.0667e-03, -2.2623e-03,  7.0413e-03, -6.5687e-03,\n",
      "        -1.2468e-03, -2.2572e-03, -1.8253e-03,  1.8935e-03, -2.8702e-03,\n",
      "        -1.8211e-03, -2.2898e-03, -3.1524e-03,  7.2478e-04,  1.0294e-02,\n",
      "         5.5850e-03,  1.2092e-03,  1.7323e-02, -5.6369e-03, -1.8872e-03,\n",
      "        -4.0856e-03, -1.0673e-03,  3.0787e-03,  9.0254e-05, -8.9801e-04,\n",
      "        -2.1648e-03, -3.7212e-04,  3.3603e-03,  4.8014e-04,  3.9875e-03,\n",
      "        -1.0309e-03,  5.6257e-03, -1.6540e-03, -2.5232e-03, -1.2108e-03,\n",
      "        -9.7306e-03, -1.9790e-03, -2.3147e-05, -8.3386e-05, -3.5182e-03,\n",
      "        -3.7783e-03,  1.1154e-03,  3.5625e-04,  8.9531e-05, -1.7630e-03,\n",
      "         1.0534e-04,  1.7845e-04, -1.7387e-03, -4.4897e-03,  1.9237e-03,\n",
      "         3.6288e-03,  3.2206e-03, -2.2943e-02,  3.1524e-03,  5.9355e-03,\n",
      "         2.4347e-03,  2.1530e-02, -5.5071e-04, -3.4741e-03,  5.3982e-03,\n",
      "        -1.2381e-03,  2.4635e-03,  2.9004e-03,  2.2773e-03,  1.2553e-03,\n",
      "        -2.4855e-03,  1.3417e-04,  2.7898e-03, -4.0438e-03,  1.2399e-03,\n",
      "         3.2339e-03, -5.2964e-04, -6.9790e-03, -1.9423e-03, -7.9660e-04,\n",
      "         1.6065e-03, -7.9243e-04, -2.4619e-03, -5.8766e-03,  7.1396e-05,\n",
      "         4.3372e-03,  8.3155e-03, -3.6206e-03, -1.7170e-03,  4.4189e-04,\n",
      "        -7.6427e-04, -1.5461e-04, -1.5696e-04,  4.3673e-03, -1.3478e-03,\n",
      "         1.5318e-02,  3.0380e-03,  3.3990e-03,  7.5114e-04,  1.9767e-04,\n",
      "        -1.7629e-02,  1.2342e-03,  6.9401e-04, -4.1343e-04,  2.5400e-02,\n",
      "        -9.6617e-04,  1.9930e-04,  6.5167e-03, -1.3715e-03, -2.8631e-03,\n",
      "        -3.2034e-03,  1.9969e-03, -4.6289e-04,  2.6600e-05, -2.1088e-05,\n",
      "         1.6107e-03, -4.6411e-05, -2.8392e-03, -8.0224e-04,  1.1996e-03,\n",
      "        -1.9807e-03, -8.0573e-03,  6.6653e-03, -2.1502e-04, -1.1827e-03,\n",
      "        -2.0425e-03, -2.1225e-03, -2.8397e-03, -2.1413e-03,  1.9816e-03,\n",
      "        -8.2725e-04,  1.5889e-03,  3.6537e-03,  1.9127e-04, -2.9947e-03,\n",
      "        -9.0565e-04,  4.4118e-03,  2.7203e-04, -3.4128e-04, -3.2103e-03,\n",
      "         6.5648e-05, -2.4658e-03,  2.3110e-03, -4.4563e-03, -1.2746e-03,\n",
      "        -5.7192e-04, -2.3824e-03, -2.5440e-03, -5.3726e-04, -9.6271e-04,\n",
      "         7.3477e-04, -7.2792e-03, -4.3412e-04,  1.8361e-03, -2.9794e-03,\n",
      "         5.9728e-03, -1.2025e-03, -5.2461e-03,  2.7465e-03,  8.9490e-05,\n",
      "         2.9579e-03, -1.4670e-03, -2.0386e-02, -2.1434e-03,  5.5853e-04,\n",
      "         1.4258e-03, -6.6215e-05,  2.3712e-04, -4.1648e-03,  1.7035e-03,\n",
      "        -1.5224e-03, -2.4893e-03, -1.6409e-03, -1.0190e-03,  4.3657e-03,\n",
      "        -3.9061e-03, -5.6120e-04,  7.6602e-04, -2.5796e-03,  2.9630e-03,\n",
      "         6.4349e-04, -1.9456e-03, -1.3882e-04,  2.0577e-03, -7.8462e-04,\n",
      "         5.2490e-03, -4.7678e-03, -1.0158e-03, -1.1564e-03,  1.7423e-03,\n",
      "         3.9666e-04,  5.6592e-04, -1.0810e-02, -7.6605e-03,  1.2472e-03,\n",
      "         2.1473e-02,  1.2231e-02, -1.3353e-04, -1.3558e-03, -2.3383e-03,\n",
      "        -9.0509e-04,  1.4432e-02,  7.5192e-04, -3.6296e-04, -4.1246e-04,\n",
      "        -1.7329e-03, -8.1329e-04,  1.2884e-03, -2.4130e-03,  6.2267e-04,\n",
      "        -1.5755e-03,  1.1495e-03, -4.4217e-03, -5.2566e-03, -3.7303e-03,\n",
      "        -8.2698e-05, -1.7825e-03,  3.7066e-04, -1.9303e-03, -1.8594e-03,\n",
      "        -4.2560e-03, -1.8858e-03,  3.2769e-03,  3.2307e-03, -2.1223e-03,\n",
      "        -1.8277e-03,  9.6698e-04,  2.2945e-03,  2.3653e-04,  6.8403e-03,\n",
      "        -4.3533e-03, -2.6755e-03, -1.7101e-03, -3.2142e-03, -5.6303e-04,\n",
      "        -2.2134e-03, -4.0303e-03, -2.9341e-03,  2.8473e-03,  4.8698e-04,\n",
      "        -1.3546e-02, -3.7583e-04,  2.0260e-04, -3.5348e-03,  1.1323e-02,\n",
      "         1.5867e-04,  1.7694e-03,  3.6352e-03,  9.1714e-04,  1.8794e-03,\n",
      "        -4.8999e-04,  5.9527e-03, -1.4102e-02,  1.3805e-03,  2.1105e-03,\n",
      "         8.2754e-03,  6.4569e-04, -3.1395e-03,  7.6958e-03, -1.9883e-03,\n",
      "         5.2012e-03,  1.1782e-03,  1.5269e-03, -7.0298e-04,  3.3108e-03,\n",
      "         1.1078e-03, -3.7715e-03,  1.4563e-03,  2.7743e-04,  1.1725e-03,\n",
      "        -8.3382e-04,  1.3707e-02,  1.2934e-03,  1.8153e-03, -9.1880e-04,\n",
      "        -2.8227e-03,  3.1051e-03,  1.1398e-02, -1.4398e-03, -2.5867e-03,\n",
      "        -7.6364e-04, -1.6478e-02], device='cuda:0', requires_grad=True))\n",
      "('7.1.bn3.weight', Parameter containing:\n",
      "tensor([1.0006, 0.9992, 0.9997,  ..., 0.9981, 0.9992, 0.9987], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('7.1.bn3.bias', Parameter containing:\n",
      "tensor([ 0.0013, -0.0011,  0.0004,  ..., -0.0004, -0.0018,  0.0006],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.2.conv1.weight', Parameter containing:\n",
      "tensor([[[ 0.0075],\n",
      "         [ 0.0118],\n",
      "         [ 0.0141],\n",
      "         ...,\n",
      "         [ 0.0113],\n",
      "         [ 0.0197],\n",
      "         [-0.0126]],\n",
      "\n",
      "        [[-0.0220],\n",
      "         [-0.0008],\n",
      "         [ 0.0003],\n",
      "         ...,\n",
      "         [ 0.0136],\n",
      "         [-0.0188],\n",
      "         [-0.0206]],\n",
      "\n",
      "        [[-0.0079],\n",
      "         [-0.0163],\n",
      "         [-0.0172],\n",
      "         ...,\n",
      "         [ 0.0038],\n",
      "         [ 0.0028],\n",
      "         [-0.0154]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0028],\n",
      "         [-0.0041],\n",
      "         [-0.0062],\n",
      "         ...,\n",
      "         [ 0.0219],\n",
      "         [-0.0067],\n",
      "         [-0.0060]],\n",
      "\n",
      "        [[-0.0170],\n",
      "         [-0.0013],\n",
      "         [-0.0059],\n",
      "         ...,\n",
      "         [-0.0232],\n",
      "         [ 0.0120],\n",
      "         [-0.0127]],\n",
      "\n",
      "        [[ 0.0250],\n",
      "         [ 0.0059],\n",
      "         [-0.0168],\n",
      "         ...,\n",
      "         [ 0.0160],\n",
      "         [-0.0050],\n",
      "         [ 0.0083]]], device='cuda:0', requires_grad=True))\n",
      "('7.2.conv1.bias', Parameter containing:\n",
      "tensor([-4.4268e-03, -1.7555e-02, -5.3211e-03,  6.8782e-03, -1.5282e-02,\n",
      "         1.0772e-05, -7.0158e-03,  9.0535e-03, -7.6364e-03,  6.1632e-03,\n",
      "        -1.2666e-02, -1.3901e-02,  2.1080e-02, -1.6212e-02,  2.1345e-02,\n",
      "         7.3527e-03, -3.6291e-03,  1.4588e-02,  3.2466e-03, -2.0645e-02,\n",
      "         1.8259e-02,  1.2670e-02, -1.4753e-02, -4.3999e-03,  1.8670e-02,\n",
      "         8.0382e-03, -9.3709e-03,  2.5758e-03, -2.0181e-02,  1.0890e-02,\n",
      "        -6.9516e-03,  1.6917e-02,  1.3262e-02, -2.1707e-03,  1.9854e-02,\n",
      "        -2.0220e-02,  2.1525e-02, -5.4190e-03,  1.2858e-02, -2.0994e-02,\n",
      "        -4.6855e-03, -4.3725e-03,  7.2609e-03, -5.7551e-04,  1.9699e-02,\n",
      "         7.5243e-03,  9.6580e-04,  3.8299e-03,  1.3214e-02, -2.0084e-03,\n",
      "        -6.0665e-03,  7.6087e-03,  1.5261e-02, -1.3888e-02,  1.7395e-02,\n",
      "        -1.8821e-02,  1.9753e-02,  1.6464e-03, -1.6071e-02, -1.7296e-02,\n",
      "        -2.7047e-03, -1.9416e-02,  2.1391e-02, -1.0101e-02, -1.9625e-02,\n",
      "         2.0360e-03,  6.6009e-03, -5.7326e-03, -8.8261e-03,  1.6922e-02,\n",
      "        -1.9797e-02, -1.6963e-02, -7.0560e-03, -1.6773e-02,  1.1081e-02,\n",
      "         8.5373e-03,  1.9480e-02,  8.5599e-03, -8.9578e-03,  2.1954e-02,\n",
      "        -2.0278e-02, -1.5739e-02, -1.7586e-02, -1.0683e-02,  5.0726e-03,\n",
      "         2.2132e-03,  5.5898e-03, -2.0099e-02,  1.6918e-02,  1.6551e-02,\n",
      "         1.1265e-02,  4.3740e-03,  1.1933e-02, -6.3388e-03, -2.0387e-02,\n",
      "         2.1919e-02, -1.7450e-02, -1.8785e-02, -1.6829e-02, -1.6206e-02,\n",
      "        -1.9095e-02,  8.1236e-03,  1.2449e-02, -5.4639e-03, -1.6508e-02,\n",
      "        -1.5470e-02, -4.0080e-03,  5.5613e-03, -6.0168e-04,  3.7809e-03,\n",
      "        -2.3876e-03, -1.5621e-02, -2.1401e-03,  4.1145e-03, -1.3048e-02,\n",
      "         1.6952e-02,  1.8024e-02,  1.1801e-02, -5.3971e-03,  1.6268e-02,\n",
      "        -9.6865e-03, -3.9461e-03, -1.0791e-02, -3.5509e-03, -1.3010e-02,\n",
      "         1.2607e-02, -1.6791e-02, -3.1069e-03,  7.6848e-03,  5.9501e-03,\n",
      "        -1.9714e-02,  5.1127e-04, -2.1740e-02, -3.5482e-03,  1.0512e-02,\n",
      "         1.4059e-03,  1.4197e-02,  1.8744e-02, -2.0308e-02,  1.7741e-02,\n",
      "         1.1636e-02, -1.4861e-02,  2.0052e-02, -1.0293e-03, -1.4461e-02,\n",
      "         1.6903e-02, -1.9535e-02,  1.8195e-02, -1.3194e-02,  9.6818e-03,\n",
      "         3.9268e-03,  1.4563e-02,  2.1321e-02, -2.0607e-02,  7.0181e-04,\n",
      "         1.2357e-02,  1.1723e-02, -3.2923e-03, -2.0973e-02, -1.1480e-02,\n",
      "         7.4591e-03,  1.6610e-02,  1.7261e-02, -1.7390e-02, -1.6742e-02,\n",
      "        -2.1604e-02, -1.0088e-02,  8.9654e-03, -9.2649e-03, -7.2274e-03,\n",
      "         1.2499e-02,  1.1974e-02,  1.4386e-02,  1.4947e-02, -3.4673e-03,\n",
      "         1.6662e-02, -4.0161e-03,  1.0074e-02,  2.0091e-02,  3.5362e-03,\n",
      "        -1.4483e-02, -1.0333e-02, -1.4640e-02,  1.9869e-02,  9.1746e-03,\n",
      "         1.1325e-02,  4.6876e-03, -1.6173e-03, -1.4450e-03, -2.1050e-02,\n",
      "        -1.1227e-02, -1.6036e-02,  1.2121e-03, -1.3269e-02,  1.8481e-02,\n",
      "        -1.2448e-02,  1.2346e-02, -7.2792e-03, -4.0720e-03,  1.9070e-02,\n",
      "         1.8184e-02,  1.5510e-02,  2.2937e-03, -2.0199e-02,  1.2028e-02,\n",
      "        -1.7881e-02, -7.2046e-03, -2.1652e-02,  2.0572e-02, -8.7961e-03,\n",
      "         1.4521e-02, -1.5839e-02,  9.2902e-03,  1.0870e-03,  2.7698e-03,\n",
      "         5.0834e-03, -2.1887e-02, -1.3575e-02,  2.0369e-02, -7.8380e-03,\n",
      "         1.7791e-02,  3.9781e-03,  2.0760e-03, -2.7104e-03,  7.5405e-03,\n",
      "         1.8964e-02,  1.3039e-02,  2.1057e-02,  1.5712e-02,  1.2031e-02,\n",
      "         2.2368e-03,  5.1427e-03,  7.9657e-03, -1.3201e-02,  2.0922e-02,\n",
      "        -1.5209e-02, -1.1002e-02,  6.5711e-03,  6.5238e-03,  7.0143e-03,\n",
      "         1.7914e-02,  2.7069e-03, -2.1307e-02, -1.6424e-02, -5.0226e-03,\n",
      "         1.7688e-02, -2.1151e-02,  1.8268e-02,  1.1327e-02, -4.1849e-03,\n",
      "         1.4252e-02, -2.5522e-03,  1.0002e-02, -8.0313e-03,  1.1095e-02,\n",
      "         1.2865e-03, -1.2637e-02, -2.1540e-02, -8.3501e-03, -1.5507e-02,\n",
      "        -2.1936e-02, -5.6762e-03, -4.8976e-03,  1.0187e-02, -4.2911e-03,\n",
      "        -2.1294e-02,  6.1646e-03,  4.2299e-03, -3.8562e-03, -1.9529e-02,\n",
      "        -1.9694e-02,  2.0349e-02, -8.2000e-03, -4.9186e-03, -1.9027e-03,\n",
      "         1.8168e-02, -1.4225e-02,  8.4343e-03, -6.9018e-03,  1.9640e-02,\n",
      "        -2.0808e-02,  1.9979e-02, -1.5119e-02,  9.4608e-04,  4.4718e-03,\n",
      "         2.1844e-03,  5.6271e-03,  8.9789e-03, -3.8176e-03,  1.1309e-02,\n",
      "         1.9758e-02, -8.1255e-03, -3.5683e-03, -5.2255e-03, -9.2872e-03,\n",
      "         1.5810e-02, -1.8370e-02,  1.8811e-02,  6.1402e-03,  9.3627e-03,\n",
      "         2.2973e-03,  2.1393e-04, -1.8708e-02,  1.4506e-02, -1.3445e-03,\n",
      "         1.6838e-02,  1.0537e-02, -1.8764e-02,  1.8596e-02,  3.3981e-03,\n",
      "        -1.4625e-02,  9.2683e-03, -1.9894e-02, -1.4405e-02,  3.7085e-03,\n",
      "        -1.7799e-02, -2.1815e-02,  1.5132e-02, -5.2036e-03,  1.8063e-02,\n",
      "         1.2430e-02,  3.3943e-03, -3.2319e-03, -7.5658e-04, -5.7670e-03,\n",
      "        -2.0052e-02,  3.8738e-03,  2.1985e-02, -9.8279e-03,  1.2387e-02,\n",
      "         5.3550e-03, -7.0543e-03,  8.5909e-03,  1.1638e-02, -1.8059e-03,\n",
      "         9.4913e-03, -1.5944e-02, -1.8409e-03,  3.3765e-03,  4.8079e-03,\n",
      "        -1.3011e-02,  9.6765e-03, -1.5852e-02,  1.9664e-02, -1.2526e-02,\n",
      "        -2.0057e-02, -3.9822e-03,  1.7022e-02, -1.5394e-02, -1.3266e-02,\n",
      "         3.5455e-03,  9.2461e-03,  9.4461e-03, -8.4905e-03, -2.0093e-02,\n",
      "        -8.3817e-03,  7.4157e-03, -9.3696e-03, -6.8567e-03, -1.9822e-02,\n",
      "         1.7296e-02,  1.8747e-02, -1.0743e-02,  8.9784e-03, -3.2168e-03,\n",
      "        -1.0046e-03, -7.7256e-03,  1.0742e-02, -9.8453e-03, -1.6296e-02,\n",
      "        -5.8654e-03, -6.9009e-03,  1.6751e-04, -1.7621e-02,  1.3217e-02,\n",
      "        -2.1426e-03,  5.1646e-03, -1.4855e-02,  2.0236e-02,  1.4195e-02,\n",
      "        -4.7314e-03,  3.9339e-03, -1.1471e-02, -1.6804e-02, -2.0398e-02,\n",
      "         1.8394e-02, -2.9199e-03,  1.6773e-02, -1.7364e-02,  4.4537e-03,\n",
      "        -4.7662e-03,  1.6582e-03,  1.2491e-02,  1.4506e-02, -5.8166e-03,\n",
      "        -1.8614e-02, -1.6428e-02, -1.7241e-02, -1.0104e-02,  2.8125e-04,\n",
      "         5.6789e-03, -2.0594e-02,  1.5501e-02,  1.4676e-02, -6.9451e-03,\n",
      "        -1.7276e-02, -1.6289e-02,  7.1363e-03,  9.1666e-03, -9.9609e-03,\n",
      "         1.2840e-02,  1.0653e-02,  1.9937e-03,  4.8254e-03, -1.3066e-02,\n",
      "         9.9199e-03, -6.5606e-03, -1.3009e-02,  2.1867e-02, -9.7829e-03,\n",
      "        -6.0479e-03, -1.3565e-02, -1.6872e-02, -1.3386e-02,  6.6554e-03,\n",
      "         5.3201e-03,  7.2693e-03,  3.8033e-03, -1.0640e-02,  4.1091e-03,\n",
      "        -2.0324e-02, -2.0212e-02, -7.0141e-03,  1.3380e-03,  1.4845e-02,\n",
      "        -1.4154e-02, -2.1089e-02,  1.1285e-02, -1.7093e-02,  1.0651e-02,\n",
      "        -7.2827e-03, -9.9144e-03, -1.3985e-02,  1.3391e-02,  1.7048e-02,\n",
      "         1.9098e-02, -8.7139e-03, -1.3646e-02, -5.1633e-03, -1.1254e-04,\n",
      "        -1.6577e-02,  5.1309e-04,  7.3195e-03,  2.0340e-02, -9.2792e-04,\n",
      "         4.6141e-03,  2.1115e-02, -8.4626e-03, -1.3349e-03, -1.9361e-02,\n",
      "        -5.9570e-03,  1.1335e-02,  1.5252e-02,  1.0104e-02, -1.9309e-02,\n",
      "         2.4945e-03, -1.6778e-02,  6.0613e-03, -1.4953e-02, -1.5358e-02,\n",
      "        -1.1828e-02, -4.9486e-04,  4.5317e-05,  2.0311e-02, -1.4617e-02,\n",
      "        -2.1241e-02,  3.7718e-04,  3.4169e-03, -1.4036e-02,  2.6252e-03,\n",
      "         8.1843e-03,  2.9247e-03, -2.1602e-02, -1.9407e-02,  9.2048e-03,\n",
      "        -1.5757e-02,  1.9151e-02, -1.2469e-02,  1.8435e-02,  2.0811e-02,\n",
      "        -1.9267e-02,  1.8183e-03, -1.4262e-02, -1.1654e-02, -2.1666e-02,\n",
      "         2.1144e-02,  1.3395e-03, -1.2450e-02, -1.0804e-02, -7.8559e-03,\n",
      "         9.0188e-03, -1.2920e-02,  1.7204e-05, -5.4398e-03, -5.3467e-03,\n",
      "        -6.5750e-03, -6.6176e-03, -2.0568e-03, -1.8498e-02,  1.5767e-02,\n",
      "         3.3052e-03,  4.6307e-03], device='cuda:0', requires_grad=True))\n",
      "('7.2.conv2.weight', Parameter containing:\n",
      "tensor([[[ 1.0804e-02,  6.2398e-03, -1.8080e-02],\n",
      "         [-1.4205e-02, -6.7830e-03, -1.6144e-02],\n",
      "         [-9.3420e-05, -2.4685e-02, -1.0626e-02],\n",
      "         ...,\n",
      "         [-1.2002e-02,  1.6745e-02,  9.4346e-03],\n",
      "         [-2.5986e-03, -2.4713e-02,  1.3840e-02],\n",
      "         [-2.0971e-02,  1.8093e-02, -2.2311e-02]],\n",
      "\n",
      "        [[ 1.9485e-02, -2.2126e-02, -3.8699e-03],\n",
      "         [ 1.6450e-02, -1.8914e-02,  4.2092e-04],\n",
      "         [ 2.6442e-02, -2.0733e-02,  2.4090e-02],\n",
      "         ...,\n",
      "         [-2.6133e-02, -1.1058e-02, -2.7798e-02],\n",
      "         [-1.3670e-02, -2.3930e-02,  1.4926e-02],\n",
      "         [-2.7030e-03,  1.8590e-02, -5.7248e-03]],\n",
      "\n",
      "        [[-8.0154e-03, -2.4498e-03, -2.3272e-02],\n",
      "         [-1.2546e-02,  1.2205e-02, -1.5106e-02],\n",
      "         [-2.2412e-02,  2.1511e-02,  2.3899e-02],\n",
      "         ...,\n",
      "         [-2.2148e-02,  1.1491e-02, -7.5434e-03],\n",
      "         [ 2.5292e-02, -1.7186e-02, -4.2628e-05],\n",
      "         [ 1.3737e-02, -1.9746e-02, -9.5930e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.4696e-03, -1.5549e-02,  1.6088e-02],\n",
      "         [-1.9193e-02,  1.5231e-02, -4.9369e-03],\n",
      "         [ 3.6390e-03,  1.0859e-02,  2.3990e-02],\n",
      "         ...,\n",
      "         [-1.9171e-02, -4.7084e-03,  2.1229e-02],\n",
      "         [ 1.9147e-02, -1.0978e-03,  1.7631e-02],\n",
      "         [ 1.1095e-02, -1.2015e-02, -3.7629e-03]],\n",
      "\n",
      "        [[-2.1730e-02, -2.9704e-04, -1.2925e-02],\n",
      "         [ 7.8792e-03, -2.1292e-02,  1.9253e-02],\n",
      "         [-1.9663e-02, -9.8511e-03,  1.8824e-04],\n",
      "         ...,\n",
      "         [-1.1494e-03,  2.8527e-03, -1.9122e-02],\n",
      "         [-1.7898e-02, -2.4535e-02,  1.0481e-02],\n",
      "         [ 1.0504e-02,  6.6809e-03,  9.7422e-03]],\n",
      "\n",
      "        [[ 7.8397e-04, -4.5539e-03,  1.7639e-02],\n",
      "         [ 2.1585e-02,  1.2685e-02, -3.5365e-03],\n",
      "         [-4.8270e-03, -2.5087e-02, -2.1220e-02],\n",
      "         ...,\n",
      "         [-2.1780e-02,  6.8534e-03,  2.3309e-02],\n",
      "         [ 1.0739e-02,  3.8293e-03, -7.2358e-04],\n",
      "         [ 1.2684e-02, -7.6092e-03,  1.1339e-02]]], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('7.2.conv2.bias', Parameter containing:\n",
      "tensor([-2.5154e-02, -1.6798e-04,  1.3354e-02, -1.4062e-02,  1.3276e-03,\n",
      "        -6.0721e-03, -5.9175e-03, -1.5757e-02,  1.2507e-04, -1.4477e-03,\n",
      "        -1.2975e-02,  2.1068e-02,  1.1233e-02,  9.6749e-05, -9.2527e-03,\n",
      "         2.2759e-03, -1.2421e-02,  2.4605e-02, -2.5479e-02,  2.4403e-03,\n",
      "        -2.4949e-02,  1.1856e-02,  1.2651e-02, -1.6473e-02, -1.4263e-02,\n",
      "        -1.8536e-02, -1.6858e-02, -1.1625e-02,  2.4685e-02,  8.3011e-03,\n",
      "        -7.9928e-03, -1.2474e-02, -8.9471e-03, -1.2782e-02, -3.2912e-03,\n",
      "        -2.0863e-02, -7.1184e-03,  9.9284e-03,  1.4095e-02,  2.4451e-02,\n",
      "        -1.5683e-02,  7.0331e-03,  8.2400e-03,  4.6520e-03,  4.3109e-03,\n",
      "         2.4885e-02, -1.0051e-02,  2.2784e-02,  2.0093e-02,  1.4016e-02,\n",
      "         5.1672e-03, -5.1221e-03, -5.9997e-04, -2.3285e-03,  6.7915e-03,\n",
      "         2.2303e-02, -1.1809e-02, -1.2251e-02, -2.2833e-02, -4.7772e-04,\n",
      "         1.2207e-02, -5.9548e-03,  3.3886e-03, -1.0382e-02,  5.5420e-03,\n",
      "         8.8887e-04,  9.6129e-03,  1.9486e-02,  2.2309e-02, -1.4345e-02,\n",
      "         9.7121e-03,  9.0028e-04,  2.1971e-02,  2.5273e-02,  2.2801e-02,\n",
      "        -1.2501e-02, -2.4390e-02, -1.2345e-02,  1.3614e-02, -1.5144e-02,\n",
      "        -2.5213e-02,  8.7497e-03, -6.4567e-03,  2.9876e-03,  1.8271e-02,\n",
      "        -1.0598e-02, -1.4711e-02, -1.0255e-02,  1.0965e-02, -1.4267e-03,\n",
      "         3.6713e-03,  8.5476e-03,  5.3358e-03, -1.9327e-03, -2.5081e-02,\n",
      "         3.3604e-03, -5.0253e-04,  2.2270e-02,  4.5315e-03, -3.0173e-03,\n",
      "        -1.8927e-02,  2.5515e-02,  3.3966e-04,  7.0304e-03, -2.6858e-04,\n",
      "         1.9745e-02,  1.4758e-02,  1.7083e-02,  3.9314e-03, -2.2352e-02,\n",
      "         1.0330e-02, -1.4761e-02,  1.0450e-02, -2.0701e-02, -1.0297e-02,\n",
      "        -1.0369e-02, -7.2568e-03, -4.9029e-03,  1.4004e-03,  8.3726e-03,\n",
      "         1.7145e-03,  1.6479e-02, -1.6002e-02, -1.5061e-02, -1.5911e-02,\n",
      "        -8.9809e-03,  2.9722e-03, -1.9047e-02, -1.0593e-02, -5.9450e-03,\n",
      "         9.4619e-03, -2.3090e-02, -1.7567e-02, -1.9073e-02,  8.0556e-03,\n",
      "        -1.0555e-02,  1.1577e-02,  1.0127e-02,  3.8724e-03, -4.0719e-03,\n",
      "         1.7760e-02, -2.1153e-03, -1.4407e-02, -1.5566e-02,  3.5689e-04,\n",
      "         1.6195e-02,  3.3492e-03, -1.7727e-02,  1.8625e-02,  2.4243e-02,\n",
      "         2.1942e-03, -2.5013e-02,  1.5953e-02, -2.4041e-02,  2.4808e-02,\n",
      "         1.8349e-02,  1.6666e-02,  1.6911e-02, -1.9332e-02,  8.1645e-03,\n",
      "         1.3723e-02,  5.9804e-03, -9.7120e-03,  2.3921e-02, -2.5323e-02,\n",
      "         2.0329e-02,  1.2540e-02, -1.9639e-02, -8.7119e-03,  5.8995e-03,\n",
      "         9.4952e-05,  1.2805e-02,  2.2852e-02,  5.3921e-03, -9.9670e-03,\n",
      "         2.2635e-02,  1.8053e-02,  2.1721e-02, -1.4929e-02,  2.5489e-02,\n",
      "         4.2409e-03,  1.7458e-02, -1.0704e-02,  3.5387e-03, -4.4102e-03,\n",
      "         2.2485e-02,  2.8065e-03,  1.4347e-02,  1.7788e-02,  1.6253e-04,\n",
      "        -1.6868e-02, -3.3715e-03,  1.9289e-02, -9.1463e-03,  1.1153e-02,\n",
      "        -9.7078e-03, -5.5054e-03,  1.3025e-03,  1.7427e-02,  6.7722e-03,\n",
      "         1.2978e-02,  1.4933e-02,  1.0146e-02,  7.0462e-03, -1.3703e-02,\n",
      "        -2.3632e-02, -1.2775e-02,  1.4894e-03, -2.0600e-02,  9.8113e-03,\n",
      "         1.7142e-02, -1.2659e-02, -1.9320e-02, -9.8232e-03, -1.8316e-02,\n",
      "         2.5176e-02,  4.7848e-03, -1.0576e-03,  1.8905e-02,  1.3094e-02,\n",
      "         1.2036e-02, -1.5443e-02,  1.1680e-03,  1.8037e-02,  1.7970e-02,\n",
      "         2.6214e-03,  2.2216e-02, -1.4914e-02,  1.1382e-02, -1.4297e-02,\n",
      "         2.0169e-02,  2.4251e-02,  1.0834e-02, -1.1877e-03,  1.0351e-02,\n",
      "        -7.9325e-03,  1.1813e-02, -1.3528e-02,  3.2219e-03,  4.0642e-03,\n",
      "         2.0587e-03,  1.0199e-02,  2.4327e-02, -1.1592e-02,  1.8367e-02,\n",
      "        -1.0139e-02,  1.7602e-02,  2.1335e-03,  5.1294e-04, -1.2043e-02,\n",
      "        -2.1839e-02, -1.5898e-02,  2.4627e-02, -1.3675e-02,  2.0700e-02,\n",
      "        -1.0731e-02,  1.9011e-03,  6.4444e-04,  2.1513e-02,  1.1438e-02,\n",
      "         3.4818e-04,  1.6063e-02,  2.0666e-02,  3.0665e-03,  5.5087e-03,\n",
      "        -1.7093e-02, -1.6055e-02, -2.0118e-02, -2.4688e-02, -1.1407e-04,\n",
      "        -2.3627e-02,  7.2555e-03, -1.3127e-02,  7.6490e-03,  3.2689e-03,\n",
      "         1.2518e-02,  3.1651e-03,  1.4825e-03,  7.7063e-03,  2.0487e-02,\n",
      "         1.2600e-02,  1.0394e-02, -7.4830e-03, -1.5174e-02, -1.9241e-02,\n",
      "        -5.2694e-03,  1.3099e-02, -6.0893e-03,  1.6722e-02, -2.3956e-02,\n",
      "         2.5860e-03,  1.2285e-02,  1.8307e-02, -2.0817e-03,  1.7873e-02,\n",
      "        -9.6607e-03, -1.8131e-03,  6.6970e-03,  9.3284e-03, -1.9507e-02,\n",
      "         1.2600e-02, -3.0880e-03, -2.1794e-02,  9.9708e-03, -3.1823e-03,\n",
      "        -3.4202e-03, -4.7378e-03, -1.1239e-02,  1.1211e-02,  1.2848e-02,\n",
      "        -9.0495e-03, -7.6230e-03, -2.0616e-02, -1.5401e-02, -2.2029e-02,\n",
      "         1.6124e-02, -9.9771e-03,  1.7830e-02,  1.0212e-02, -8.0568e-03,\n",
      "         1.0774e-02,  9.8097e-03,  1.9766e-02, -1.8542e-02,  1.4373e-02,\n",
      "        -1.9654e-02, -1.1245e-02,  1.3638e-02,  2.0716e-02,  1.6100e-02,\n",
      "         9.5163e-03, -2.4057e-02,  5.6476e-03,  1.6987e-02,  1.5467e-02,\n",
      "         1.0233e-02, -1.1368e-02, -1.8995e-02,  1.9049e-02,  2.3059e-02,\n",
      "         1.0948e-02,  2.2867e-02,  8.7349e-03, -2.3046e-03,  1.6135e-02,\n",
      "         2.0413e-02,  2.4358e-02,  5.4797e-03, -8.8048e-03,  6.9401e-03,\n",
      "         1.7999e-02,  9.8219e-03,  7.7595e-03, -1.0650e-02,  1.3955e-02,\n",
      "         1.6263e-02,  3.7151e-04,  2.3210e-02,  1.0175e-02, -2.3414e-02,\n",
      "        -1.1652e-02,  4.2935e-04,  8.4292e-03, -6.5854e-04, -9.2806e-03,\n",
      "        -1.5853e-02, -1.1261e-02,  1.2991e-02, -8.0037e-03,  1.2279e-04,\n",
      "         1.1234e-02,  5.0984e-04,  1.1590e-02, -1.1019e-02, -6.0731e-03,\n",
      "         1.9054e-02, -6.0271e-03, -1.4487e-02, -8.2978e-03, -1.2734e-02,\n",
      "        -1.9667e-02, -1.2380e-02, -1.2634e-02,  3.5102e-03, -6.1325e-03,\n",
      "         5.3166e-03, -1.3892e-02, -1.4878e-02,  1.3725e-02,  1.2458e-02,\n",
      "        -1.7303e-02,  1.6793e-02,  2.4983e-02, -7.8857e-03,  1.3627e-03,\n",
      "         8.2720e-03,  6.6137e-03,  1.5215e-02,  9.9258e-03,  9.4367e-03,\n",
      "        -1.5953e-02,  1.6308e-02, -2.3367e-02, -6.8761e-03, -9.5815e-03,\n",
      "         2.2768e-03, -1.6454e-02,  2.2394e-02, -2.3721e-02,  2.4636e-02,\n",
      "         2.2083e-02, -1.4109e-02,  1.9906e-02, -1.6513e-02,  7.9251e-03,\n",
      "         3.5744e-03,  1.0784e-02,  2.0412e-02,  2.4405e-02, -2.1346e-02,\n",
      "         2.0488e-02,  4.6766e-03, -8.0519e-03, -7.0603e-03, -8.5999e-03,\n",
      "         1.5387e-02,  2.4831e-02,  2.0804e-02, -1.2341e-02,  1.4039e-02,\n",
      "        -2.0855e-03, -1.9183e-02, -1.1046e-02,  6.4901e-03,  1.7596e-02,\n",
      "        -1.6470e-02, -1.0942e-02, -9.0920e-03,  7.4170e-03,  3.4724e-03,\n",
      "         2.1404e-02, -1.2569e-02, -1.0816e-02, -1.0803e-02,  2.3492e-02,\n",
      "         2.2728e-02,  1.2067e-02, -1.6398e-03, -1.1499e-02, -3.0666e-03,\n",
      "         1.4760e-02, -2.3315e-03, -2.2490e-02, -4.1692e-03,  8.5691e-03,\n",
      "         1.2385e-02, -8.3660e-03, -2.5319e-02, -5.2353e-03, -1.5967e-02,\n",
      "        -9.8555e-03, -1.7560e-02, -1.1981e-02,  6.3611e-03,  3.1862e-03,\n",
      "         1.0419e-02,  9.1350e-04, -1.6183e-02,  2.0475e-02,  1.8081e-02,\n",
      "         2.5313e-02,  1.7881e-02, -1.6944e-02, -2.4899e-02, -5.5994e-03,\n",
      "        -3.8806e-04, -1.9048e-03, -1.2797e-02, -2.6104e-03,  1.3271e-03,\n",
      "        -3.4601e-03,  2.1151e-02, -1.7608e-02,  1.7407e-02, -9.5258e-03,\n",
      "         2.5437e-02,  5.7333e-03,  9.6282e-03,  2.1000e-02,  2.4405e-02,\n",
      "         1.5060e-02, -2.0869e-02,  8.1143e-03,  1.0159e-02, -7.2673e-03,\n",
      "         1.0443e-02, -9.2436e-03, -6.0690e-04, -2.0942e-02,  1.9391e-02,\n",
      "         2.2553e-04,  1.7231e-02, -2.0505e-02, -1.4451e-02, -2.2592e-02,\n",
      "         1.1832e-02,  3.7870e-03, -2.3698e-02, -1.9980e-03, -1.4788e-02,\n",
      "         1.8742e-02, -9.7358e-03], device='cuda:0', requires_grad=True))\n",
      "('7.2.conv3.weight', Parameter containing:\n",
      "tensor([[[-0.0090],\n",
      "         [ 0.0073],\n",
      "         [-0.0025],\n",
      "         ...,\n",
      "         [ 0.0133],\n",
      "         [ 0.0117],\n",
      "         [-0.0346]],\n",
      "\n",
      "        [[ 0.0339],\n",
      "         [ 0.0282],\n",
      "         [-0.0381],\n",
      "         ...,\n",
      "         [-0.0308],\n",
      "         [ 0.0271],\n",
      "         [-0.0143]],\n",
      "\n",
      "        [[-0.0310],\n",
      "         [ 0.0105],\n",
      "         [ 0.0354],\n",
      "         ...,\n",
      "         [ 0.0234],\n",
      "         [-0.0147],\n",
      "         [ 0.0371]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0203],\n",
      "         [ 0.0325],\n",
      "         [-0.0120],\n",
      "         ...,\n",
      "         [-0.0310],\n",
      "         [ 0.0041],\n",
      "         [ 0.0096]],\n",
      "\n",
      "        [[-0.0248],\n",
      "         [ 0.0390],\n",
      "         [-0.0176],\n",
      "         ...,\n",
      "         [-0.0377],\n",
      "         [ 0.0202],\n",
      "         [ 0.0224]],\n",
      "\n",
      "        [[-0.0116],\n",
      "         [ 0.0277],\n",
      "         [ 0.0311],\n",
      "         ...,\n",
      "         [-0.0368],\n",
      "         [-0.0085],\n",
      "         [-0.0377]]], device='cuda:0', requires_grad=True))\n",
      "('7.2.conv3.bias', Parameter containing:\n",
      "tensor([-0.0177,  0.0164,  0.0434,  ..., -0.0193, -0.0295, -0.0120],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.2.bn1.weight', Parameter containing:\n",
      "tensor([0.9986, 0.9998, 0.9989, 0.9971, 1.0004, 0.9978, 0.9982, 0.9981, 0.9982,\n",
      "        0.9965, 1.0007, 1.0001, 0.9972, 0.9954, 0.9983, 0.9983, 0.9991, 0.9952,\n",
      "        0.9965, 1.0026, 1.0007, 1.0031, 0.9980, 0.9977, 0.9980, 0.9940, 1.0000,\n",
      "        1.0016, 1.0035, 0.9977, 1.0000, 1.0036, 0.9973, 0.9963, 0.9996, 1.0000,\n",
      "        1.0016, 1.0055, 1.0040, 1.0047, 1.0076, 1.0043, 1.0017, 0.9972, 1.0020,\n",
      "        1.0022, 1.0023, 1.0025, 1.0076, 1.0000, 1.0016, 0.9932, 0.9984, 1.0034,\n",
      "        0.9999, 0.9989, 1.0006, 1.0005, 1.0006, 1.0005, 1.0060, 1.0007, 0.9992,\n",
      "        0.9984, 1.0006, 0.9992, 0.9981, 1.0005, 0.9979, 0.9964, 0.9973, 1.0021,\n",
      "        1.0015, 0.9972, 1.0011, 0.9988, 1.0022, 1.0081, 1.0058, 0.9972, 1.0010,\n",
      "        0.9975, 0.9977, 0.9977, 0.9989, 1.0075, 0.9950, 1.0001, 0.9991, 1.0017,\n",
      "        1.0003, 1.0010, 0.9996, 0.9972, 1.0102, 0.9961, 0.9985, 1.0031, 0.9989,\n",
      "        1.0024, 0.9995, 1.0000, 0.9990, 1.0026, 0.9979, 1.0020, 0.9992, 1.0020,\n",
      "        0.9978, 1.0053, 0.9960, 0.9984, 1.0053, 0.9961, 1.0013, 1.0042, 1.0001,\n",
      "        0.9965, 0.9969, 0.9973, 1.0015, 0.9978, 0.9976, 0.9971, 0.9984, 1.0005,\n",
      "        1.0011, 1.0007, 1.0009, 0.9997, 1.0001, 0.9961, 0.9979, 1.0001, 1.0034,\n",
      "        0.9995, 1.0000, 1.0020, 1.0010, 0.9989, 1.0018, 1.0005, 0.9993, 1.0007,\n",
      "        1.0050, 0.9996, 0.9972, 1.0003, 1.0050, 0.9937, 0.9953, 0.9985, 0.9967,\n",
      "        0.9985, 1.0021, 0.9995, 0.9993, 1.0016, 0.9952, 0.9996, 0.9989, 1.0013,\n",
      "        0.9987, 0.9959, 0.9991, 1.0016, 1.0051, 0.9995, 0.9999, 0.9991, 1.0029,\n",
      "        1.0024, 0.9981, 0.9979, 1.0027, 1.0013, 0.9993, 0.9960, 0.9992, 1.0087,\n",
      "        0.9984, 0.9988, 1.0001, 0.9991, 1.0001, 0.9977, 1.0024, 1.0023, 1.0020,\n",
      "        0.9998, 0.9983, 0.9980, 1.0015, 1.0005, 0.9974, 0.9997, 0.9993, 1.0038,\n",
      "        0.9960, 0.9979, 1.0010, 1.0045, 0.9977, 0.9995, 0.9985, 1.0026, 0.9999,\n",
      "        0.9996, 0.9998, 0.9989, 1.0008, 1.0008, 1.0016, 0.9997, 0.9980, 1.0021,\n",
      "        0.9974, 1.0017, 1.0000, 0.9999, 0.9991, 0.9990, 0.9975, 1.0025, 1.0020,\n",
      "        0.9979, 0.9983, 1.0026, 0.9970, 0.9996, 0.9981, 1.0017, 0.9989, 0.9996,\n",
      "        0.9987, 0.9983, 0.9973, 0.9981, 0.9983, 1.0013, 1.0013, 1.0004, 0.9962,\n",
      "        0.9964, 0.9990, 0.9987, 1.0008, 1.0028, 0.9984, 0.9979, 0.9989, 1.0015,\n",
      "        1.0038, 0.9983, 1.0009, 1.0036, 1.0004, 1.0042, 1.0021, 1.0020, 1.0012,\n",
      "        1.0007, 1.0017, 1.0025, 1.0011, 1.0000, 0.9958, 0.9974, 1.0029, 0.9985,\n",
      "        1.0042, 1.0004, 1.0017, 1.0018, 1.0002, 0.9994, 1.0003, 0.9992, 1.0001,\n",
      "        1.0006, 1.0021, 0.9980, 1.0029, 1.0009, 1.0027, 0.9966, 0.9985, 0.9993,\n",
      "        0.9992, 1.0022, 1.0007, 0.9969, 1.0009, 0.9978, 1.0001, 0.9961, 0.9992,\n",
      "        0.9978, 1.0067, 0.9946, 1.0007, 0.9966, 0.9982, 1.0026, 0.9981, 1.0018,\n",
      "        1.0038, 0.9998, 1.0015, 0.9970, 1.0017, 0.9962, 1.0016, 0.9996, 1.0035,\n",
      "        0.9964, 1.0019, 1.0061, 1.0005, 0.9993, 0.9982, 0.9964, 0.9996, 0.9970,\n",
      "        0.9978, 0.9987, 1.0013, 0.9986, 0.9972, 0.9978, 0.9985, 1.0009, 1.0015,\n",
      "        0.9995, 1.0117, 1.0049, 1.0098, 1.0007, 0.9992, 1.0022, 1.0006, 0.9988,\n",
      "        0.9976, 1.0012, 0.9975, 1.0012, 1.0036, 1.0015, 0.9973, 1.0027, 0.9980,\n",
      "        1.0011, 0.9991, 1.0026, 0.9954, 0.9993, 1.0003, 0.9965, 0.9972, 1.0011,\n",
      "        0.9973, 1.0021, 0.9999, 0.9986, 0.9978, 1.0001, 0.9979, 0.9996, 0.9988,\n",
      "        1.0038, 0.9988, 0.9954, 1.0019, 1.0002, 0.9990, 1.0027, 0.9964, 0.9953,\n",
      "        0.9965, 0.9986, 1.0050, 0.9992, 1.0005, 1.0002, 0.9983, 0.9972, 1.0051,\n",
      "        0.9996, 0.9998, 1.0002, 0.9993, 1.0000, 0.9975, 1.0049, 0.9975, 1.0005,\n",
      "        0.9955, 0.9960, 0.9997, 0.9957, 0.9962, 1.0029, 1.0039, 0.9968, 1.0098,\n",
      "        1.0026, 1.0043, 0.9991, 1.0053, 0.9976, 1.0001, 0.9993, 1.0065, 1.0059,\n",
      "        1.0013, 0.9988, 0.9947, 0.9989, 1.0017, 1.0015, 1.0028, 0.9975, 0.9971,\n",
      "        0.9995, 0.9992, 0.9990, 0.9974, 1.0008, 1.0009, 0.9974, 1.0009, 0.9948,\n",
      "        0.9962, 1.0003, 1.0060, 1.0022, 1.0015, 0.9975, 1.0013, 0.9970, 1.0003,\n",
      "        0.9992, 0.9995, 0.9978, 1.0029, 1.0004, 1.0000, 1.0042, 1.0008, 0.9986,\n",
      "        0.9995, 0.9986, 0.9993, 1.0005, 1.0000, 0.9996, 0.9990, 0.9985, 1.0008,\n",
      "        0.9984, 0.9983, 1.0011, 1.0012, 0.9996, 1.0057, 1.0010, 1.0066, 0.9946,\n",
      "        0.9985, 0.9993, 1.0008, 1.0015, 1.0009, 0.9991, 1.0018, 1.0008, 1.0003,\n",
      "        0.9991, 0.9961, 0.9997, 0.9989, 1.0006, 0.9990, 0.9967, 1.0040, 1.0076,\n",
      "        0.9999, 1.0010, 0.9996, 0.9977, 1.0040, 1.0012, 1.0021, 0.9984, 0.9997,\n",
      "        0.9979, 0.9964, 0.9991, 0.9992, 0.9969, 0.9986, 1.0018, 1.0010, 0.9998,\n",
      "        1.0018, 1.0040, 0.9988, 0.9981, 1.0042, 1.0008, 0.9987, 0.9969],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.2.bn1.bias', Parameter containing:\n",
      "tensor([-8.9940e-04,  1.0800e-03, -2.1202e-03, -2.4298e-03, -1.4763e-03,\n",
      "        -2.2515e-03, -9.1793e-04, -3.0433e-03, -3.0511e-03, -3.5712e-03,\n",
      "         6.7227e-03, -8.5952e-04, -1.1895e-03,  2.9012e-04,  2.6593e-04,\n",
      "        -2.7353e-03, -1.4132e-04, -5.3121e-03, -5.6027e-03, -1.3420e-03,\n",
      "         4.5582e-03, -2.4422e-03, -1.1355e-03, -6.2850e-04,  1.0050e-03,\n",
      "        -5.0343e-03,  7.0632e-04, -1.1639e-03,  4.8557e-03, -4.9569e-04,\n",
      "         2.8952e-03,  2.1089e-03, -2.0971e-03, -4.1510e-03, -4.7081e-03,\n",
      "        -8.8896e-04, -1.7460e-03, -9.6809e-05, -1.9998e-04,  2.9325e-03,\n",
      "         1.9995e-03, -4.3845e-03,  1.1464e-03, -4.4638e-03,  2.6354e-03,\n",
      "         1.2734e-03, -2.2395e-04, -1.2444e-03,  8.2316e-04, -7.5326e-03,\n",
      "        -2.6991e-03, -2.1492e-03, -2.9205e-03,  1.7080e-03, -6.0855e-04,\n",
      "        -9.7731e-04, -1.0943e-03, -1.9812e-03,  2.2279e-03,  1.6232e-03,\n",
      "         6.5217e-03,  1.6724e-05, -2.2142e-03,  3.0922e-03,  1.2964e-03,\n",
      "         3.0194e-04, -3.5946e-03, -2.5502e-03, -2.2645e-04, -3.0478e-03,\n",
      "        -1.7233e-03, -1.0216e-03, -5.5185e-03, -4.7798e-03,  1.6619e-03,\n",
      "         2.3849e-03, -2.3421e-03,  3.9541e-03, -8.2560e-03, -1.2883e-03,\n",
      "         4.5234e-05, -2.6245e-03, -1.2750e-03, -9.5485e-04,  2.5493e-03,\n",
      "         6.4612e-03, -4.5079e-03,  5.6597e-03, -3.9374e-03, -2.2351e-03,\n",
      "         2.4374e-03, -8.4498e-04, -9.4698e-04,  1.2733e-04, -1.4167e-03,\n",
      "        -3.9743e-03, -2.2216e-03, -3.4223e-03, -2.3805e-03,  1.1014e-04,\n",
      "        -1.3292e-03, -1.2692e-03,  1.9312e-04, -5.3026e-04, -1.7691e-03,\n",
      "         2.8639e-03, -1.1655e-03,  1.8618e-03,  7.7321e-05,  3.1911e-03,\n",
      "        -1.4466e-03,  2.5548e-03,  5.1397e-03, -5.2562e-03, -1.6989e-04,\n",
      "        -4.4568e-03,  2.0568e-04,  8.5149e-04, -2.9727e-03, -5.5090e-03,\n",
      "        -6.0715e-04,  9.6382e-04, -2.2831e-03, -3.1617e-03,  4.9314e-05,\n",
      "        -4.8019e-04,  1.8042e-03, -9.9313e-04,  1.4254e-03, -2.6002e-03,\n",
      "        -8.3970e-04, -1.5768e-03, -3.4076e-03, -1.7142e-03,  1.3603e-03,\n",
      "        -4.5490e-03, -7.9453e-04,  4.1641e-03,  2.7365e-04, -4.7173e-03,\n",
      "        -7.5444e-03,  7.2023e-04,  7.9542e-05,  6.3657e-04,  3.8671e-03,\n",
      "        -1.2085e-03,  3.6280e-04,  3.8161e-03, -1.6286e-03, -3.4024e-03,\n",
      "        -3.0721e-03, -2.9780e-04, -3.3991e-03, -5.9046e-04, -7.3909e-03,\n",
      "        -5.2430e-03, -3.5639e-03,  1.6975e-03, -3.2647e-03,  6.7788e-03,\n",
      "        -2.4947e-03,  1.5416e-03, -3.3292e-03, -3.0228e-03, -9.8930e-04,\n",
      "         1.4933e-03,  3.9350e-03,  4.1169e-04, -3.9097e-04, -5.0648e-03,\n",
      "         1.0554e-03,  1.3241e-03, -2.2255e-03, -8.1071e-04, -1.1261e-02,\n",
      "         2.1904e-03,  1.8624e-03, -5.1610e-03, -3.5440e-03, -5.3605e-03,\n",
      "        -1.0354e-03, -1.5580e-03, -7.1969e-04,  1.1910e-03,  1.2342e-03,\n",
      "         3.8129e-04,  2.7870e-03, -1.1266e-03, -1.8378e-04, -7.2694e-05,\n",
      "        -1.6538e-03, -2.3971e-03, -6.4830e-04, -2.6394e-03, -3.4730e-03,\n",
      "         1.8559e-04,  2.1946e-04,  2.6787e-03,  1.3092e-03, -1.4887e-03,\n",
      "         7.1707e-04,  2.6239e-03, -3.4134e-03, -4.6581e-05,  1.2652e-04,\n",
      "         4.1090e-04, -3.0049e-03,  2.1964e-04, -2.0999e-03, -6.7704e-03,\n",
      "         1.3335e-04,  9.3546e-04, -5.2558e-04,  4.3760e-03, -2.0119e-03,\n",
      "        -2.0501e-03, -1.6167e-03, -4.3322e-04, -3.2191e-03, -2.2262e-03,\n",
      "        -2.4022e-03, -1.9688e-03, -2.9082e-03, -5.4685e-04, -4.6468e-03,\n",
      "         2.1890e-04, -5.0107e-03, -6.1084e-03, -3.6964e-03, -1.0461e-03,\n",
      "        -2.5715e-03, -2.9123e-04, -2.0598e-03,  3.0253e-03, -2.8880e-03,\n",
      "        -3.4779e-03, -1.0338e-03, -1.4255e-03, -3.7129e-03, -2.6395e-03,\n",
      "         3.2141e-03,  2.2953e-04, -2.3554e-03, -1.4293e-03, -3.3403e-03,\n",
      "        -1.4042e-03, -3.7492e-03,  3.2799e-03, -1.9506e-03, -1.4898e-03,\n",
      "        -1.4523e-04, -1.6234e-03, -5.7960e-03,  2.4092e-03,  6.4597e-04,\n",
      "        -3.0229e-04, -3.0258e-03,  3.8961e-03, -1.2233e-03,  1.1620e-03,\n",
      "        -3.4036e-03, -1.6710e-03,  5.5795e-04,  1.6350e-03,  4.6687e-03,\n",
      "         1.7710e-03, -5.5135e-03, -3.1466e-03, -6.5117e-03, -7.9612e-04,\n",
      "         2.3448e-04,  5.8501e-04, -4.0343e-03,  1.1554e-03,  7.2897e-05,\n",
      "        -1.4563e-03,  1.6117e-03, -2.2644e-03, -1.2747e-03,  1.1074e-03,\n",
      "        -5.0732e-03, -4.1784e-03, -1.4885e-03,  5.4459e-04,  9.3931e-04,\n",
      "        -2.6248e-03,  1.3333e-03,  2.4338e-04, -1.2736e-03,  1.2208e-03,\n",
      "        -6.4039e-03, -2.4927e-03, -5.5107e-03, -1.2744e-03,  1.7046e-03,\n",
      "        -1.9181e-03, -2.2868e-03,  7.0612e-04, -4.2730e-03, -2.6367e-03,\n",
      "        -4.8484e-03, -3.6243e-03, -2.0568e-03, -1.2255e-03, -3.0583e-03,\n",
      "        -2.1762e-03,  1.3672e-03, -3.1047e-03, -8.3649e-04, -1.5356e-03,\n",
      "         3.6930e-04, -1.0465e-03, -2.2695e-03,  5.6690e-04, -6.7338e-03,\n",
      "        -1.3047e-03,  5.6456e-04,  1.8362e-03, -5.3234e-04,  1.0383e-03,\n",
      "        -1.1234e-03, -8.9780e-04,  4.1243e-03, -5.8607e-03, -7.7530e-03,\n",
      "         3.0475e-04, -2.6403e-04, -1.0686e-03,  8.8391e-04, -5.9838e-03,\n",
      "        -1.7127e-03,  4.6757e-04,  1.8480e-03, -4.9011e-04, -8.6854e-03,\n",
      "        -4.6619e-03, -4.4257e-03, -1.9729e-03, -4.6807e-03,  5.8881e-03,\n",
      "        -4.0826e-03, -3.9258e-04, -6.6570e-04,  6.9206e-04, -4.4066e-03,\n",
      "        -1.4236e-03,  1.8014e-03,  1.2518e-03, -1.5001e-03,  8.0850e-05,\n",
      "        -2.9893e-03, -1.2483e-03, -5.0502e-04,  2.7690e-04, -5.5576e-03,\n",
      "        -1.1104e-03, -8.7693e-04, -4.5395e-03, -5.2414e-03, -5.0033e-03,\n",
      "         7.8536e-04,  1.9684e-03,  3.1212e-03, -4.7536e-05,  5.9677e-04,\n",
      "         2.7059e-04, -4.2507e-03,  1.6220e-04, -9.5553e-04,  2.1936e-03,\n",
      "        -3.5238e-03, -8.0611e-03, -1.8425e-03, -9.8963e-04, -3.1483e-03,\n",
      "         1.3775e-03, -5.2206e-03, -1.4299e-03, -2.9921e-03, -3.8873e-03,\n",
      "         2.2628e-03, -4.4784e-03,  2.1094e-03,  1.5860e-04, -3.5736e-03,\n",
      "        -9.4428e-05,  2.6907e-04, -1.4111e-04,  2.3368e-03, -4.7888e-03,\n",
      "        -1.8117e-03, -2.8462e-03, -2.5164e-03,  1.4524e-03, -3.0438e-03,\n",
      "        -7.1564e-04, -1.1212e-03, -4.5245e-03,  2.7224e-03, -3.2643e-03,\n",
      "        -3.3484e-03, -2.1014e-03, -4.0555e-04, -4.2764e-03,  1.8816e-03,\n",
      "        -3.6875e-04, -2.2383e-03,  4.3712e-04,  2.7821e-03,  1.2087e-03,\n",
      "        -7.3596e-04,  7.4762e-04,  9.8294e-04,  4.8281e-03, -1.8068e-03,\n",
      "        -2.1212e-03, -6.3890e-03, -1.0705e-03, -1.5538e-03, -1.8268e-04,\n",
      "         3.5767e-03, -1.9818e-03, -3.3654e-04,  3.1377e-03, -2.7350e-04,\n",
      "         2.7319e-04, -6.5512e-04,  8.7969e-04,  2.9948e-03, -3.9047e-03,\n",
      "         9.0044e-05, -6.9892e-03,  1.1785e-03, -2.3584e-03,  1.2679e-03,\n",
      "        -4.8588e-03,  1.1226e-03, -2.2371e-03, -1.0548e-03, -1.8241e-03,\n",
      "         7.7418e-04, -6.6703e-04, -4.8159e-04, -5.5516e-03, -1.0331e-03,\n",
      "        -4.4707e-04, -1.7619e-03,  4.5734e-04, -7.8580e-03, -2.3949e-03,\n",
      "         6.3274e-04, -2.0808e-03, -1.2614e-03,  1.7097e-03,  4.6816e-04,\n",
      "        -1.5912e-03, -1.6174e-03, -4.0225e-03,  1.3842e-03, -5.9452e-03,\n",
      "        -1.7079e-03,  2.6962e-03, -1.5346e-03, -1.2784e-03,  3.4004e-03,\n",
      "        -1.1536e-03,  4.3878e-03, -3.8110e-03, -7.5826e-04,  1.5803e-04,\n",
      "         1.6328e-04,  9.9094e-04,  1.7328e-03,  6.8592e-04, -4.8881e-03,\n",
      "        -1.0540e-03, -8.4422e-04,  1.2314e-03, -4.5988e-04, -1.7878e-03,\n",
      "        -2.8571e-03,  1.8870e-03, -9.4482e-04, -8.9390e-04,  1.8705e-03,\n",
      "         6.0806e-03,  3.2188e-03,  2.8141e-03, -1.3824e-03, -7.0018e-04,\n",
      "         6.6876e-03, -2.9852e-05,  5.1713e-03, -1.3113e-03,  1.2824e-03,\n",
      "        -6.0068e-04, -2.6640e-03, -1.5583e-03, -1.2709e-03, -6.2118e-04,\n",
      "         2.0809e-05,  7.4964e-05,  3.3662e-03, -1.7212e-03,  2.1430e-03,\n",
      "         1.7075e-05,  1.0603e-03, -3.4611e-03,  1.1727e-03, -2.8053e-03,\n",
      "        -2.0186e-03, -3.2800e-03], device='cuda:0', requires_grad=True))\n",
      "('7.2.bn2.weight', Parameter containing:\n",
      "tensor([0.9998, 0.9994, 1.0003, 1.0004, 1.0018, 0.9961, 0.9972, 1.0031, 1.0021,\n",
      "        0.9999, 1.0019, 1.0015, 0.9980, 1.0018, 0.9997, 1.0016, 1.0031, 1.0019,\n",
      "        1.0004, 0.9990, 1.0016, 1.0033, 0.9991, 1.0025, 1.0012, 1.0090, 0.9994,\n",
      "        1.0028, 0.9978, 1.0011, 1.0007, 0.9975, 0.9987, 1.0010, 0.9947, 0.9992,\n",
      "        0.9967, 1.0001, 0.9968, 0.9999, 0.9981, 0.9980, 0.9972, 1.0000, 1.0135,\n",
      "        0.9985, 0.9989, 1.0014, 1.0019, 0.9957, 1.0048, 0.9980, 1.0012, 0.9979,\n",
      "        0.9985, 1.0000, 1.0045, 1.0006, 1.0012, 0.9989, 0.9985, 0.9956, 0.9977,\n",
      "        1.0010, 1.0013, 1.0015, 0.9996, 1.0199, 1.0049, 1.0068, 0.9981, 1.0011,\n",
      "        1.0049, 1.0048, 1.0001, 0.9986, 0.9994, 0.9997, 0.9984, 0.9989, 0.9999,\n",
      "        1.0007, 1.0020, 1.0042, 0.9981, 1.0002, 1.0051, 0.9988, 1.0006, 0.9969,\n",
      "        0.9987, 1.0007, 1.0037, 1.0115, 0.9986, 0.9987, 1.0005, 0.9989, 1.0002,\n",
      "        1.0016, 0.9963, 0.9977, 1.0020, 0.9972, 0.9966, 1.0055, 0.9970, 0.9996,\n",
      "        1.0069, 0.9984, 0.9952, 1.0036, 1.0040, 0.9973, 0.9990, 0.9975, 0.9973,\n",
      "        1.0011, 0.9983, 0.9988, 0.9995, 1.0002, 0.9973, 0.9999, 1.0028, 0.9991,\n",
      "        0.9981, 1.0053, 0.9998, 0.9982, 1.0005, 1.0001, 0.9989, 0.9996, 1.0005,\n",
      "        1.0030, 1.0051, 0.9990, 1.0036, 0.9989, 0.9983, 0.9989, 0.9991, 0.9969,\n",
      "        1.0010, 1.0003, 1.0035, 0.9985, 0.9962, 1.0000, 0.9995, 1.0006, 0.9983,\n",
      "        1.0078, 0.9981, 0.9964, 0.9967, 1.0033, 0.9984, 0.9994, 1.0009, 1.0006,\n",
      "        0.9980, 1.0000, 0.9980, 1.0006, 0.9940, 0.9986, 0.9992, 1.0020, 1.0062,\n",
      "        0.9979, 1.0027, 0.9942, 0.9992, 0.9991, 0.9992, 1.0000, 1.0004, 0.9998,\n",
      "        0.9990, 0.9979, 0.9997, 1.0047, 1.0040, 1.0013, 0.9978, 0.9986, 0.9968,\n",
      "        0.9972, 0.9982, 1.0017, 0.9972, 0.9979, 0.9990, 0.9983, 0.9975, 1.0029,\n",
      "        0.9959, 0.9969, 1.0020, 1.0004, 1.0005, 1.0010, 1.0002, 0.9969, 1.0045,\n",
      "        1.0114, 1.0073, 1.0008, 0.9987, 1.0000, 1.0023, 1.0031, 0.9927, 0.9988,\n",
      "        1.0046, 1.0029, 1.0003, 0.9994, 1.0004, 0.9985, 1.0004, 0.9981, 0.9977,\n",
      "        0.9982, 1.0030, 1.0025, 0.9994, 0.9986, 0.9987, 1.0061, 0.9991, 0.9960,\n",
      "        1.0043, 1.0008, 1.0023, 1.0008, 0.9995, 1.0002, 0.9995, 1.0023, 1.0055,\n",
      "        1.0000, 0.9973, 1.0025, 0.9956, 1.0017, 0.9990, 1.0037, 1.0000, 0.9978,\n",
      "        1.0009, 1.0038, 0.9961, 1.0008, 1.0016, 0.9987, 0.9987, 1.0040, 0.9984,\n",
      "        1.0050, 0.9971, 1.0024, 0.9993, 0.9979, 0.9994, 0.9974, 0.9976, 1.0009,\n",
      "        1.0072, 0.9993, 0.9993, 1.0016, 1.0171, 1.0012, 0.9990, 1.0043, 1.0011,\n",
      "        1.0010, 0.9977, 1.0003, 0.9991, 0.9990, 1.0023, 1.0045, 1.0008, 1.0011,\n",
      "        0.9958, 0.9970, 1.0023, 1.0021, 1.0003, 0.9995, 0.9983, 1.0019, 0.9958,\n",
      "        0.9975, 0.9962, 0.9965, 1.0018, 0.9983, 0.9997, 0.9994, 1.0039, 0.9978,\n",
      "        1.0012, 1.0010, 0.9995, 1.0007, 0.9990, 1.0019, 0.9978, 1.0005, 0.9965,\n",
      "        0.9985, 0.9973, 0.9992, 0.9994, 0.9958, 0.9975, 1.0039, 1.0022, 0.9995,\n",
      "        1.0000, 0.9995, 0.9975, 1.0011, 0.9972, 1.0012, 0.9996, 1.0004, 0.9980,\n",
      "        0.9991, 0.9969, 0.9996, 0.9971, 1.0032, 0.9972, 0.9948, 0.9968, 0.9980,\n",
      "        1.0012, 1.0002, 0.9985, 1.0056, 1.0038, 0.9982, 0.9987, 1.0004, 0.9997,\n",
      "        1.0001, 0.9996, 0.9997, 0.9971, 1.0007, 1.0023, 0.9984, 0.9993, 1.0022,\n",
      "        0.9988, 0.9995, 1.0011, 1.0001, 1.0020, 0.9999, 0.9965, 0.9978, 0.9991,\n",
      "        1.0010, 1.0038, 1.0046, 0.9996, 0.9984, 0.9980, 0.9994, 1.0019, 1.0010,\n",
      "        0.9974, 1.0058, 0.9973, 1.0066, 0.9991, 1.0001, 1.0004, 1.0010, 0.9981,\n",
      "        0.9988, 0.9970, 0.9987, 0.9994, 0.9977, 0.9976, 0.9996, 1.0021, 0.9969,\n",
      "        0.9983, 0.9962, 0.9968, 0.9982, 1.0083, 0.9973, 1.0001, 0.9972, 0.9990,\n",
      "        0.9967, 1.0034, 0.9988, 0.9991, 0.9998, 0.9991, 0.9978, 0.9965, 0.9993,\n",
      "        0.9951, 1.0087, 1.0011, 0.9996, 0.9958, 0.9997, 0.9985, 0.9970, 0.9977,\n",
      "        1.0000, 0.9944, 1.0007, 0.9986, 0.9990, 1.0101, 0.9972, 1.0041, 0.9973,\n",
      "        0.9978, 0.9967, 1.0007, 0.9998, 0.9976, 1.0003, 1.0006, 0.9996, 0.9992,\n",
      "        0.9977, 0.9964, 1.0003, 0.9973, 1.0013, 0.9998, 0.9965, 1.0018, 1.0080,\n",
      "        0.9990, 0.9975, 0.9988, 1.0000, 0.9993, 0.9987, 0.9981, 0.9988, 0.9971,\n",
      "        0.9997, 1.0015, 0.9973, 0.9987, 1.0013, 0.9983, 1.0001, 0.9981, 1.0008,\n",
      "        0.9986, 1.0023, 1.0004, 1.0007, 1.0034, 1.0032, 0.9974, 1.0007, 0.9963,\n",
      "        1.0018, 1.0021, 1.0000, 1.0025, 0.9949, 1.0003, 1.0001, 1.0016, 0.9993,\n",
      "        0.9980, 0.9979, 1.0017, 0.9963, 0.9969, 0.9966, 0.9969, 1.0021, 0.9981,\n",
      "        0.9968, 0.9987, 0.9976, 1.0027, 0.9994, 1.0010, 1.0046, 1.0006, 0.9990,\n",
      "        0.9976, 0.9972, 0.9985, 0.9986, 1.0002, 1.0013, 1.0010, 0.9997],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('7.2.bn2.bias', Parameter containing:\n",
      "tensor([ 2.1373e-04,  1.8015e-03,  2.7044e-04,  3.8905e-03,  1.5353e-03,\n",
      "        -2.1840e-03, -1.0193e-03,  4.7355e-03,  8.6573e-03,  2.3823e-03,\n",
      "        -1.6026e-03,  1.5685e-03, -1.8603e-03,  1.1761e-03,  2.1441e-04,\n",
      "        -2.4375e-03,  1.5813e-02,  1.1999e-03, -4.9654e-03, -3.8625e-04,\n",
      "         2.5995e-03,  5.3459e-04,  1.7776e-03,  7.2475e-03,  1.6104e-03,\n",
      "         7.3135e-03,  1.3616e-03,  9.5006e-04, -6.1326e-03, -1.0125e-03,\n",
      "        -5.8449e-04, -2.1074e-03,  2.3312e-04,  4.7602e-03, -2.5344e-03,\n",
      "        -6.2604e-04, -4.6759e-04, -3.0593e-04, -3.6392e-03,  8.7016e-04,\n",
      "        -3.7307e-03,  3.0059e-04,  8.1468e-04,  1.9071e-04, -7.0827e-03,\n",
      "         3.4624e-04,  7.6164e-04,  3.0175e-04,  6.4782e-03, -2.0384e-03,\n",
      "        -9.1092e-03, -9.7099e-05, -1.3017e-03, -1.2188e-03,  1.3531e-03,\n",
      "         2.3909e-03, -1.6887e-03,  1.0284e-02,  1.2966e-03, -2.3329e-03,\n",
      "         1.1887e-03, -2.6545e-03, -8.1130e-04, -9.4232e-05,  3.9342e-03,\n",
      "         3.0593e-03, -1.9943e-03,  2.1412e-02,  5.5055e-03, -4.5634e-03,\n",
      "        -2.1703e-03,  5.4803e-03,  8.0424e-03, -2.4288e-03, -2.2610e-03,\n",
      "         7.9531e-04,  3.7620e-03,  1.0587e-03, -1.5596e-03,  4.3944e-04,\n",
      "        -2.7586e-03,  9.1461e-04, -7.1409e-04,  5.1850e-03, -1.8080e-03,\n",
      "         1.0745e-03,  4.9111e-04, -1.3942e-03, -4.2872e-04, -4.3374e-03,\n",
      "         9.1805e-04,  3.1248e-04, -7.5461e-03,  9.1277e-03, -5.8259e-04,\n",
      "        -1.2492e-03,  7.6130e-04,  1.6842e-04, -1.1987e-03,  5.8904e-04,\n",
      "        -2.8658e-03,  4.9472e-05,  8.0634e-03, -1.5033e-03, -4.7063e-03,\n",
      "         6.2859e-03, -3.3710e-03, -9.1609e-04, -4.9717e-04,  4.8199e-04,\n",
      "        -3.5121e-03,  2.5222e-03,  2.4210e-03, -2.3160e-04, -1.1958e-03,\n",
      "        -3.8863e-03, -1.1905e-03,  4.6850e-03, -8.1964e-04, -9.6144e-04,\n",
      "         3.7257e-05,  5.7170e-04, -1.5529e-03, -4.4648e-03, -2.7970e-03,\n",
      "         7.4168e-05, -1.8805e-03,  8.6767e-03, -5.6262e-06,  1.8745e-03,\n",
      "        -4.8018e-04, -9.8174e-04,  1.1964e-03, -1.9372e-03,  1.2935e-03,\n",
      "        -3.8395e-04, -5.1356e-03,  3.7529e-04,  1.8775e-03, -9.3435e-04,\n",
      "        -2.2336e-03,  2.6206e-03, -3.1491e-03, -4.8203e-04, -1.4941e-03,\n",
      "         3.7342e-04, -6.4856e-03, -1.4183e-03, -3.8950e-03,  7.3700e-04,\n",
      "        -3.9552e-05,  2.0601e-03, -1.2762e-03,  5.4884e-03, -2.3501e-03,\n",
      "        -3.3122e-03, -3.0035e-03,  9.1498e-04, -8.7439e-03, -3.3445e-03,\n",
      "         6.4369e-04,  2.1399e-03,  1.1795e-03, -1.2087e-03, -3.3161e-03,\n",
      "        -3.9407e-03, -1.7839e-03, -3.7974e-04, -3.1723e-04, -2.6979e-03,\n",
      "        -4.6753e-03, -2.4287e-03,  1.7592e-03, -4.9386e-03, -2.4490e-03,\n",
      "         2.8537e-04,  1.5949e-03, -2.2474e-03, -3.9937e-04, -8.5267e-05,\n",
      "         1.6007e-03,  2.2694e-03, -1.9335e-03, -3.6931e-03,  2.0235e-04,\n",
      "         1.0074e-03, -5.9199e-04, -3.4938e-03, -2.3295e-03, -4.9293e-04,\n",
      "         4.2686e-04,  9.6339e-04, -3.5438e-03, -9.0919e-04, -1.6185e-03,\n",
      "        -2.6934e-03, -2.9946e-03, -6.4491e-03, -1.1917e-03, -2.0242e-03,\n",
      "         2.0643e-03, -1.0615e-03,  1.8576e-03,  1.3316e-04,  1.0444e-03,\n",
      "        -3.1879e-03,  2.3677e-03,  1.3500e-02, -1.1466e-02, -1.2093e-04,\n",
      "        -5.1284e-04,  1.6687e-04,  2.6044e-03, -1.6842e-03, -1.5584e-03,\n",
      "        -1.0422e-03,  6.4922e-03, -1.7212e-03, -4.3934e-03, -1.5251e-03,\n",
      "         7.9067e-04, -1.1477e-04, -3.5041e-03, -2.5789e-03, -3.7633e-03,\n",
      "        -5.7377e-04,  1.1799e-03,  3.2580e-03,  1.6585e-04,  1.5016e-03,\n",
      "        -4.5112e-03,  7.2029e-03,  8.4486e-04, -3.6347e-03,  5.4657e-03,\n",
      "        -5.7349e-03, -6.2873e-03, -6.8371e-03,  1.5879e-03, -9.7546e-04,\n",
      "         3.1369e-03,  6.7203e-03,  6.8671e-03, -2.0254e-03, -6.0101e-03,\n",
      "         4.0795e-03, -4.9726e-03,  2.3738e-03,  2.0298e-03,  3.7635e-03,\n",
      "         8.6915e-05, -1.5101e-03, -1.7859e-04, -8.7879e-03, -3.9535e-03,\n",
      "         3.0323e-03, -2.1840e-03, -7.7624e-04, -1.7233e-03,  6.3209e-03,\n",
      "         2.8634e-05,  6.1586e-03, -2.6773e-03,  4.9470e-03, -4.5149e-03,\n",
      "        -5.8179e-04,  2.6866e-03, -1.0626e-03, -2.4304e-03,  3.1788e-03,\n",
      "        -3.0144e-03,  1.0146e-03, -4.4233e-04,  3.5431e-03,  1.3727e-02,\n",
      "         2.1784e-03,  1.7854e-03, -3.5617e-03, -8.6976e-04,  1.3139e-03,\n",
      "        -3.1808e-04,  1.1858e-03,  6.2049e-04,  1.3485e-04,  2.7865e-03,\n",
      "         6.8924e-03,  2.6121e-03, -4.0621e-03, -2.5885e-03,  4.6334e-03,\n",
      "        -5.9243e-05,  1.8760e-03, -1.7592e-04, -5.6996e-04, -1.4974e-04,\n",
      "        -3.6519e-03, -3.0429e-03, -1.3797e-03, -4.1712e-03, -4.2466e-03,\n",
      "         3.8661e-03, -1.8473e-03,  7.7767e-03,  1.8290e-03, -8.9219e-04,\n",
      "        -4.8517e-03, -1.7713e-03, -2.4534e-04, -2.9128e-03,  1.7380e-03,\n",
      "        -1.3268e-03, -4.2670e-03, -1.4472e-03, -1.6208e-03, -1.9616e-03,\n",
      "         1.0029e-03, -1.3944e-03, -1.4997e-03,  4.5544e-04, -2.1050e-03,\n",
      "        -1.2957e-03,  2.1549e-03,  1.1451e-03, -1.6308e-03, -2.9085e-03,\n",
      "        -1.0193e-03, -1.4470e-03,  3.3191e-04, -1.4827e-03,  3.9183e-03,\n",
      "        -1.7527e-03, -1.2313e-04, -3.1522e-04, -5.5400e-03, -1.0607e-03,\n",
      "         7.2155e-05, -1.0166e-03,  5.0703e-03,  1.2589e-05,  4.9528e-03,\n",
      "        -1.3887e-03, -5.3632e-03, -1.3708e-03,  1.3692e-03, -1.1459e-03,\n",
      "         7.6066e-03,  5.0420e-03, -1.7703e-03, -2.9761e-05, -3.5552e-03,\n",
      "         1.4680e-03, -5.5832e-03, -6.3571e-03, -6.1394e-04, -1.2078e-03,\n",
      "         6.1421e-04, -4.8458e-03, -8.0727e-04, -2.4448e-04,  4.5491e-03,\n",
      "        -3.3916e-04,  1.8900e-03,  7.7484e-04,  8.9558e-04,  1.2517e-02,\n",
      "         1.9645e-03, -1.7307e-03,  9.9729e-04, -2.4255e-04,  2.3854e-03,\n",
      "         2.6590e-03,  9.5031e-03, -8.5478e-04,  6.5930e-04,  2.2073e-04,\n",
      "         4.5116e-05,  1.8517e-04,  1.9719e-04,  7.0414e-04, -2.9476e-03,\n",
      "         1.2437e-03,  4.7680e-04, -1.7473e-03, -4.4797e-03, -1.3683e-03,\n",
      "         4.6594e-04, -5.9159e-03, -1.4464e-03, -8.6500e-04,  2.0335e-03,\n",
      "        -1.1371e-03, -3.3891e-03, -1.0450e-03, -2.3994e-03,  2.3111e-03,\n",
      "        -2.1145e-03,  5.0842e-04, -2.9648e-03, -5.9302e-04,  3.0472e-03,\n",
      "        -1.2536e-02, -3.2938e-03, -6.4999e-04, -1.9272e-03, -1.3251e-03,\n",
      "        -6.1076e-04, -6.1722e-04, -1.2216e-03, -5.8932e-04,  3.0354e-03,\n",
      "         5.5278e-04, -1.1019e-03, -5.3828e-03,  1.4475e-04, -1.3675e-03,\n",
      "        -8.7737e-03,  1.7316e-03,  1.1012e-03, -5.1157e-03,  1.2628e-03,\n",
      "        -5.9312e-04, -3.0738e-03, -2.5295e-03, -4.2554e-03, -1.7487e-03,\n",
      "        -2.6157e-04, -1.4462e-04, -1.7105e-03,  1.7915e-02, -3.2295e-03,\n",
      "         2.1742e-03, -2.3130e-03, -1.9943e-03, -2.0958e-03, -1.3185e-04,\n",
      "        -4.0201e-04, -3.3846e-03, -1.1261e-03, -2.1174e-04,  9.1474e-04,\n",
      "         2.8880e-04, -1.5169e-03, -1.7812e-03,  3.1081e-04, -1.2643e-03,\n",
      "         3.8304e-03, -8.2420e-04, -2.3421e-03,  1.8928e-03, -1.3039e-02,\n",
      "        -3.4776e-03, -2.4071e-03, -1.4023e-03, -5.4868e-04,  8.6359e-04,\n",
      "        -1.9480e-03,  6.1361e-05, -9.7454e-04, -2.4450e-03,  2.6991e-03,\n",
      "         4.6280e-03, -1.7504e-03, -1.4053e-04,  9.2360e-04, -4.4003e-03,\n",
      "        -1.0153e-02, -1.2031e-03, -2.0635e-03, -1.7403e-03, -9.3778e-03,\n",
      "         3.9373e-04,  3.7018e-04,  5.2715e-03,  2.8993e-03, -4.0399e-04,\n",
      "        -4.0889e-03, -1.3988e-03,  1.9453e-03,  3.4676e-03, -9.1990e-07,\n",
      "         2.7965e-03,  2.0520e-04, -5.8877e-03, -8.6483e-04, -2.2229e-03,\n",
      "        -6.1674e-04, -4.4297e-04, -2.1668e-03,  1.5441e-03, -1.6465e-03,\n",
      "        -4.1622e-03, -1.9287e-03, -2.0649e-03,  2.0342e-04, -2.8908e-03,\n",
      "        -5.5748e-03, -5.3151e-04, -3.5051e-03,  5.5691e-03, -1.6850e-03,\n",
      "         9.2573e-04, -8.5776e-03,  4.3265e-03,  2.8843e-03, -1.1156e-03,\n",
      "        -2.7115e-03,  1.7441e-03,  7.1483e-04, -8.0828e-03, -1.2688e-03,\n",
      "        -4.7206e-04, -2.8243e-04], device='cuda:0', requires_grad=True))\n",
      "('7.2.bn3.weight', Parameter containing:\n",
      "tensor([1.0040, 1.0008, 1.0014,  ..., 0.9996, 0.9995, 0.9998], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('7.2.bn3.bias', Parameter containing:\n",
      "tensor([ 0.0004, -0.0003,  0.0010,  ..., -0.0007, -0.0017,  0.0007],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.0.weight', Parameter containing:\n",
      "tensor([[-0.0470, -0.0046,  0.0184,  ..., -0.0126,  0.0192, -0.0041],\n",
      "        [ 0.0002, -0.0263, -0.0248,  ..., -0.0034, -0.0260,  0.0272],\n",
      "        [-0.0040,  0.0060,  0.0144,  ..., -0.0243,  0.0070,  0.0041],\n",
      "        ...,\n",
      "        [-0.0036,  0.0134, -0.0130,  ...,  0.0201,  0.0224,  0.0282],\n",
      "        [-0.0028,  0.0246,  0.0180,  ...,  0.0141,  0.0054,  0.0263],\n",
      "        [-0.0242,  0.0091,  0.0186,  ...,  0.0228,  0.0239, -0.0007]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.0.bias', Parameter containing:\n",
      "tensor([-0.0125, -0.0068,  0.0109,  ...,  0.0041, -0.0110,  0.0026],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.2.weight', Parameter containing:\n",
      "tensor([1.0000, 1.0007, 1.0032,  ..., 1.0010, 1.0003, 1.0017], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('10.2.bias', Parameter containing:\n",
      "tensor([-0.0020, -0.0031, -0.0112,  ...,  0.0016, -0.0018,  0.0042],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.3.weight', Parameter containing:\n",
      "tensor([[ 0.0099,  0.0025,  0.0130,  ...,  0.0161,  0.0155,  0.0341],\n",
      "        [-0.0113, -0.0335,  0.0040,  ...,  0.0122,  0.0030, -0.0138],\n",
      "        [ 0.0256,  0.0005,  0.0129,  ...,  0.0362, -0.0168,  0.0067],\n",
      "        ...,\n",
      "        [ 0.0206,  0.0287, -0.0144,  ...,  0.0197, -0.0151,  0.0170],\n",
      "        [ 0.0096,  0.0074, -0.0212,  ...,  0.0349, -0.0081,  0.0078],\n",
      "        [ 0.0073, -0.0310, -0.0052,  ...,  0.0072,  0.0153,  0.0244]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.3.bias', Parameter containing:\n",
      "tensor([ 0.0036, -0.0099, -0.0160,  ...,  0.0010, -0.0043, -0.0064],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.5.weight', Parameter containing:\n",
      "tensor([0.9954, 1.0018, 1.0111,  ..., 1.0087, 0.9958, 0.9882], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('10.5.bias', Parameter containing:\n",
      "tensor([-0.0304, -0.1153, -0.1434,  ..., -0.0682, -0.0935, -0.0275],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.6.weight', Parameter containing:\n",
      "tensor([[-0.0033, -0.0109,  0.0573,  ..., -0.0311,  0.0563, -0.0089],\n",
      "        [-0.0028,  0.0027, -0.0464,  ..., -0.0471,  0.0628,  0.0476],\n",
      "        [ 0.0658,  0.0019, -0.0236,  ..., -0.0337, -0.0512,  0.0411],\n",
      "        ...,\n",
      "        [-0.0503,  0.0463,  0.0279,  ..., -0.0005, -0.0183, -0.0337],\n",
      "        [ 0.0498,  0.0775,  0.0023,  ...,  0.0800, -0.0098,  0.0850],\n",
      "        [ 0.0442,  0.0089, -0.0154,  ...,  0.0683, -0.0056,  0.0095]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.6.bias', Parameter containing:\n",
      "tensor([-0.0243, -0.0263, -0.1144,  0.0889,  0.0832,  0.1247,  0.0242,  0.0088,\n",
      "        -0.0026,  0.0030, -0.0578, -0.0273,  0.0035, -0.0319, -0.0193,  0.0351,\n",
      "        -0.0212,  0.0512, -0.0293, -0.0306, -0.0005, -0.1337,  0.1095,  0.0209,\n",
      "        -0.0672,  0.0123, -0.0047,  0.0114, -0.0614, -0.0223,  0.0251,  0.0137,\n",
      "        -0.0072, -0.0093, -0.0431, -0.0006, -0.0398,  0.0142, -0.0306,  0.0206,\n",
      "         0.0241, -0.1105, -0.0482, -0.0535,  0.0104,  0.0113, -0.1520, -0.0067,\n",
      "        -0.0253, -0.0305,  0.0158,  0.0384,  0.0055,  0.0427, -0.0017, -0.0008,\n",
      "         0.0997,  0.0357,  0.0040, -0.0918, -0.0163, -0.0367,  0.1272,  0.0338,\n",
      "         0.0617,  0.1065, -0.0133,  0.0085,  0.0158, -0.0754, -0.0180, -0.0014,\n",
      "        -0.0020,  0.0177, -0.0372, -0.1097, -0.1453, -0.0156, -0.1290,  0.0036,\n",
      "        -0.0044, -0.0604,  0.0261, -0.0459, -0.1135, -0.0808, -0.0459,  0.0122,\n",
      "        -0.0293, -0.0235,  0.0102, -0.0825, -0.0165, -0.1365,  0.0254, -0.0393,\n",
      "        -0.1412, -0.0891,  0.0131,  0.0039, -0.0176,  0.0918,  0.0097,  0.0359,\n",
      "         0.0173,  0.0040,  0.0061,  0.0149,  0.0139,  0.0223, -0.0223, -0.0176,\n",
      "        -0.0613, -0.0802, -0.0006, -0.0336, -0.1277,  0.0167,  0.0079,  0.0031,\n",
      "         0.0230,  0.0057, -0.1042, -0.0176, -0.0796, -0.0073, -0.0907, -0.0448,\n",
      "        -0.1745, -0.1041, -0.0721, -0.0989, -0.0094,  0.0171, -0.0441, -0.0568,\n",
      "        -0.0908,  0.0298, -0.1171, -0.1070,  0.0074,  0.0343,  0.1318, -0.0245,\n",
      "        -0.0403,  0.0112, -0.0827, -0.0364,  0.0072,  0.0076,  0.0152,  0.0026,\n",
      "        -0.1257, -0.0222,  0.0087, -0.0223,  0.0204, -0.0197, -0.1264, -0.0297,\n",
      "         0.0139,  0.0162, -0.0033,  0.0637, -0.0125, -0.0136, -0.0089,  0.0957,\n",
      "         0.0019, -0.0351, -0.0145,  0.0110, -0.0887, -0.0201, -0.0002, -0.0875,\n",
      "        -0.0227, -0.0051, -0.0060, -0.0263,  0.0201,  0.0092, -0.0240,  0.0368,\n",
      "         0.0567,  0.0239, -0.0958, -0.0238,  0.0076, -0.0071, -0.0002,  0.0197,\n",
      "         0.0221,  0.1469, -0.0160,  0.0242,  0.0165, -0.0467, -0.1052, -0.0173,\n",
      "         0.0202, -0.0193,  0.0352, -0.0282, -0.0492, -0.0652, -0.0224,  0.0300,\n",
      "        -0.0931,  0.0286, -0.0801, -0.1202,  0.0093,  0.0004,  0.0209, -0.0880,\n",
      "        -0.1078, -0.0041, -0.1076,  0.0075,  0.0105, -0.1004, -0.0679,  0.0136,\n",
      "        -0.0201, -0.0611, -0.0289, -0.0953, -0.0064,  0.0144, -0.0124, -0.0631,\n",
      "         0.0088, -0.0098, -0.0088, -0.0545, -0.0067,  0.0020, -0.0731, -0.0565,\n",
      "         0.1123, -0.0060,  0.0133, -0.0285, -0.0041,  0.0408, -0.0131,  0.0686,\n",
      "         0.0246,  0.0446, -0.0162, -0.0073, -0.0178, -0.0830, -0.1444, -0.1421],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.8.weight', Parameter containing:\n",
      "tensor([0.9590, 0.9153, 1.0453, 1.0177, 1.0281, 1.1040, 0.9435, 0.9631, 0.9989,\n",
      "        0.9405, 0.9947, 0.9242, 0.9364, 0.9633, 0.8947, 1.0019, 1.0276, 1.0402,\n",
      "        0.9096, 0.9352, 0.9264, 1.0707, 1.1307, 0.9543, 0.9637, 0.9296, 0.9255,\n",
      "        0.9743, 0.9751, 0.9497, 0.9606, 0.9086, 1.0627, 1.0565, 0.9300, 0.9333,\n",
      "        0.9196, 0.9698, 0.9696, 0.9321, 0.9182, 1.0156, 0.9332, 0.9968, 0.9570,\n",
      "        0.9209, 1.1082, 0.9232, 0.9187, 0.9410, 0.9216, 0.9438, 1.0017, 1.0235,\n",
      "        0.9395, 0.9371, 1.1365, 0.9513, 0.9183, 0.9961, 0.9319, 0.9404, 1.0769,\n",
      "        0.9573, 1.0251, 1.1400, 0.9607, 0.8986, 1.0121, 1.0254, 0.9155, 0.9204,\n",
      "        0.8980, 1.0036, 0.9841, 1.0556, 1.0549, 0.9193, 1.0361, 0.9670, 0.9839,\n",
      "        0.9547, 0.9647, 0.9676, 1.0211, 1.0003, 0.9716, 0.9522, 0.9270, 0.9438,\n",
      "        0.9232, 0.9670, 1.0621, 1.0977, 0.9306, 1.0052, 1.0861, 1.0244, 0.9568,\n",
      "        0.9314, 0.9466, 1.0624, 1.0012, 1.0623, 1.0357, 1.0378, 0.9259, 0.9352,\n",
      "        0.9719, 0.9079, 0.9206, 0.9198, 0.9506, 1.0232, 0.9215, 0.8839, 1.0702,\n",
      "        0.9799, 0.9719, 0.9300, 0.9131, 0.8968, 0.9898, 0.9234, 0.9787, 0.9377,\n",
      "        1.0093, 0.9316, 1.1386, 1.1034, 0.9688, 1.0469, 0.9338, 0.9290, 0.9709,\n",
      "        0.9240, 1.0159, 1.0514, 1.0122, 1.0995, 0.9976, 0.9370, 1.1469, 1.1768,\n",
      "        0.9291, 0.9565, 1.0251, 0.9224, 0.9630, 0.9661, 0.9360, 0.9386, 1.0662,\n",
      "        0.9380, 0.9466, 0.9225, 0.9258, 0.9516, 1.0751, 0.9675, 0.9531, 0.9523,\n",
      "        0.9705, 1.2400, 0.9176, 0.9322, 0.9371, 1.0685, 0.9342, 0.9304, 0.9384,\n",
      "        0.9341, 0.9993, 0.9499, 1.0036, 1.0194, 0.9570, 0.9320, 0.9282, 0.9875,\n",
      "        0.9094, 0.9307, 0.9144, 1.0044, 1.0267, 0.9569, 1.0298, 0.9526, 0.9601,\n",
      "        0.9502, 0.9525, 0.9301, 0.9131, 1.2064, 0.9397, 0.9693, 0.9382, 0.9401,\n",
      "        1.0164, 1.0240, 0.9583, 0.9191, 0.9424, 0.9313, 0.9572, 1.0051, 0.9215,\n",
      "        0.9078, 0.9898, 1.0018, 0.9695, 1.0820, 0.9377, 0.9662, 0.9974, 0.9774,\n",
      "        1.0268, 0.9961, 1.0158, 0.9817, 0.9551, 1.0103, 0.9704, 0.8901, 0.9259,\n",
      "        0.9682, 0.9632, 0.9974, 0.9261, 0.9354, 0.9475, 0.9674, 0.9275, 0.9364,\n",
      "        0.9408, 0.9519, 0.9371, 1.0570, 0.9834, 0.9498, 1.0926, 0.9296, 0.9666,\n",
      "        0.9544, 0.9502, 1.0442, 0.9515, 0.9962, 0.9381, 0.9802, 0.9686, 0.9083,\n",
      "        0.9344, 1.0413, 1.1401, 1.0591], device='cuda:0', requires_grad=True))\n",
      "('10.8.bias', Parameter containing:\n",
      "tensor([-2.9322e-02, -2.9961e-02, -2.8652e-01, -2.3002e-01, -2.2276e-01,\n",
      "        -3.5930e-01, -1.0057e-01,  9.1663e-02,  4.0789e-02, -6.4970e-02,\n",
      "        -1.6719e-01, -1.9288e-03,  2.6849e-02, -6.2469e-02, -4.4028e-02,\n",
      "         1.0692e-01,  4.2663e-02, -2.0446e-01, -3.1632e-01,  6.2056e-02,\n",
      "        -3.3322e-02, -4.5461e-01, -4.6264e-01, -9.0209e-02, -1.6073e-01,\n",
      "        -5.7891e-02, -6.8078e-02,  1.0007e-01, -1.9843e-01, -4.5552e-02,\n",
      "        -1.4976e-01,  7.6323e-03,  1.8777e-01,  4.4001e-02, -1.1708e-03,\n",
      "        -2.6508e-02, -1.7614e-01, -4.5300e-02, -1.4008e-01,  6.2170e-02,\n",
      "        -1.2331e-01, -2.8472e-01, -1.2800e-01, -2.1808e-01,  1.5218e-03,\n",
      "        -1.0151e-01, -4.9062e-01, -7.2303e-02, -1.3023e-01, -3.8161e-02,\n",
      "         5.6974e-02, -6.0744e-02, -7.5922e-02, -4.4020e-02,  1.8980e-01,\n",
      "        -8.9679e-02, -2.7108e-01,  7.0058e-03, -1.7688e-01, -1.9705e-01,\n",
      "        -1.6590e-01, -1.5641e-01, -4.5144e-01, -1.7457e-02, -2.3603e-01,\n",
      "        -5.4837e-01, -4.5474e-02,  3.2039e-02,  2.6661e-01, -3.4615e-01,\n",
      "         5.7992e-02,  8.8225e-02, -9.6452e-02, -1.5725e-01, -2.1393e-01,\n",
      "        -3.9171e-01, -2.8588e-01, -2.3912e-02, -3.4650e-01,  6.8262e-02,\n",
      "        -1.0904e-01, -1.3220e-01, -1.1173e-01, -1.4262e-01, -2.3994e-01,\n",
      "        -1.9635e-01, -2.8938e-01,  1.2293e-01, -1.0562e-01, -1.3318e-01,\n",
      "         2.5339e-01, -2.3077e-01, -4.4827e-03, -4.9057e-01, -1.3802e-02,\n",
      "         2.1408e-01, -4.2950e-01, -3.0014e-01,  1.4417e-01, -1.1625e-01,\n",
      "        -2.1775e-01, -3.7099e-01,  1.5261e-01,  9.4747e-04, -1.3679e-03,\n",
      "        -3.5205e-02, -2.5072e-01,  6.9790e-02,  4.6926e-02,  1.7136e-01,\n",
      "        -1.2873e-01, -5.3686e-02, -1.5242e-01, -3.0440e-01,  6.0441e-03,\n",
      "        -1.8043e-01, -4.1985e-01, -2.0734e-01,  3.1643e-02, -3.8061e-02,\n",
      "         1.9921e-02,  3.9238e-02, -2.7941e-01, -1.3225e-01, -4.1997e-01,\n",
      "         6.0355e-04, -2.4240e-01,  6.7461e-04, -5.3360e-01, -4.6506e-01,\n",
      "        -1.6867e-01, -3.3627e-01, -1.5727e-01,  2.4144e-02, -1.3755e-01,\n",
      "        -1.3071e-01, -2.2446e-01,  2.0328e-02, -3.2325e-01, -4.5061e-01,\n",
      "         6.2379e-02,  4.8917e-02, -6.4083e-01, -9.7402e-02, -8.3062e-02,\n",
      "        -5.4549e-02, -3.1271e-01, -2.4662e-01,  1.3359e-01, -5.3027e-02,\n",
      "         3.6722e-02,  8.7100e-03, -3.7885e-01, -6.5880e-02, -1.7736e-01,\n",
      "         2.3850e-02,  4.3914e-02, -1.2207e-01, -4.5554e-01, -1.2840e-01,\n",
      "        -6.1821e-02,  3.8592e-02,  7.1077e-02, -1.4206e-01, -9.2541e-02,\n",
      "        -4.2563e-02, -1.0702e-01, -2.4458e-01, -3.6547e-02, -8.8145e-02,\n",
      "        -1.7284e-01, -7.6189e-02, -2.2768e-01, -1.5244e-01, -4.9874e-02,\n",
      "        -2.3515e-01, -5.5547e-02,  2.5864e-02,  4.3027e-02, -2.2164e-01,\n",
      "         9.4900e-02,  9.4373e-02, -2.3003e-01, -1.4866e-01, -2.7701e-01,\n",
      "        -1.0040e-02, -2.9932e-01, -5.0405e-02,  2.1284e-02,  2.0258e-01,\n",
      "        -1.1839e-01,  1.3269e-01,  1.8621e-01, -6.9939e-01,  3.9187e-02,\n",
      "         3.7521e-02, -6.4503e-02, -1.2457e-01, -2.0076e-01,  1.0591e-01,\n",
      "        -6.6215e-02, -9.6544e-04, -6.8523e-03, -2.1485e-03, -1.4114e-02,\n",
      "        -1.9686e-01, -2.0682e-02,  4.5805e-02, -3.4655e-01,  3.5958e-02,\n",
      "        -1.6343e-01, -4.9657e-01, -8.5346e-02,  9.1213e-03,  1.2029e-01,\n",
      "        -1.7846e-01, -3.3309e-01,  8.1066e-02, -3.5745e-01,  2.8089e-02,\n",
      "         3.9884e-02, -2.5549e-01, -1.5367e-01, -1.8249e-01,  9.4269e-02,\n",
      "        -1.1401e-01, -5.6418e-02, -2.7661e-01,  1.6780e-01,  1.3759e-02,\n",
      "         2.2937e-01,  5.8549e-03,  1.1655e-01, -9.9180e-02,  1.0295e-03,\n",
      "        -1.6488e-01,  2.7217e-02,  2.7454e-03, -1.8904e-01, -2.7618e-01,\n",
      "        -4.6984e-01,  3.0176e-02,  9.7233e-03, -3.0438e-01,  1.2694e-02,\n",
      "        -2.5021e-01,  3.9956e-02, -2.0879e-01, -1.1936e-01, -7.8785e-02,\n",
      "        -5.4559e-02,  5.4081e-02,  2.7423e-02, -2.9306e-01, -5.4065e-01,\n",
      "        -3.7253e-01], device='cuda:0', requires_grad=True))\n",
      "('10.9.weight', Parameter containing:\n",
      "tensor([[ 0.0379,  0.1279, -0.1145,  ...,  0.0696, -0.1506, -0.1028],\n",
      "        [-0.0157,  0.1118, -0.1253,  ...,  0.0263, -0.0655, -0.1258],\n",
      "        [-0.1518,  0.0164,  0.0623,  ...,  0.0043,  0.1968,  0.2024],\n",
      "        ...,\n",
      "        [-0.1276, -0.0653,  0.2121,  ...,  0.1056,  0.3132,  0.1867],\n",
      "        [-0.0570, -0.0375,  0.0006,  ...,  0.1295,  0.1987, -0.0608],\n",
      "        [-0.0517,  0.1216,  0.0351,  ...,  0.2284,  0.1870,  0.0702]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.9.bias', Parameter containing:\n",
      "tensor([ 0.0085, -0.1063, -0.2468,  0.0336, -0.0780, -0.4778, -0.2102, -0.0369,\n",
      "         0.0452,  0.0181,  0.0237,  0.0217, -0.0489,  0.0044, -0.0023, -0.0539,\n",
      "        -0.0160, -0.0670,  0.0022, -0.5262,  0.0195, -0.3439,  0.1461,  0.0727,\n",
      "        -0.0305, -0.0770,  0.0183, -0.0623, -0.0749, -0.0145,  0.0415,  0.0927,\n",
      "        -0.3895, -0.0841, -0.1797, -0.0485, -0.2382, -0.0317, -0.0524, -0.0318,\n",
      "        -0.0910, -0.2401, -0.0819, -0.4337, -0.1854, -0.0518, -0.0596,  0.0442,\n",
      "        -0.0630,  0.0649, -0.0024, -0.0967, -0.0365, -0.1058,  0.0793, -0.0810,\n",
      "         0.0388, -0.1889, -0.1049, -0.0730, -0.0610, -0.2223, -0.1650, -0.3652],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.11.weight', Parameter containing:\n",
      "tensor([0.5148, 0.2989, 0.8755, 0.7921, 0.3490, 1.3796, 0.6278, 0.3205, 0.1058,\n",
      "        0.4603, 0.3972, 0.4598, 0.0415, 0.7174, 0.4693, 0.5326, 1.0233, 0.4385,\n",
      "        0.6884, 1.9146, 0.2247, 1.3036, 1.1520, 0.6037, 0.3638, 0.7200, 0.3432,\n",
      "        0.5231, 0.6627, 0.3955, 0.3373, 0.6438, 1.3961, 0.1233, 0.9775, 0.2702,\n",
      "        1.0135, 0.2777, 0.3504, 0.2908, 0.5394, 1.1290, 0.4291, 1.4833, 0.6725,\n",
      "        0.5236, 0.4345, 0.2771, 0.4559, 0.9915, 0.3277, 0.4608, 0.1587, 0.7435,\n",
      "        0.8365, 0.4244, 0.3081, 0.8334, 0.6167, 0.4308, 0.5124, 0.9210, 0.7788,\n",
      "        1.2620], device='cuda:0', requires_grad=True))\n",
      "('10.11.bias', Parameter containing:\n",
      "tensor([ 0.2292,  0.0288,  0.1572,  0.3158, -0.0471,  0.2480,  0.1156,  0.0933,\n",
      "         0.0118,  0.1908, -0.0752,  0.1512, -0.0078,  0.2718,  0.1975,  0.1381,\n",
      "        -0.0970,  0.1680, -0.1197,  0.3471,  0.0761,  0.2274,  0.3652,  0.0797,\n",
      "         0.0667,  0.3170,  0.1031,  0.1060,  0.1012, -0.0849, -0.0788,  0.2666,\n",
      "         0.2376,  0.0159,  0.1686,  0.0825,  0.1803,  0.0643,  0.1035, -0.0724,\n",
      "         0.0852,  0.1871,  0.0857,  0.2554,  0.1236, -0.1036,  0.1041,  0.0725,\n",
      "         0.0987, -0.1420,  0.0960,  0.0934, -0.0501,  0.1189, -0.2076,  0.1313,\n",
      "         0.1019,  0.1536,  0.1224,  0.0830,  0.2142,  0.1678,  0.1377,  0.2111],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.12.weight', Parameter containing:\n",
      "tensor([[ 0.2873, -0.0943, -0.3631,  0.4963, -0.2837, -0.5476, -0.2375,  0.2000,\n",
      "         -0.0443,  0.2458, -0.3337,  0.2591,  0.0156,  0.4459,  0.1806,  0.3680,\n",
      "         -0.8689,  0.2396, -0.5769, -0.7641,  0.1192, -0.5395,  0.8198,  0.4971,\n",
      "         -0.1539,  0.3727,  0.1972, -0.1931, -0.3288, -0.3173, -0.2758,  0.3758,\n",
      "         -0.5558, -0.0583, -0.4345,  0.1601, -0.4336, -0.0694,  0.1654, -0.2306,\n",
      "         -0.2642, -0.5100, -0.1245, -0.6549, -0.2740, -0.4303, -0.0949,  0.1746,\n",
      "         -0.1224, -0.8217,  0.1508, -0.1533, -0.1253, -0.3487, -0.6807,  0.2922,\n",
      "          0.2022, -0.3462, -0.2307, -0.1491,  0.3079, -0.3808, -0.3241, -0.4793]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('10.12.bias', Parameter containing:\n",
      "tensor([0.0838], device='cuda:0', requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for param in net.named_parameters():\n",
    "    # if param[0] in need_frozen_list:\n",
    "    #     param[1].requires_grad = False\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ebd495a-e8c1-4d26-9d18-d310d01b3b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:47:28.998706Z",
     "iopub.status.busy": "2023-11-05T14:47:28.998706Z",
     "iopub.status.idle": "2023-11-05T14:47:29.006260Z",
     "shell.execute_reply": "2023-11-05T14:47:29.005902Z",
     "shell.execute_reply.started": "2023-11-05T14:47:28.998706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (2): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (3): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Residual(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (4): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (5): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): Residual(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (7): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "      (conv4): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool1d(output_size=2)\n",
       "  (9): Flatten(start_dim=1, end_dim=-1)\n",
       "  (10): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3e75b9d-e935-46f7-91df-9dd611d10d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:47:47.308536Z",
     "iopub.status.busy": "2023-11-05T14:47:47.308536Z",
     "iopub.status.idle": "2023-11-05T14:47:47.324075Z",
     "shell.execute_reply": "2023-11-05T14:47:47.324075Z",
     "shell.execute_reply.started": "2023-11-05T14:47:47.308536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,))\n",
       "  (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0582175b-82a3-4fa0-8287-a0846ec6e0e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:49:00.432349Z",
     "iopub.status.busy": "2023-11-05T14:49:00.432349Z",
     "iopub.status.idle": "2023-11-05T14:49:00.476607Z",
     "shell.execute_reply": "2023-11-05T14:49:00.475557Z",
     "shell.execute_reply.started": "2023-11-05T14:49:00.432349Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "net[0].requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "503cae9c-65ef-4b84-b068-d806ed8f1a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:51:17.148414Z",
     "iopub.status.busy": "2023-11-05T14:51:17.148414Z",
     "iopub.status.idle": "2023-11-05T14:51:17.171810Z",
     "shell.execute_reply": "2023-11-05T14:51:17.171362Z",
     "shell.execute_reply.started": "2023-11-05T14:51:17.148414Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in net[0]:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c87c66ca-65ca-481e-a1eb-a133121b3b1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T14:51:17.648804Z",
     "iopub.status.busy": "2023-11-05T14:51:17.648804Z",
     "iopub.status.idle": "2023-11-05T14:51:17.664835Z",
     "shell.execute_reply": "2023-11-05T14:51:17.664835Z",
     "shell.execute_reply.started": "2023-11-05T14:51:17.648804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->name: 0.0.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 0.0.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 0.1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 0.1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv4.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.conv4.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.0.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.1.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 1.2.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv4.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.conv4.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.0.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.1.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.2.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 3.3.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv4.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.conv4.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.0.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.1.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.2.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.3.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.4.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 5.5.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv4.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.conv4.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.0.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.1.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.conv3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn1.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn1.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 7.2.bn3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.0.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.0.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.2.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.2.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.3.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.3.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.5.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.5.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.6.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.6.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.8.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.8.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.9.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.9.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.11.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.11.bias\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.12.weight\n",
      "-->grad_requirs: True\n",
      "===\n",
      "-->name: 10.12.bias\n",
      "-->grad_requirs: True\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "for name, parms in net.named_parameters():\t\n",
    "                print('-->name:', name)\n",
    "                # print('-->para:', parms)\n",
    "                print('-->grad_requirs:',parms.requires_grad)\n",
    "                # print('-->grad_value:',parms.grad)\n",
    "                print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c00dd-7f18-40ac-9c2e-ecb07d49e59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
