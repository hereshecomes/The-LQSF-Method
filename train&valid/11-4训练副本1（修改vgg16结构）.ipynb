{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e25e8fe-ec3a-4a94-8ebf-4c94a9bfa183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T14:38:21.960721Z",
     "iopub.status.busy": "2023-11-04T14:38:21.960721Z",
     "iopub.status.idle": "2023-11-04T14:38:53.555948Z",
     "shell.execute_reply": "2023-11-04T14:38:53.554948Z",
     "shell.execute_reply.started": "2023-11-04T14:38:21.960721Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib.jianji.code_csf import csf\n",
    "from lib.model.vgg16_bn import VGG16_BN\n",
    "from lib.model.vgg19_bn import VGG19_BN\n",
    "from lib.jianji.tool import *\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.utils.prune as prune\n",
    "from d2l import torch as d2l\n",
    "traindSet = csf(csv_path='original_train_set.pkl', mode='train')\n",
    "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=256, drop_last=True, shuffle=True)\n",
    "testset = csf(csv_path='test_valid_edited(30000).pkl', mode='valid')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152771d6-3406-401f-ad57-edee2285d4dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T14:39:21.654635Z",
     "iopub.status.busy": "2023-11-04T14:39:21.654635Z",
     "iopub.status.idle": "2023-11-04T14:39:21.665989Z",
     "shell.execute_reply": "2023-11-04T14:39:21.665446Z",
     "shell.execute_reply.started": "2023-11-04T14:39:21.654635Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold_value_list = [0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 , 0.65, 0.7 , \n",
    "                        0.75, 0.8 , 0.85, 0.9 , 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5e7e0f-0ca1-45b6-9e7f-e9239aefb1d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T05:37:26.094874Z",
     "iopub.status.busy": "2023-11-04T05:37:26.094874Z",
     "iopub.status.idle": "2023-11-04T05:50:45.650103Z",
     "shell.execute_reply": "2023-11-04T05:50:45.649064Z",
     "shell.execute_reply.started": "2023-11-04T05:37:26.094874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7001, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6554, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6338, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6069, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6203, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6030, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5946, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5481, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5942, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5442, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5703, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5561, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5648, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5675, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5839, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6274, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5705, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5654, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5812, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5628, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5526, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5470, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5763, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5477, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5456, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5470, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5566, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5699, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5448, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5629, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5504, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5355, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5116, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5679, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5447, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5349, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5428, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5294, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6684, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5590, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5766, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5525, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5932, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6001, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5538, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5560, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5160, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5111, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5530, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5635, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.6272702991452992\n",
      "0.1 0.6342147435897436\n",
      "0.15 0.637520032051282\n",
      "0.2 0.6401241987179487\n",
      "0.25 0.6422943376068376\n",
      "0.3 0.6445646367521367\n",
      "0.35 0.6470352564102564\n",
      "0.4 0.6483707264957265\n",
      "0.45 0.6474358974358975\n",
      "0.5 0.6388888888888888\n",
      "0.55 0.6268028846153846\n",
      "0.6 0.6053685897435898\n",
      "0.65 0.5733173076923077\n",
      "0.7 0.5458400106837606\n",
      "0.75 0.5209001068376068\n",
      "0.8 0.5062767094017094\n",
      "0.85 0.5\n",
      "0.9 0.5000333867521367\n",
      "0.95 0.49976629273504275\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "net = VGG16_BN()\n",
    "device = d2l.try_gpu()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "loss = nn.BCELoss()\n",
    "train_from_scratch(net, optimizer, loss, 3, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a1f8d8-2482-465c-a7bc-17961607e0e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T05:51:19.702112Z",
     "iopub.status.busy": "2023-11-04T05:51:19.702112Z",
     "iopub.status.idle": "2023-11-04T06:00:28.716540Z",
     "shell.execute_reply": "2023-11-04T06:00:28.716540Z",
     "shell.execute_reply.started": "2023-11-04T05:51:19.702112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4986, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5194, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5008, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5275, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4621, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4718, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4542, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4626, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4105, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4037, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3504, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3512, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3258, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2995, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3490, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2061, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2521, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2364, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2484, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2215, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2057, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1690, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1591, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2574, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2507, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2162, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1414, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1565, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1504, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2194, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1717, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2295, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.6406917735042735\n",
      "0.1 0.6543803418803419\n",
      "0.15 0.6608907585470085\n",
      "0.2 0.6653645833333334\n",
      "0.25 0.6670673076923077\n",
      "0.3 0.6682692307692307\n",
      "0.35 0.6694711538461539\n",
      "0.4 0.6698717948717948\n",
      "0.45 0.6697382478632479\n",
      "0.5 0.6697716346153846\n",
      "0.55 0.6698050213675214\n",
      "0.6 0.6699719551282052\n",
      "0.65 0.6691706730769231\n",
      "0.7 0.6684027777777778\n",
      "0.75 0.6669337606837606\n",
      "0.8 0.6653979700854701\n",
      "0.85 0.6639289529914529\n",
      "0.9 0.660690438034188\n",
      "0.95 0.6551482371794872\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "continue_train(net, optimizer, loss, 2, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179796e7-9800-4236-8e1c-a9d5b4cee0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:01:34.753727Z",
     "iopub.status.busy": "2023-11-04T06:01:34.753727Z",
     "iopub.status.idle": "2023-11-04T06:03:12.212828Z",
     "shell.execute_reply": "2023-11-04T06:03:12.212828Z",
     "shell.execute_reply.started": "2023-11-04T06:01:34.753727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0420, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0722, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0495, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0661, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcontinue_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m threshold_value_list:\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\tool.py:26\u001b[0m, in \u001b[0;36mcontinue_train\u001b[1;34m(net, optimizer, loss, num_epochs, train_iter, device)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     25\u001b[0m     net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_iter):\n\u001b[0;32m     27\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\code_csf.py:30\u001b[0m, in \u001b[0;36mcsf.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     28\u001b[0m feature \u001b[38;5;241m=\u001b[39m feature \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m     29\u001b[0m feature \u001b[38;5;241m=\u001b[39m feature[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m---> 30\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m  feature, label\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d136c26f-3125-4f5d-aff7-9235c36229a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:03:36.964144Z",
     "iopub.status.busy": "2023-11-04T06:03:36.964144Z",
     "iopub.status.idle": "2023-11-04T06:03:57.946518Z",
     "shell.execute_reply": "2023-11-04T06:03:57.946518Z",
     "shell.execute_reply.started": "2023-11-04T06:03:36.964144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.7001201923076923\n",
      "0.1 0.7042267628205128\n",
      "0.15 0.7054286858974359\n",
      "0.2 0.7065972222222222\n",
      "0.25 0.7071981837606838\n",
      "0.3 0.7073317307692307\n",
      "0.35 0.7077323717948718\n",
      "0.4 0.707832532051282\n",
      "0.45 0.7078659188034188\n",
      "0.5 0.7083333333333334\n",
      "0.55 0.7085002670940171\n",
      "0.6 0.7084334935897436\n",
      "0.65 0.7081997863247863\n",
      "0.7 0.7077991452991453\n",
      "0.75 0.7079326923076923\n",
      "0.8 0.7077991452991453\n",
      "0.85 0.7075988247863247\n",
      "0.9 0.7073317307692307\n",
      "0.95 0.7061298076923077\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231b0751-60dc-4934-bd68-2ef8e14938ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:04:52.358439Z",
     "iopub.status.busy": "2023-11-04T06:04:52.357392Z",
     "iopub.status.idle": "2023-11-04T06:09:32.532819Z",
     "shell.execute_reply": "2023-11-04T06:09:32.531797Z",
     "shell.execute_reply.started": "2023-11-04T06:04:52.358439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0441, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0325, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0095, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0127, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0039, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0481, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0109, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.6992521367521367\n",
      "0.1 0.7038595085470085\n",
      "0.15 0.7053619123931624\n",
      "0.2 0.7059962606837606\n",
      "0.25 0.706497061965812\n",
      "0.3 0.7063301282051282\n",
      "0.35 0.7072315705128205\n",
      "0.4 0.7072315705128205\n",
      "0.45 0.7075988247863247\n",
      "0.5 0.7076655982905983\n",
      "0.55 0.7076322115384616\n",
      "0.6 0.7078659188034188\n",
      "0.65 0.7081997863247863\n",
      "0.7 0.7083667200854701\n",
      "0.75 0.7085336538461539\n",
      "0.8 0.7085336538461539\n",
      "0.85 0.7080328525641025\n",
      "0.9 0.7076655982905983\n",
      "0.95 0.7073985042735043\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31eba80e-8982-4c8c-8b06-9ee45c945f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:10:05.963299Z",
     "iopub.status.busy": "2023-11-04T06:10:05.963299Z",
     "iopub.status.idle": "2023-11-04T06:12:36.764677Z",
     "shell.execute_reply": "2023-11-04T06:12:36.763651Z",
     "shell.execute_reply.started": "2023-11-04T06:10:05.963299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0106, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0087, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0527, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0077, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0122, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0106, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcontinue_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m threshold_value_list:\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\tool.py:29\u001b[0m, in \u001b[0;36mcontinue_train\u001b[1;34m(net, optimizer, loss, num_epochs, train_iter, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[0;32m     31\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\model\\vgg16_bn.py:71\u001b[0m, in \u001b[0;36mVGG16_BN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 71\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# x = self.avgpool(x)\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.002)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6551384a-6740-4238-ae67-2b5e53bcaa69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:12:44.722740Z",
     "iopub.status.busy": "2023-11-04T06:12:44.722740Z",
     "iopub.status.idle": "2023-11-04T06:13:05.594530Z",
     "shell.execute_reply": "2023-11-04T06:13:05.594530Z",
     "shell.execute_reply.started": "2023-11-04T06:12:44.722740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.7006877670940171\n",
      "0.1 0.7046274038461539\n",
      "0.15 0.7062967414529915\n",
      "0.2 0.7065972222222222\n",
      "0.25 0.7068309294871795\n",
      "0.3 0.7073651175213675\n",
      "0.35 0.7078659188034188\n",
      "0.4 0.7078993055555556\n",
      "0.45 0.7081330128205128\n",
      "0.5 0.7085670405982906\n",
      "0.55 0.7089676816239316\n",
      "0.6 0.7091346153846154\n",
      "0.65 0.7094017094017094\n",
      "0.7 0.7092681623931624\n",
      "0.75 0.7091346153846154\n",
      "0.8 0.7091346153846154\n",
      "0.85 0.7096354166666666\n",
      "0.9 0.7096354166666666\n",
      "0.95 0.7089342948717948\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d702ad-d5cf-4018-9255-03fc8d8b9bca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:14:18.910751Z",
     "iopub.status.busy": "2023-11-04T06:14:18.910751Z",
     "iopub.status.idle": "2023-11-04T06:14:19.201100Z",
     "shell.execute_reply": "2023-11-04T06:14:19.201100Z",
     "shell.execute_reply.started": "2023-11-04T06:14:18.910751Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'vgg_16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c84ad15-ff80-4754-a36b-62d12a126941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:14:36.329646Z",
     "iopub.status.busy": "2023-11-04T06:14:36.329646Z",
     "iopub.status.idle": "2023-11-04T06:16:03.270822Z",
     "shell.execute_reply": "2023-11-04T06:16:03.269817Z",
     "shell.execute_reply.started": "2023-11-04T06:14:36.329646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0210, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0081, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0066, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcontinue_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\tool.py:29\u001b[0m, in \u001b[0;36mcontinue_train\u001b[1;34m(net, optimizer, loss, num_epochs, train_iter, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[0;32m     31\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\model\\vgg16_bn.py:71\u001b[0m, in \u001b[0;36mVGG16_BN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 71\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# x = self.avgpool(x)\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94ae2e10-7ed7-477e-83ee-160b064c35a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:16:11.720212Z",
     "iopub.status.busy": "2023-11-04T06:16:11.719212Z",
     "iopub.status.idle": "2023-11-04T06:16:32.790534Z",
     "shell.execute_reply": "2023-11-04T06:16:32.789532Z",
     "shell.execute_reply.started": "2023-11-04T06:16:11.720212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.6971487713675214\n",
      "0.1 0.7008547008547008\n",
      "0.15 0.7024238782051282\n",
      "0.2 0.7034254807692307\n",
      "0.25 0.7040264423076923\n",
      "0.3 0.7040598290598291\n",
      "0.35 0.7047943376068376\n",
      "0.4 0.7053619123931624\n",
      "0.45 0.7056957799145299\n",
      "0.5 0.7058293269230769\n",
      "0.55 0.7061965811965812\n",
      "0.6 0.706764155982906\n",
      "0.65 0.7068309294871795\n",
      "0.7 0.7074986645299145\n",
      "0.75 0.7075988247863247\n",
      "0.8 0.7078993055555556\n",
      "0.85 0.7080996260683761\n",
      "0.9 0.7086004273504274\n",
      "0.95 0.7088007478632479\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93bd27d6-c613-47d0-9e48-be8e72a0a02f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:19:15.586140Z",
     "iopub.status.busy": "2023-11-04T06:19:15.586140Z",
     "iopub.status.idle": "2023-11-04T06:19:16.120731Z",
     "shell.execute_reply": "2023-11-04T06:19:16.120119Z",
     "shell.execute_reply.started": "2023-11-04T06:19:15.586140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = VGG16_BN()\n",
    "net.load_state_dict(torch.load('vgg_16.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c2d412d-5f27-4396-b2e2-d3a43da6a66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:21:01.169171Z",
     "iopub.status.busy": "2023-11-04T06:21:01.169171Z",
     "iopub.status.idle": "2023-11-04T06:25:54.543416Z",
     "shell.execute_reply": "2023-11-04T06:25:54.542543Z",
     "shell.execute_reply.started": "2023-11-04T06:21:01.169171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0134, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0099, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0120, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0279, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0076, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0113, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0705, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.6996527777777778\n",
      "0.1 0.703125\n",
      "0.15 0.7041266025641025\n",
      "0.2 0.7048944978632479\n",
      "0.25 0.7050948183760684\n",
      "0.3 0.7059294871794872\n",
      "0.35 0.7063969017094017\n",
      "0.4 0.7068309294871795\n",
      "0.45 0.7074986645299145\n",
      "0.5 0.7075320512820513\n",
      "0.55 0.7075988247863247\n",
      "0.6 0.7077991452991453\n",
      "0.65 0.7085670405982906\n",
      "0.7 0.7085336538461539\n",
      "0.75 0.7089009081196581\n",
      "0.8 0.7094350961538461\n",
      "0.85 0.7096688034188035\n",
      "0.9 0.7097355769230769\n",
      "0.95 0.7096020299145299\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "loss = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.003)\n",
    "net.cuda()\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ba18ae-4b66-4357-aec2-ca96de3e0ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:26:28.168084Z",
     "iopub.status.busy": "2023-11-04T06:26:28.168084Z",
     "iopub.status.idle": "2023-11-04T06:30:58.110208Z",
     "shell.execute_reply": "2023-11-04T06:30:58.110208Z",
     "shell.execute_reply.started": "2023-11-04T06:26:28.168084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0027, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0072, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0050, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0053, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0069, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0108, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0097, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.0005)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89df4777-6c0a-46ee-af27-fa8cd488715b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:32:32.654626Z",
     "iopub.status.busy": "2023-11-04T06:32:32.654626Z",
     "iopub.status.idle": "2023-11-04T06:35:54.275801Z",
     "shell.execute_reply": "2023-11-04T06:35:54.275801Z",
     "shell.execute_reply.started": "2023-11-04T06:32:32.654626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.9541326192579506\n",
      "0.1 0.9530180267226148\n",
      "0.15 0.9522726645318021\n",
      "0.2 0.9515790636042403\n",
      "0.25 0.9508406029151943\n",
      "0.3 0.9503229902826855\n",
      "0.35 0.949843335909894\n",
      "0.4 0.9493050187720848\n",
      "0.45 0.9488219136484098\n",
      "0.5 0.9481490172261484\n",
      "0.55 0.9474933745583038\n",
      "0.6 0.9468480841431095\n",
      "0.65 0.9460371576855123\n",
      "0.7 0.9451020041961131\n",
      "0.75 0.9440529759275619\n",
      "0.8 0.9426657740724381\n",
      "0.85 0.9410818794169611\n",
      "0.9 0.9385800850265018\n",
      "0.95 0.9334419169611308\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11249e9a-8b17-4ad4-8185-592f6b51a30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:32:17.326734Z",
     "iopub.status.busy": "2023-11-04T06:32:17.326734Z",
     "iopub.status.idle": "2023-11-04T06:32:18.337892Z",
     "shell.execute_reply": "2023-11-04T06:32:18.337892Z",
     "shell.execute_reply.started": "2023-11-04T06:32:17.326734Z"
    }
   },
   "outputs": [],
   "source": [
    "testset = csf(csv_path='original_valid_set.pkl', mode='valid')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a822a5-0f8f-4e36-8e58-fa32c47a1e77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T06:37:21.098997Z",
     "iopub.status.busy": "2023-11-04T06:37:21.098997Z",
     "iopub.status.idle": "2023-11-04T06:37:31.720598Z",
     "shell.execute_reply": "2023-11-04T06:37:31.719785Z",
     "shell.execute_reply.started": "2023-11-04T06:37:21.098997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7635027882067138"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalute_results(net, testloader, 0.9999, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e4c72-dff7-41af-85a7-3dfbe322cd10",
   "metadata": {},
   "source": [
    "### vgg19搜参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c94b59-011a-48d6-97de-81bdb5f2d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list=[0.05,0.07,0.09,0.1,0.3,0.5,0.7,0.9]\n",
    "threshold_value_list = [0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95]\n",
    "for i in lr_list:\n",
    "    net = VGG19_BN()\n",
    "    device = d2l.try_gpu()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=i)\n",
    "    loss = nn.BCELoss()\n",
    "    print('$'*20, f'learning rate: {i}')\n",
    "    train_from_scratch(net, optimizer, loss, 3, trainloader, device)\n",
    "    print('=='*10+'>',  ' begining of evaluation')\n",
    "    for j in threshold_value_list:\n",
    "        print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "    print('***'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc2f16b-5b22-43bf-ae28-75e5a8c5a945",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T08:20:13.858797Z",
     "iopub.status.busy": "2023-11-04T08:20:13.857796Z",
     "iopub.status.idle": "2023-11-04T08:30:08.031712Z",
     "shell.execute_reply": "2023-11-04T08:30:08.031712Z",
     "shell.execute_reply.started": "2023-11-04T08:20:13.858797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$$$$$$$$$$$$$$$$ learning rate: 0.09\n",
      "tensor(0.6918, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6502, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6649, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6368, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6181, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6151, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6179, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5874, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6037, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6155, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5932, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5608, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5540, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5762, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5528, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5430, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4986, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5505, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4635, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4541, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4370, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4757, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4038, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3781, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3888, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3392, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3546, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3602, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3019, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3196, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2506, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3091, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2549, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3365, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2091, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2160, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2647, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2337, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2166, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1472, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1409, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1460, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1816, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2309, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2295, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1263, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1881, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1880, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1458, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1631, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1095, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1414, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1499, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0677, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "====================>  begining of evaluation\n",
      "0.05 0.6263020833333334\n",
      "0.1 0.640357905982906\n",
      "0.15 0.6468015491452992\n",
      "0.2 0.6512419871794872\n",
      "0.25 0.6539129273504274\n",
      "0.3 0.65625\n",
      "0.35 0.6587873931623932\n",
      "0.4 0.6594551282051282\n",
      "0.45 0.6608907585470085\n",
      "0.5 0.6617588141025641\n",
      "0.55 0.6630608974358975\n",
      "0.6 0.6642294337606838\n",
      "0.65 0.6648303952991453\n",
      "0.7 0.664596688034188\n",
      "0.75 0.6645633012820513\n",
      "0.8 0.6649639423076923\n",
      "0.85 0.6643629807692307\n",
      "0.9 0.6617588141025641\n",
      "0.95 0.6564837072649573\n",
      "******************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "threshold_value_list = [0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95]\n",
    "net = VGG19_BN()\n",
    "device = d2l.try_gpu()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.09)\n",
    "loss = nn.BCELoss()\n",
    "print('$'*20, f'learning rate: 0.09')\n",
    "train_from_scratch(net, optimizer, loss, 3, trainloader, device)\n",
    "print('=='*10+'>',  ' begining of evaluation')\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('***'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6c4a0b-48bc-4059-80e8-11ab4fda9696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T09:03:53.830134Z",
     "iopub.status.busy": "2023-11-04T09:03:53.830134Z",
     "iopub.status.idle": "2023-11-04T09:06:47.341238Z",
     "shell.execute_reply": "2023-11-04T09:06:47.341238Z",
     "shell.execute_reply.started": "2023-11-04T09:03:53.830134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0427, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0362, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0338, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0293, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0130, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0114, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce1a680-c76d-49de-9be4-16876ffa2558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T09:07:20.696812Z",
     "iopub.status.busy": "2023-11-04T09:07:20.695811Z",
     "iopub.status.idle": "2023-11-04T09:07:33.214799Z",
     "shell.execute_reply": "2023-11-04T09:07:33.214799Z",
     "shell.execute_reply.started": "2023-11-04T09:07:20.696812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.6447649572649573\n",
      "0.1 0.6520432692307693\n",
      "0.15 0.6558493589743589\n",
      "0.2 0.6581530448717948\n",
      "0.25 0.6600560897435898\n",
      "0.3 0.6612246260683761\n",
      "0.35 0.6618589743589743\n",
      "0.4 0.6631944444444444\n",
      "0.45 0.6642962072649573\n",
      "0.5 0.6652978098290598\n",
      "0.55 0.6661992521367521\n",
      "0.6 0.6678685897435898\n",
      "0.65 0.6691038995726496\n",
      "0.7 0.6700721153846154\n",
      "0.75 0.6712406517094017\n",
      "0.8 0.6722422542735043\n",
      "0.85 0.6737446581196581\n",
      "0.9 0.6745125534188035\n",
      "0.95 0.6737446581196581\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd93a5a-8803-4e85-9775-aa1eae7c4e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T09:07:40.845007Z",
     "iopub.status.busy": "2023-11-04T09:07:40.845007Z",
     "iopub.status.idle": "2023-11-04T09:10:55.839323Z",
     "shell.execute_reply": "2023-11-04T09:10:55.839323Z",
     "shell.execute_reply.started": "2023-11-04T09:07:40.845007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0126, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0245, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0316, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0078, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0079, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0107, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0060, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0083, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4cd421-3af3-4ba3-b29e-5087f6e078a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T09:23:58.635558Z",
     "iopub.status.busy": "2023-11-04T09:23:58.635558Z",
     "iopub.status.idle": "2023-11-04T09:24:11.175548Z",
     "shell.execute_reply": "2023-11-04T09:24:11.175548Z",
     "shell.execute_reply.started": "2023-11-04T09:23:58.635558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.6427617521367521\n",
      "0.1 0.6486378205128205\n",
      "0.15 0.6517427884615384\n",
      "0.2 0.6536124465811965\n",
      "0.25 0.6557491987179487\n",
      "0.3 0.656784188034188\n",
      "0.35 0.6583199786324786\n",
      "0.4 0.6587873931623932\n",
      "0.45 0.6599893162393162\n",
      "0.5 0.6610243055555556\n",
      "0.55 0.6614583333333334\n",
      "0.6 0.6624265491452992\n",
      "0.65 0.6640958867521367\n",
      "0.7 0.6648303952991453\n",
      "0.75 0.6657652243589743\n",
      "0.8 0.6670005341880342\n",
      "0.85 0.6693376068376068\n",
      "0.9 0.6702390491452992\n",
      "0.95 0.6722422542735043\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213dbe9b-9d7b-4fee-a3be-49d85fbc20b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T13:25:37.066847Z",
     "iopub.status.busy": "2023-11-04T13:25:37.066847Z",
     "iopub.status.idle": "2023-11-04T13:42:34.718490Z",
     "shell.execute_reply": "2023-11-04T13:42:34.717520Z",
     "shell.execute_reply.started": "2023-11-04T13:25:37.066847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6074, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6032, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6574, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6049, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5898, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5998, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5858, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6183, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5849, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5656, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5522, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5965, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6001, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5619, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5539, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5419, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5276, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5329, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5378, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5073, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5793, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5188, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4737, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4721, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4373, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4519, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4150, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4174, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4184, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4707, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3191, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3545, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3155, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3344, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3194, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2472, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2435, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2190, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1876, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1546, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2229, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1774, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1503, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1903, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1624, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1434, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0944, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1966, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1132, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0987, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1267, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1421, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "****************************************************************************************************\n",
      "0.05 0.6608573717948718\n",
      "0.1 0.672142094017094\n",
      "0.15 0.6783520299145299\n",
      "0.2 0.6810229700854701\n",
      "0.25 0.6832598824786325\n",
      "0.3 0.684395032051282\n",
      "0.35 0.6854300213675214\n",
      "0.4 0.6859308226495726\n",
      "0.45 0.6857638888888888\n",
      "0.5 0.6866319444444444\n",
      "0.55 0.6878004807692307\n",
      "0.6 0.6884682158119658\n",
      "0.65 0.6889022435897436\n",
      "0.7 0.687767094017094\n",
      "0.75 0.6871327457264957\n",
      "0.8 0.6856637286324786\n",
      "0.85 0.6836939102564102\n",
      "0.9 0.6811899038461539\n",
      "0.95 0.6730769230769231\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "net = VGG19_BN()\n",
    "device = d2l.try_gpu()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "loss = nn.BCELoss()\n",
    "train_from_scratch(net, optimizer, loss, 3, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5752c9c-c77b-42d0-9398-219a1d21b832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T13:48:25.185109Z",
     "iopub.status.busy": "2023-11-04T13:48:25.184041Z",
     "iopub.status.idle": "2023-11-04T13:50:06.546310Z",
     "shell.execute_reply": "2023-11-04T13:50:06.546310Z",
     "shell.execute_reply.started": "2023-11-04T13:48:25.185109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0228, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0056, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0102, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0282, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0104, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcontinue_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\jianji\\tool.py:29\u001b[0m, in \u001b[0;36mcontinue_train\u001b[1;34m(net, optimizer, loss, num_epochs, train_iter, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y)\n\u001b[0;32m     31\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\workspace\\essay\\mbessay\\lib\\model\\vgg19_bn.py:83\u001b[0m, in \u001b[0;36mVGG19_BN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# x = self.avgpool(x)\u001b[39;00m\n\u001b[0;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 83\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.0005)\n",
    "continue_train(net, optimizer, loss, 1, trainloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fb354c-1b42-4aa9-9b2f-926e19a10744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T13:47:46.899701Z",
     "iopub.status.busy": "2023-11-04T13:47:46.899701Z",
     "iopub.status.idle": "2023-11-04T13:48:09.948596Z",
     "shell.execute_reply": "2023-11-04T13:48:09.948596Z",
     "shell.execute_reply.started": "2023-11-04T13:47:46.899701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.6743790064102564\n",
      "0.1 0.6803552350427351\n",
      "0.15 0.6829260149572649\n",
      "0.2 0.6852964743589743\n",
      "0.25 0.6870659722222222\n",
      "0.3 0.6880675747863247\n",
      "0.35 0.6893362713675214\n",
      "0.4 0.6903712606837606\n",
      "0.45 0.691139155982906\n",
      "0.5 0.6920739850427351\n",
      "0.55 0.6931423611111112\n",
      "0.6 0.6939436431623932\n",
      "0.65 0.6949118589743589\n",
      "0.7 0.695846688034188\n",
      "0.75 0.6965144230769231\n",
      "0.8 0.6972155448717948\n",
      "0.85 0.6975160256410257\n",
      "0.9 0.6980836004273504\n",
      "0.95 0.6998530982905983\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272f67d7-d4ac-47b6-a2a2-74dde6e27a5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T13:50:14.324400Z",
     "iopub.status.busy": "2023-11-04T13:50:14.324400Z",
     "iopub.status.idle": "2023-11-04T13:50:37.311034Z",
     "shell.execute_reply": "2023-11-04T13:50:37.311034Z",
     "shell.execute_reply.started": "2023-11-04T13:50:14.324400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.6711071047008547\n",
      "0.1 0.6767494658119658\n",
      "0.15 0.6803886217948718\n",
      "0.2 0.6822582799145299\n",
      "0.25 0.6842948717948718\n",
      "0.3 0.6857305021367521\n",
      "0.35 0.6866653311965812\n",
      "0.4 0.6879340277777778\n",
      "0.45 0.6890024038461539\n",
      "0.5 0.6901709401709402\n",
      "0.55 0.6910389957264957\n",
      "0.6 0.6924412393162394\n",
      "0.65 0.6934428418803419\n",
      "0.7 0.6940771901709402\n",
      "0.75 0.6951455662393162\n",
      "0.8 0.6958133012820513\n",
      "0.85 0.6960803952991453\n",
      "0.9 0.6971153846153846\n",
      "0.95 0.6975827991452992\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ce9f52-7300-449f-b17d-4940bee4c427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T13:51:25.517704Z",
     "iopub.status.busy": "2023-11-04T13:51:25.517704Z",
     "iopub.status.idle": "2023-11-04T13:51:25.585921Z",
     "shell.execute_reply": "2023-11-04T13:51:25.585921Z",
     "shell.execute_reply.started": "2023-11-04T13:51:25.517704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [256, 64, 1, 150]             256\n",
      "       BatchNorm2d-2          [256, 64, 1, 150]             128\n",
      "              ReLU-3          [256, 64, 1, 150]               0\n",
      "            Conv2d-4          [256, 64, 1, 148]          12,352\n",
      "       BatchNorm2d-5          [256, 64, 1, 148]             128\n",
      "              ReLU-6          [256, 64, 1, 148]               0\n",
      "         MaxPool2d-7           [256, 64, 1, 74]               0\n",
      "            Conv2d-8          [256, 128, 1, 72]          24,704\n",
      "       BatchNorm2d-9          [256, 128, 1, 72]             256\n",
      "             ReLU-10          [256, 128, 1, 72]               0\n",
      "           Conv2d-11          [256, 128, 1, 70]          49,280\n",
      "      BatchNorm2d-12          [256, 128, 1, 70]             256\n",
      "             ReLU-13          [256, 128, 1, 70]               0\n",
      "           Conv2d-14          [256, 256, 1, 68]          98,560\n",
      "      BatchNorm2d-15          [256, 256, 1, 68]             512\n",
      "             ReLU-16          [256, 256, 1, 68]               0\n",
      "           Conv2d-17          [256, 256, 1, 66]         196,864\n",
      "      BatchNorm2d-18          [256, 256, 1, 66]             512\n",
      "             ReLU-19          [256, 256, 1, 66]               0\n",
      "           Conv2d-20          [256, 256, 1, 64]         196,864\n",
      "      BatchNorm2d-21          [256, 256, 1, 64]             512\n",
      "             ReLU-22          [256, 256, 1, 64]               0\n",
      "           Conv2d-23          [256, 256, 1, 62]         196,864\n",
      "      BatchNorm2d-24          [256, 256, 1, 62]             512\n",
      "             ReLU-25          [256, 256, 1, 62]               0\n",
      "           Conv2d-26          [256, 512, 1, 60]         393,728\n",
      "      BatchNorm2d-27          [256, 512, 1, 60]           1,024\n",
      "             ReLU-28          [256, 512, 1, 60]               0\n",
      "           Conv2d-29          [256, 512, 1, 58]         786,944\n",
      "      BatchNorm2d-30          [256, 512, 1, 58]           1,024\n",
      "             ReLU-31          [256, 512, 1, 58]               0\n",
      "           Conv2d-32          [256, 512, 1, 56]         786,944\n",
      "      BatchNorm2d-33          [256, 512, 1, 56]           1,024\n",
      "             ReLU-34          [256, 512, 1, 56]               0\n",
      "           Conv2d-35          [256, 512, 1, 54]         786,944\n",
      "      BatchNorm2d-36          [256, 512, 1, 54]           1,024\n",
      "             ReLU-37          [256, 512, 1, 54]               0\n",
      "        MaxPool2d-38          [256, 512, 1, 27]               0\n",
      "           Conv2d-39          [256, 512, 1, 25]         786,944\n",
      "      BatchNorm2d-40          [256, 512, 1, 25]           1,024\n",
      "             ReLU-41          [256, 512, 1, 25]               0\n",
      "           Conv2d-42          [256, 512, 1, 23]         786,944\n",
      "      BatchNorm2d-43          [256, 512, 1, 23]           1,024\n",
      "             ReLU-44          [256, 512, 1, 23]               0\n",
      "           Conv2d-45          [256, 512, 1, 21]         786,944\n",
      "      BatchNorm2d-46          [256, 512, 1, 21]           1,024\n",
      "             ReLU-47          [256, 512, 1, 21]               0\n",
      "           Conv2d-48          [256, 512, 1, 19]         786,944\n",
      "      BatchNorm2d-49          [256, 512, 1, 19]           1,024\n",
      "             ReLU-50          [256, 512, 1, 19]               0\n",
      "           Linear-51                [256, 4096]      39,849,984\n",
      "             ReLU-52                [256, 4096]               0\n",
      "      BatchNorm1d-53                [256, 4096]           8,192\n",
      "           Linear-54                [256, 1024]       4,195,328\n",
      "             ReLU-55                [256, 1024]               0\n",
      "      BatchNorm1d-56                [256, 1024]           2,048\n",
      "           Linear-57                 [256, 512]         524,800\n",
      "             ReLU-58                 [256, 512]               0\n",
      "      BatchNorm1d-59                 [256, 512]           1,024\n",
      "           Linear-60                  [256, 64]          32,832\n",
      "             ReLU-61                  [256, 64]               0\n",
      "      BatchNorm1d-62                  [256, 64]             128\n",
      "           Linear-63                   [256, 1]              65\n",
      "          Sigmoid-64                   [256, 1]               0\n",
      "================================================================\n",
      "Total params: 51,303,489\n",
      "Trainable params: 51,303,489\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 1625.88\n",
      "Params size (MB): 195.71\n",
      "Estimated Total Size (MB): 1821.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (1, 1, 152), 256, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8566e39c-bd6b-472a-9227-80d46ae3a9dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T13:52:19.833838Z",
     "iopub.status.busy": "2023-11-04T13:52:19.833838Z",
     "iopub.status.idle": "2023-11-04T13:52:20.083948Z",
     "shell.execute_reply": "2023-11-04T13:52:20.083829Z",
     "shell.execute_reply.started": "2023-11-04T13:52:19.833838Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'vgg_19_acc_0.699.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009714ff-269a-4ed0-a27e-743722b43ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T14:39:33.454212Z",
     "iopub.status.busy": "2023-11-04T14:39:33.454212Z",
     "iopub.status.idle": "2023-11-04T14:39:33.672380Z",
     "shell.execute_reply": "2023-11-04T14:39:33.671548Z",
     "shell.execute_reply.started": "2023-11-04T14:39:33.454212Z"
    }
   },
   "outputs": [],
   "source": [
    "net = VGG19_BN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7dc273-cd18-40e0-a17d-3f6cabafeaf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T14:39:37.548410Z",
     "iopub.status.busy": "2023-11-04T14:39:37.548410Z",
     "iopub.status.idle": "2023-11-04T14:39:37.579277Z",
     "shell.execute_reply": "2023-11-04T14:39:37.578278Z",
     "shell.execute_reply.started": "2023-11-04T14:39:37.548410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG19_BN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=(1, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(128, 256, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(256, 256, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): Conv2d(256, 256, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(256, 512, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU(inplace=True)\n",
       "    (31): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): MaxPool2d(kernel_size=(1, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (38): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (40): ReLU(inplace=True)\n",
       "    (41): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (43): ReLU(inplace=True)\n",
       "    (44): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (46): ReLU(inplace=True)\n",
       "    (47): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1))\n",
       "    (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (49): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=9728, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8ea47-6ba1-4a6a-abea-987088d3db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    prune.l1_unstructured(net.features[i], name='weight', amount=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "881d3168-8805-4846-a22f-dfb365a40121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T14:35:49.893808Z",
     "iopub.status.busy": "2023-11-04T14:35:49.893808Z",
     "iopub.status.idle": "2023-11-04T14:35:49.907289Z",
     "shell.execute_reply": "2023-11-04T14:35:49.906876Z",
     "shell.execute_reply.started": "2023-11-04T14:35:49.893808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0e21e-ca0b-410f-b75c-eae29709df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG16_BN()\n",
    "device = d2l.try_gpu()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "loss = nn.BCELoss()\n",
    "train_from_scratch(net, optimizer, loss, 3, trainloader, device)\n",
    "print('**'*50)\n",
    "for j in threshold_value_list:\n",
    "    print(j,evalute_results(net, testloader, j, d2l.try_gpu()))\n",
    "print('**'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
